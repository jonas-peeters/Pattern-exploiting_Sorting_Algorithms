	.section	__TEXT,__text,regular,pure_instructions
	.build_version macos, 11, 3	sdk_version 11, 3
	.globl	_partition_quick_block          ## -- Begin function partition_quick_block
	.p2align	4, 0x90
_partition_quick_block:                 ## @partition_quick_block
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$1128, %rsp                     ## imm = 0x468
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movq	%rdi, %r13
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	movq	%rax, -48(%rbp)
	movl	%edx, %eax
	subl	%esi, %eax
	movslq	%edx, %r11
	cmpl	$3, %eax
	jl	LBB0_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%r13,%r8,4), %edi
	movslq	%ecx, %r9
	movl	(%r13,%r9,4), %r10d
	movl	(%r13,%r11,4), %ecx
	cmpl	%r10d, %edi
	movl	%r10d, %ebx
	cmovll	%edi, %ebx
	movl	%r10d, %eax
	cmovgl	%edi, %eax
	cmpl	%ecx, %ebx
	cmovgel	%ecx, %ebx
	cmpl	%ecx, %eax
	cmovlel	%ecx, %eax
	addl	%edi, %r10d
	addl	%ecx, %r10d
	subl	%ebx, %r10d
	subl	%eax, %r10d
	movl	%ebx, (%r13,%r8,4)
	movl	%r10d, (%r13,%r11,4)
	movl	%eax, (%r13,%r9,4)
	jmp	LBB0_3
LBB0_2:
	movl	(%r13,%r11,4), %r10d
LBB0_3:
	movq	%r11, -1112(%rbp)               ## 8-byte Spill
	decl	%edx
	movq	%rdx, %r9
	movl	%edx, %ebx
	subl	%esi, %ebx
	cmpl	$256, %ebx                      ## imm = 0x100
	movq	%r13, -1080(%rbp)               ## 8-byte Spill
	movq	%rsi, %rdi
	jl	LBB0_4
## %bb.12:
	leaq	12(%r13), %rax
	movq	%rax, -1136(%rbp)               ## 8-byte Spill
	xorl	%ecx, %ecx
	xorl	%r11d, %r11d
	xorl	%r12d, %r12d
	xorl	%r8d, %r8d
	movq	%r9, %rsi
	jmp	LBB0_13
	.p2align	4, 0x90
LBB0_25:                                ##   in Loop: Header=BB0_13 Depth=1
	addl	%ebx, %r8d
	addl	%ebx, %r12d
	leal	128(%rdi), %eax
	subl	%ebx, %r11d
	cmovel	%eax, %edi
	leal	-128(%rsi), %eax
	subl	%ebx, %ecx
	cmovel	%eax, %esi
	movl	%esi, %ebx
	subl	%edi, %ebx
	cmpl	$255, %ebx
	jle	LBB0_26
LBB0_13:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_15 Depth 2
                                        ##     Child Loop BB0_19 Depth 2
                                        ##     Child Loop BB0_36 Depth 2
	testl	%r11d, %r11d
	je	LBB0_14
## %bb.17:                              ##   in Loop: Header=BB0_13 Depth=1
	testl	%ecx, %ecx
	jne	LBB0_20
	jmp	LBB0_18
	.p2align	4, 0x90
LBB0_14:                                ##   in Loop: Header=BB0_13 Depth=1
	movq	%rsi, %r14
	movslq	%edi, %rax
	movq	-1136(%rbp), %rdx               ## 8-byte Reload
	leaq	(%rdx,%rax,4), %rax
	xorl	%r8d, %r8d
	xorl	%ebx, %ebx
	xorl	%r11d, %r11d
	.p2align	4, 0x90
LBB0_15:                                ##   Parent Loop BB0_13 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	%r11d, %edx
	movl	%ebx, -560(%rbp,%rdx,4)
	xorl	%edx, %edx
	cmpl	-12(%rax,%rbx,4), %r10d
	setle	%dl
	addl	%r11d, %edx
	leal	1(%rbx), %esi
	movl	%esi, -560(%rbp,%rdx,4)
	xorl	%esi, %esi
	cmpl	-8(%rax,%rbx,4), %r10d
	setle	%sil
	addl	%edx, %esi
	leal	2(%rbx), %edx
	movl	%edx, -560(%rbp,%rsi,4)
	xorl	%edx, %edx
	cmpl	-4(%rax,%rbx,4), %r10d
	setle	%dl
	addl	%esi, %edx
	leal	3(%rbx), %esi
	movl	%esi, -560(%rbp,%rdx,4)
	xorl	%r11d, %r11d
	cmpl	(%rax,%rbx,4), %r10d
	setle	%r11b
	addl	%edx, %r11d
	addq	$4, %rbx
	cmpq	$128, %rbx
	jne	LBB0_15
## %bb.16:                              ##   in Loop: Header=BB0_13 Depth=1
	movq	%r14, %rsi
	testl	%ecx, %ecx
	jne	LBB0_20
LBB0_18:                                ##   in Loop: Header=BB0_13 Depth=1
	movslq	%esi, %rax
	leaq	(,%rax,4), %rax
	addq	%r13, %rax
	xorl	%r12d, %r12d
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_19:                                ##   Parent Loop BB0_13 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	%ecx, %edx
	movl	%ebx, -1072(%rbp,%rdx,4)
	xorl	%edx, %edx
	cmpl	(%rax), %r10d
	setge	%dl
	addl	%ecx, %edx
	movl	%ebx, %ecx
	orl	$1, %ecx
	movl	%ecx, -1072(%rbp,%rdx,4)
	xorl	%ecx, %ecx
	cmpl	-4(%rax), %r10d
	setge	%cl
	addl	%edx, %ecx
	movl	%ebx, %edx
	orl	$2, %edx
	movl	%edx, -1072(%rbp,%rcx,4)
	xorl	%edx, %edx
	cmpl	-8(%rax), %r10d
	setge	%dl
	addl	%ecx, %edx
	movl	%ebx, %ecx
	orl	$3, %ecx
	movl	%ecx, -1072(%rbp,%rdx,4)
	xorl	%ecx, %ecx
	cmpl	-12(%rax), %r10d
	setge	%cl
	addl	%edx, %ecx
	addq	$4, %rbx
	addq	$-16, %rax
	cmpq	$128, %rbx
	jne	LBB0_19
LBB0_20:                                ##   in Loop: Header=BB0_13 Depth=1
	cmpl	%ecx, %r11d
	movl	%ecx, %ebx
	cmovll	%r11d, %ebx
	testl	%ebx, %ebx
	jle	LBB0_25
## %bb.21:                              ##   in Loop: Header=BB0_13 Depth=1
	movq	%r8, -1128(%rbp)                ## 8-byte Spill
	movq	%rsi, %rax
	movslq	%r8d, %rsi
	movq	%r12, -1104(%rbp)               ## 8-byte Spill
	movslq	%r12d, %rdx
	movl	%ebx, %r8d
	movq	%rdi, -1160(%rbp)               ## 8-byte Spill
	movslq	%edi, %r15
	movq	%rax, -1120(%rbp)               ## 8-byte Spill
	movslq	%eax, %r14
	movl	%ebx, -1084(%rbp)               ## 4-byte Spill
	cmpl	$1, %ebx
	movq	%rdx, -1152(%rbp)               ## 8-byte Spill
	movq	%rsi, -1144(%rbp)               ## 8-byte Spill
	movq	%r8, -1096(%rbp)                ## 8-byte Spill
	jne	LBB0_35
## %bb.22:                              ##   in Loop: Header=BB0_13 Depth=1
	xorl	%r9d, %r9d
	jmp	LBB0_23
	.p2align	4, 0x90
LBB0_35:                                ##   in Loop: Header=BB0_13 Depth=1
                                        ## kill: def $r8d killed $r8d killed $r8 def $r8
	andl	$-2, %r8d
	leaq	-556(%rbp), %rax
	leaq	(%rax,%rsi,4), %rsi
	leaq	-1068(%rbp), %rax
	leaq	(%rax,%rdx,4), %r12
	xorl	%r9d, %r9d
	.p2align	4, 0x90
LBB0_36:                                ##   Parent Loop BB0_13 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movslq	-4(%rsi,%r9,4), %rdx
	addq	%r15, %rdx
	movslq	-4(%r12,%r9,4), %r13
	movq	%r14, %rax
	subq	%r13, %rax
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	movl	(%r13,%rdx,4), %ebx
	movl	(%r13,%rax,4), %edi
	movl	%edi, (%r13,%rdx,4)
	movl	%ebx, (%r13,%rax,4)
	movslq	(%rsi,%r9,4), %rax
	addq	%r15, %rax
	movslq	(%r12,%r9,4), %rdx
	movq	%r14, %rdi
	subq	%rdx, %rdi
	movl	(%r13,%rax,4), %edx
	movl	(%r13,%rdi,4), %ebx
	movl	%ebx, (%r13,%rax,4)
	movl	%edx, (%r13,%rdi,4)
	addq	$2, %r9
	cmpq	%r9, %r8
	jne	LBB0_36
LBB0_23:                                ##   in Loop: Header=BB0_13 Depth=1
	testb	$1, -1096(%rbp)                 ## 1-byte Folded Reload
	movq	-1120(%rbp), %rsi               ## 8-byte Reload
	movq	-1160(%rbp), %rdi               ## 8-byte Reload
	movq	-1128(%rbp), %r8                ## 8-byte Reload
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	-1084(%rbp), %ebx               ## 4-byte Reload
	je	LBB0_25
## %bb.24:                              ##   in Loop: Header=BB0_13 Depth=1
	movq	-1144(%rbp), %rax               ## 8-byte Reload
	addq	%r9, %rax
	movslq	-560(%rbp,%rax,4), %rdx
	addq	%r15, %rdx
	movq	-1152(%rbp), %rax               ## 8-byte Reload
	addq	%r9, %rax
	movq	%rsi, %r9
	movslq	-1072(%rbp,%rax,4), %rsi
	subq	%rsi, %r14
	movl	(%r13,%rdx,4), %r8d
	movl	(%r13,%r14,4), %esi
	movl	%esi, (%r13,%rdx,4)
	movq	%r9, %rsi
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	%r8d, (%r13,%r14,4)
	movq	-1128(%rbp), %r8                ## 8-byte Reload
	jmp	LBB0_25
LBB0_4:
	movq	%r9, %rsi
	jmp	LBB0_5
LBB0_26:
	movl	%ecx, %eax
	orl	%r11d, %eax
	je	LBB0_5
## %bb.27:
	leal	-127(%rbx), %r9d
	testl	%ecx, %ecx
	movq	%rsi, -1120(%rbp)               ## 8-byte Spill
	je	LBB0_43
## %bb.28:
	xorl	%r8d, %r8d
	cmpl	$128, %ebx
	jl	LBB0_34
## %bb.29:
	movslq	%edi, %r14
	movl	%r9d, %r13d
	leaq	-1(%r13), %rax
	movl	%r13d, %r15d
	andl	$3, %r15d
	xorl	%r8d, %r8d
	cmpq	$3, %rax
	jae	LBB0_40
## %bb.30:
	xorl	%ebx, %ebx
	jmp	LBB0_31
LBB0_5:
	leal	1(%rbx), %r14d
	movl	%r14d, %eax
	shrl	$31, %eax
	leal	(%rbx,%rax), %edx
	incl	%edx
	sarl	%edx
	subl	%edx, %r14d
	xorl	%r8d, %r8d
	movl	$0, %r11d
	movl	$0, %ecx
	testl	%ebx, %ebx
	movq	%rsi, -1120(%rbp)               ## 8-byte Spill
	jle	LBB0_10
## %bb.6:
	movq	%rsi, %r9
	movq	%rdi, %rsi
	movslq	%edi, %r15
	movslq	%r9d, %rcx
	testl	%edx, %edx
	movl	$1, %r8d
	movl	%edx, -1084(%rbp)               ## 4-byte Spill
	cmovgl	%edx, %r8d
	cmpl	$3, %ebx
	movq	%rcx, -1104(%rbp)               ## 8-byte Spill
	jge	LBB0_37
## %bb.7:
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	xorl	%r11d, %r11d
	jmp	LBB0_8
LBB0_37:
	movq	%r13, %rax
	movl	%r8d, %r13d
	andl	$2147483646, %r13d              ## imm = 0x7FFFFFFE
	movq	%r15, %rdi
	leaq	(%rax,%r15,4), %r15
	addq	$4, %r15
	leaq	(%rax,%rcx,4), %r12
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	xorl	%r11d, %r11d
	.p2align	4, 0x90
LBB0_38:                                ## =>This Inner Loop Header: Depth=1
	movl	%r11d, %eax
	movl	%ebx, -560(%rbp,%rax,4)
	xorl	%eax, %eax
	cmpl	-4(%r15,%rbx,4), %r10d
	setle	%al
	addl	%r11d, %eax
	movl	%ecx, %edx
	movl	%ebx, -1072(%rbp,%rdx,4)
	xorl	%edx, %edx
	cmpl	(%r12), %r10d
	setge	%dl
	addl	%ecx, %edx
	leal	1(%rbx), %ecx
	movl	%ecx, -560(%rbp,%rax,4)
	xorl	%r11d, %r11d
	cmpl	(%r15,%rbx,4), %r10d
	setle	%r11b
	addl	%eax, %r11d
	movl	%ecx, -1072(%rbp,%rdx,4)
	xorl	%ecx, %ecx
	cmpl	-4(%r12), %r10d
	setge	%cl
	addl	%edx, %ecx
	addq	$2, %rbx
	addq	$-8, %r12
	cmpq	%rbx, %r13
	jne	LBB0_38
## %bb.39:
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	movq	-1120(%rbp), %r9                ## 8-byte Reload
	movq	%rdi, %r15
LBB0_8:
	testb	$1, %r8b
	movl	$0, %r8d
	movq	%rsi, %rdi
	movq	%r9, %rsi
	movl	-1084(%rbp), %edx               ## 4-byte Reload
	je	LBB0_10
## %bb.9:
	movl	%r11d, %eax
	movl	%ebx, -560(%rbp,%rax,4)
	addq	%rbx, %r15
	movl	%ecx, %eax
	movq	-1104(%rbp), %rsi               ## 8-byte Reload
	subq	%rbx, %rsi
	xorl	%r12d, %r12d
	cmpl	(%r13,%r15,4), %r10d
	movl	%ebx, -1072(%rbp,%rax,4)
	setle	%r12b
	xorl	%eax, %eax
	cmpl	(%r13,%rsi,4), %r10d
	movq	%r9, %rsi
	setge	%al
	addl	%ecx, %eax
	addl	%r11d, %r12d
	movl	%r12d, %r11d
	movl	%eax, %ecx
LBB0_10:
	cmpl	%r14d, %edx
	movl	%edx, %ebx
	movq	%r14, -1096(%rbp)               ## 8-byte Spill
	jge	LBB0_55
## %bb.11:
	leal	-1(%r14), %eax
	movl	%ecx, %edx
	movl	%eax, -1072(%rbp,%rdx,4)
	movl	%esi, %eax
	subl	%r14d, %eax
	incl	%eax
	cltq
	xorl	%edx, %edx
	cmpl	(%r13,%rax,4), %r10d
	setge	%dl
	addl	%ecx, %edx
	xorl	%r12d, %r12d
	movl	%edx, %ecx
	jmp	LBB0_56
LBB0_43:
	xorl	%r12d, %r12d
	cmpl	$128, %ebx
	jl	LBB0_44
## %bb.45:
	movq	%rdi, %rdx
	movq	%r8, %rdi
	movslq	%esi, %r13
	movl	%r9d, %r8d
	leaq	-1(%r8), %rax
	movl	%r8d, %r14d
	andl	$3, %r14d
	xorl	%r12d, %r12d
	cmpq	$3, %rax
	jae	LBB0_47
## %bb.46:
	movl	%r9d, %ebx
	xorl	%r15d, %r15d
	xorl	%ecx, %ecx
	testq	%r14, %r14
	movq	%rdi, %r8
	movq	%rdx, %rdi
	je	LBB0_51
LBB0_52:
	leaq	(,%r15,4), %rax
	movq	-1080(%rbp), %rdx               ## 8-byte Reload
	subq	%rax, %rdx
	leaq	(%rdx,%r13,4), %rax
	negq	%r14
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB0_53:                                ## =>This Inner Loop Header: Depth=1
	movl	%ecx, %esi
	movl	%ecx, %ecx
	movl	%r15d, -1072(%rbp,%rcx,4)
	xorl	%ecx, %ecx
	cmpl	(%rax,%rdx,4), %r10d
	setge	%cl
	addl	%esi, %ecx
	decq	%rdx
	incl	%r15d
	cmpq	%rdx, %r14
	jne	LBB0_53
## %bb.54:
	movl	%ebx, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	$128, %ebx
	movq	-1080(%rbp), %r13               ## 8-byte Reload
LBB0_55:
	xorl	%r12d, %r12d
	jmp	LBB0_56
LBB0_44:
	xorl	%ecx, %ecx
	movl	%r9d, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	$128, %ebx
	jmp	LBB0_56
LBB0_40:
	andl	$-4, %r13d
	movq	-1080(%rbp), %rax               ## 8-byte Reload
	leaq	(%rax,%r14,4), %r8
	addq	$12, %r8
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB0_41:                                ## =>This Inner Loop Header: Depth=1
	movslq	%r11d, %rax
	movl	%ebx, -560(%rbp,%rax,4)
	xorl	%edx, %edx
	cmpl	-12(%r8,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %eax
	cltq
	leal	1(%rbx), %edx
	movl	%edx, -560(%rbp,%rax,4)
	xorl	%edx, %edx
	cmpl	-8(%r8,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %eax
	cltq
	leal	2(%rbx), %edx
	movl	%edx, -560(%rbp,%rax,4)
	xorl	%edx, %edx
	cmpl	-4(%r8,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %eax
	movslq	%eax, %r11
	leal	3(%rbx), %eax
	movl	%eax, -560(%rbp,%r11,4)
	xorl	%eax, %eax
	cmpl	(%r8,%rbx,4), %r10d
	setle	%al
	addl	%eax, %r11d
	addq	$4, %rbx
	cmpq	%rbx, %r13
	jne	LBB0_41
## %bb.42:
	xorl	%r8d, %r8d
LBB0_31:
	testq	%r15, %r15
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	je	LBB0_34
## %bb.32:
	leaq	(,%r14,4), %rax
	addq	%r13, %rax
	.p2align	4, 0x90
LBB0_33:                                ## =>This Inner Loop Header: Depth=1
	movslq	%r11d, %r11
	movl	%ebx, -560(%rbp,%r11,4)
	xorl	%edx, %edx
	cmpl	(%rax,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %r11d
	incq	%rbx
	decq	%r15
	jne	LBB0_33
LBB0_34:
	movl	$128, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	%r9d, %ebx
LBB0_56:
	cmpl	%ecx, %r11d
	movl	%ecx, %r10d
	cmovll	%r11d, %r10d
	testl	%r10d, %r10d
	jle	LBB0_61
## %bb.57:
	movl	%ebx, -1084(%rbp)               ## 4-byte Spill
	movq	%r8, -1128(%rbp)                ## 8-byte Spill
	movslq	%r8d, %rdx
	movq	%r12, -1104(%rbp)               ## 8-byte Spill
	movslq	%r12d, %rax
	movl	%r10d, %r12d
	movq	%rdi, -1160(%rbp)               ## 8-byte Spill
	movslq	%edi, %r9
	movslq	-1120(%rbp), %r14               ## 4-byte Folded Reload
	movq	%r10, -1152(%rbp)               ## 8-byte Spill
	cmpl	$1, %r10d
	movq	%rax, -1136(%rbp)               ## 8-byte Spill
	movq	%rdx, -1168(%rbp)               ## 8-byte Spill
	movq	%r12, -1144(%rbp)               ## 8-byte Spill
	jne	LBB0_64
## %bb.58:
	xorl	%eax, %eax
	jmp	LBB0_59
LBB0_64:
                                        ## kill: def $r12d killed $r12d killed $r12 def $r12
	andl	$-2, %r12d
	leaq	-556(,%rdx,4), %r15
	addq	%rbp, %r15
	leaq	-1068(,%rax,4), %r10
	addq	%rbp, %r10
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB0_65:                                ## =>This Inner Loop Header: Depth=1
	movslq	-4(%r15,%rax,4), %rdx
	addq	%r9, %rdx
	movslq	-4(%r10,%rax,4), %rdi
	movq	%r14, %r13
	subq	%rdi, %r13
	movq	-1080(%rbp), %rsi               ## 8-byte Reload
	movl	(%rsi,%rdx,4), %edi
	movq	-1080(%rbp), %rsi               ## 8-byte Reload
	movl	(%rsi,%r13,4), %r8d
	movq	-1080(%rbp), %rsi               ## 8-byte Reload
	movl	%r8d, (%rsi,%rdx,4)
	movq	-1080(%rbp), %rdx               ## 8-byte Reload
	movl	%edi, (%rdx,%r13,4)
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	movslq	(%r15,%rax,4), %rdx
	addq	%r9, %rdx
	movslq	(%r10,%rax,4), %rdi
	movq	%r14, %rsi
	subq	%rdi, %rsi
	movl	(%r13,%rdx,4), %edi
	movl	(%r13,%rsi,4), %ebx
	movl	%ebx, (%r13,%rdx,4)
	movl	%edi, (%r13,%rsi,4)
	addq	$2, %rax
	cmpq	%rax, %r12
	jne	LBB0_65
LBB0_59:
	testb	$1, -1144(%rbp)                 ## 1-byte Folded Reload
	movq	-1160(%rbp), %rdi               ## 8-byte Reload
	movq	-1128(%rbp), %r8                ## 8-byte Reload
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	-1084(%rbp), %ebx               ## 4-byte Reload
	movq	-1152(%rbp), %r10               ## 8-byte Reload
	je	LBB0_61
## %bb.60:
	movq	-1168(%rbp), %rdx               ## 8-byte Reload
	addq	%rax, %rdx
	movslq	-560(%rbp,%rdx,4), %rdx
	addq	%r9, %rdx
	movq	-1136(%rbp), %rsi               ## 8-byte Reload
	addq	%rax, %rsi
	movslq	-1072(%rbp,%rsi,4), %rax
	subq	%rax, %r14
	movl	(%r13,%rdx,4), %eax
	movl	(%r13,%r14,4), %esi
	movl	%esi, (%r13,%rdx,4)
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	%eax, (%r13,%r14,4)
LBB0_61:
	leal	(%r10,%r12), %r9d
	addl	%edi, %ebx
	xorl	%eax, %eax
	cmpl	%ecx, %r11d
	movq	-1096(%rbp), %rdx               ## 8-byte Reload
	cmovll	%eax, %edx
	movq	-1120(%rbp), %r15               ## 8-byte Reload
	subl	%edx, %r15d
	cmpl	%ecx, %r11d
	cmovlel	%ebx, %edi
	jle	LBB0_79
## %bb.62:
	addl	%r8d, %r10d
	leal	(%r11,%r8), %eax
	subl	%edi, %r15d
	movslq	%r10d, %r14
	cmpl	%r10d, %eax
	jle	LBB0_63
## %bb.66:
	movslq	%eax, %rcx
	leal	-1(%r10), %eax
	leal	(%r11,%r8), %ebx
	decl	%ebx
	movq	-1112(%rbp), %rdx               ## 8-byte Reload
	.p2align	4, 0x90
LBB0_67:                                ## =>This Inner Loop Header: Depth=1
	cmpl	-564(%rbp,%rcx,4), %r15d
	jne	LBB0_70
## %bb.68:                              ##   in Loop: Header=BB0_67 Depth=1
	decq	%rcx
	decl	%r15d
	decl	%ebx
	cmpq	%r14, %rcx
	jg	LBB0_67
## %bb.69:
	movl	%eax, %ebx
	jmp	LBB0_70
LBB0_79:
	jge	LBB0_95
## %bb.80:
	leal	(%rcx,%r12), %edx
	movl	%r15d, %eax
	subl	%edi, %eax
	movslq	%r9d, %r10
	cmpl	%r9d, %edx
	movq	-1112(%rbp), %r11               ## 8-byte Reload
	jle	LBB0_81
## %bb.82:
	movslq	%edx, %rsi
	leal	-1(%r9), %edx
	addl	%r12d, %ecx
	decl	%ecx
	.p2align	4, 0x90
LBB0_83:                                ## =>This Inner Loop Header: Depth=1
	cmpl	-1076(%rbp,%rsi,4), %eax
	jne	LBB0_86
## %bb.84:                              ##   in Loop: Header=BB0_83 Depth=1
	decq	%rsi
	decl	%eax
	decl	%ecx
	cmpq	%r10, %rsi
	jg	LBB0_83
## %bb.85:
	movl	%edx, %ecx
	jmp	LBB0_86
LBB0_63:
	leal	(%r11,%r8), %ebx
	decl	%ebx
	movq	-1112(%rbp), %rdx               ## 8-byte Reload
LBB0_70:
	movl	%ebx, %ecx
	subl	%r10d, %ecx
	jl	LBB0_78
## %bb.71:
	movslq	%r15d, %rax
	movq	%rdi, %r12
	movslq	%edi, %r9
	movslq	%ebx, %rbx
	incl	%ecx
	movq	%rbx, %r8
	subq	%r14, %r8
	andq	$3, %rcx
	je	LBB0_74
## %bb.72:
	leaq	(,%r9,4), %r10
	addq	%r13, %r10
	negq	%rcx
	movq	%rax, %rsi
	.p2align	4, 0x90
LBB0_73:                                ## =>This Inner Loop Header: Depth=1
	leaq	-1(%rsi), %rax
	movslq	-560(%rbp,%rbx,4), %rdi
	decq	%rbx
	addq	%r9, %rdi
	movl	(%r10,%rsi,4), %r11d
	movl	(%r13,%rdi,4), %edx
	movl	%edx, (%r10,%rsi,4)
	movl	%r11d, (%r13,%rdi,4)
	movq	%rax, %rsi
	incq	%rcx
	jne	LBB0_73
LBB0_74:
	movq	%rax, %r15
	cmpq	$3, %r8
	jb	LBB0_77
## %bb.75:
	incq	%rbx
	leaq	(,%r9,4), %rcx
	addq	%r13, %rcx
	.p2align	4, 0x90
LBB0_76:                                ## =>This Inner Loop Header: Depth=1
	movslq	-564(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, (%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	movslq	-568(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	-4(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, -4(%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	movslq	-572(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	-8(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, -8(%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	leaq	-4(%rax), %r15
	movslq	-576(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	-12(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, -12(%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	addq	$-4, %rbx
	movq	%r15, %rax
	cmpq	%r14, %rbx
	jg	LBB0_76
LBB0_77:
	movq	-1112(%rbp), %rdx               ## 8-byte Reload
	movq	%r12, %rdi
LBB0_78:
	leaq	(,%rdx,4), %rcx
	addq	%r13, %rcx
	addl	%r15d, %edi
	incl	%edi
	movl	%edi, %ebx
	jmp	LBB0_96
LBB0_95:
	movq	-1112(%rbp), %rax               ## 8-byte Reload
	leaq	(,%rax,4), %rcx
	addq	%r13, %rcx
	jmp	LBB0_96
LBB0_81:
	addl	%r12d, %ecx
	decl	%ecx
LBB0_86:
	movl	%ecx, %edx
	subl	%r9d, %edx
	jl	LBB0_94
## %bb.87:
	movq	%r9, %rsi
	movl	%eax, %r9d
	movslq	%ecx, %rbx
	incl	%edx
	movslq	%r15d, %r14
	testb	$1, %dl
	je	LBB0_89
## %bb.88:
	decq	%r9
	movl	%r15d, %edx
	subl	%eax, %edx
	decl	%eax
	movslq	%edx, %r11
	movslq	-1072(%rbp,%rbx,4), %r8
	decq	%rbx
	movq	%r14, %rdi
	subq	%r8, %rdi
	movl	(%r13,%r11,4), %r8d
	movl	(%r13,%rdi,4), %edx
	movl	%edx, (%r13,%r11,4)
	movq	-1112(%rbp), %r11               ## 8-byte Reload
	movl	%r8d, (%r13,%rdi,4)
LBB0_89:
	cmpl	%esi, %ecx
	je	LBB0_93
## %bb.90:
	incq	%rbx
	cltq
	movq	%r14, %rcx
	subq	%rax, %rcx
	leaq	4(,%rcx,4), %rcx
	addq	%r13, %rcx
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB0_91:                                ## =>This Inner Loop Header: Depth=1
	movslq	-1076(%rbp,%rbx,4), %rdx
	movq	%r14, %rdi
	subq	%rdx, %rdi
	movl	-4(%rcx,%rax,4), %edx
	movl	(%r13,%rdi,4), %esi
	movl	%esi, -4(%rcx,%rax,4)
	movl	%edx, (%r13,%rdi,4)
	movslq	-1080(%rbp,%rbx,4), %rdx
	movq	%r14, %rsi
	subq	%rdx, %rsi
	movl	(%rcx,%rax,4), %edx
	movl	(%r13,%rsi,4), %edi
	movl	%edi, (%rcx,%rax,4)
	movl	%edx, (%r13,%rsi,4)
	addq	$-2, %rbx
	addq	$2, %rax
	cmpq	%r10, %rbx
	jg	LBB0_91
## %bb.92:
	subq	%rax, %r9
LBB0_93:
	movl	%r9d, %eax
LBB0_94:
	leaq	(,%r11,4), %rcx
	addq	%r13, %rcx
	subl	%eax, %r15d
	movl	%r15d, %edi
	movl	%r15d, %ebx
LBB0_96:
	movslq	%edi, %rax
	movl	(%rcx), %edx
	movl	(%r13,%rax,4), %esi
	movl	%esi, (%rcx)
	movl	%edx, (%r13,%rax,4)
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB0_98
## %bb.97:
	movl	%ebx, %eax
	addq	$1128, %rsp                     ## imm = 0x468
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB0_47:
	andl	$-4, %r8d
	movq	-1080(%rbp), %rax               ## 8-byte Reload
	leaq	(%rax,%r13,4), %rbx
	xorl	%r15d, %r15d
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_48:                                ## =>This Inner Loop Header: Depth=1
	movl	%ecx, %eax
	movl	%r15d, -1072(%rbp,%rax,4)
	xorl	%eax, %eax
	cmpl	(%rbx), %r10d
	setge	%al
	addl	%ecx, %eax
	leal	1(%r15), %ecx
	movl	%ecx, -1072(%rbp,%rax,4)
	xorl	%ecx, %ecx
	cmpl	-4(%rbx), %r10d
	setge	%cl
	addl	%eax, %ecx
	leal	2(%r15), %eax
	movl	%eax, -1072(%rbp,%rcx,4)
	xorl	%eax, %eax
	cmpl	-8(%rbx), %r10d
	setge	%al
	addl	%ecx, %eax
	leal	3(%r15), %ecx
	movl	%ecx, -1072(%rbp,%rax,4)
	xorl	%ecx, %ecx
	cmpl	-12(%rbx), %r10d
	setge	%cl
	addl	%eax, %ecx
	addq	$4, %r15
	addq	$-16, %rbx
	cmpq	%r15, %r8
	jne	LBB0_48
## %bb.49:
	movl	%r9d, %ebx
	testq	%r14, %r14
	movq	%rdi, %r8
	movq	%rdx, %rdi
	jne	LBB0_52
LBB0_51:
	movl	%ebx, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	$128, %ebx
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	jmp	LBB0_56
LBB0_98:
	callq	___stack_chk_fail
	.cfi_endproc
                                        ## -- End function
	.globl	_median_of_three                ## -- Begin function median_of_three
	.p2align	4, 0x90
_median_of_three:                       ## @median_of_three
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%rdi,%r8,4), %r11d
	movslq	%ecx, %r9
	movl	(%rdi,%r9,4), %eax
	movslq	%edx, %r10
	movl	(%rdi,%r10,4), %ecx
	cmpl	%eax, %r11d
	movl	%eax, %edx
	cmovll	%r11d, %edx
	movl	%eax, %esi
	cmovgl	%r11d, %esi
	cmpl	%ecx, %edx
	cmovgel	%ecx, %edx
	cmpl	%ecx, %esi
	cmovlel	%ecx, %esi
	addl	%r11d, %eax
	addl	%ecx, %eax
	subl	%edx, %eax
	subl	%esi, %eax
	movl	%edx, (%rdi,%r8,4)
	movl	%eax, (%rdi,%r10,4)
	movl	%esi, (%rdi,%r9,4)
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_min                            ## -- Begin function min
	.p2align	4, 0x90
_min:                                   ## @min
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	%esi, %eax
	cmpl	%esi, %edi
	cmovll	%edi, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_swap                           ## -- Begin function swap
	.p2align	4, 0x90
_swap:                                  ## @swap
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	(%rdi), %eax
	movl	(%rsi), %ecx
	movl	%ecx, (%rdi)
	movl	%eax, (%rsi)
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_block               ## -- Begin function sort_quick_block
	.p2align	4, 0x90
_sort_quick_block:                      ## @sort_quick_block
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	%esi, %edx
	jle	LBB4_22
## %bb.1:
	movl	%edx, %r15d
	movl	%esi, %r12d
	movq	%rdi, %r14
	.p2align	4, 0x90
LBB4_2:                                 ## =>This Inner Loop Header: Depth=1
	movl	%r15d, %esi
	subl	%r12d, %esi
	cmpl	$21, %esi
	jl	LBB4_4
## %bb.3:                               ##   in Loop: Header=BB4_2 Depth=1
	movq	%r14, %rdi
	movl	%r12d, %esi
	movl	%r15d, %edx
	callq	_partition_quick_block
	movl	%eax, %ebx
	leal	-1(%rbx), %edx
	movq	%r14, %rdi
	movl	%r12d, %esi
	callq	_sort_quick_block
	incl	%ebx
	movl	%ebx, %r12d
	cmpl	%r15d, %ebx
	jl	LBB4_2
	jmp	LBB4_22
LBB4_4:
	testl	%esi, %esi
	jle	LBB4_22
## %bb.5:
	movslq	%r12d, %rax
	leaq	(%r14,%rax,4), %rax
	movabsq	$-4294967296, %rcx              ## imm = 0xFFFFFFFF00000000
	movl	%esi, %r8d
	movl	$1, %r15d
	cmpl	$1, %esi
	jne	LBB4_6
LBB4_16:
	testb	$1, %r8b
	je	LBB4_22
## %bb.17:
	movl	(%rax,%r15,4), %esi
	movq	%r15, %rdi
	shlq	$32, %rdi
	addq	%rcx, %rdi
	.p2align	4, 0x90
LBB4_18:                                ## =>This Inner Loop Header: Depth=1
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB4_21
## %bb.19:                              ##   in Loop: Header=BB4_18 Depth=1
	movl	%edx, (%rax,%r15,4)
	leaq	-1(%r15), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %r15
	movq	%rdx, %r15
	jg	LBB4_18
## %bb.20:
	xorl	%r15d, %r15d
LBB4_21:
	movslq	%r15d, %rcx
	movl	%esi, (%rax,%rcx,4)
LBB4_22:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB4_6:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movl	%r8d, %r10d
	andl	$-2, %r10d
	movl	$1, %r15d
	movabsq	$4294967296, %r11               ## imm = 0x100000000
	xorl	%r14d, %r14d
	jmp	LBB4_7
	.p2align	4, 0x90
LBB4_15:                                ##   in Loop: Header=BB4_7 Depth=1
	movslq	%ebx, %rdx
	movl	%esi, (%rax,%rdx,4)
	addq	$2, %r15
	addq	%r9, %r14
	addq	%r9, %r11
	addq	$-2, %r10
	je	LBB4_16
LBB4_7:                                 ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB4_8 Depth 2
                                        ##     Child Loop BB4_12 Depth 2
	movl	(%rax,%r15,4), %esi
	movq	%r14, %rdi
	movq	%r15, %rbx
	.p2align	4, 0x90
LBB4_8:                                 ##   Parent Loop BB4_7 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB4_11
## %bb.9:                               ##   in Loop: Header=BB4_8 Depth=2
	movl	%edx, (%rax,%rbx,4)
	leaq	-1(%rbx), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %rbx
	movq	%rdx, %rbx
	jg	LBB4_8
## %bb.10:                              ##   in Loop: Header=BB4_7 Depth=1
	xorl	%ebx, %ebx
LBB4_11:                                ##   in Loop: Header=BB4_7 Depth=1
	movslq	%ebx, %rdx
	movl	%esi, (%rax,%rdx,4)
	leaq	1(%r15), %rbx
	movl	4(%rax,%r15,4), %esi
	movq	%r11, %rdi
	.p2align	4, 0x90
LBB4_12:                                ##   Parent Loop BB4_7 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB4_15
## %bb.13:                              ##   in Loop: Header=BB4_12 Depth=2
	movl	%edx, (%rax,%rbx,4)
	leaq	-1(%rbx), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %rbx
	movq	%rdx, %rbx
	jg	LBB4_12
## %bb.14:                              ##   in Loop: Header=BB4_7 Depth=1
	xorl	%ebx, %ebx
	jmp	LBB4_15
	.cfi_endproc
                                        ## -- End function
	.globl	_insertionSort                  ## -- Begin function insertionSort
	.p2align	4, 0x90
_insertionSort:                         ## @insertionSort
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	$2, %esi
	jl	LBB5_18
## %bb.1:
	movabsq	$-4294967296, %rax              ## imm = 0xFFFFFFFF00000000
	movl	%esi, %r8d
	decq	%r8
	movl	$1, %r15d
	cmpl	$2, %esi
	jne	LBB5_2
LBB5_12:
	testb	$1, %r8b
	je	LBB5_18
## %bb.13:
	movl	(%rdi,%r15,4), %edx
	movq	%r15, %rsi
	shlq	$32, %rsi
	addq	%rax, %rsi
	.p2align	4, 0x90
LBB5_14:                                ## =>This Inner Loop Header: Depth=1
	movq	%rsi, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%edx, %ecx
	jle	LBB5_17
## %bb.15:                              ##   in Loop: Header=BB5_14 Depth=1
	movl	%ecx, (%rdi,%r15,4)
	leaq	-1(%r15), %rcx
	addq	%rax, %rsi
	cmpq	$1, %r15
	movq	%rcx, %r15
	jg	LBB5_14
## %bb.16:
	xorl	%r15d, %r15d
LBB5_17:
	movslq	%r15d, %rax
	movl	%edx, (%rdi,%rax,4)
LBB5_18:
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB5_2:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movq	%r8, %r10
	andq	$-2, %r10
	movl	$1, %r15d
	movabsq	$4294967296, %r11               ## imm = 0x100000000
	xorl	%r14d, %r14d
	jmp	LBB5_3
	.p2align	4, 0x90
LBB5_11:                                ##   in Loop: Header=BB5_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	addq	$2, %r15
	addq	%r9, %r14
	addq	%r9, %r11
	addq	$-2, %r10
	je	LBB5_12
LBB5_3:                                 ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB5_4 Depth 2
                                        ##     Child Loop BB5_8 Depth 2
	movl	(%rdi,%r15,4), %esi
	movq	%r14, %rdx
	movq	%r15, %rbx
	.p2align	4, 0x90
LBB5_4:                                 ##   Parent Loop BB5_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB5_7
## %bb.5:                               ##   in Loop: Header=BB5_4 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB5_4
## %bb.6:                               ##   in Loop: Header=BB5_3 Depth=1
	xorl	%ebx, %ebx
LBB5_7:                                 ##   in Loop: Header=BB5_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	leaq	1(%r15), %rbx
	movl	4(%rdi,%r15,4), %esi
	movq	%r11, %rdx
	.p2align	4, 0x90
LBB5_8:                                 ##   Parent Loop BB5_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB5_11
## %bb.9:                               ##   in Loop: Header=BB5_8 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB5_8
## %bb.10:                              ##   in Loop: Header=BB5_3 Depth=1
	xorl	%ebx, %ebx
	jmp	LBB5_11
	.cfi_endproc
                                        ## -- End function
	.globl	_random_data                    ## -- Begin function random_data
	.p2align	4, 0x90
_random_data:                           ## @random_data
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movl	%esi, %r14d
	movq	%rdi, %r15
	callq	_clock
	movl	%eax, %edi
	callq	_srand
	testl	%r14d, %r14d
	jle	LBB6_3
## %bb.1:
	movl	%r14d, %r14d
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB6_2:                                 ## =>This Inner Loop Header: Depth=1
	callq	_rand
	movl	%eax, (%r15,%rbx,4)
	incq	%rbx
	cmpq	%rbx, %r14
	jne	LBB6_2
LBB6_3:
	addq	$8, %rsp
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_insertionSortOptimized         ## -- Begin function insertionSortOptimized
	.p2align	4, 0x90
_insertionSortOptimized:                ## @insertionSortOptimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	$2, %esi
	jl	LBB7_18
## %bb.1:
	movabsq	$-4294967296, %rax              ## imm = 0xFFFFFFFF00000000
	movl	%esi, %r8d
	decq	%r8
	movl	$1, %r15d
	cmpl	$2, %esi
	jne	LBB7_2
LBB7_12:
	testb	$1, %r8b
	je	LBB7_18
## %bb.13:
	movl	(%rdi,%r15,4), %edx
	movq	%r15, %rsi
	shlq	$32, %rsi
	addq	%rax, %rsi
	.p2align	4, 0x90
LBB7_14:                                ## =>This Inner Loop Header: Depth=1
	movq	%rsi, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%edx, %ecx
	jle	LBB7_17
## %bb.15:                              ##   in Loop: Header=BB7_14 Depth=1
	movl	%ecx, (%rdi,%r15,4)
	leaq	-1(%r15), %rcx
	addq	%rax, %rsi
	cmpq	$1, %r15
	movq	%rcx, %r15
	jg	LBB7_14
## %bb.16:
	xorl	%r15d, %r15d
LBB7_17:
	movslq	%r15d, %rax
	movl	%edx, (%rdi,%rax,4)
LBB7_18:
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB7_2:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movq	%r8, %r10
	andq	$-2, %r10
	movl	$1, %r15d
	movabsq	$4294967296, %r11               ## imm = 0x100000000
	xorl	%r14d, %r14d
	jmp	LBB7_3
	.p2align	4, 0x90
LBB7_11:                                ##   in Loop: Header=BB7_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	addq	$2, %r15
	addq	%r9, %r14
	addq	%r9, %r11
	addq	$-2, %r10
	je	LBB7_12
LBB7_3:                                 ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB7_4 Depth 2
                                        ##     Child Loop BB7_8 Depth 2
	movl	(%rdi,%r15,4), %esi
	movq	%r14, %rdx
	movq	%r15, %rbx
	.p2align	4, 0x90
LBB7_4:                                 ##   Parent Loop BB7_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB7_7
## %bb.5:                               ##   in Loop: Header=BB7_4 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB7_4
## %bb.6:                               ##   in Loop: Header=BB7_3 Depth=1
	xorl	%ebx, %ebx
LBB7_7:                                 ##   in Loop: Header=BB7_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	leaq	1(%r15), %rbx
	movl	4(%rdi,%r15,4), %esi
	movq	%r11, %rdx
	.p2align	4, 0x90
LBB7_8:                                 ##   Parent Loop BB7_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB7_11
## %bb.9:                               ##   in Loop: Header=BB7_8 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB7_8
## %bb.10:                              ##   in Loop: Header=BB7_3 Depth=1
	xorl	%ebx, %ebx
	jmp	LBB7_11
	.cfi_endproc
                                        ## -- End function
	.globl	_sign                           ## -- Begin function sign
	.p2align	4, 0x90
_sign:                                  ## @sign
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	%edi, %ecx
	sarl	$31, %ecx
	xorl	%eax, %eax
	testl	%edi, %edi
	setne	%al
	orl	%ecx, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_merging_optimzed               ## -- Begin function merging_optimzed
	.p2align	4, 0x90
_merging_optimzed:                      ## @merging_optimzed
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $ecx killed $ecx def $rcx
                                        ## kill: def $edx killed $edx def $rdx
	movl	%esi, %r13d
	leal	1(%rdx), %r11d
	cmpl	%ecx, %edx
	jge	LBB9_1
## %bb.8:
	cmpl	%edx, %r13d
	jg	LBB9_1
## %bb.9:
	movslq	%r13d, %rax
	leaq	(%r8,%rax,4), %r14
	movl	%r13d, %r9d
	movl	%r13d, %ebx
	.p2align	4, 0x90
LBB9_10:                                ## =>This Inner Loop Header: Depth=1
	movslq	%r11d, %r11
	movl	(%rdi,%r11,4), %r10d
	movslq	%ebx, %rbx
	movl	(%rdi,%rbx,4), %esi
	xorl	%eax, %eax
	xorl	%r15d, %r15d
	cmpl	%r10d, %esi
	setle	%al
	setg	%r15b
	cmovgl	%r10d, %esi
	addl	%eax, %ebx
	addl	%r15d, %r11d
	movl	%esi, (%r14)
	incl	%r9d
	cmpl	%ecx, %r11d
	jg	LBB9_2
## %bb.11:                              ##   in Loop: Header=BB9_10 Depth=1
	addq	$4, %r14
	cmpl	%edx, %ebx
	jle	LBB9_10
	jmp	LBB9_2
LBB9_1:
	movl	%r13d, %r9d
	movl	%r13d, %ebx
LBB9_2:
	cmpl	%edx, %ebx
	jg	LBB9_25
## %bb.3:
	movslq	%ebx, %r10
	movslq	%r9d, %r9
	movl	%edx, %r14d
	subl	%ebx, %r14d
	cmpl	$31, %r14d
	jb	LBB9_19
## %bb.4:
	leaq	(%r8,%r9,4), %rax
	leaq	(%r10,%r14), %rsi
	leaq	(%rdi,%rsi,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rax
	jae	LBB9_6
## %bb.5:
	leaq	(%r9,%r14), %rax
	leaq	(%r8,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r10,4), %rsi
	cmpq	%rax, %rsi
	jb	LBB9_19
LBB9_6:
	movl	%r13d, %esi
	incq	%r14
	movq	%r14, -56(%rbp)                 ## 8-byte Spill
	andq	$-32, %r14
	movq	%r14, -48(%rbp)                 ## 8-byte Spill
	leaq	-32(%r14), %rax
	movq	%rax, %r12
	shrq	$5, %r12
	incq	%r12
	movl	%r12d, %r15d
	andl	$3, %r15d
	cmpq	$96, %rax
	jae	LBB9_12
## %bb.7:
	xorl	%ebx, %ebx
	jmp	LBB9_14
LBB9_12:
	leaq	(%r8,%r9,4), %r13
	addq	$480, %r13                      ## imm = 0x1E0
	leaq	(%rdi,%r10,4), %r14
	addq	$480, %r14                      ## imm = 0x1E0
	andq	$-4, %r12
	negq	%r12
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB9_13:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%r14,%rbx,4), %ymm0
	vmovups	-448(%r14,%rbx,4), %ymm1
	vmovups	-416(%r14,%rbx,4), %ymm2
	vmovups	-384(%r14,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%r13,%rbx,4)
	vmovups	%ymm1, -448(%r13,%rbx,4)
	vmovups	%ymm2, -416(%r13,%rbx,4)
	vmovups	%ymm3, -384(%r13,%rbx,4)
	vmovups	-352(%r14,%rbx,4), %ymm0
	vmovups	-320(%r14,%rbx,4), %ymm1
	vmovups	-288(%r14,%rbx,4), %ymm2
	vmovups	-256(%r14,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%r13,%rbx,4)
	vmovups	%ymm1, -320(%r13,%rbx,4)
	vmovups	%ymm2, -288(%r13,%rbx,4)
	vmovups	%ymm3, -256(%r13,%rbx,4)
	vmovups	-224(%r14,%rbx,4), %ymm0
	vmovups	-192(%r14,%rbx,4), %ymm1
	vmovups	-160(%r14,%rbx,4), %ymm2
	vmovups	-128(%r14,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%r13,%rbx,4)
	vmovups	%ymm1, -192(%r13,%rbx,4)
	vmovups	%ymm2, -160(%r13,%rbx,4)
	vmovups	%ymm3, -128(%r13,%rbx,4)
	vmovups	-96(%r14,%rbx,4), %ymm0
	vmovups	-64(%r14,%rbx,4), %ymm1
	vmovups	-32(%r14,%rbx,4), %ymm2
	vmovups	(%r14,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%r13,%rbx,4)
	vmovups	%ymm1, -64(%r13,%rbx,4)
	vmovups	%ymm2, -32(%r13,%rbx,4)
	vmovups	%ymm3, (%r13,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %r12
	jne	LBB9_13
LBB9_14:
	testq	%r15, %r15
	movl	%esi, %r13d
	je	LBB9_17
## %bb.15:
	leaq	(%rbx,%r10), %rax
	leaq	(%rdi,%rax,4), %rax
	addq	$96, %rax
	addq	%r9, %rbx
	leaq	(%r8,%rbx,4), %rbx
	addq	$96, %rbx
	shlq	$7, %r15
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB9_16:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rax,%rsi), %ymm0
	vmovups	-64(%rax,%rsi), %ymm1
	vmovups	-32(%rax,%rsi), %ymm2
	vmovups	(%rax,%rsi), %ymm3
	vmovups	%ymm0, -96(%rbx,%rsi)
	vmovups	%ymm1, -64(%rbx,%rsi)
	vmovups	%ymm2, -32(%rbx,%rsi)
	vmovups	%ymm3, (%rbx,%rsi)
	subq	$-128, %rsi
	cmpq	%rsi, %r15
	jne	LBB9_16
LBB9_17:
	movq	-48(%rbp), %rax                 ## 8-byte Reload
	addq	%rax, %r9
	cmpq	%rax, -56(%rbp)                 ## 8-byte Folded Reload
	je	LBB9_25
## %bb.18:
	addq	%rax, %r10
LBB9_19:
	movl	%edx, %eax
	subl	%r10d, %eax
	leal	1(%rax), %ebx
	andl	$7, %ebx
	je	LBB9_21
	.p2align	4, 0x90
LBB9_20:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r10,4), %esi
	incq	%r10
	movl	%esi, (%r8,%r9,4)
	incq	%r9
	decl	%ebx
	jne	LBB9_20
LBB9_21:
	cmpl	$7, %eax
	jb	LBB9_25
## %bb.22:
	leaq	(%r8,%r9,4), %r14
	addq	$28, %r14
	subl	%r10d, %edx
	incl	%edx
	leaq	(%rdi,%r10,4), %rax
	addq	$28, %rax
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB9_23:                                ## =>This Inner Loop Header: Depth=1
	movl	-28(%rax,%rbx,4), %esi
	movl	%esi, -28(%r14,%rbx,4)
	movl	-24(%rax,%rbx,4), %esi
	movl	%esi, -24(%r14,%rbx,4)
	movl	-20(%rax,%rbx,4), %esi
	movl	%esi, -20(%r14,%rbx,4)
	movl	-16(%rax,%rbx,4), %esi
	movl	%esi, -16(%r14,%rbx,4)
	movl	-12(%rax,%rbx,4), %esi
	movl	%esi, -12(%r14,%rbx,4)
	movl	-8(%rax,%rbx,4), %esi
	movl	%esi, -8(%r14,%rbx,4)
	movl	-4(%rax,%rbx,4), %esi
	movl	%esi, -4(%r14,%rbx,4)
	movl	(%rax,%rbx,4), %esi
	movl	%esi, (%r14,%rbx,4)
	addq	$8, %rbx
	cmpl	%ebx, %edx
	jne	LBB9_23
## %bb.24:
	addq	%rbx, %r9
LBB9_25:
	cmpl	%ecx, %r11d
	jg	LBB9_43
## %bb.26:
	movslq	%r9d, %r9
	movslq	%r11d, %r12
	movl	%ecx, %r10d
	subl	%r11d, %r10d
	cmpl	$31, %r10d
	jb	LBB9_38
## %bb.27:
	leaq	(%r8,%r9,4), %rax
	leaq	(%r12,%r10), %rdx
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	cmpq	%rdx, %rax
	jae	LBB9_29
## %bb.28:
	leaq	(%r9,%r10), %rax
	leaq	(%r8,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r12,4), %rdx
	cmpq	%rax, %rdx
	jb	LBB9_38
LBB9_29:
	incq	%r10
	movq	%r10, %r11
	andq	$-32, %r11
	leaq	-32(%r11), %rax
	movq	%rax, %r15
	shrq	$5, %r15
	incq	%r15
	movl	%r15d, %r14d
	andl	$3, %r14d
	cmpq	$96, %rax
	jae	LBB9_31
## %bb.30:
	xorl	%eax, %eax
	jmp	LBB9_33
LBB9_31:
	leaq	(%rdi,%r12,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r8,%r9,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	andq	$-4, %r15
	negq	%r15
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB9_32:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rax,4), %ymm0
	vmovups	-448(%rbx,%rax,4), %ymm1
	vmovups	-416(%rbx,%rax,4), %ymm2
	vmovups	-384(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rax,4)
	vmovups	%ymm1, -448(%rdx,%rax,4)
	vmovups	%ymm2, -416(%rdx,%rax,4)
	vmovups	%ymm3, -384(%rdx,%rax,4)
	vmovups	-352(%rbx,%rax,4), %ymm0
	vmovups	-320(%rbx,%rax,4), %ymm1
	vmovups	-288(%rbx,%rax,4), %ymm2
	vmovups	-256(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rax,4)
	vmovups	%ymm1, -320(%rdx,%rax,4)
	vmovups	%ymm2, -288(%rdx,%rax,4)
	vmovups	%ymm3, -256(%rdx,%rax,4)
	vmovups	-224(%rbx,%rax,4), %ymm0
	vmovups	-192(%rbx,%rax,4), %ymm1
	vmovups	-160(%rbx,%rax,4), %ymm2
	vmovups	-128(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rax,4)
	vmovups	%ymm1, -192(%rdx,%rax,4)
	vmovups	%ymm2, -160(%rdx,%rax,4)
	vmovups	%ymm3, -128(%rdx,%rax,4)
	vmovups	-96(%rbx,%rax,4), %ymm0
	vmovups	-64(%rbx,%rax,4), %ymm1
	vmovups	-32(%rbx,%rax,4), %ymm2
	vmovups	(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rax,4)
	vmovups	%ymm1, -64(%rdx,%rax,4)
	vmovups	%ymm2, -32(%rdx,%rax,4)
	vmovups	%ymm3, (%rdx,%rax,4)
	subq	$-128, %rax
	addq	$4, %r15
	jne	LBB9_32
LBB9_33:
	testq	%r14, %r14
	je	LBB9_36
## %bb.34:
	leaq	(%rax,%r9), %rdx
	leaq	(%r8,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%r12, %rax
	leaq	(%rdi,%rax,4), %rax
	addq	$96, %rax
	shlq	$7, %r14
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB9_35:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rax,%rsi), %ymm0
	vmovups	-64(%rax,%rsi), %ymm1
	vmovups	-32(%rax,%rsi), %ymm2
	vmovups	(%rax,%rsi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rsi)
	vmovups	%ymm1, -64(%rdx,%rsi)
	vmovups	%ymm2, -32(%rdx,%rsi)
	vmovups	%ymm3, (%rdx,%rsi)
	subq	$-128, %rsi
	cmpq	%rsi, %r14
	jne	LBB9_35
LBB9_36:
	cmpq	%r11, %r10
	je	LBB9_43
## %bb.37:
	addq	%r11, %r12
	addq	%r11, %r9
LBB9_38:
	movl	%ecx, %eax
	subl	%r12d, %eax
	leal	1(%rax), %edx
	andl	$7, %edx
	je	LBB9_40
	.p2align	4, 0x90
LBB9_39:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r12,4), %esi
	incq	%r12
	movl	%esi, (%r8,%r9,4)
	incq	%r9
	decl	%edx
	jne	LBB9_39
LBB9_40:
	cmpl	$7, %eax
	jb	LBB9_43
## %bb.41:
	movl	%ecx, %r10d
	subl	%r12d, %r10d
	incl	%r10d
	leaq	(%rdi,%r12,4), %rdx
	addq	$28, %rdx
	leaq	(%r8,%r9,4), %rbx
	addq	$28, %rbx
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB9_42:                                ## =>This Inner Loop Header: Depth=1
	movl	-28(%rdx,%rax,4), %esi
	movl	%esi, -28(%rbx,%rax,4)
	movl	-24(%rdx,%rax,4), %esi
	movl	%esi, -24(%rbx,%rax,4)
	movl	-20(%rdx,%rax,4), %esi
	movl	%esi, -20(%rbx,%rax,4)
	movl	-16(%rdx,%rax,4), %esi
	movl	%esi, -16(%rbx,%rax,4)
	movl	-12(%rdx,%rax,4), %esi
	movl	%esi, -12(%rbx,%rax,4)
	movl	-8(%rdx,%rax,4), %esi
	movl	%esi, -8(%rbx,%rax,4)
	movl	-4(%rdx,%rax,4), %esi
	movl	%esi, -4(%rbx,%rax,4)
	movl	(%rdx,%rax,4), %esi
	movl	%esi, (%rbx,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %r10d
	jne	LBB9_42
LBB9_43:
	movl	%ecx, %r11d
	subl	%r13d, %r11d
	jl	LBB9_61
## %bb.44:
	movslq	%r13d, %rax
	cmpl	$31, %r11d
	jb	LBB9_56
## %bb.45:
	leaq	(%rdi,%rax,4), %rsi
	leaq	(%r11,%rax), %rdx
	leaq	(%r8,%rdx,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rsi
	jae	LBB9_47
## %bb.46:
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r8,%rax,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB9_56
LBB9_47:
	incq	%r11
	movq	%r11, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %r14
	shrq	$5, %r14
	incq	%r14
	movl	%r14d, %r10d
	andl	$3, %r10d
	cmpq	$96, %rdx
	jae	LBB9_49
## %bb.48:
	xorl	%esi, %esi
	jmp	LBB9_51
LBB9_49:
	leaq	(%rdi,%rax,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	(%r8,%rax,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	andq	$-4, %r14
	negq	%r14
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB9_50:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rsi,4), %ymm0
	vmovups	-448(%rbx,%rsi,4), %ymm1
	vmovups	-416(%rbx,%rsi,4), %ymm2
	vmovups	-384(%rbx,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rsi,4)
	vmovups	%ymm1, -448(%rdx,%rsi,4)
	vmovups	%ymm2, -416(%rdx,%rsi,4)
	vmovups	%ymm3, -384(%rdx,%rsi,4)
	vmovups	-352(%rbx,%rsi,4), %ymm0
	vmovups	-320(%rbx,%rsi,4), %ymm1
	vmovups	-288(%rbx,%rsi,4), %ymm2
	vmovups	-256(%rbx,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rsi,4)
	vmovups	%ymm1, -320(%rdx,%rsi,4)
	vmovups	%ymm2, -288(%rdx,%rsi,4)
	vmovups	%ymm3, -256(%rdx,%rsi,4)
	vmovups	-224(%rbx,%rsi,4), %ymm0
	vmovups	-192(%rbx,%rsi,4), %ymm1
	vmovups	-160(%rbx,%rsi,4), %ymm2
	vmovups	-128(%rbx,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rsi,4)
	vmovups	%ymm1, -192(%rdx,%rsi,4)
	vmovups	%ymm2, -160(%rdx,%rsi,4)
	vmovups	%ymm3, -128(%rdx,%rsi,4)
	vmovups	-96(%rbx,%rsi,4), %ymm0
	vmovups	-64(%rbx,%rsi,4), %ymm1
	vmovups	-32(%rbx,%rsi,4), %ymm2
	vmovups	(%rbx,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rsi,4)
	vmovups	%ymm1, -64(%rdx,%rsi,4)
	vmovups	%ymm2, -32(%rdx,%rsi,4)
	vmovups	%ymm3, (%rdx,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %r14
	jne	LBB9_50
LBB9_51:
	testq	%r10, %r10
	je	LBB9_54
## %bb.52:
	addq	%rax, %rsi
	leaq	(%rdi,%rsi,4), %rdx
	addq	$96, %rdx
	leaq	(%r8,%rsi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r10
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB9_53:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rbx), %ymm0
	vmovups	-64(%rsi,%rbx), %ymm1
	vmovups	-32(%rsi,%rbx), %ymm2
	vmovups	(%rsi,%rbx), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx)
	vmovups	%ymm1, -64(%rdx,%rbx)
	vmovups	%ymm2, -32(%rdx,%rbx)
	vmovups	%ymm3, (%rdx,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r10
	jne	LBB9_53
LBB9_54:
	cmpq	%r9, %r11
	je	LBB9_61
## %bb.55:
	addq	%r9, %rax
LBB9_56:
	leal	1(%rcx), %edx
	movl	%edx, %esi
	subl	%eax, %esi
	subl	%eax, %ecx
	andl	$7, %esi
	je	LBB9_58
	.p2align	4, 0x90
LBB9_57:                                ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rax,4), %ebx
	movl	%ebx, (%rdi,%rax,4)
	incq	%rax
	decl	%esi
	jne	LBB9_57
LBB9_58:
	cmpl	$7, %ecx
	jb	LBB9_61
## %bb.59:
	movl	%edx, %ecx
	.p2align	4, 0x90
LBB9_60:                                ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rax,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	4(%r8,%rax,4), %edx
	movl	%edx, 4(%rdi,%rax,4)
	movl	8(%r8,%rax,4), %edx
	movl	%edx, 8(%rdi,%rax,4)
	movl	12(%r8,%rax,4), %edx
	movl	%edx, 12(%rdi,%rax,4)
	movl	16(%r8,%rax,4), %edx
	movl	%edx, 16(%rdi,%rax,4)
	movl	20(%r8,%rax,4), %edx
	movl	%edx, 20(%rdi,%rax,4)
	movl	24(%r8,%rax,4), %edx
	movl	%edx, 24(%rdi,%rax,4)
	movl	28(%r8,%rax,4), %edx
	movl	%edx, 28(%rdi,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %ecx
	jne	LBB9_60
LBB9_61:
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_merge_o                   ## -- Begin function sort_merge_o
	.p2align	4, 0x90
_sort_merge_o:                          ## @sort_merge_o
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB10_64
## %bb.1:
	movq	%rcx, %r14
	movl	%edx, %ebx
	movq	%rdi, %r13
	leal	(%rbx,%rsi), %eax
	movl	%eax, %r12d
	shrl	$31, %r12d
	addl	%eax, %r12d
	sarl	%r12d
	movl	%r12d, %edx
	movq	%rbx, -48(%rbp)                 ## 8-byte Spill
	movq	%rsi, %rbx
	callq	_sort_merge_o
	leal	1(%r12), %r15d
	movq	%r13, %rdi
	movl	%r15d, %esi
	movq	-48(%rbp), %rdx                 ## 8-byte Reload
                                        ## kill: def $edx killed $edx killed $rdx
	movq	%r14, %rcx
	callq	_sort_merge_o
	movq	-48(%rbp), %r11                 ## 8-byte Reload
	cmpl	%r11d, %r12d
	jge	LBB10_2
## %bb.3:
	cmpl	%ebx, %r12d
	movq	%rbx, %r9
	jl	LBB10_4
## %bb.31:
	movslq	%r9d, %rax
	leaq	(%r14,%rax,4), %rdx
	movl	%r9d, %r8d
	movl	%r9d, %ecx
	.p2align	4, 0x90
LBB10_32:                               ## =>This Inner Loop Header: Depth=1
	movslq	%r15d, %r15
	movl	(%r13,%r15,4), %esi
	movslq	%ecx, %rcx
	movl	(%r13,%rcx,4), %edi
	xorl	%eax, %eax
	xorl	%ebx, %ebx
	cmpl	%esi, %edi
	setle	%al
	setg	%bl
	cmovgl	%esi, %edi
	addl	%eax, %ecx
	addl	%ebx, %r15d
	movl	%edi, (%rdx)
	incl	%r8d
	cmpl	%r11d, %r15d
	jg	LBB10_5
## %bb.33:                              ##   in Loop: Header=BB10_32 Depth=1
	addq	$4, %rdx
	cmpl	%r12d, %ecx
	jle	LBB10_32
	jmp	LBB10_5
LBB10_4:
	movl	%r9d, %r8d
	movl	%r9d, %ecx
LBB10_5:
	movl	%r12d, %r10d
	subl	%ecx, %r10d
	jl	LBB10_18
LBB10_6:
	movslq	%ecx, %rcx
	movslq	%r8d, %r8
	cmpl	$31, %r10d
	jb	LBB10_25
## %bb.7:
	leaq	(%r14,%r8,4), %rdx
	leaq	(%rcx,%r10), %rsi
	leaq	4(,%rsi,4), %rsi
	addq	%r13, %rsi
	cmpq	%rsi, %rdx
	jae	LBB10_9
## %bb.8:
	leaq	(%r8,%r10), %rdx
	leaq	(%r14,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(,%rcx,4), %rsi
	addq	%r13, %rsi
	cmpq	%rdx, %rsi
	jb	LBB10_25
LBB10_9:
	movq	%r9, %rbx
	incq	%r10
	movq	%r10, %rax
	andq	$-32, %rax
	leaq	-32(%rax), %rdx
	movq	%rdx, %r11
	shrq	$5, %r11
	incq	%r11
	movl	%r11d, %r9d
	andl	$3, %r9d
	cmpq	$96, %rdx
	jae	LBB10_11
## %bb.10:
	xorl	%esi, %esi
	jmp	LBB10_13
LBB10_2:
	movl	%ebx, %r8d
	movl	%ebx, %ecx
	movq	%rbx, %r9
	movl	%r12d, %r10d
	subl	%ecx, %r10d
	jge	LBB10_6
	jmp	LBB10_18
LBB10_11:
	leaq	(%r14,%r8,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	480(,%rcx,4), %rdi
	addq	%r13, %rdi
	andq	$-4, %r11
	negq	%r11
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB10_12:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdi,%rsi,4), %ymm0
	vmovups	-448(%rdi,%rsi,4), %ymm1
	vmovups	-416(%rdi,%rsi,4), %ymm2
	vmovups	-384(%rdi,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rsi,4)
	vmovups	%ymm1, -448(%rdx,%rsi,4)
	vmovups	%ymm2, -416(%rdx,%rsi,4)
	vmovups	%ymm3, -384(%rdx,%rsi,4)
	vmovups	-352(%rdi,%rsi,4), %ymm0
	vmovups	-320(%rdi,%rsi,4), %ymm1
	vmovups	-288(%rdi,%rsi,4), %ymm2
	vmovups	-256(%rdi,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rsi,4)
	vmovups	%ymm1, -320(%rdx,%rsi,4)
	vmovups	%ymm2, -288(%rdx,%rsi,4)
	vmovups	%ymm3, -256(%rdx,%rsi,4)
	vmovups	-224(%rdi,%rsi,4), %ymm0
	vmovups	-192(%rdi,%rsi,4), %ymm1
	vmovups	-160(%rdi,%rsi,4), %ymm2
	vmovups	-128(%rdi,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rsi,4)
	vmovups	%ymm1, -192(%rdx,%rsi,4)
	vmovups	%ymm2, -160(%rdx,%rsi,4)
	vmovups	%ymm3, -128(%rdx,%rsi,4)
	vmovups	-96(%rdi,%rsi,4), %ymm0
	vmovups	-64(%rdi,%rsi,4), %ymm1
	vmovups	-32(%rdi,%rsi,4), %ymm2
	vmovups	(%rdi,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rsi,4)
	vmovups	%ymm1, -64(%rdx,%rsi,4)
	vmovups	%ymm2, -32(%rdx,%rsi,4)
	vmovups	%ymm3, (%rdx,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %r11
	jne	LBB10_12
LBB10_13:
	testq	%r9, %r9
	je	LBB10_16
## %bb.14:
	leaq	(%rsi,%rcx), %rdx
	leaq	96(,%rdx,4), %rdx
	addq	%r13, %rdx
	addq	%r8, %rsi
	leaq	(%r14,%rsi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r9
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB10_15:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rdx,%rdi), %ymm0
	vmovups	-64(%rdx,%rdi), %ymm1
	vmovups	-32(%rdx,%rdi), %ymm2
	vmovups	(%rdx,%rdi), %ymm3
	vmovups	%ymm0, -96(%rsi,%rdi)
	vmovups	%ymm1, -64(%rsi,%rdi)
	vmovups	%ymm2, -32(%rsi,%rdi)
	vmovups	%ymm3, (%rsi,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r9
	jne	LBB10_15
LBB10_16:
	addq	%rax, %r8
	cmpq	%rax, %r10
	movq	-48(%rbp), %r11                 ## 8-byte Reload
	jne	LBB10_24
## %bb.17:
	movq	%rbx, %r9
	jmp	LBB10_18
LBB10_24:
	addq	%rax, %rcx
	movq	%rbx, %r9
LBB10_25:
	movl	%r12d, %edx
	subl	%ecx, %edx
	leal	1(%rdx), %esi
	andl	$7, %esi
	je	LBB10_27
	.p2align	4, 0x90
LBB10_26:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r13,%rcx,4), %edi
	incq	%rcx
	movl	%edi, (%r14,%r8,4)
	incq	%r8
	decl	%esi
	jne	LBB10_26
LBB10_27:
	cmpl	$7, %edx
	jb	LBB10_18
## %bb.28:
	leaq	(%r14,%r8,4), %rdx
	addq	$28, %rdx
	subl	%ecx, %r12d
	incl	%r12d
	leaq	28(,%rcx,4), %rsi
	addq	%r13, %rsi
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB10_29:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rcx,4), %eax
	movl	%eax, -28(%rdx,%rcx,4)
	movl	-24(%rsi,%rcx,4), %eax
	movl	%eax, -24(%rdx,%rcx,4)
	movl	-20(%rsi,%rcx,4), %eax
	movl	%eax, -20(%rdx,%rcx,4)
	movl	-16(%rsi,%rcx,4), %eax
	movl	%eax, -16(%rdx,%rcx,4)
	movl	-12(%rsi,%rcx,4), %eax
	movl	%eax, -12(%rdx,%rcx,4)
	movl	-8(%rsi,%rcx,4), %eax
	movl	%eax, -8(%rdx,%rcx,4)
	movl	-4(%rsi,%rcx,4), %eax
	movl	%eax, -4(%rdx,%rcx,4)
	movl	(%rsi,%rcx,4), %eax
	movl	%eax, (%rdx,%rcx,4)
	addq	$8, %rcx
	cmpl	%ecx, %r12d
	jne	LBB10_29
## %bb.30:
	addq	%rcx, %r8
LBB10_18:
	cmpl	%r11d, %r15d
	jg	LBB10_46
## %bb.19:
	movq	%r9, %r12
	movslq	%r8d, %rax
	movslq	%r15d, %rcx
	movl	%r11d, %r9d
	subl	%r15d, %r9d
	cmpl	$31, %r9d
	jb	LBB10_41
## %bb.20:
	leaq	(%r14,%rax,4), %rdx
	leaq	(%rcx,%r9), %rsi
	leaq	4(,%rsi,4), %rsi
	addq	%r13, %rsi
	cmpq	%rsi, %rdx
	jae	LBB10_22
## %bb.21:
	leaq	(%rax,%r9), %rdx
	leaq	(%r14,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(,%rcx,4), %rsi
	addq	%r13, %rsi
	cmpq	%rdx, %rsi
	jb	LBB10_41
LBB10_22:
	incq	%r9
	movq	%r9, %r8
	andq	$-32, %r8
	leaq	-32(%r8), %rdx
	movq	%rdx, %rdi
	shrq	$5, %rdi
	incq	%rdi
	movl	%edi, %r10d
	andl	$3, %r10d
	cmpq	$96, %rdx
	jae	LBB10_34
## %bb.23:
	xorl	%esi, %esi
	jmp	LBB10_36
LBB10_34:
	leaq	480(,%rcx,4), %rdx
	addq	%r13, %rdx
	leaq	(%r14,%rax,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	andq	$-4, %rdi
	negq	%rdi
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB10_35:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdx,%rsi,4), %ymm0
	vmovups	-448(%rdx,%rsi,4), %ymm1
	vmovups	-416(%rdx,%rsi,4), %ymm2
	vmovups	-384(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%rbx,%rsi,4)
	vmovups	%ymm1, -448(%rbx,%rsi,4)
	vmovups	%ymm2, -416(%rbx,%rsi,4)
	vmovups	%ymm3, -384(%rbx,%rsi,4)
	vmovups	-352(%rdx,%rsi,4), %ymm0
	vmovups	-320(%rdx,%rsi,4), %ymm1
	vmovups	-288(%rdx,%rsi,4), %ymm2
	vmovups	-256(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%rbx,%rsi,4)
	vmovups	%ymm1, -320(%rbx,%rsi,4)
	vmovups	%ymm2, -288(%rbx,%rsi,4)
	vmovups	%ymm3, -256(%rbx,%rsi,4)
	vmovups	-224(%rdx,%rsi,4), %ymm0
	vmovups	-192(%rdx,%rsi,4), %ymm1
	vmovups	-160(%rdx,%rsi,4), %ymm2
	vmovups	-128(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%rbx,%rsi,4)
	vmovups	%ymm1, -192(%rbx,%rsi,4)
	vmovups	%ymm2, -160(%rbx,%rsi,4)
	vmovups	%ymm3, -128(%rbx,%rsi,4)
	vmovups	-96(%rdx,%rsi,4), %ymm0
	vmovups	-64(%rdx,%rsi,4), %ymm1
	vmovups	-32(%rdx,%rsi,4), %ymm2
	vmovups	(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%rbx,%rsi,4)
	vmovups	%ymm1, -64(%rbx,%rsi,4)
	vmovups	%ymm2, -32(%rbx,%rsi,4)
	vmovups	%ymm3, (%rbx,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %rdi
	jne	LBB10_35
LBB10_36:
	testq	%r10, %r10
	je	LBB10_39
## %bb.37:
	leaq	(%rsi,%rax), %rdx
	leaq	(%r14,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%rcx, %rsi
	leaq	96(,%rsi,4), %rsi
	addq	%r13, %rsi
	shlq	$7, %r10
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB10_38:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r10
	jne	LBB10_38
LBB10_39:
	cmpq	%r8, %r9
	movq	%r12, %r9
	je	LBB10_46
## %bb.40:
	addq	%r8, %rcx
	addq	%r8, %rax
LBB10_41:
	movl	%r11d, %edx
	subl	%ecx, %edx
	leal	1(%rdx), %esi
	movq	%r12, %r9
	andl	$7, %esi
	je	LBB10_43
	.p2align	4, 0x90
LBB10_42:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r13,%rcx,4), %edi
	incq	%rcx
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	decl	%esi
	jne	LBB10_42
LBB10_43:
	cmpl	$7, %edx
	jb	LBB10_46
## %bb.44:
	movl	%r11d, %edx
	subl	%ecx, %edx
	incl	%edx
	leaq	28(,%rcx,4), %rcx
	addq	%r13, %rcx
	leaq	(%r14,%rax,4), %rax
	addq	$28, %rax
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB10_45:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rcx,%rsi,4), %edi
	movl	%edi, -28(%rax,%rsi,4)
	movl	-24(%rcx,%rsi,4), %edi
	movl	%edi, -24(%rax,%rsi,4)
	movl	-20(%rcx,%rsi,4), %edi
	movl	%edi, -20(%rax,%rsi,4)
	movl	-16(%rcx,%rsi,4), %edi
	movl	%edi, -16(%rax,%rsi,4)
	movl	-12(%rcx,%rsi,4), %edi
	movl	%edi, -12(%rax,%rsi,4)
	movl	-8(%rcx,%rsi,4), %edi
	movl	%edi, -8(%rax,%rsi,4)
	movl	-4(%rcx,%rsi,4), %edi
	movl	%edi, -4(%rax,%rsi,4)
	movl	(%rcx,%rsi,4), %edi
	movl	%edi, (%rax,%rsi,4)
	addq	$8, %rsi
	cmpl	%esi, %edx
	jne	LBB10_45
LBB10_46:
	movl	%r11d, %ecx
	subl	%r9d, %ecx
	jl	LBB10_64
## %bb.47:
	movslq	%r9d, %rax
	cmpl	$31, %ecx
	jb	LBB10_59
## %bb.48:
	leaq	(,%rax,4), %rsi
	addq	%r13, %rsi
	leaq	(%rcx,%rax), %rdx
	leaq	(%r14,%rdx,4), %rdi
	addq	$4, %rdi
	cmpq	%rdi, %rsi
	jae	LBB10_50
## %bb.49:
	leaq	4(,%rdx,4), %rdx
	addq	%r13, %rdx
	leaq	(%r14,%rax,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB10_59
LBB10_50:
	incq	%rcx
	movq	%rcx, %r8
	andq	$-32, %r8
	leaq	-32(%r8), %rdx
	movq	%rdx, %rdi
	shrq	$5, %rdi
	incq	%rdi
	movl	%edi, %r9d
	andl	$3, %r9d
	cmpq	$96, %rdx
	jae	LBB10_52
## %bb.51:
	xorl	%ebx, %ebx
	jmp	LBB10_54
LBB10_52:
	leaq	480(,%rax,4), %rdx
	addq	%r13, %rdx
	leaq	(%r14,%rax,4), %rsi
	addq	$480, %rsi                      ## imm = 0x1E0
	andq	$-4, %rdi
	negq	%rdi
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB10_53:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rsi,%rbx,4), %ymm0
	vmovups	-448(%rsi,%rbx,4), %ymm1
	vmovups	-416(%rsi,%rbx,4), %ymm2
	vmovups	-384(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rbx,4)
	vmovups	%ymm1, -448(%rdx,%rbx,4)
	vmovups	%ymm2, -416(%rdx,%rbx,4)
	vmovups	%ymm3, -384(%rdx,%rbx,4)
	vmovups	-352(%rsi,%rbx,4), %ymm0
	vmovups	-320(%rsi,%rbx,4), %ymm1
	vmovups	-288(%rsi,%rbx,4), %ymm2
	vmovups	-256(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rbx,4)
	vmovups	%ymm1, -320(%rdx,%rbx,4)
	vmovups	%ymm2, -288(%rdx,%rbx,4)
	vmovups	%ymm3, -256(%rdx,%rbx,4)
	vmovups	-224(%rsi,%rbx,4), %ymm0
	vmovups	-192(%rsi,%rbx,4), %ymm1
	vmovups	-160(%rsi,%rbx,4), %ymm2
	vmovups	-128(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rbx,4)
	vmovups	%ymm1, -192(%rdx,%rbx,4)
	vmovups	%ymm2, -160(%rdx,%rbx,4)
	vmovups	%ymm3, -128(%rdx,%rbx,4)
	vmovups	-96(%rsi,%rbx,4), %ymm0
	vmovups	-64(%rsi,%rbx,4), %ymm1
	vmovups	-32(%rsi,%rbx,4), %ymm2
	vmovups	(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx,4)
	vmovups	%ymm1, -64(%rdx,%rbx,4)
	vmovups	%ymm2, -32(%rdx,%rbx,4)
	vmovups	%ymm3, (%rdx,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %rdi
	jne	LBB10_53
LBB10_54:
	testq	%r9, %r9
	je	LBB10_57
## %bb.55:
	addq	%rax, %rbx
	leaq	96(,%rbx,4), %rdx
	addq	%r13, %rdx
	leaq	(%r14,%rbx,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r9
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB10_56:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r9
	jne	LBB10_56
LBB10_57:
	cmpq	%r8, %rcx
	je	LBB10_64
## %bb.58:
	addq	%r8, %rax
LBB10_59:
	leal	1(%r11), %ecx
	movl	%ecx, %edx
	subl	%eax, %edx
	subl	%eax, %r11d
	andl	$7, %edx
	je	LBB10_61
	.p2align	4, 0x90
LBB10_60:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r14,%rax,4), %esi
	movl	%esi, (%r13,%rax,4)
	incq	%rax
	decl	%edx
	jne	LBB10_60
LBB10_61:
	cmpl	$7, %r11d
	jb	LBB10_64
## %bb.62:
	movl	%ecx, %ecx
	.p2align	4, 0x90
LBB10_63:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r14,%rax,4), %edx
	movl	%edx, (%r13,%rax,4)
	movl	4(%r14,%rax,4), %edx
	movl	%edx, 4(%r13,%rax,4)
	movl	8(%r14,%rax,4), %edx
	movl	%edx, 8(%r13,%rax,4)
	movl	12(%r14,%rax,4), %edx
	movl	%edx, 12(%r13,%rax,4)
	movl	16(%r14,%rax,4), %edx
	movl	%edx, 16(%r13,%rax,4)
	movl	20(%r14,%rax,4), %edx
	movl	%edx, 20(%r13,%rax,4)
	movl	24(%r14,%rax,4), %edx
	movl	%edx, 24(%r13,%rax,4)
	movl	28(%r14,%rax,4), %edx
	movl	%edx, 28(%r13,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %ecx
	jne	LBB10_63
LBB10_64:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_merge_optimized           ## -- Begin function sort_merge_optimized
	.p2align	4, 0x90
_sort_merge_optimized:                  ## @sort_merge_optimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movl	%edx, %r14d
	movl	%esi, %r12d
	movq	%rdi, %r15
	movl	%edx, %eax
	subl	%esi, %eax
	movslq	%eax, %rdi
	shlq	$2, %rdi
	callq	_malloc
	movq	%rax, %rbx
	movq	%r15, %rdi
	movl	%r12d, %esi
	movl	%r14d, %edx
	movq	%rax, %rcx
	callq	_sort_merge_o
	movq	%rbx, %rdi
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	jmp	_free                           ## TAILCALL
	.cfi_endproc
                                        ## -- End function
	.globl	_merging_standard               ## -- Begin function merging_standard
	.p2align	4, 0x90
_merging_standard:                      ## @merging_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $ecx killed $ecx def $rcx
                                        ## kill: def $edx killed $edx def $rdx
	leal	1(%rdx), %r14d
	cmpl	%edx, %esi
	jg	LBB12_1
## %bb.8:
	cmpl	%ecx, %edx
	jge	LBB12_1
## %bb.9:
	movslq	%esi, %r9
	shlq	$2, %r9
	addq	_b@GOTPCREL(%rip), %r9
	movl	%esi, %r8d
	movl	%esi, %ebx
	.p2align	4, 0x90
LBB12_10:                               ## =>This Inner Loop Header: Depth=1
	movslq	%ebx, %rbx
	movl	(%rdi,%rbx,4), %r15d
	movslq	%r14d, %r14
	movl	(%rdi,%r14,4), %r10d
	xorl	%r11d, %r11d
	xorl	%eax, %eax
	cmpl	%r10d, %r15d
	setg	%r11b
	setle	%al
	cmovgl	%r10d, %r15d
	addl	%eax, %ebx
	addl	%r11d, %r14d
	movl	%r15d, (%r9)
	incl	%r8d
	cmpl	%edx, %ebx
	jg	LBB12_2
## %bb.11:                              ##   in Loop: Header=BB12_10 Depth=1
	addq	$4, %r9
	cmpl	%ecx, %r14d
	jle	LBB12_10
	jmp	LBB12_2
LBB12_1:
	movl	%esi, %ebx
	movl	%esi, %r8d
LBB12_2:
	cmpl	%edx, %ebx
	jg	LBB12_26
## %bb.3:
	movslq	%r8d, %r8
	movslq	%ebx, %r9
	movl	%edx, %r10d
	subl	%ebx, %r10d
	cmpl	$31, %r10d
	jb	LBB12_19
## %bb.4:
	movq	_b@GOTPCREL(%rip), %r11
	leaq	(%r11,%r8,4), %rax
	leaq	(%r9,%r10), %rbx
	leaq	(%rdi,%rbx,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rax
	jae	LBB12_6
## %bb.5:
	leaq	(%r8,%r10), %rax
	leaq	(%r11,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r9,4), %rbx
	cmpq	%rax, %rbx
	jb	LBB12_19
LBB12_6:
	incq	%r10
	movq	%r10, %rax
	andq	$-32, %rax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	addq	$-32, %rax
	movq	%rax, %r12
	shrq	$5, %r12
	incq	%r12
	movl	%r12d, %r15d
	andl	$3, %r15d
	cmpq	$96, %rax
	jae	LBB12_12
## %bb.7:
	xorl	%r11d, %r11d
	jmp	LBB12_14
LBB12_12:
	leaq	(%rdi,%r9,4), %r13
	addq	$480, %r13                      ## imm = 0x1E0
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r8,4), %rax
	addq	$480, %rax                      ## imm = 0x1E0
	andq	$-4, %r12
	negq	%r12
	xorl	%r11d, %r11d
	.p2align	4, 0x90
LBB12_13:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%r13,%r11,4), %ymm0
	vmovups	-448(%r13,%r11,4), %ymm1
	vmovups	-416(%r13,%r11,4), %ymm2
	vmovups	-384(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -480(%rax,%r11,4)
	vmovups	%ymm1, -448(%rax,%r11,4)
	vmovups	%ymm2, -416(%rax,%r11,4)
	vmovups	%ymm3, -384(%rax,%r11,4)
	vmovups	-352(%r13,%r11,4), %ymm0
	vmovups	-320(%r13,%r11,4), %ymm1
	vmovups	-288(%r13,%r11,4), %ymm2
	vmovups	-256(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -352(%rax,%r11,4)
	vmovups	%ymm1, -320(%rax,%r11,4)
	vmovups	%ymm2, -288(%rax,%r11,4)
	vmovups	%ymm3, -256(%rax,%r11,4)
	vmovups	-224(%r13,%r11,4), %ymm0
	vmovups	-192(%r13,%r11,4), %ymm1
	vmovups	-160(%r13,%r11,4), %ymm2
	vmovups	-128(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -224(%rax,%r11,4)
	vmovups	%ymm1, -192(%rax,%r11,4)
	vmovups	%ymm2, -160(%rax,%r11,4)
	vmovups	%ymm3, -128(%rax,%r11,4)
	vmovups	-96(%r13,%r11,4), %ymm0
	vmovups	-64(%r13,%r11,4), %ymm1
	vmovups	-32(%r13,%r11,4), %ymm2
	vmovups	(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -96(%rax,%r11,4)
	vmovups	%ymm1, -64(%rax,%r11,4)
	vmovups	%ymm2, -32(%rax,%r11,4)
	vmovups	%ymm3, (%rax,%r11,4)
	subq	$-128, %r11
	addq	$4, %r12
	jne	LBB12_13
LBB12_14:
	testq	%r15, %r15
	je	LBB12_17
## %bb.15:
	leaq	(%r11,%r8), %rax
	movq	_b@GOTPCREL(%rip), %rbx
	leaq	(%rbx,%rax,4), %r12
	addq	$96, %r12
	addq	%r9, %r11
	leaq	(%rdi,%r11,4), %rbx
	addq	$96, %rbx
	shlq	$7, %r15
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB12_16:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rbx,%rax), %ymm0
	vmovups	-64(%rbx,%rax), %ymm1
	vmovups	-32(%rbx,%rax), %ymm2
	vmovups	(%rbx,%rax), %ymm3
	vmovups	%ymm0, -96(%r12,%rax)
	vmovups	%ymm1, -64(%r12,%rax)
	vmovups	%ymm2, -32(%r12,%rax)
	vmovups	%ymm3, (%r12,%rax)
	subq	$-128, %rax
	cmpq	%rax, %r15
	jne	LBB12_16
LBB12_17:
	movq	-48(%rbp), %rax                 ## 8-byte Reload
	addq	%rax, %r8
	cmpq	%rax, %r10
	je	LBB12_26
## %bb.18:
	addq	%rax, %r9
LBB12_19:
	movl	%edx, %r10d
	subl	%r9d, %r10d
	leal	1(%r10), %ebx
	andl	$7, %ebx
	je	LBB12_22
## %bb.20:
	movq	_b@GOTPCREL(%rip), %r11
	.p2align	4, 0x90
LBB12_21:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r9,4), %eax
	incq	%r9
	movl	%eax, (%r11,%r8,4)
	incq	%r8
	decl	%ebx
	jne	LBB12_21
LBB12_22:
	cmpl	$7, %r10d
	jb	LBB12_26
## %bb.23:
	subl	%r9d, %edx
	incl	%edx
	leaq	(%rdi,%r9,4), %r9
	addq	$28, %r9
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r8,4), %r10
	addq	$28, %r10
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB12_24:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%r9,%rbx,4), %eax
	movl	%eax, -28(%r10,%rbx,4)
	movl	-24(%r9,%rbx,4), %eax
	movl	%eax, -24(%r10,%rbx,4)
	movl	-20(%r9,%rbx,4), %eax
	movl	%eax, -20(%r10,%rbx,4)
	movl	-16(%r9,%rbx,4), %eax
	movl	%eax, -16(%r10,%rbx,4)
	movl	-12(%r9,%rbx,4), %eax
	movl	%eax, -12(%r10,%rbx,4)
	movl	-8(%r9,%rbx,4), %eax
	movl	%eax, -8(%r10,%rbx,4)
	movl	-4(%r9,%rbx,4), %eax
	movl	%eax, -4(%r10,%rbx,4)
	movl	(%r9,%rbx,4), %eax
	movl	%eax, (%r10,%rbx,4)
	addq	$8, %rbx
	cmpl	%ebx, %edx
	jne	LBB12_24
## %bb.25:
	addq	%rbx, %r8
LBB12_26:
	cmpl	%ecx, %r14d
	jg	LBB12_45
## %bb.27:
	movslq	%r8d, %r8
	movslq	%r14d, %r12
	movl	%ecx, %r9d
	subl	%r14d, %r9d
	cmpl	$31, %r9d
	jb	LBB12_39
## %bb.28:
	movq	_b@GOTPCREL(%rip), %r10
	leaq	(%r10,%r8,4), %rax
	leaq	(%r12,%r9), %rdx
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	cmpq	%rdx, %rax
	jae	LBB12_30
## %bb.29:
	leaq	(%r8,%r9), %rax
	leaq	(%r10,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r12,4), %rdx
	cmpq	%rax, %rdx
	jb	LBB12_39
LBB12_30:
	incq	%r9
	movq	%r9, %r11
	andq	$-32, %r11
	leaq	-32(%r11), %rax
	movq	%rax, %r15
	shrq	$5, %r15
	incq	%r15
	movl	%r15d, %r14d
	andl	$3, %r14d
	cmpq	$96, %rax
	jae	LBB12_32
## %bb.31:
	xorl	%eax, %eax
	jmp	LBB12_34
LBB12_32:
	leaq	(%rdi,%r12,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r10,%r8,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	andq	$-4, %r15
	negq	%r15
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB12_33:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rax,4), %ymm0
	vmovups	-448(%rbx,%rax,4), %ymm1
	vmovups	-416(%rbx,%rax,4), %ymm2
	vmovups	-384(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rax,4)
	vmovups	%ymm1, -448(%rdx,%rax,4)
	vmovups	%ymm2, -416(%rdx,%rax,4)
	vmovups	%ymm3, -384(%rdx,%rax,4)
	vmovups	-352(%rbx,%rax,4), %ymm0
	vmovups	-320(%rbx,%rax,4), %ymm1
	vmovups	-288(%rbx,%rax,4), %ymm2
	vmovups	-256(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rax,4)
	vmovups	%ymm1, -320(%rdx,%rax,4)
	vmovups	%ymm2, -288(%rdx,%rax,4)
	vmovups	%ymm3, -256(%rdx,%rax,4)
	vmovups	-224(%rbx,%rax,4), %ymm0
	vmovups	-192(%rbx,%rax,4), %ymm1
	vmovups	-160(%rbx,%rax,4), %ymm2
	vmovups	-128(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rax,4)
	vmovups	%ymm1, -192(%rdx,%rax,4)
	vmovups	%ymm2, -160(%rdx,%rax,4)
	vmovups	%ymm3, -128(%rdx,%rax,4)
	vmovups	-96(%rbx,%rax,4), %ymm0
	vmovups	-64(%rbx,%rax,4), %ymm1
	vmovups	-32(%rbx,%rax,4), %ymm2
	vmovups	(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rax,4)
	vmovups	%ymm1, -64(%rdx,%rax,4)
	vmovups	%ymm2, -32(%rdx,%rax,4)
	vmovups	%ymm3, (%rdx,%rax,4)
	subq	$-128, %rax
	addq	$4, %r15
	jne	LBB12_33
LBB12_34:
	testq	%r14, %r14
	je	LBB12_37
## %bb.35:
	leaq	(%rax,%r8), %rdx
	leaq	(%r10,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%r12, %rax
	leaq	(%rdi,%rax,4), %rax
	addq	$96, %rax
	shlq	$7, %r14
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB12_36:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rax,%rbx), %ymm0
	vmovups	-64(%rax,%rbx), %ymm1
	vmovups	-32(%rax,%rbx), %ymm2
	vmovups	(%rax,%rbx), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx)
	vmovups	%ymm1, -64(%rdx,%rbx)
	vmovups	%ymm2, -32(%rdx,%rbx)
	vmovups	%ymm3, (%rdx,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r14
	jne	LBB12_36
LBB12_37:
	cmpq	%r11, %r9
	je	LBB12_45
## %bb.38:
	addq	%r11, %r12
	addq	%r11, %r8
LBB12_39:
	movl	%ecx, %r9d
	subl	%r12d, %r9d
	leal	1(%r9), %edx
	andl	$7, %edx
	je	LBB12_42
## %bb.40:
	movq	_b@GOTPCREL(%rip), %rbx
	.p2align	4, 0x90
LBB12_41:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r12,4), %eax
	incq	%r12
	movl	%eax, (%rbx,%r8,4)
	incq	%r8
	decl	%edx
	jne	LBB12_41
LBB12_42:
	cmpl	$7, %r9d
	jb	LBB12_45
## %bb.43:
	movl	%ecx, %r9d
	subl	%r12d, %r9d
	incl	%r9d
	leaq	(%rdi,%r12,4), %r10
	addq	$28, %r10
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r8,4), %rbx
	addq	$28, %rbx
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB12_44:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%r10,%rax,4), %edx
	movl	%edx, -28(%rbx,%rax,4)
	movl	-24(%r10,%rax,4), %edx
	movl	%edx, -24(%rbx,%rax,4)
	movl	-20(%r10,%rax,4), %edx
	movl	%edx, -20(%rbx,%rax,4)
	movl	-16(%r10,%rax,4), %edx
	movl	%edx, -16(%rbx,%rax,4)
	movl	-12(%r10,%rax,4), %edx
	movl	%edx, -12(%rbx,%rax,4)
	movl	-8(%r10,%rax,4), %edx
	movl	%edx, -8(%rbx,%rax,4)
	movl	-4(%r10,%rax,4), %edx
	movl	%edx, -4(%rbx,%rax,4)
	movl	(%r10,%rax,4), %edx
	movl	%edx, (%rbx,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %r9d
	jne	LBB12_44
LBB12_45:
	movl	%ecx, %r10d
	subl	%esi, %r10d
	jl	LBB12_64
## %bb.46:
	movslq	%esi, %rax
	cmpl	$31, %r10d
	jb	LBB12_58
## %bb.47:
	leaq	(%rdi,%rax,4), %rbx
	leaq	(%r10,%rax), %rdx
	movq	_b@GOTPCREL(%rip), %r8
	leaq	(%r8,%rdx,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rbx
	jae	LBB12_49
## %bb.48:
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r8,%rax,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB12_58
LBB12_49:
	incq	%r10
	movq	%r10, %r8
	andq	$-32, %r8
	leaq	-32(%r8), %rdx
	movq	%rdx, %r11
	shrq	$5, %r11
	incq	%r11
	movl	%r11d, %r9d
	andl	$3, %r9d
	cmpq	$96, %rdx
	jae	LBB12_51
## %bb.50:
	xorl	%ebx, %ebx
	jmp	LBB12_53
LBB12_51:
	leaq	(%rdi,%rax,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	480(,%rax,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	andq	$-4, %r11
	negq	%r11
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB12_52:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rsi,%rbx,4), %ymm0
	vmovups	-448(%rsi,%rbx,4), %ymm1
	vmovups	-416(%rsi,%rbx,4), %ymm2
	vmovups	-384(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rbx,4)
	vmovups	%ymm1, -448(%rdx,%rbx,4)
	vmovups	%ymm2, -416(%rdx,%rbx,4)
	vmovups	%ymm3, -384(%rdx,%rbx,4)
	vmovups	-352(%rsi,%rbx,4), %ymm0
	vmovups	-320(%rsi,%rbx,4), %ymm1
	vmovups	-288(%rsi,%rbx,4), %ymm2
	vmovups	-256(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rbx,4)
	vmovups	%ymm1, -320(%rdx,%rbx,4)
	vmovups	%ymm2, -288(%rdx,%rbx,4)
	vmovups	%ymm3, -256(%rdx,%rbx,4)
	vmovups	-224(%rsi,%rbx,4), %ymm0
	vmovups	-192(%rsi,%rbx,4), %ymm1
	vmovups	-160(%rsi,%rbx,4), %ymm2
	vmovups	-128(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rbx,4)
	vmovups	%ymm1, -192(%rdx,%rbx,4)
	vmovups	%ymm2, -160(%rdx,%rbx,4)
	vmovups	%ymm3, -128(%rdx,%rbx,4)
	vmovups	-96(%rsi,%rbx,4), %ymm0
	vmovups	-64(%rsi,%rbx,4), %ymm1
	vmovups	-32(%rsi,%rbx,4), %ymm2
	vmovups	(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx,4)
	vmovups	%ymm1, -64(%rdx,%rbx,4)
	vmovups	%ymm2, -32(%rdx,%rbx,4)
	vmovups	%ymm3, (%rdx,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %r11
	jne	LBB12_52
LBB12_53:
	testq	%r9, %r9
	je	LBB12_56
## %bb.54:
	addq	%rax, %rbx
	leaq	(%rdi,%rbx,4), %rdx
	addq	$96, %rdx
	leaq	96(,%rbx,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	shlq	$7, %r9
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB12_55:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rbx), %ymm0
	vmovups	-64(%rsi,%rbx), %ymm1
	vmovups	-32(%rsi,%rbx), %ymm2
	vmovups	(%rsi,%rbx), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx)
	vmovups	%ymm1, -64(%rdx,%rbx)
	vmovups	%ymm2, -32(%rdx,%rbx)
	vmovups	%ymm3, (%rdx,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r9
	jne	LBB12_55
LBB12_56:
	cmpq	%r8, %r10
	je	LBB12_64
## %bb.57:
	addq	%r8, %rax
LBB12_58:
	leal	1(%rcx), %r8d
	movl	%r8d, %esi
	subl	%eax, %esi
	subl	%eax, %ecx
	andl	$7, %esi
	je	LBB12_61
## %bb.59:
	movq	_b@GOTPCREL(%rip), %rbx
	.p2align	4, 0x90
LBB12_60:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rbx,%rax,4), %edx
	movl	%edx, (%rdi,%rax,4)
	incq	%rax
	decl	%esi
	jne	LBB12_60
LBB12_61:
	cmpl	$7, %ecx
	jb	LBB12_64
## %bb.62:
	movl	%r8d, %ecx
	movq	_b@GOTPCREL(%rip), %rdx
	.p2align	4, 0x90
LBB12_63:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdx,%rax,4), %esi
	movl	%esi, (%rdi,%rax,4)
	movl	4(%rdx,%rax,4), %esi
	movl	%esi, 4(%rdi,%rax,4)
	movl	8(%rdx,%rax,4), %esi
	movl	%esi, 8(%rdi,%rax,4)
	movl	12(%rdx,%rax,4), %esi
	movl	%esi, 12(%rdi,%rax,4)
	movl	16(%rdx,%rax,4), %esi
	movl	%esi, 16(%rdi,%rax,4)
	movl	20(%rdx,%rax,4), %esi
	movl	%esi, 20(%rdi,%rax,4)
	movl	24(%rdx,%rax,4), %esi
	movl	%esi, 24(%rdi,%rax,4)
	movl	28(%rdx,%rax,4), %esi
	movl	%esi, 28(%rdi,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %ecx
	jne	LBB12_63
LBB12_64:
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_merge_standard            ## -- Begin function sort_merge_standard
	.p2align	4, 0x90
_sort_merge_standard:                   ## @sort_merge_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	%esi, %edx
	jle	LBB13_70
## %bb.1:
	movl	%edx, %r15d
	movl	%esi, %ebx
	movq	%rdi, %r12
	leal	(%r15,%rbx), %eax
	movl	%eax, %r13d
	shrl	$31, %r13d
	addl	%eax, %r13d
	sarl	%r13d
	movl	%r13d, %edx
	callq	_sort_merge_standard
	leal	1(%r13), %r14d
	movq	%r12, %rdi
	movl	%r14d, %esi
	movl	%r15d, %edx
	callq	_sort_merge_standard
	cmpl	%ebx, %r13d
	movq	%rbx, -48(%rbp)                 ## 8-byte Spill
	jl	LBB13_7
## %bb.2:
	cmpl	%r15d, %r13d
	movq	%r15, %r10
	jge	LBB13_6
## %bb.3:
	movslq	%ebx, %rdx
	shlq	$2, %rdx
	addq	_b@GOTPCREL(%rip), %rdx
	movl	%ebx, %r15d
	movl	%ebx, %ecx
	.p2align	4, 0x90
LBB13_4:                                ## =>This Inner Loop Header: Depth=1
	movslq	%ecx, %rcx
	movl	(%r12,%rcx,4), %esi
	movslq	%r14d, %r14
	movl	(%r12,%r14,4), %edi
	xorl	%eax, %eax
	xorl	%ebx, %ebx
	cmpl	%edi, %esi
	setg	%al
	setle	%bl
	cmovgl	%edi, %esi
	addl	%ebx, %ecx
	addl	%eax, %r14d
	movl	%esi, (%rdx)
	incl	%r15d
	cmpl	%r13d, %ecx
	jg	LBB13_9
## %bb.5:                               ##   in Loop: Header=BB13_4 Depth=1
	addq	$4, %rdx
	cmpl	%r10d, %r14d
	jle	LBB13_4
	jmp	LBB13_9
LBB13_6:
	movl	%ebx, %ecx
	jmp	LBB13_8
LBB13_7:
	movl	%ebx, %ecx
	movq	%r15, %r10
LBB13_8:
	movl	%ebx, %r15d
LBB13_9:
	movl	%r13d, %r11d
	subl	%ecx, %r11d
	jl	LBB13_30
## %bb.10:
	movslq	%r15d, %r15
	movslq	%ecx, %rcx
	cmpl	$31, %r11d
	jb	LBB13_23
## %bb.11:
	movq	_b@GOTPCREL(%rip), %rbx
	leaq	(%rbx,%r15,4), %rdx
	leaq	(%rcx,%r11), %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rdx
	jae	LBB13_13
## %bb.12:
	leaq	(%r15,%r11), %rdx
	leaq	(%rbx,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r12,%rcx,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB13_23
LBB13_13:
	movq	%r10, %rax
	incq	%r11
	movq	%r11, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rdi
	shrq	$5, %rdi
	incq	%rdi
	movl	%edi, %r10d
	andl	$3, %r10d
	cmpq	$96, %rdx
	jae	LBB13_15
## %bb.14:
	xorl	%esi, %esi
	jmp	LBB13_17
LBB13_15:
	leaq	(%r12,%rcx,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	(%rbx,%r15,4), %r8
	addq	$480, %r8                       ## imm = 0x1E0
	andq	$-4, %rdi
	negq	%rdi
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB13_16:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdx,%rsi,4), %ymm0
	vmovups	-448(%rdx,%rsi,4), %ymm1
	vmovups	-416(%rdx,%rsi,4), %ymm2
	vmovups	-384(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%r8,%rsi,4)
	vmovups	%ymm1, -448(%r8,%rsi,4)
	vmovups	%ymm2, -416(%r8,%rsi,4)
	vmovups	%ymm3, -384(%r8,%rsi,4)
	vmovups	-352(%rdx,%rsi,4), %ymm0
	vmovups	-320(%rdx,%rsi,4), %ymm1
	vmovups	-288(%rdx,%rsi,4), %ymm2
	vmovups	-256(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%r8,%rsi,4)
	vmovups	%ymm1, -320(%r8,%rsi,4)
	vmovups	%ymm2, -288(%r8,%rsi,4)
	vmovups	%ymm3, -256(%r8,%rsi,4)
	vmovups	-224(%rdx,%rsi,4), %ymm0
	vmovups	-192(%rdx,%rsi,4), %ymm1
	vmovups	-160(%rdx,%rsi,4), %ymm2
	vmovups	-128(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%r8,%rsi,4)
	vmovups	%ymm1, -192(%r8,%rsi,4)
	vmovups	%ymm2, -160(%r8,%rsi,4)
	vmovups	%ymm3, -128(%r8,%rsi,4)
	vmovups	-96(%rdx,%rsi,4), %ymm0
	vmovups	-64(%rdx,%rsi,4), %ymm1
	vmovups	-32(%rdx,%rsi,4), %ymm2
	vmovups	(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%r8,%rsi,4)
	vmovups	%ymm1, -64(%r8,%rsi,4)
	vmovups	%ymm2, -32(%r8,%rsi,4)
	vmovups	%ymm3, (%r8,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %rdi
	jne	LBB13_16
LBB13_17:
	testq	%r10, %r10
	je	LBB13_20
## %bb.18:
	leaq	(%rsi,%r15), %rdx
	leaq	(%rbx,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%rcx, %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r10
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB13_19:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r10
	jne	LBB13_19
LBB13_20:
	addq	%r9, %r15
	cmpq	%r9, %r11
	jne	LBB13_22
## %bb.21:
	movq	%rax, %r10
	jmp	LBB13_30
LBB13_22:
	addq	%r9, %rcx
	movq	%rax, %r10
LBB13_23:
	movl	%r13d, %r8d
	subl	%ecx, %r8d
	leal	1(%r8), %esi
	andl	$7, %esi
	je	LBB13_26
## %bb.24:
	movq	_b@GOTPCREL(%rip), %rdi
	.p2align	4, 0x90
LBB13_25:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r12,%rcx,4), %edx
	incq	%rcx
	movl	%edx, (%rdi,%r15,4)
	incq	%r15
	decl	%esi
	jne	LBB13_25
LBB13_26:
	cmpl	$7, %r8d
	jb	LBB13_30
## %bb.27:
	subl	%ecx, %r13d
	incl	%r13d
	leaq	(%r12,%rcx,4), %rcx
	addq	$28, %rcx
	movq	_b@GOTPCREL(%rip), %rdx
	leaq	(%rdx,%r15,4), %rsi
	addq	$28, %rsi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB13_28:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rcx,%rdx,4), %eax
	movl	%eax, -28(%rsi,%rdx,4)
	movl	-24(%rcx,%rdx,4), %eax
	movl	%eax, -24(%rsi,%rdx,4)
	movl	-20(%rcx,%rdx,4), %eax
	movl	%eax, -20(%rsi,%rdx,4)
	movl	-16(%rcx,%rdx,4), %eax
	movl	%eax, -16(%rsi,%rdx,4)
	movl	-12(%rcx,%rdx,4), %eax
	movl	%eax, -12(%rsi,%rdx,4)
	movl	-8(%rcx,%rdx,4), %eax
	movl	%eax, -8(%rsi,%rdx,4)
	movl	-4(%rcx,%rdx,4), %eax
	movl	%eax, -4(%rsi,%rdx,4)
	movl	(%rcx,%rdx,4), %eax
	movl	%eax, (%rsi,%rdx,4)
	addq	$8, %rdx
	cmpl	%edx, %r13d
	jne	LBB13_28
## %bb.29:
	addq	%rdx, %r15
LBB13_30:
	cmpl	%r10d, %r14d
	jg	LBB13_51
## %bb.31:
	movslq	%r15d, %rax
	movslq	%r14d, %rcx
	movq	%r10, %r15
                                        ## kill: def $r10d killed $r10d killed $r10 def $r10
	subl	%r14d, %r10d
	cmpl	$31, %r10d
	jb	LBB13_32
## %bb.33:
	movq	_b@GOTPCREL(%rip), %r8
	leaq	(%r8,%rax,4), %rdx
	leaq	(%rcx,%r10), %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rdx
	jae	LBB13_36
## %bb.34:
	leaq	(%rax,%r10), %rdx
	leaq	(%r8,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r12,%rcx,4), %rsi
	cmpq	%rdx, %rsi
	jae	LBB13_36
LBB13_32:
	movq	%r15, %r10
LBB13_45:
	movl	%r10d, %edx
	subl	%ecx, %edx
	leal	1(%rdx), %esi
	andl	$7, %esi
	je	LBB13_48
## %bb.46:
	movq	_b@GOTPCREL(%rip), %rdi
	.p2align	4, 0x90
LBB13_47:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r12,%rcx,4), %ebx
	incq	%rcx
	movl	%ebx, (%rdi,%rax,4)
	incq	%rax
	decl	%esi
	jne	LBB13_47
LBB13_48:
	cmpl	$7, %edx
	jb	LBB13_51
## %bb.49:
	movl	%r10d, %edx
	subl	%ecx, %edx
	incl	%edx
	leaq	(%r12,%rcx,4), %rcx
	addq	$28, %rcx
	movq	_b@GOTPCREL(%rip), %rsi
	leaq	(%rsi,%rax,4), %rax
	addq	$28, %rax
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB13_50:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rcx,%rsi,4), %edi
	movl	%edi, -28(%rax,%rsi,4)
	movl	-24(%rcx,%rsi,4), %edi
	movl	%edi, -24(%rax,%rsi,4)
	movl	-20(%rcx,%rsi,4), %edi
	movl	%edi, -20(%rax,%rsi,4)
	movl	-16(%rcx,%rsi,4), %edi
	movl	%edi, -16(%rax,%rsi,4)
	movl	-12(%rcx,%rsi,4), %edi
	movl	%edi, -12(%rax,%rsi,4)
	movl	-8(%rcx,%rsi,4), %edi
	movl	%edi, -8(%rax,%rsi,4)
	movl	-4(%rcx,%rsi,4), %edi
	movl	%edi, -4(%rax,%rsi,4)
	movl	(%rcx,%rsi,4), %edi
	movl	%edi, (%rax,%rsi,4)
	addq	$8, %rsi
	cmpl	%esi, %edx
	jne	LBB13_50
	jmp	LBB13_51
LBB13_36:
	incq	%r10
	movq	%r10, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rbx
	shrq	$5, %rbx
	incq	%rbx
	movl	%ebx, %r11d
	andl	$3, %r11d
	cmpq	$96, %rdx
	jae	LBB13_38
## %bb.37:
	xorl	%esi, %esi
	jmp	LBB13_40
LBB13_38:
	leaq	(%r12,%rcx,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	(%r8,%rax,4), %rdi
	addq	$480, %rdi                      ## imm = 0x1E0
	andq	$-4, %rbx
	negq	%rbx
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB13_39:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdx,%rsi,4), %ymm0
	vmovups	-448(%rdx,%rsi,4), %ymm1
	vmovups	-416(%rdx,%rsi,4), %ymm2
	vmovups	-384(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%rdi,%rsi,4)
	vmovups	%ymm1, -448(%rdi,%rsi,4)
	vmovups	%ymm2, -416(%rdi,%rsi,4)
	vmovups	%ymm3, -384(%rdi,%rsi,4)
	vmovups	-352(%rdx,%rsi,4), %ymm0
	vmovups	-320(%rdx,%rsi,4), %ymm1
	vmovups	-288(%rdx,%rsi,4), %ymm2
	vmovups	-256(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%rdi,%rsi,4)
	vmovups	%ymm1, -320(%rdi,%rsi,4)
	vmovups	%ymm2, -288(%rdi,%rsi,4)
	vmovups	%ymm3, -256(%rdi,%rsi,4)
	vmovups	-224(%rdx,%rsi,4), %ymm0
	vmovups	-192(%rdx,%rsi,4), %ymm1
	vmovups	-160(%rdx,%rsi,4), %ymm2
	vmovups	-128(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%rdi,%rsi,4)
	vmovups	%ymm1, -192(%rdi,%rsi,4)
	vmovups	%ymm2, -160(%rdi,%rsi,4)
	vmovups	%ymm3, -128(%rdi,%rsi,4)
	vmovups	-96(%rdx,%rsi,4), %ymm0
	vmovups	-64(%rdx,%rsi,4), %ymm1
	vmovups	-32(%rdx,%rsi,4), %ymm2
	vmovups	(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%rdi,%rsi,4)
	vmovups	%ymm1, -64(%rdi,%rsi,4)
	vmovups	%ymm2, -32(%rdi,%rsi,4)
	vmovups	%ymm3, (%rdi,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %rbx
	jne	LBB13_39
LBB13_40:
	testq	%r11, %r11
	je	LBB13_43
## %bb.41:
	leaq	(%rsi,%rax), %rdx
	leaq	(%r8,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%rcx, %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r11
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB13_42:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r11
	jne	LBB13_42
LBB13_43:
	cmpq	%r9, %r10
	movq	%r15, %r10
	jne	LBB13_44
LBB13_51:
	movl	%r10d, %ecx
	movq	-48(%rbp), %rax                 ## 8-byte Reload
	subl	%eax, %ecx
	jl	LBB13_70
## %bb.52:
	cltq
	cmpl	$31, %ecx
	jb	LBB13_64
## %bb.53:
	leaq	(%r12,%rax,4), %rdi
	leaq	(%rcx,%rax), %rdx
	movq	_b@GOTPCREL(%rip), %rsi
	leaq	(%rsi,%rdx,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rdi
	jae	LBB13_55
## %bb.54:
	leaq	(%r12,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%rsi,%rax,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB13_64
LBB13_55:
	incq	%rcx
	movq	%rcx, %r8
	andq	$-32, %r8
	leaq	-32(%r8), %rdx
	movq	%rdx, %rdi
	shrq	$5, %rdi
	incq	%rdi
	movl	%edi, %r9d
	andl	$3, %r9d
	cmpq	$96, %rdx
	jae	LBB13_57
## %bb.56:
	xorl	%ebx, %ebx
	jmp	LBB13_59
LBB13_44:
	addq	%r9, %rcx
	addq	%r9, %rax
	jmp	LBB13_45
LBB13_57:
	leaq	(%r12,%rax,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	480(,%rax,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	andq	$-4, %rdi
	negq	%rdi
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB13_58:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rsi,%rbx,4), %ymm0
	vmovups	-448(%rsi,%rbx,4), %ymm1
	vmovups	-416(%rsi,%rbx,4), %ymm2
	vmovups	-384(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rbx,4)
	vmovups	%ymm1, -448(%rdx,%rbx,4)
	vmovups	%ymm2, -416(%rdx,%rbx,4)
	vmovups	%ymm3, -384(%rdx,%rbx,4)
	vmovups	-352(%rsi,%rbx,4), %ymm0
	vmovups	-320(%rsi,%rbx,4), %ymm1
	vmovups	-288(%rsi,%rbx,4), %ymm2
	vmovups	-256(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rbx,4)
	vmovups	%ymm1, -320(%rdx,%rbx,4)
	vmovups	%ymm2, -288(%rdx,%rbx,4)
	vmovups	%ymm3, -256(%rdx,%rbx,4)
	vmovups	-224(%rsi,%rbx,4), %ymm0
	vmovups	-192(%rsi,%rbx,4), %ymm1
	vmovups	-160(%rsi,%rbx,4), %ymm2
	vmovups	-128(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rbx,4)
	vmovups	%ymm1, -192(%rdx,%rbx,4)
	vmovups	%ymm2, -160(%rdx,%rbx,4)
	vmovups	%ymm3, -128(%rdx,%rbx,4)
	vmovups	-96(%rsi,%rbx,4), %ymm0
	vmovups	-64(%rsi,%rbx,4), %ymm1
	vmovups	-32(%rsi,%rbx,4), %ymm2
	vmovups	(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx,4)
	vmovups	%ymm1, -64(%rdx,%rbx,4)
	vmovups	%ymm2, -32(%rdx,%rbx,4)
	vmovups	%ymm3, (%rdx,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %rdi
	jne	LBB13_58
LBB13_59:
	testq	%r9, %r9
	je	LBB13_62
## %bb.60:
	addq	%rax, %rbx
	leaq	(%r12,%rbx,4), %rdx
	addq	$96, %rdx
	leaq	96(,%rbx,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	shlq	$7, %r9
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB13_61:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r9
	jne	LBB13_61
LBB13_62:
	cmpq	%r8, %rcx
	je	LBB13_70
## %bb.63:
	addq	%r8, %rax
LBB13_64:
	leal	1(%r10), %ecx
	movl	%ecx, %edx
	subl	%eax, %edx
	subl	%eax, %r10d
	andl	$7, %edx
	je	LBB13_67
## %bb.65:
	movq	_b@GOTPCREL(%rip), %rsi
	.p2align	4, 0x90
LBB13_66:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rsi,%rax,4), %edi
	movl	%edi, (%r12,%rax,4)
	incq	%rax
	decl	%edx
	jne	LBB13_66
LBB13_67:
	cmpl	$7, %r10d
	jb	LBB13_70
## %bb.68:
	movl	%ecx, %ecx
	movq	_b@GOTPCREL(%rip), %rdx
	.p2align	4, 0x90
LBB13_69:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdx,%rax,4), %esi
	movl	%esi, (%r12,%rax,4)
	movl	4(%rdx,%rax,4), %esi
	movl	%esi, 4(%r12,%rax,4)
	movl	8(%rdx,%rax,4), %esi
	movl	%esi, 8(%r12,%rax,4)
	movl	12(%rdx,%rax,4), %esi
	movl	%esi, 12(%r12,%rax,4)
	movl	16(%rdx,%rax,4), %esi
	movl	%esi, 16(%r12,%rax,4)
	movl	20(%rdx,%rax,4), %esi
	movl	%esi, 20(%r12,%rax,4)
	movl	24(%rdx,%rax,4), %esi
	movl	%esi, 24(%r12,%rax,4)
	movl	28(%rdx,%rax,4), %esi
	movl	%esi, 28(%r12,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %ecx
	jne	LBB13_69
LBB13_70:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_max                            ## -- Begin function max
	.p2align	4, 0x90
_max:                                   ## @max
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	%esi, %eax
	cmpl	%esi, %edi
	cmovgl	%edi, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_optimized      ## -- Begin function partition_quick_optimized
	.p2align	4, 0x90
_partition_quick_optimized:             ## @partition_quick_optimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB15_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %r9d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r15d
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r11d
	cmpl	%r15d, %r9d
	movl	%r15d, %ebx
	cmovll	%r9d, %ebx
	movl	%r15d, %r14d
	cmovgl	%r9d, %r14d
	cmpl	%r11d, %ebx
	cmovgel	%r11d, %ebx
	cmpl	%r11d, %r14d
	cmovlel	%r11d, %r14d
	addl	%r9d, %r15d
	addl	%r11d, %r15d
	subl	%ebx, %r15d
	subl	%r14d, %r15d
	movl	%ebx, (%rdi,%rax,4)
	movl	%r15d, (%rdi,%r8,4)
	movl	%r14d, (%rdi,%r10,4)
	cmpl	%esi, %edx
	jg	LBB15_4
	jmp	LBB15_10
LBB15_2:
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r15d
	movslq	%esi, %rax
	cmpl	%esi, %edx
	jle	LBB15_10
LBB15_4:
	movl	%r8d, %edx
	subl	%eax, %edx
	leaq	1(%rax), %r9
	testb	$1, %dl
	jne	LBB15_6
## %bb.5:
	movq	%rax, %rdx
	cmpq	%r9, %r8
	jne	LBB15_8
	jmp	LBB15_10
LBB15_6:
	movl	(%rdi,%rax,4), %edx
	xorl	%ebx, %ebx
	xorl	%esi, %esi
	cmpl	%edx, %r15d
	setg	%bl
	setle	%sil
	movq	_x@GOTPCREL(%rip), %r10
	movl	%edx, (%r10)
	movl	(%rdi,%rax,4), %edx
	movl	%edx, 4(%r10)
	movl	(%r10,%rsi,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	(%r10,%rbx,4), %edx
	movl	%edx, (%rdi,%rax,4)
	addq	%rbx, %rax
	movq	%r9, %rdx
	cmpq	%r9, %r8
	je	LBB15_10
LBB15_8:
	movq	_x@GOTPCREL(%rip), %r9
	.p2align	4, 0x90
LBB15_9:                                ## =>This Inner Loop Header: Depth=1
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	cmpl	(%rdi,%rdx,4), %r15d
	setg	%bl
	setle	%cl
	movl	(%rdi,%rax,4), %esi
	movl	%esi, (%r9)
	movl	(%rdi,%rdx,4), %esi
	movl	%esi, 4(%r9)
	movl	(%r9,%rcx,4), %ecx
	movl	%ecx, (%rdi,%rdx,4)
	movl	(%r9,%rbx,4), %ecx
	movl	%ecx, (%rdi,%rax,4)
	addq	%rbx, %rax
	xorl	%ecx, %ecx
	xorl	%esi, %esi
	cmpl	4(%rdi,%rdx,4), %r15d
	setg	%cl
	setle	%sil
	movl	(%rdi,%rax,4), %ebx
	movl	%ebx, (%r9)
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ebx, 4(%r9)
	movl	(%r9,%rsi,4), %esi
	movl	%esi, 4(%rdi,%rdx,4)
	movl	(%r9,%rcx,4), %esi
	movl	%esi, (%rdi,%rax,4)
	addq	%rcx, %rax
	addq	$2, %rdx
	cmpq	%rdx, %r8
	jne	LBB15_9
LBB15_10:
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r8,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r8,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_optimized           ## -- Begin function sort_quick_optimized
	.p2align	4, 0x90
_sort_quick_optimized:                  ## @sort_quick_optimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB16_11
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %rbx
	movslq	%edx, %r15
	movq	%r15, %rax
	negq	%rax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	movq	_x@GOTPCREL(%rip), %r13
	jmp	LBB16_2
	.p2align	4, 0x90
LBB16_10:                               ##   in Loop: Header=BB16_2 Depth=1
	movl	(%rbx,%r12,4), %eax
	movl	(%rbx,%r15,4), %ecx
	movl	%ecx, (%rbx,%r12,4)
	movl	%eax, (%rbx,%r15,4)
	leal	-1(%r12), %edx
	movq	%rbx, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	callq	_sort_quick_optimized
	incl	%r12d
	movl	%r12d, %esi
	cmpl	%r14d, %r12d
	jge	LBB16_11
LBB16_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB16_9 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB16_11
## %bb.3:                               ##   in Loop: Header=BB16_2 Depth=1
	cmpl	$1, %eax
	jne	LBB16_4
## %bb.5:                               ##   in Loop: Header=BB16_2 Depth=1
	movl	(%rbx,%r15,4), %r11d
	movslq	%esi, %rcx
	jmp	LBB16_6
	.p2align	4, 0x90
LBB16_4:                                ##   in Loop: Header=BB16_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %edx
	shrl	$31, %edx
	addl	%eax, %edx
	sarl	%edx
	movslq	%esi, %rcx
	movl	(%rbx,%rcx,4), %r9d
	movslq	%edx, %r8
	movl	(%rbx,%r8,4), %r11d
	movl	(%rbx,%r15,4), %r10d
	cmpl	%r11d, %r9d
	movl	%r11d, %edi
	cmovll	%r9d, %edi
	movl	%r11d, %edx
	cmovgl	%r9d, %edx
	cmpl	%r10d, %edi
	cmovgel	%r10d, %edi
	cmpl	%r10d, %edx
	cmovlel	%r10d, %edx
	addl	%r9d, %r11d
	addl	%r10d, %r11d
	subl	%edi, %r11d
	subl	%edx, %r11d
	movl	%edi, (%rbx,%rcx,4)
	movl	%r11d, (%rbx,%r15,4)
	movl	%edx, (%rbx,%r8,4)
LBB16_6:                                ##   in Loop: Header=BB16_2 Depth=1
	movl	%r14d, %edi
	subl	%ecx, %edi
	movq	%rcx, %r12
	movq	%rcx, %rdx
	testb	$1, %dil
	je	LBB16_8
## %bb.7:                               ##   in Loop: Header=BB16_2 Depth=1
	movl	(%rbx,%rcx,4), %edx
	xorl	%r12d, %r12d
	xorl	%edi, %edi
	cmpl	%edx, %r11d
	setg	%r12b
	setle	%dil
	movl	%edx, (%r13)
	movl	(%rbx,%rcx,4), %edx
	movl	%edx, 4(%r13)
	movl	(%r13,%rdi,4), %edx
	movl	%edx, (%rbx,%rcx,4)
	movl	(%r13,%r12,4), %edx
	movl	%edx, (%rbx,%rcx,4)
	addq	%rcx, %r12
	leaq	1(%rcx), %rdx
LBB16_8:                                ##   in Loop: Header=BB16_2 Depth=1
	notq	%rcx
	cmpq	-48(%rbp), %rcx                 ## 8-byte Folded Reload
	je	LBB16_10
	.p2align	4, 0x90
LBB16_9:                                ##   Parent Loop BB16_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	xorl	%ecx, %ecx
	xorl	%edi, %edi
	cmpl	(%rbx,%rdx,4), %r11d
	setg	%cl
	setle	%dil
	movl	(%rbx,%r12,4), %eax
	movl	%eax, (%r13)
	movl	(%rbx,%rdx,4), %eax
	movl	%eax, 4(%r13)
	movl	(%r13,%rdi,4), %eax
	movl	%eax, (%rbx,%rdx,4)
	movl	(%r13,%rcx,4), %eax
	movl	%eax, (%rbx,%r12,4)
	addq	%rcx, %r12
	xorl	%eax, %eax
	xorl	%ecx, %ecx
	cmpl	4(%rbx,%rdx,4), %r11d
	setg	%al
	setle	%cl
	movl	(%rbx,%r12,4), %edi
	movl	%edi, (%r13)
	movl	4(%rbx,%rdx,4), %edi
	movl	%edi, 4(%r13)
	movl	(%r13,%rcx,4), %ecx
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	(%r13,%rax,4), %ecx
	movl	%ecx, (%rbx,%r12,4)
	addq	%rax, %r12
	addq	$2, %rdx
	cmpq	%rdx, %r15
	jne	LBB16_9
	jmp	LBB16_10
LBB16_11:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_hsum_epi32_avx                 ## -- Begin function hsum_epi32_avx
	.p2align	4, 0x90
_hsum_epi32_avx:                        ## @hsum_epi32_avx
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	vpshufd	$238, %xmm0, %xmm1              ## xmm1 = xmm0[2,3,2,3]
	vpaddd	%xmm0, %xmm1, %xmm0
	vpshufd	$85, %xmm0, %xmm1               ## xmm1 = xmm0[1,1,1,1]
	vpaddd	%xmm0, %xmm1, %xmm0
	vmovd	%xmm0, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_hsum_8x32                      ## -- Begin function hsum_8x32
	.p2align	4, 0x90
_hsum_8x32:                             ## @hsum_8x32
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	vextracti128	$1, %ymm0, %xmm1
	vpaddd	%xmm0, %xmm1, %xmm0
	vpshufd	$238, %xmm0, %xmm1              ## xmm1 = xmm0[2,3,2,3]
	vpaddd	%xmm1, %xmm0, %xmm0
	vpshufd	$85, %xmm0, %xmm1               ## xmm1 = xmm0[1,1,1,1]
	vpaddd	%xmm0, %xmm1, %xmm0
	vmovd	%xmm0, %eax
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_multi          ## -- Begin function partition_quick_multi
	.p2align	4, 0x90
_partition_quick_multi:                 ## @partition_quick_multi
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%rbx
	.cfi_offset %rbx, -24
	movl	%edx, %r8d
	movslq	%esi, %rax
	subl	%esi, %r8d
	jle	LBB19_1
## %bb.7:
	vmovdqu	(%rdi,%rax,4), %ymm0
	movslq	%edx, %r10
	vmovd	%xmm0, %r11d
	leaq	1(%rax), %rsi
	movq	_tmp@GOTPCREL(%rip), %r9
	.p2align	4, 0x90
LBB19_8:                                ## =>This Inner Loop Header: Depth=1
	vmovd	%r11d, %xmm1
	vpbroadcastd	%xmm1, %ymm1
	vpcmpgtd	%ymm1, %ymm0, %ymm1
	vextracti128	$1, %ymm1, %xmm2
	vpaddd	%xmm1, %xmm2, %xmm1
	vpshufd	$238, %xmm1, %xmm2              ## xmm2 = xmm1[2,3,2,3]
	vpaddd	%xmm2, %xmm1, %xmm1
	vpshufd	$85, %xmm1, %xmm2               ## xmm2 = xmm1[1,1,1,1]
	vpaddd	%xmm1, %xmm2, %xmm1
	vmovd	%xmm1, %edx
	addl	$8, %edx
	movslq	(%rcx,%rdx,4), %rbx
	movl	%r11d, (%r9,%rbx,4)
	incl	(%rcx,%rdx,4)
	cmpq	%rsi, %r10
	je	LBB19_1
## %bb.9:                               ##   in Loop: Header=BB19_8 Depth=1
	movl	(%rdi,%rsi,4), %r11d
	incq	%rsi
	jmp	LBB19_8
LBB19_1:
	movslq	%r8d, %r8
	xorl	%r11d, %r11d
	movq	_tmp@GOTPCREL(%rip), %r10
	jmp	LBB19_2
	.p2align	4, 0x90
LBB19_5:                                ##   in Loop: Header=BB19_2 Depth=1
	subl	%r9d, %esi
	movl	%esi, (%rcx,%r11,4)
	incq	%r11
	cmpq	$9, %r11
	je	LBB19_6
LBB19_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB19_10 Depth 2
                                        ##     Child Loop BB19_4 Depth 2
	movq	%r11, %r9
	imulq	%r8, %r9
	movslq	(%rcx,%r11,4), %rsi
	movq	%rsi, %rbx
	addq	$-8, %rbx
	movq	%r9, %rdx
	cmpq	%rbx, %r9
	jge	LBB19_3
	.p2align	4, 0x90
LBB19_10:                               ##   Parent Loop BB19_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	vmovdqu	(%r10,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%rdi,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	movslq	(%rcx,%r11,4), %rsi
	leaq	-8(%rsi), %rbx
	cmpq	%rbx, %rdx
	jl	LBB19_10
LBB19_3:                                ##   in Loop: Header=BB19_2 Depth=1
	movslq	%esi, %rbx
	cmpq	%rbx, %rdx
	jge	LBB19_5
	.p2align	4, 0x90
LBB19_4:                                ##   Parent Loop BB19_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r10,%rdx,4), %esi
	movl	%esi, (%rdi,%rax,4)
	incq	%rax
	incq	%rdx
	movslq	(%rcx,%r11,4), %rsi
	cmpq	%rsi, %rdx
	jl	LBB19_4
	jmp	LBB19_5
LBB19_6:
	popq	%rbx
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.section	__TEXT,__literal16,16byte_literals
	.p2align	4                               ## -- Begin function sort_quick_multi
LCPI20_0:
	.long	2                               ## 0x2
	.long	3                               ## 0x3
	.long	4                               ## 0x4
	.long	5                               ## 0x5
	.section	__TEXT,__text,regular,pure_instructions
	.globl	_sort_quick_multi
	.p2align	4, 0x90
_sort_quick_multi:                      ## @sort_quick_multi
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$120, %rsp
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	movq	%rax, -48(%rbp)
	movl	%edx, %eax
	subl	%esi, %eax
	jle	LBB20_39
## %bb.1:
	movq	%rdi, %r14
	cmpl	$201, %eax
	jl	LBB20_37
## %bb.2:
	leal	1(%rax), %ecx
	movl	$0, -96(%rbp)
	movl	%ecx, -92(%rbp)
	vmovd	%ecx, %xmm0
	vpbroadcastd	%xmm0, %xmm0
	vpmulld	LCPI20_0(%rip), %xmm0, %xmm0
	vmovdqu	%xmm0, -88(%rbp)
	leal	2(%rax,%rax), %edi
	leal	(%rdi,%rdi,2), %edi
	movl	%edi, -72(%rbp)
	leal	8(,%rax,8), %eax
	movl	%eax, %edi
	subl	%ecx, %edi
	movl	%edi, -68(%rbp)
	movl	%eax, -64(%rbp)
	incl	%edx
	movslq	%edx, %r10
	subl	%esi, %edx
	movslq	%edx, %r9
	movq	%rsi, -160(%rbp)                ## 8-byte Spill
	movslq	%esi, %rax
	vmovdqu	(%r14,%rax,4), %ymm0
	vmovdqu	(%r14,%rax,4), %xmm1
	vmovd	%xmm1, %edi
	leaq	1(%rax), %rsi
	movq	_tmp@GOTPCREL(%rip), %r8
	.p2align	4, 0x90
LBB20_3:                                ## =>This Inner Loop Header: Depth=1
	vmovd	%edi, %xmm1
	vpbroadcastd	%xmm1, %ymm1
	vpcmpgtd	%ymm1, %ymm0, %ymm1
	vextracti128	$1, %ymm1, %xmm2
	vpaddd	%xmm1, %xmm2, %xmm1
	vpshufd	$238, %xmm1, %xmm2              ## xmm2 = xmm1[2,3,2,3]
	vpaddd	%xmm2, %xmm1, %xmm1
	vpshufd	$85, %xmm1, %xmm2               ## xmm2 = xmm1[1,1,1,1]
	vpaddd	%xmm1, %xmm2, %xmm1
	vmovd	%xmm1, %ebx
	addl	$8, %ebx
	movslq	-96(%rbp,%rbx,4), %rcx
	movl	%edi, (%r8,%rcx,4)
	incl	%ecx
	movl	%ecx, -96(%rbp,%rbx,4)
	cmpq	%rsi, %r10
	je	LBB20_4
## %bb.6:                               ##   in Loop: Header=BB20_3 Depth=1
	movl	(%r14,%rsi,4), %edi
	incq	%rsi
	jmp	LBB20_3
LBB20_37:
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB20_206
## %bb.38:
	movq	%r14, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	addq	$120, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	jmp	_sort_quick_optimized           ## TAILCALL
LBB20_4:
	movslq	-96(%rbp), %r15
	cmpq	$9, %r15
	jl	LBB20_5
## %bb.35:
	leaq	-8(%r15), %rsi
	leaq	(%r14,%rax,4), %rdi
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB20_36:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rcx,4), %ymm0
	vmovdqu	%ymm0, (%rdi,%rcx,4)
	addq	$8, %rcx
	cmpq	%rsi, %rcx
	jl	LBB20_36
## %bb.7:
	addq	%rcx, %rax
	cmpq	%r15, %rcx
	movq	%r15, -152(%rbp)                ## 8-byte Spill
	jl	LBB20_9
	jmp	LBB20_27
LBB20_5:
	xorl	%ecx, %ecx
	cmpq	%r15, %rcx
	movq	%r15, -152(%rbp)                ## 8-byte Spill
	jge	LBB20_27
LBB20_9:
	movq	%r15, %r11
	subq	%rcx, %r11
	cmpq	$32, %r11
	jb	LBB20_21
## %bb.10:
	leaq	(%r14,%rax,4), %rsi
	leaq	(%r8,%r15,4), %rdi
	cmpq	%rdi, %rsi
	jae	LBB20_12
## %bb.11:
	leaq	(%rax,%r15), %rsi
	subq	%rcx, %rsi
	leaq	(%r14,%rsi,4), %rsi
	leaq	(%r8,%rcx,4), %rdi
	cmpq	%rsi, %rdi
	jb	LBB20_21
LBB20_12:
	movq	%r11, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %r12
	shrq	$5, %r12
	incq	%r12
	movl	%r12d, %r15d
	andl	$3, %r15d
	cmpq	$96, %rsi
	jae	LBB20_14
## %bb.13:
	xorl	%edi, %edi
	jmp	LBB20_16
LBB20_14:
	leaq	(%r8,%rcx,4), %r13
	addq	$480, %r13                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	andq	$-4, %r12
	negq	%r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_15:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%r13,%rdi,4), %ymm0
	vmovups	-448(%r13,%rdi,4), %ymm1
	vmovups	-416(%r13,%rdi,4), %ymm2
	vmovups	-384(%r13,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rbx,%rdi,4)
	vmovups	%ymm1, -448(%rbx,%rdi,4)
	vmovups	%ymm2, -416(%rbx,%rdi,4)
	vmovups	%ymm3, -384(%rbx,%rdi,4)
	vmovups	-352(%r13,%rdi,4), %ymm0
	vmovups	-320(%r13,%rdi,4), %ymm1
	vmovups	-288(%r13,%rdi,4), %ymm2
	vmovups	-256(%r13,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rbx,%rdi,4)
	vmovups	%ymm1, -320(%rbx,%rdi,4)
	vmovups	%ymm2, -288(%rbx,%rdi,4)
	vmovups	%ymm3, -256(%rbx,%rdi,4)
	vmovups	-224(%r13,%rdi,4), %ymm0
	vmovups	-192(%r13,%rdi,4), %ymm1
	vmovups	-160(%r13,%rdi,4), %ymm2
	vmovups	-128(%r13,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rbx,%rdi,4)
	vmovups	%ymm1, -192(%rbx,%rdi,4)
	vmovups	%ymm2, -160(%rbx,%rdi,4)
	vmovups	%ymm3, -128(%rbx,%rdi,4)
	vmovdqu	-96(%r13,%rdi,4), %ymm0
	vmovdqu	-64(%r13,%rdi,4), %ymm1
	vmovdqu	-32(%r13,%rdi,4), %ymm2
	vmovups	(%r13,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rbx,%rdi,4)
	vmovdqu	%ymm1, -64(%rbx,%rdi,4)
	vmovdqu	%ymm2, -32(%rbx,%rdi,4)
	vmovups	%ymm3, (%rbx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r12
	jne	LBB20_15
LBB20_16:
	testq	%r15, %r15
	je	LBB20_19
## %bb.17:
	leaq	(%rax,%rdi), %rsi
	leaq	(%r14,%rsi,4), %rsi
	addq	$96, %rsi
	addq	%rcx, %rdi
	leaq	(%r8,%rdi,4), %rdi
	addq	$96, %rdi
	shlq	$7, %r15
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB20_18:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rdi,%rbx), %ymm0
	vmovdqu	-64(%rdi,%rbx), %ymm1
	vmovdqu	-32(%rdi,%rbx), %ymm2
	vmovups	(%rdi,%rbx), %ymm3
	vmovdqu	%ymm0, -96(%rsi,%rbx)
	vmovdqu	%ymm1, -64(%rsi,%rbx)
	vmovdqu	%ymm2, -32(%rsi,%rbx)
	vmovups	%ymm3, (%rsi,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r15
	jne	LBB20_18
LBB20_19:
	addq	%r10, %rax
	cmpq	%r10, %r11
	movq	-152(%rbp), %r15                ## 8-byte Reload
	je	LBB20_27
## %bb.20:
	addq	%r10, %rcx
LBB20_21:
	movl	%r15d, %edi
	subl	%ecx, %edi
	movq	%rcx, %rsi
	notq	%rsi
	addq	%r15, %rsi
	andq	$7, %rdi
	je	LBB20_23
	.p2align	4, 0x90
LBB20_22:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rcx,4), %ebx
	movl	%ebx, (%r14,%rax,4)
	incq	%rax
	incq	%rcx
	decq	%rdi
	jne	LBB20_22
LBB20_23:
	cmpq	$7, %rsi
	jb	LBB20_27
## %bb.24:
	movq	%r15, %r10
	subq	%rcx, %r10
	leaq	(%r8,%rcx,4), %rdi
	addq	$28, %rdi
	leaq	(%r14,%rax,4), %rbx
	addq	$28, %rbx
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB20_25:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rdi,%rcx,4), %esi
	movl	%esi, -28(%rbx,%rcx,4)
	movl	-24(%rdi,%rcx,4), %esi
	movl	%esi, -24(%rbx,%rcx,4)
	movl	-20(%rdi,%rcx,4), %esi
	movl	%esi, -20(%rbx,%rcx,4)
	movl	-16(%rdi,%rcx,4), %esi
	movl	%esi, -16(%rbx,%rcx,4)
	movl	-12(%rdi,%rcx,4), %esi
	movl	%esi, -12(%rbx,%rcx,4)
	movl	-8(%rdi,%rcx,4), %esi
	movl	%esi, -8(%rbx,%rcx,4)
	movl	-4(%rdi,%rcx,4), %esi
	movl	%esi, -4(%rbx,%rcx,4)
	movl	(%rdi,%rcx,4), %esi
	movl	%esi, (%rbx,%rcx,4)
	addq	$8, %rcx
	cmpq	%rcx, %r10
	jne	LBB20_25
## %bb.26:
	addq	%rcx, %rax
LBB20_27:
	movslq	-92(%rbp), %r15
	leaq	-8(%r15), %rsi
	movq	%r9, %rcx
	cmpl	%esi, %edx
	jge	LBB20_29
	.p2align	4, 0x90
LBB20_28:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rcx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rcx
	cmpq	%rsi, %rcx
	jl	LBB20_28
LBB20_29:
	cmpq	%r15, %rcx
	jge	LBB20_54
## %bb.30:
	movq	%r15, %r11
	subq	%rcx, %r11
	cmpq	$32, %r11
	jb	LBB20_48
## %bb.31:
	leaq	(%r14,%rax,4), %rsi
	leaq	(%r8,%r15,4), %rdi
	cmpq	%rdi, %rsi
	jae	LBB20_33
## %bb.32:
	leaq	(%rax,%r15), %rsi
	subq	%rcx, %rsi
	leaq	(%r14,%rsi,4), %rsi
	leaq	(%r8,%rcx,4), %rdi
	cmpq	%rsi, %rdi
	jb	LBB20_48
LBB20_33:
	movq	%r15, -144(%rbp)                ## 8-byte Spill
	movq	%r11, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %r12
	shrq	$5, %r12
	incq	%r12
	movl	%r12d, %r15d
	andl	$3, %r15d
	cmpq	$96, %rsi
	jae	LBB20_41
## %bb.34:
	xorl	%edi, %edi
	jmp	LBB20_43
LBB20_41:
	leaq	(%r8,%rcx,4), %r13
	addq	$480, %r13                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	andq	$-4, %r12
	negq	%r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_42:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%r13,%rdi,4), %ymm0
	vmovups	-448(%r13,%rdi,4), %ymm1
	vmovups	-416(%r13,%rdi,4), %ymm2
	vmovups	-384(%r13,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rbx,%rdi,4)
	vmovups	%ymm1, -448(%rbx,%rdi,4)
	vmovups	%ymm2, -416(%rbx,%rdi,4)
	vmovups	%ymm3, -384(%rbx,%rdi,4)
	vmovups	-352(%r13,%rdi,4), %ymm0
	vmovups	-320(%r13,%rdi,4), %ymm1
	vmovups	-288(%r13,%rdi,4), %ymm2
	vmovups	-256(%r13,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rbx,%rdi,4)
	vmovups	%ymm1, -320(%rbx,%rdi,4)
	vmovups	%ymm2, -288(%rbx,%rdi,4)
	vmovups	%ymm3, -256(%rbx,%rdi,4)
	vmovups	-224(%r13,%rdi,4), %ymm0
	vmovups	-192(%r13,%rdi,4), %ymm1
	vmovups	-160(%r13,%rdi,4), %ymm2
	vmovups	-128(%r13,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rbx,%rdi,4)
	vmovups	%ymm1, -192(%rbx,%rdi,4)
	vmovups	%ymm2, -160(%rbx,%rdi,4)
	vmovups	%ymm3, -128(%rbx,%rdi,4)
	vmovdqu	-96(%r13,%rdi,4), %ymm0
	vmovdqu	-64(%r13,%rdi,4), %ymm1
	vmovdqu	-32(%r13,%rdi,4), %ymm2
	vmovups	(%r13,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rbx,%rdi,4)
	vmovdqu	%ymm1, -64(%rbx,%rdi,4)
	vmovdqu	%ymm2, -32(%rbx,%rdi,4)
	vmovups	%ymm3, (%rbx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r12
	jne	LBB20_42
LBB20_43:
	testq	%r15, %r15
	je	LBB20_46
## %bb.44:
	leaq	(%rax,%rdi), %rsi
	leaq	(%r14,%rsi,4), %rsi
	addq	$96, %rsi
	addq	%rcx, %rdi
	leaq	(%r8,%rdi,4), %rdi
	addq	$96, %rdi
	shlq	$7, %r15
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB20_45:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rdi,%rbx), %ymm0
	vmovdqu	-64(%rdi,%rbx), %ymm1
	vmovdqu	-32(%rdi,%rbx), %ymm2
	vmovups	(%rdi,%rbx), %ymm3
	vmovdqu	%ymm0, -96(%rsi,%rbx)
	vmovdqu	%ymm1, -64(%rsi,%rbx)
	vmovdqu	%ymm2, -32(%rsi,%rbx)
	vmovups	%ymm3, (%rsi,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r15
	jne	LBB20_45
LBB20_46:
	addq	%r10, %rax
	cmpq	%r10, %r11
	movq	-144(%rbp), %r15                ## 8-byte Reload
	je	LBB20_54
## %bb.47:
	addq	%r10, %rcx
LBB20_48:
	movl	%r15d, %edi
	subl	%ecx, %edi
	movq	%rcx, %rsi
	notq	%rsi
	addq	%r15, %rsi
	andq	$7, %rdi
	je	LBB20_50
	.p2align	4, 0x90
LBB20_49:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rcx,4), %ebx
	movl	%ebx, (%r14,%rax,4)
	incq	%rax
	incq	%rcx
	decq	%rdi
	jne	LBB20_49
LBB20_50:
	cmpq	$7, %rsi
	jb	LBB20_54
## %bb.51:
	movq	%r15, %r10
	subq	%rcx, %r10
	leaq	(%r8,%rcx,4), %rdi
	addq	$28, %rdi
	leaq	(%r14,%rax,4), %rbx
	addq	$28, %rbx
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB20_52:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rdi,%rcx,4), %esi
	movl	%esi, -28(%rbx,%rcx,4)
	movl	-24(%rdi,%rcx,4), %esi
	movl	%esi, -24(%rbx,%rcx,4)
	movl	-20(%rdi,%rcx,4), %esi
	movl	%esi, -20(%rbx,%rcx,4)
	movl	-16(%rdi,%rcx,4), %esi
	movl	%esi, -16(%rbx,%rcx,4)
	movl	-12(%rdi,%rcx,4), %esi
	movl	%esi, -12(%rbx,%rcx,4)
	movl	-8(%rdi,%rcx,4), %esi
	movl	%esi, -8(%rbx,%rcx,4)
	movl	-4(%rdi,%rcx,4), %esi
	movl	%esi, -4(%rbx,%rcx,4)
	movl	(%rdi,%rcx,4), %esi
	movl	%esi, (%rbx,%rcx,4)
	addq	$8, %rcx
	cmpq	%rcx, %r10
	jne	LBB20_52
## %bb.53:
	addq	%rcx, %rax
LBB20_54:
	subl	%edx, %r15d
	movl	%r15d, -92(%rbp)
	leaq	(%r9,%r9), %r11
	movslq	-88(%rbp), %r10
	leaq	-8(%r10), %rcx
	movq	%r11, %rdx
	cmpq	%rcx, %r11
	jge	LBB20_56
	.p2align	4, 0x90
LBB20_55:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	cmpq	%rcx, %rdx
	jl	LBB20_55
LBB20_56:
	cmpq	%r10, %rdx
	movq	%r15, -144(%rbp)                ## 8-byte Spill
	jge	LBB20_76
## %bb.57:
	movq	%r10, %r15
	subq	%rdx, %r15
	cmpq	$32, %r15
	jb	LBB20_70
## %bb.58:
	leaq	(%r14,%rax,4), %rcx
	leaq	(%r8,%r10,4), %rsi
	cmpq	%rsi, %rcx
	jae	LBB20_60
## %bb.59:
	leaq	(%rax,%r10), %rcx
	subq	%rdx, %rcx
	leaq	(%r14,%rcx,4), %rcx
	leaq	(%r8,%rdx,4), %rsi
	cmpq	%rcx, %rsi
	jb	LBB20_70
LBB20_60:
	movq	%r10, -136(%rbp)                ## 8-byte Spill
	movq	%r15, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rcx
	movq	%rcx, %r13
	shrq	$5, %r13
	incq	%r13
	movl	%r13d, %r12d
	andl	$3, %r12d
	cmpq	$96, %rcx
	jae	LBB20_62
## %bb.61:
	xorl	%edi, %edi
	jmp	LBB20_64
LBB20_62:
	leaq	(%r8,%rdx,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rcx
	addq	$480, %rcx                      ## imm = 0x1E0
	andq	$-4, %r13
	negq	%r13
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_63:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rdi,4), %ymm0
	vmovups	-448(%rbx,%rdi,4), %ymm1
	vmovups	-416(%rbx,%rdi,4), %ymm2
	vmovups	-384(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rcx,%rdi,4)
	vmovups	%ymm1, -448(%rcx,%rdi,4)
	vmovups	%ymm2, -416(%rcx,%rdi,4)
	vmovups	%ymm3, -384(%rcx,%rdi,4)
	vmovups	-352(%rbx,%rdi,4), %ymm0
	vmovups	-320(%rbx,%rdi,4), %ymm1
	vmovups	-288(%rbx,%rdi,4), %ymm2
	vmovups	-256(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rcx,%rdi,4)
	vmovups	%ymm1, -320(%rcx,%rdi,4)
	vmovups	%ymm2, -288(%rcx,%rdi,4)
	vmovups	%ymm3, -256(%rcx,%rdi,4)
	vmovups	-224(%rbx,%rdi,4), %ymm0
	vmovups	-192(%rbx,%rdi,4), %ymm1
	vmovups	-160(%rbx,%rdi,4), %ymm2
	vmovups	-128(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rcx,%rdi,4)
	vmovups	%ymm1, -192(%rcx,%rdi,4)
	vmovups	%ymm2, -160(%rcx,%rdi,4)
	vmovups	%ymm3, -128(%rcx,%rdi,4)
	vmovdqu	-96(%rbx,%rdi,4), %ymm0
	vmovdqu	-64(%rbx,%rdi,4), %ymm1
	vmovdqu	-32(%rbx,%rdi,4), %ymm2
	vmovups	(%rbx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi,4)
	vmovdqu	%ymm1, -64(%rcx,%rdi,4)
	vmovdqu	%ymm2, -32(%rcx,%rdi,4)
	vmovups	%ymm3, (%rcx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r13
	jne	LBB20_63
LBB20_64:
	testq	%r12, %r12
	je	LBB20_67
## %bb.65:
	leaq	(%rax,%rdi), %rcx
	leaq	(%r14,%rcx,4), %rcx
	addq	$96, %rcx
	addq	%rdx, %rdi
	leaq	(%r8,%rdi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_66:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rsi,%rdi), %ymm0
	vmovdqu	-64(%rsi,%rdi), %ymm1
	vmovdqu	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi)
	vmovdqu	%ymm1, -64(%rcx,%rdi)
	vmovdqu	%ymm2, -32(%rcx,%rdi)
	vmovups	%ymm3, (%rcx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r12
	jne	LBB20_66
LBB20_67:
	addq	%r10, %rax
	cmpq	%r10, %r15
	jne	LBB20_69
## %bb.68:
	movq	-136(%rbp), %r10                ## 8-byte Reload
	jmp	LBB20_76
LBB20_69:
	addq	%r10, %rdx
	movq	-136(%rbp), %r10                ## 8-byte Reload
LBB20_70:
	movl	%r10d, %esi
	subl	%edx, %esi
	movq	%rdx, %rcx
	notq	%rcx
	addq	%r10, %rcx
	andq	$7, %rsi
	je	LBB20_72
	.p2align	4, 0x90
LBB20_71:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rdx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rdx
	decq	%rsi
	jne	LBB20_71
LBB20_72:
	cmpq	$7, %rcx
	jb	LBB20_76
## %bb.73:
	movq	%r10, %rcx
	subq	%rdx, %rcx
	leaq	(%r8,%rdx,4), %rsi
	addq	$28, %rsi
	leaq	(%r14,%rax,4), %rdi
	addq	$28, %rdi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB20_74:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rdx,4), %ebx
	movl	%ebx, -28(%rdi,%rdx,4)
	movl	-24(%rsi,%rdx,4), %ebx
	movl	%ebx, -24(%rdi,%rdx,4)
	movl	-20(%rsi,%rdx,4), %ebx
	movl	%ebx, -20(%rdi,%rdx,4)
	movl	-16(%rsi,%rdx,4), %ebx
	movl	%ebx, -16(%rdi,%rdx,4)
	movl	-12(%rsi,%rdx,4), %ebx
	movl	%ebx, -12(%rdi,%rdx,4)
	movl	-8(%rsi,%rdx,4), %ebx
	movl	%ebx, -8(%rdi,%rdx,4)
	movl	-4(%rsi,%rdx,4), %ebx
	movl	%ebx, -4(%rdi,%rdx,4)
	movl	(%rsi,%rdx,4), %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB20_74
## %bb.75:
	addq	%rdx, %rax
LBB20_76:
	subl	%r11d, %r10d
	movl	%r10d, -88(%rbp)
	leaq	(%r9,%r9,2), %r11
	movslq	-84(%rbp), %r12
	leaq	-8(%r12), %rcx
	movq	%r11, %rdx
	cmpq	%rcx, %r11
	jge	LBB20_78
	.p2align	4, 0x90
LBB20_77:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	cmpq	%rcx, %rdx
	jl	LBB20_77
LBB20_78:
	cmpq	%r12, %rdx
	movq	%r10, -136(%rbp)                ## 8-byte Spill
	jge	LBB20_98
## %bb.79:
	movq	%r12, %r15
	subq	%rdx, %r15
	cmpq	$32, %r15
	jb	LBB20_92
## %bb.80:
	leaq	(%r14,%rax,4), %rcx
	leaq	(%r8,%r12,4), %rsi
	cmpq	%rsi, %rcx
	jae	LBB20_82
## %bb.81:
	leaq	(%rax,%r12), %rcx
	subq	%rdx, %rcx
	leaq	(%r14,%rcx,4), %rcx
	leaq	(%r8,%rdx,4), %rsi
	cmpq	%rcx, %rsi
	jb	LBB20_92
LBB20_82:
	movq	%r12, -128(%rbp)                ## 8-byte Spill
	movq	%r15, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rcx
	movq	%rcx, %r13
	shrq	$5, %r13
	incq	%r13
	movl	%r13d, %r12d
	andl	$3, %r12d
	cmpq	$96, %rcx
	jae	LBB20_84
## %bb.83:
	xorl	%edi, %edi
	jmp	LBB20_86
LBB20_84:
	leaq	(%r8,%rdx,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rcx
	addq	$480, %rcx                      ## imm = 0x1E0
	andq	$-4, %r13
	negq	%r13
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_85:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rdi,4), %ymm0
	vmovups	-448(%rbx,%rdi,4), %ymm1
	vmovups	-416(%rbx,%rdi,4), %ymm2
	vmovups	-384(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rcx,%rdi,4)
	vmovups	%ymm1, -448(%rcx,%rdi,4)
	vmovups	%ymm2, -416(%rcx,%rdi,4)
	vmovups	%ymm3, -384(%rcx,%rdi,4)
	vmovups	-352(%rbx,%rdi,4), %ymm0
	vmovups	-320(%rbx,%rdi,4), %ymm1
	vmovups	-288(%rbx,%rdi,4), %ymm2
	vmovups	-256(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rcx,%rdi,4)
	vmovups	%ymm1, -320(%rcx,%rdi,4)
	vmovups	%ymm2, -288(%rcx,%rdi,4)
	vmovups	%ymm3, -256(%rcx,%rdi,4)
	vmovups	-224(%rbx,%rdi,4), %ymm0
	vmovups	-192(%rbx,%rdi,4), %ymm1
	vmovups	-160(%rbx,%rdi,4), %ymm2
	vmovups	-128(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rcx,%rdi,4)
	vmovups	%ymm1, -192(%rcx,%rdi,4)
	vmovups	%ymm2, -160(%rcx,%rdi,4)
	vmovups	%ymm3, -128(%rcx,%rdi,4)
	vmovdqu	-96(%rbx,%rdi,4), %ymm0
	vmovdqu	-64(%rbx,%rdi,4), %ymm1
	vmovdqu	-32(%rbx,%rdi,4), %ymm2
	vmovups	(%rbx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi,4)
	vmovdqu	%ymm1, -64(%rcx,%rdi,4)
	vmovdqu	%ymm2, -32(%rcx,%rdi,4)
	vmovups	%ymm3, (%rcx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r13
	jne	LBB20_85
LBB20_86:
	testq	%r12, %r12
	je	LBB20_89
## %bb.87:
	leaq	(%rax,%rdi), %rcx
	leaq	(%r14,%rcx,4), %rcx
	addq	$96, %rcx
	addq	%rdx, %rdi
	leaq	(%r8,%rdi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_88:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rsi,%rdi), %ymm0
	vmovdqu	-64(%rsi,%rdi), %ymm1
	vmovdqu	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi)
	vmovdqu	%ymm1, -64(%rcx,%rdi)
	vmovdqu	%ymm2, -32(%rcx,%rdi)
	vmovups	%ymm3, (%rcx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r12
	jne	LBB20_88
LBB20_89:
	addq	%r10, %rax
	cmpq	%r10, %r15
	jne	LBB20_91
## %bb.90:
	movq	-128(%rbp), %r12                ## 8-byte Reload
	jmp	LBB20_98
LBB20_91:
	addq	%r10, %rdx
	movq	-128(%rbp), %r12                ## 8-byte Reload
LBB20_92:
	movl	%r12d, %esi
	subl	%edx, %esi
	movq	%rdx, %rcx
	notq	%rcx
	addq	%r12, %rcx
	andq	$7, %rsi
	je	LBB20_94
	.p2align	4, 0x90
LBB20_93:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rdx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rdx
	decq	%rsi
	jne	LBB20_93
LBB20_94:
	cmpq	$7, %rcx
	jb	LBB20_98
## %bb.95:
	movq	%r12, %rcx
	subq	%rdx, %rcx
	leaq	(%r8,%rdx,4), %rsi
	addq	$28, %rsi
	leaq	(%r14,%rax,4), %rdi
	addq	$28, %rdi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB20_96:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rdx,4), %ebx
	movl	%ebx, -28(%rdi,%rdx,4)
	movl	-24(%rsi,%rdx,4), %ebx
	movl	%ebx, -24(%rdi,%rdx,4)
	movl	-20(%rsi,%rdx,4), %ebx
	movl	%ebx, -20(%rdi,%rdx,4)
	movl	-16(%rsi,%rdx,4), %ebx
	movl	%ebx, -16(%rdi,%rdx,4)
	movl	-12(%rsi,%rdx,4), %ebx
	movl	%ebx, -12(%rdi,%rdx,4)
	movl	-8(%rsi,%rdx,4), %ebx
	movl	%ebx, -8(%rdi,%rdx,4)
	movl	-4(%rsi,%rdx,4), %ebx
	movl	%ebx, -4(%rdi,%rdx,4)
	movl	(%rsi,%rdx,4), %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB20_96
## %bb.97:
	addq	%rdx, %rax
LBB20_98:
	subl	%r11d, %r12d
	movl	%r12d, -84(%rbp)
	leaq	(,%r9,4), %r11
	movslq	-80(%rbp), %r10
	leaq	-8(%r10), %rcx
	movq	%r11, %rdx
	cmpq	%rcx, %r11
	jge	LBB20_100
	.p2align	4, 0x90
LBB20_99:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	cmpq	%rcx, %rdx
	jl	LBB20_99
LBB20_100:
	cmpq	%r10, %rdx
	movq	%r12, -128(%rbp)                ## 8-byte Spill
	jge	LBB20_120
## %bb.101:
	movq	%r10, %r15
	subq	%rdx, %r15
	cmpq	$32, %r15
	jb	LBB20_114
## %bb.102:
	leaq	(%r14,%rax,4), %rcx
	leaq	(%r8,%r10,4), %rsi
	cmpq	%rsi, %rcx
	jae	LBB20_104
## %bb.103:
	leaq	(%rax,%r10), %rcx
	subq	%rdx, %rcx
	leaq	(%r14,%rcx,4), %rcx
	leaq	(%r8,%rdx,4), %rsi
	cmpq	%rcx, %rsi
	jb	LBB20_114
LBB20_104:
	movq	%r10, -120(%rbp)                ## 8-byte Spill
	movq	%r15, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rcx
	movq	%rcx, %r13
	shrq	$5, %r13
	incq	%r13
	movl	%r13d, %r12d
	andl	$3, %r12d
	cmpq	$96, %rcx
	jae	LBB20_106
## %bb.105:
	xorl	%edi, %edi
	jmp	LBB20_108
LBB20_106:
	leaq	(%r8,%rdx,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rcx
	addq	$480, %rcx                      ## imm = 0x1E0
	andq	$-4, %r13
	negq	%r13
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_107:                              ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rdi,4), %ymm0
	vmovups	-448(%rbx,%rdi,4), %ymm1
	vmovups	-416(%rbx,%rdi,4), %ymm2
	vmovups	-384(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rcx,%rdi,4)
	vmovups	%ymm1, -448(%rcx,%rdi,4)
	vmovups	%ymm2, -416(%rcx,%rdi,4)
	vmovups	%ymm3, -384(%rcx,%rdi,4)
	vmovups	-352(%rbx,%rdi,4), %ymm0
	vmovups	-320(%rbx,%rdi,4), %ymm1
	vmovups	-288(%rbx,%rdi,4), %ymm2
	vmovups	-256(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rcx,%rdi,4)
	vmovups	%ymm1, -320(%rcx,%rdi,4)
	vmovups	%ymm2, -288(%rcx,%rdi,4)
	vmovups	%ymm3, -256(%rcx,%rdi,4)
	vmovups	-224(%rbx,%rdi,4), %ymm0
	vmovups	-192(%rbx,%rdi,4), %ymm1
	vmovups	-160(%rbx,%rdi,4), %ymm2
	vmovups	-128(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rcx,%rdi,4)
	vmovups	%ymm1, -192(%rcx,%rdi,4)
	vmovups	%ymm2, -160(%rcx,%rdi,4)
	vmovups	%ymm3, -128(%rcx,%rdi,4)
	vmovdqu	-96(%rbx,%rdi,4), %ymm0
	vmovdqu	-64(%rbx,%rdi,4), %ymm1
	vmovdqu	-32(%rbx,%rdi,4), %ymm2
	vmovups	(%rbx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi,4)
	vmovdqu	%ymm1, -64(%rcx,%rdi,4)
	vmovdqu	%ymm2, -32(%rcx,%rdi,4)
	vmovups	%ymm3, (%rcx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r13
	jne	LBB20_107
LBB20_108:
	testq	%r12, %r12
	je	LBB20_111
## %bb.109:
	leaq	(%rax,%rdi), %rcx
	leaq	(%r14,%rcx,4), %rcx
	addq	$96, %rcx
	addq	%rdx, %rdi
	leaq	(%r8,%rdi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_110:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rsi,%rdi), %ymm0
	vmovdqu	-64(%rsi,%rdi), %ymm1
	vmovdqu	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi)
	vmovdqu	%ymm1, -64(%rcx,%rdi)
	vmovdqu	%ymm2, -32(%rcx,%rdi)
	vmovups	%ymm3, (%rcx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r12
	jne	LBB20_110
LBB20_111:
	addq	%r10, %rax
	cmpq	%r10, %r15
	jne	LBB20_113
## %bb.112:
	movq	-120(%rbp), %r10                ## 8-byte Reload
	jmp	LBB20_120
LBB20_113:
	addq	%r10, %rdx
	movq	-120(%rbp), %r10                ## 8-byte Reload
LBB20_114:
	movl	%r10d, %esi
	subl	%edx, %esi
	movq	%rdx, %rcx
	notq	%rcx
	addq	%r10, %rcx
	andq	$7, %rsi
	je	LBB20_116
	.p2align	4, 0x90
LBB20_115:                              ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rdx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rdx
	decq	%rsi
	jne	LBB20_115
LBB20_116:
	cmpq	$7, %rcx
	jb	LBB20_120
## %bb.117:
	movq	%r10, %rcx
	subq	%rdx, %rcx
	leaq	(%r8,%rdx,4), %rsi
	addq	$28, %rsi
	leaq	(%r14,%rax,4), %rdi
	addq	$28, %rdi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB20_118:                              ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rdx,4), %ebx
	movl	%ebx, -28(%rdi,%rdx,4)
	movl	-24(%rsi,%rdx,4), %ebx
	movl	%ebx, -24(%rdi,%rdx,4)
	movl	-20(%rsi,%rdx,4), %ebx
	movl	%ebx, -20(%rdi,%rdx,4)
	movl	-16(%rsi,%rdx,4), %ebx
	movl	%ebx, -16(%rdi,%rdx,4)
	movl	-12(%rsi,%rdx,4), %ebx
	movl	%ebx, -12(%rdi,%rdx,4)
	movl	-8(%rsi,%rdx,4), %ebx
	movl	%ebx, -8(%rdi,%rdx,4)
	movl	-4(%rsi,%rdx,4), %ebx
	movl	%ebx, -4(%rdi,%rdx,4)
	movl	(%rsi,%rdx,4), %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB20_118
## %bb.119:
	addq	%rdx, %rax
LBB20_120:
	subl	%r11d, %r10d
	movl	%r10d, -80(%rbp)
	leaq	(%r9,%r9,4), %r11
	movslq	-76(%rbp), %r12
	leaq	-8(%r12), %rcx
	movq	%r11, %rdx
	cmpq	%rcx, %r11
	jge	LBB20_122
	.p2align	4, 0x90
LBB20_121:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	cmpq	%rcx, %rdx
	jl	LBB20_121
LBB20_122:
	cmpq	%r12, %rdx
	movq	%r10, -120(%rbp)                ## 8-byte Spill
	jge	LBB20_142
## %bb.123:
	movq	%r12, %r15
	subq	%rdx, %r15
	cmpq	$32, %r15
	jb	LBB20_136
## %bb.124:
	leaq	(%r14,%rax,4), %rcx
	leaq	(%r8,%r12,4), %rsi
	cmpq	%rsi, %rcx
	jae	LBB20_126
## %bb.125:
	leaq	(%rax,%r12), %rcx
	subq	%rdx, %rcx
	leaq	(%r14,%rcx,4), %rcx
	leaq	(%r8,%rdx,4), %rsi
	cmpq	%rcx, %rsi
	jb	LBB20_136
LBB20_126:
	movq	%r12, -112(%rbp)                ## 8-byte Spill
	movq	%r15, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rcx
	movq	%rcx, %r13
	shrq	$5, %r13
	incq	%r13
	movl	%r13d, %r12d
	andl	$3, %r12d
	cmpq	$96, %rcx
	jae	LBB20_128
## %bb.127:
	xorl	%edi, %edi
	jmp	LBB20_130
LBB20_128:
	leaq	(%r8,%rdx,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rcx
	addq	$480, %rcx                      ## imm = 0x1E0
	andq	$-4, %r13
	negq	%r13
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_129:                              ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rdi,4), %ymm0
	vmovups	-448(%rbx,%rdi,4), %ymm1
	vmovups	-416(%rbx,%rdi,4), %ymm2
	vmovups	-384(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rcx,%rdi,4)
	vmovups	%ymm1, -448(%rcx,%rdi,4)
	vmovups	%ymm2, -416(%rcx,%rdi,4)
	vmovups	%ymm3, -384(%rcx,%rdi,4)
	vmovups	-352(%rbx,%rdi,4), %ymm0
	vmovups	-320(%rbx,%rdi,4), %ymm1
	vmovups	-288(%rbx,%rdi,4), %ymm2
	vmovups	-256(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rcx,%rdi,4)
	vmovups	%ymm1, -320(%rcx,%rdi,4)
	vmovups	%ymm2, -288(%rcx,%rdi,4)
	vmovups	%ymm3, -256(%rcx,%rdi,4)
	vmovups	-224(%rbx,%rdi,4), %ymm0
	vmovups	-192(%rbx,%rdi,4), %ymm1
	vmovups	-160(%rbx,%rdi,4), %ymm2
	vmovups	-128(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rcx,%rdi,4)
	vmovups	%ymm1, -192(%rcx,%rdi,4)
	vmovups	%ymm2, -160(%rcx,%rdi,4)
	vmovups	%ymm3, -128(%rcx,%rdi,4)
	vmovdqu	-96(%rbx,%rdi,4), %ymm0
	vmovdqu	-64(%rbx,%rdi,4), %ymm1
	vmovdqu	-32(%rbx,%rdi,4), %ymm2
	vmovups	(%rbx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi,4)
	vmovdqu	%ymm1, -64(%rcx,%rdi,4)
	vmovdqu	%ymm2, -32(%rcx,%rdi,4)
	vmovups	%ymm3, (%rcx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r13
	jne	LBB20_129
LBB20_130:
	testq	%r12, %r12
	je	LBB20_133
## %bb.131:
	leaq	(%rax,%rdi), %rcx
	leaq	(%r14,%rcx,4), %rcx
	addq	$96, %rcx
	addq	%rdx, %rdi
	leaq	(%r8,%rdi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_132:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rsi,%rdi), %ymm0
	vmovdqu	-64(%rsi,%rdi), %ymm1
	vmovdqu	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi)
	vmovdqu	%ymm1, -64(%rcx,%rdi)
	vmovdqu	%ymm2, -32(%rcx,%rdi)
	vmovups	%ymm3, (%rcx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r12
	jne	LBB20_132
LBB20_133:
	addq	%r10, %rax
	cmpq	%r10, %r15
	jne	LBB20_135
## %bb.134:
	movq	-112(%rbp), %r12                ## 8-byte Reload
	jmp	LBB20_142
LBB20_135:
	addq	%r10, %rdx
	movq	-112(%rbp), %r12                ## 8-byte Reload
LBB20_136:
	movl	%r12d, %esi
	subl	%edx, %esi
	movq	%rdx, %rcx
	notq	%rcx
	addq	%r12, %rcx
	andq	$7, %rsi
	je	LBB20_138
	.p2align	4, 0x90
LBB20_137:                              ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rdx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rdx
	decq	%rsi
	jne	LBB20_137
LBB20_138:
	cmpq	$7, %rcx
	jb	LBB20_142
## %bb.139:
	movq	%r12, %rcx
	subq	%rdx, %rcx
	leaq	(%r8,%rdx,4), %rsi
	addq	$28, %rsi
	leaq	(%r14,%rax,4), %rdi
	addq	$28, %rdi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB20_140:                              ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rdx,4), %ebx
	movl	%ebx, -28(%rdi,%rdx,4)
	movl	-24(%rsi,%rdx,4), %ebx
	movl	%ebx, -24(%rdi,%rdx,4)
	movl	-20(%rsi,%rdx,4), %ebx
	movl	%ebx, -20(%rdi,%rdx,4)
	movl	-16(%rsi,%rdx,4), %ebx
	movl	%ebx, -16(%rdi,%rdx,4)
	movl	-12(%rsi,%rdx,4), %ebx
	movl	%ebx, -12(%rdi,%rdx,4)
	movl	-8(%rsi,%rdx,4), %ebx
	movl	%ebx, -8(%rdi,%rdx,4)
	movl	-4(%rsi,%rdx,4), %ebx
	movl	%ebx, -4(%rdi,%rdx,4)
	movl	(%rsi,%rdx,4), %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB20_140
## %bb.141:
	addq	%rdx, %rax
LBB20_142:
	subl	%r11d, %r12d
	movl	%r12d, -76(%rbp)
	leaq	(%r9,%r9), %rcx
	leaq	(%rcx,%rcx,2), %r11
	movslq	-72(%rbp), %r10
	leaq	-8(%r10), %rcx
	movq	%r11, %rdx
	cmpq	%rcx, %r11
	jge	LBB20_144
	.p2align	4, 0x90
LBB20_143:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	cmpq	%rcx, %rdx
	jl	LBB20_143
LBB20_144:
	cmpq	%r10, %rdx
	movq	%r12, -112(%rbp)                ## 8-byte Spill
	jge	LBB20_164
## %bb.145:
	movq	%r10, %r15
	subq	%rdx, %r15
	cmpq	$32, %r15
	jb	LBB20_158
## %bb.146:
	leaq	(%r14,%rax,4), %rcx
	leaq	(%r8,%r10,4), %rsi
	cmpq	%rsi, %rcx
	jae	LBB20_148
## %bb.147:
	leaq	(%rax,%r10), %rcx
	subq	%rdx, %rcx
	leaq	(%r14,%rcx,4), %rcx
	leaq	(%r8,%rdx,4), %rsi
	cmpq	%rcx, %rsi
	jb	LBB20_158
LBB20_148:
	movq	%r10, -104(%rbp)                ## 8-byte Spill
	movq	%r15, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rcx
	movq	%rcx, %r13
	shrq	$5, %r13
	incq	%r13
	movl	%r13d, %r12d
	andl	$3, %r12d
	cmpq	$96, %rcx
	jae	LBB20_150
## %bb.149:
	xorl	%edi, %edi
	jmp	LBB20_152
LBB20_150:
	leaq	(%r8,%rdx,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rcx
	addq	$480, %rcx                      ## imm = 0x1E0
	andq	$-4, %r13
	negq	%r13
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_151:                              ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rdi,4), %ymm0
	vmovups	-448(%rbx,%rdi,4), %ymm1
	vmovups	-416(%rbx,%rdi,4), %ymm2
	vmovups	-384(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rcx,%rdi,4)
	vmovups	%ymm1, -448(%rcx,%rdi,4)
	vmovups	%ymm2, -416(%rcx,%rdi,4)
	vmovups	%ymm3, -384(%rcx,%rdi,4)
	vmovups	-352(%rbx,%rdi,4), %ymm0
	vmovups	-320(%rbx,%rdi,4), %ymm1
	vmovups	-288(%rbx,%rdi,4), %ymm2
	vmovups	-256(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rcx,%rdi,4)
	vmovups	%ymm1, -320(%rcx,%rdi,4)
	vmovups	%ymm2, -288(%rcx,%rdi,4)
	vmovups	%ymm3, -256(%rcx,%rdi,4)
	vmovups	-224(%rbx,%rdi,4), %ymm0
	vmovups	-192(%rbx,%rdi,4), %ymm1
	vmovups	-160(%rbx,%rdi,4), %ymm2
	vmovups	-128(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rcx,%rdi,4)
	vmovups	%ymm1, -192(%rcx,%rdi,4)
	vmovups	%ymm2, -160(%rcx,%rdi,4)
	vmovups	%ymm3, -128(%rcx,%rdi,4)
	vmovdqu	-96(%rbx,%rdi,4), %ymm0
	vmovdqu	-64(%rbx,%rdi,4), %ymm1
	vmovdqu	-32(%rbx,%rdi,4), %ymm2
	vmovups	(%rbx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi,4)
	vmovdqu	%ymm1, -64(%rcx,%rdi,4)
	vmovdqu	%ymm2, -32(%rcx,%rdi,4)
	vmovups	%ymm3, (%rcx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r13
	jne	LBB20_151
LBB20_152:
	testq	%r12, %r12
	je	LBB20_155
## %bb.153:
	leaq	(%rax,%rdi), %rcx
	leaq	(%r14,%rcx,4), %rcx
	addq	$96, %rcx
	addq	%rdx, %rdi
	leaq	(%r8,%rdi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_154:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rsi,%rdi), %ymm0
	vmovdqu	-64(%rsi,%rdi), %ymm1
	vmovdqu	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi)
	vmovdqu	%ymm1, -64(%rcx,%rdi)
	vmovdqu	%ymm2, -32(%rcx,%rdi)
	vmovups	%ymm3, (%rcx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r12
	jne	LBB20_154
LBB20_155:
	addq	%r10, %rax
	cmpq	%r10, %r15
	jne	LBB20_157
## %bb.156:
	movq	-104(%rbp), %r10                ## 8-byte Reload
	jmp	LBB20_164
LBB20_157:
	addq	%r10, %rdx
	movq	-104(%rbp), %r10                ## 8-byte Reload
LBB20_158:
	movl	%r10d, %esi
	subl	%edx, %esi
	movq	%rdx, %rcx
	notq	%rcx
	addq	%r10, %rcx
	andq	$7, %rsi
	je	LBB20_160
	.p2align	4, 0x90
LBB20_159:                              ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rdx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rdx
	decq	%rsi
	jne	LBB20_159
LBB20_160:
	cmpq	$7, %rcx
	jb	LBB20_164
## %bb.161:
	movq	%r10, %rcx
	subq	%rdx, %rcx
	leaq	(%r8,%rdx,4), %rsi
	addq	$28, %rsi
	leaq	(%r14,%rax,4), %rdi
	addq	$28, %rdi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB20_162:                              ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rdx,4), %ebx
	movl	%ebx, -28(%rdi,%rdx,4)
	movl	-24(%rsi,%rdx,4), %ebx
	movl	%ebx, -24(%rdi,%rdx,4)
	movl	-20(%rsi,%rdx,4), %ebx
	movl	%ebx, -20(%rdi,%rdx,4)
	movl	-16(%rsi,%rdx,4), %ebx
	movl	%ebx, -16(%rdi,%rdx,4)
	movl	-12(%rsi,%rdx,4), %ebx
	movl	%ebx, -12(%rdi,%rdx,4)
	movl	-8(%rsi,%rdx,4), %ebx
	movl	%ebx, -8(%rdi,%rdx,4)
	movl	-4(%rsi,%rdx,4), %ebx
	movl	%ebx, -4(%rdi,%rdx,4)
	movl	(%rsi,%rdx,4), %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB20_162
## %bb.163:
	addq	%rdx, %rax
LBB20_164:
	subl	%r11d, %r10d
	movq	%r10, -104(%rbp)                ## 8-byte Spill
	movl	%r10d, -72(%rbp)
	leaq	(,%r9,8), %r10
	movq	%r10, %r15
	subq	%r9, %r15
	movslq	-68(%rbp), %r12
	leaq	-8(%r12), %rcx
	movq	%r15, %rdx
	cmpq	%rcx, %r15
	jge	LBB20_166
	.p2align	4, 0x90
LBB20_165:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	cmpq	%rcx, %rdx
	jl	LBB20_165
LBB20_166:
	cmpq	%r12, %rdx
	jge	LBB20_185
## %bb.167:
	movq	%r12, %r11
	subq	%rdx, %r11
	cmpq	$32, %r11
	jb	LBB20_179
## %bb.168:
	leaq	(%r14,%rax,4), %rcx
	leaq	(%r8,%r12,4), %rsi
	cmpq	%rsi, %rcx
	jae	LBB20_170
## %bb.169:
	leaq	(%rax,%r12), %rcx
	subq	%rdx, %rcx
	leaq	(%r14,%rcx,4), %rcx
	leaq	(%r8,%rdx,4), %rsi
	cmpq	%rcx, %rsi
	jb	LBB20_179
LBB20_170:
	movq	%r11, %rsi
	andq	$-32, %rsi
	leaq	-32(%rsi), %rcx
	movq	%rcx, %rbx
	shrq	$5, %rbx
	incq	%rbx
	movl	%ebx, %r13d
	andl	$3, %r13d
	cmpq	$96, %rcx
	jae	LBB20_172
## %bb.171:
	xorl	%edi, %edi
	jmp	LBB20_174
LBB20_172:
	leaq	(%r8,%rdx,4), %rcx
	addq	$480, %rcx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %r9
	addq	$480, %r9                       ## imm = 0x1E0
	andq	$-4, %rbx
	negq	%rbx
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_173:                              ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rcx,%rdi,4), %ymm0
	vmovups	-448(%rcx,%rdi,4), %ymm1
	vmovups	-416(%rcx,%rdi,4), %ymm2
	vmovups	-384(%rcx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%r9,%rdi,4)
	vmovups	%ymm1, -448(%r9,%rdi,4)
	vmovups	%ymm2, -416(%r9,%rdi,4)
	vmovups	%ymm3, -384(%r9,%rdi,4)
	vmovups	-352(%rcx,%rdi,4), %ymm0
	vmovups	-320(%rcx,%rdi,4), %ymm1
	vmovups	-288(%rcx,%rdi,4), %ymm2
	vmovups	-256(%rcx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%r9,%rdi,4)
	vmovups	%ymm1, -320(%r9,%rdi,4)
	vmovups	%ymm2, -288(%r9,%rdi,4)
	vmovups	%ymm3, -256(%r9,%rdi,4)
	vmovups	-224(%rcx,%rdi,4), %ymm0
	vmovups	-192(%rcx,%rdi,4), %ymm1
	vmovups	-160(%rcx,%rdi,4), %ymm2
	vmovups	-128(%rcx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%r9,%rdi,4)
	vmovups	%ymm1, -192(%r9,%rdi,4)
	vmovups	%ymm2, -160(%r9,%rdi,4)
	vmovups	%ymm3, -128(%r9,%rdi,4)
	vmovdqu	-96(%rcx,%rdi,4), %ymm0
	vmovdqu	-64(%rcx,%rdi,4), %ymm1
	vmovdqu	-32(%rcx,%rdi,4), %ymm2
	vmovups	(%rcx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%r9,%rdi,4)
	vmovdqu	%ymm1, -64(%r9,%rdi,4)
	vmovdqu	%ymm2, -32(%r9,%rdi,4)
	vmovups	%ymm3, (%r9,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %rbx
	jne	LBB20_173
LBB20_174:
	testq	%r13, %r13
	je	LBB20_177
## %bb.175:
	leaq	(%rax,%rdi), %rcx
	leaq	(%r14,%rcx,4), %rcx
	addq	$96, %rcx
	addq	%rdx, %rdi
	leaq	(%r8,%rdi,4), %rdi
	addq	$96, %rdi
	shlq	$7, %r13
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB20_176:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rdi,%rbx), %ymm0
	vmovdqu	-64(%rdi,%rbx), %ymm1
	vmovdqu	-32(%rdi,%rbx), %ymm2
	vmovups	(%rdi,%rbx), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rbx)
	vmovdqu	%ymm1, -64(%rcx,%rbx)
	vmovdqu	%ymm2, -32(%rcx,%rbx)
	vmovups	%ymm3, (%rcx,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r13
	jne	LBB20_176
LBB20_177:
	addq	%rsi, %rax
	cmpq	%rsi, %r11
	je	LBB20_185
## %bb.178:
	addq	%rsi, %rdx
LBB20_179:
	movl	%r12d, %esi
	subl	%edx, %esi
	movq	%rdx, %rcx
	notq	%rcx
	addq	%r12, %rcx
	andq	$7, %rsi
	je	LBB20_181
	.p2align	4, 0x90
LBB20_180:                              ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rdx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rdx
	decq	%rsi
	jne	LBB20_180
LBB20_181:
	cmpq	$7, %rcx
	jb	LBB20_185
## %bb.182:
	movq	%r12, %rcx
	subq	%rdx, %rcx
	leaq	(%r8,%rdx,4), %rsi
	addq	$28, %rsi
	leaq	(%r14,%rax,4), %rdi
	addq	$28, %rdi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB20_183:                              ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rdx,4), %ebx
	movl	%ebx, -28(%rdi,%rdx,4)
	movl	-24(%rsi,%rdx,4), %ebx
	movl	%ebx, -24(%rdi,%rdx,4)
	movl	-20(%rsi,%rdx,4), %ebx
	movl	%ebx, -20(%rdi,%rdx,4)
	movl	-16(%rsi,%rdx,4), %ebx
	movl	%ebx, -16(%rdi,%rdx,4)
	movl	-12(%rsi,%rdx,4), %ebx
	movl	%ebx, -12(%rdi,%rdx,4)
	movl	-8(%rsi,%rdx,4), %ebx
	movl	%ebx, -8(%rdi,%rdx,4)
	movl	-4(%rsi,%rdx,4), %ebx
	movl	%ebx, -4(%rdi,%rdx,4)
	movl	(%rsi,%rdx,4), %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB20_183
## %bb.184:
	addq	%rdx, %rax
LBB20_185:
	subl	%r15d, %r12d
	movl	%r12d, -68(%rbp)
	movslq	-64(%rbp), %r13
	leaq	-8(%r13), %rdx
	movq	%r10, %rcx
	cmpq	%rdx, %r10
	jge	LBB20_187
	.p2align	4, 0x90
LBB20_186:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rcx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rcx
	cmpq	%rdx, %rcx
	jl	LBB20_186
LBB20_187:
	cmpq	%r13, %rcx
	jge	LBB20_205
## %bb.188:
	movq	%r13, %r11
	subq	%rcx, %r11
	cmpq	$32, %r11
	jb	LBB20_200
## %bb.189:
	leaq	(%r14,%rax,4), %rdx
	leaq	(%r8,%r13,4), %rsi
	cmpq	%rsi, %rdx
	jae	LBB20_191
## %bb.190:
	leaq	(%rax,%r13), %rdx
	subq	%rcx, %rdx
	leaq	(%r14,%rdx,4), %rdx
	leaq	(%r8,%rcx,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB20_200
LBB20_191:
	movq	%r11, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rbx
	shrq	$5, %rbx
	incq	%rbx
	movl	%ebx, %r15d
	andl	$3, %r15d
	cmpq	$96, %rdx
	jae	LBB20_193
## %bb.192:
	xorl	%edi, %edi
	jmp	LBB20_195
LBB20_193:
	leaq	(%r8,%rcx,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rsi
	addq	$480, %rsi                      ## imm = 0x1E0
	andq	$-4, %rbx
	negq	%rbx
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_194:                              ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdx,%rdi,4), %ymm0
	vmovups	-448(%rdx,%rdi,4), %ymm1
	vmovups	-416(%rdx,%rdi,4), %ymm2
	vmovups	-384(%rdx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rsi,%rdi,4)
	vmovups	%ymm1, -448(%rsi,%rdi,4)
	vmovups	%ymm2, -416(%rsi,%rdi,4)
	vmovups	%ymm3, -384(%rsi,%rdi,4)
	vmovups	-352(%rdx,%rdi,4), %ymm0
	vmovups	-320(%rdx,%rdi,4), %ymm1
	vmovups	-288(%rdx,%rdi,4), %ymm2
	vmovups	-256(%rdx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rsi,%rdi,4)
	vmovups	%ymm1, -320(%rsi,%rdi,4)
	vmovups	%ymm2, -288(%rsi,%rdi,4)
	vmovups	%ymm3, -256(%rsi,%rdi,4)
	vmovups	-224(%rdx,%rdi,4), %ymm0
	vmovups	-192(%rdx,%rdi,4), %ymm1
	vmovups	-160(%rdx,%rdi,4), %ymm2
	vmovups	-128(%rdx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rsi,%rdi,4)
	vmovups	%ymm1, -192(%rsi,%rdi,4)
	vmovups	%ymm2, -160(%rsi,%rdi,4)
	vmovups	%ymm3, -128(%rsi,%rdi,4)
	vmovdqu	-96(%rdx,%rdi,4), %ymm0
	vmovdqu	-64(%rdx,%rdi,4), %ymm1
	vmovdqu	-32(%rdx,%rdi,4), %ymm2
	vmovups	(%rdx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rsi,%rdi,4)
	vmovdqu	%ymm1, -64(%rsi,%rdi,4)
	vmovdqu	%ymm2, -32(%rsi,%rdi,4)
	vmovups	%ymm3, (%rsi,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %rbx
	jne	LBB20_194
LBB20_195:
	testq	%r15, %r15
	je	LBB20_198
## %bb.196:
	leaq	(%rax,%rdi), %rdx
	leaq	(%r14,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%rcx, %rdi
	leaq	(%r8,%rdi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r15
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB20_197:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rsi,%rdi), %ymm0
	vmovdqu	-64(%rsi,%rdi), %ymm1
	vmovdqu	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovdqu	%ymm0, -96(%rdx,%rdi)
	vmovdqu	%ymm1, -64(%rdx,%rdi)
	vmovdqu	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r15
	jne	LBB20_197
LBB20_198:
	cmpq	%r9, %r11
	je	LBB20_205
## %bb.199:
	addq	%r9, %rcx
	addq	%r9, %rax
LBB20_200:
	movl	%r13d, %esi
	subl	%ecx, %esi
	movq	%rcx, %rdx
	notq	%rdx
	addq	%r13, %rdx
	andq	$7, %rsi
	je	LBB20_202
	.p2align	4, 0x90
LBB20_201:                              ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rcx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rcx
	decq	%rsi
	jne	LBB20_201
LBB20_202:
	cmpq	$7, %rdx
	jb	LBB20_205
## %bb.203:
	movq	%r13, %rdx
	subq	%rcx, %rdx
	leaq	(%r8,%rcx,4), %rcx
	addq	$28, %rcx
	leaq	(%r14,%rax,4), %rax
	addq	$28, %rax
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB20_204:                              ## =>This Inner Loop Header: Depth=1
	movl	-28(%rcx,%rsi,4), %edi
	movl	%edi, -28(%rax,%rsi,4)
	movl	-24(%rcx,%rsi,4), %edi
	movl	%edi, -24(%rax,%rsi,4)
	movl	-20(%rcx,%rsi,4), %edi
	movl	%edi, -20(%rax,%rsi,4)
	movl	-16(%rcx,%rsi,4), %edi
	movl	%edi, -16(%rax,%rsi,4)
	movl	-12(%rcx,%rsi,4), %edi
	movl	%edi, -12(%rax,%rsi,4)
	movl	-8(%rcx,%rsi,4), %edi
	movl	%edi, -8(%rax,%rsi,4)
	movl	-4(%rcx,%rsi,4), %edi
	movl	%edi, -4(%rax,%rsi,4)
	movl	(%rcx,%rsi,4), %edi
	movl	%edi, (%rax,%rsi,4)
	addq	$8, %rsi
	cmpq	%rsi, %rdx
	jne	LBB20_204
LBB20_205:
	subl	%r10d, %r13d
	movq	-152(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %ebx
	movq	-160(%rbp), %rsi                ## 8-byte Reload
	addl	%esi, %ebx
	leal	(%rax,%rsi), %edx
	decl	%edx
	movq	%r14, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	vzeroupper
	callq	_sort_quick_multi
	movq	-144(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %r15d
	addl	%ebx, %r15d
	leal	(%rax,%rbx), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%ebx, %esi
	callq	_sort_quick_multi
	movq	-136(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %ebx
	addl	%r15d, %ebx
	leal	(%rax,%r15), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%r15d, %esi
	callq	_sort_quick_multi
	movq	-128(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %r15d
	addl	%ebx, %r15d
	leal	(%rax,%rbx), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%ebx, %esi
	callq	_sort_quick_multi
	movq	-120(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %ebx
	addl	%r15d, %ebx
	leal	(%rax,%r15), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%r15d, %esi
	callq	_sort_quick_multi
	movq	-112(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %r15d
	addl	%ebx, %r15d
	leal	(%rax,%rbx), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%ebx, %esi
	callq	_sort_quick_multi
	movq	-104(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %ebx
	addl	%r15d, %ebx
	leal	(%rax,%r15), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%r15d, %esi
	callq	_sort_quick_multi
	movl	%r12d, %r15d
	addl	%ebx, %r15d
	leal	(%r12,%rbx), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%ebx, %esi
	callq	_sort_quick_multi
	leal	(%r15,%r13), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%r15d, %esi
	callq	_sort_quick_multi
LBB20_39:
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB20_206
## %bb.40:
	addq	$120, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB20_206:
	callq	___stack_chk_fail
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_simd           ## -- Begin function partition_quick_simd
	.p2align	4, 0x90
_partition_quick_simd:                  ## @partition_quick_simd
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -32
	.cfi_offset %r14, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movslq	%edx, %r8
	subl	%esi, %edx
	cmpl	$2, %edx
	jl	LBB21_2
## %bb.1:
	leal	(%r8,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %r9d
	movslq	%ecx, %r11
	movl	(%rdi,%r11,4), %r10d
	movl	(%rdi,%r8,4), %r14d
	cmpl	%r10d, %r9d
	movl	%r10d, %ebx
	cmovll	%r9d, %ebx
	movl	%r10d, %ecx
	cmovgl	%r9d, %ecx
	cmpl	%r14d, %ebx
	cmovgel	%r14d, %ebx
	cmpl	%r14d, %ecx
	cmovlel	%r14d, %ecx
	addl	%r9d, %r10d
	addl	%r14d, %r10d
	subl	%ebx, %r10d
	subl	%ecx, %r10d
	movl	%ebx, (%rdi,%rax,4)
	movl	%r10d, (%rdi,%r8,4)
	movl	%ecx, (%rdi,%r11,4)
	jmp	LBB21_3
LBB21_2:
	movl	(%rdi,%r8,4), %r10d
	movslq	%esi, %rax
LBB21_3:
	leal	7(%rdx), %ecx
	testl	%edx, %edx
	cmovnsl	%edx, %ecx
	andl	$-8, %ecx
	cmpl	%esi, %ecx
	jle	LBB21_4
## %bb.11:
	vmovd	%r10d, %xmm0
	vpbroadcastd	%xmm0, %ymm0
	movslq	%ecx, %r9
	movq	%rax, %rdx
	.p2align	4, 0x90
LBB21_12:                               ## =>This Inner Loop Header: Depth=1
	vpcmpgtd	(%rdi,%rdx,4), %ymm0, %ymm1
	vpsrld	$31, %ymm1, %ymm1
	vmovdqu	(%rdi,%rdx,4), %xmm2
	vmovdqu	%ymm1, -48(%rbp)
	vmovd	%xmm1, %ecx
	movl	(%rdi,%rax,4), %ebx
	vmovd	%xmm2, %r11d
	testl	%ecx, %ecx
	movl	%r11d, %esi
	cmovel	%ebx, %esi
	movl	%esi, (%rdi,%rax,4)
	cmovel	%r11d, %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	%rax, %rcx
	vpextrd	$1, %xmm1, %eax
	movl	(%rdi,%rcx,4), %esi
	movl	4(%rdi,%rdx,4), %r11d
	testl	%eax, %eax
	movl	%r11d, %ebx
	cmovel	%esi, %ebx
	movl	%ebx, (%rdi,%rcx,4)
	cmovel	%r11d, %esi
	movl	%esi, 4(%rdi,%rdx,4)
	vpextrd	$2, %xmm1, %esi
	addq	%rcx, %rax
	movl	(%rdi,%rax,4), %ecx
	movl	8(%rdi,%rdx,4), %r11d
	testl	%esi, %esi
	movl	%r11d, %ebx
	cmovel	%ecx, %ebx
	movl	%ebx, (%rdi,%rax,4)
	cmovel	%r11d, %ecx
	movl	%ecx, 8(%rdi,%rdx,4)
	addq	%rax, %rsi
	vpextrd	$3, %xmm1, %eax
	movl	(%rdi,%rsi,4), %ecx
	movl	12(%rdi,%rdx,4), %r11d
	testl	%eax, %eax
	movl	%r11d, %ebx
	cmovel	%ecx, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovel	%r11d, %ecx
	movl	%ecx, 12(%rdi,%rdx,4)
	addq	%rsi, %rax
	vextracti128	$1, %ymm1, %xmm1
	vmovd	%xmm1, %ecx
	movl	(%rdi,%rax,4), %esi
	movl	16(%rdi,%rdx,4), %r11d
	testl	%ecx, %ecx
	movl	%r11d, %ebx
	cmovel	%esi, %ebx
	movl	%ebx, (%rdi,%rax,4)
	cmovel	%r11d, %esi
	movl	%esi, 16(%rdi,%rdx,4)
	vpextrd	$1, %xmm1, %esi
	addq	%rax, %rcx
	movl	(%rdi,%rcx,4), %eax
	movl	20(%rdi,%rdx,4), %r11d
	testl	%esi, %esi
	movl	%r11d, %ebx
	cmovel	%eax, %ebx
	movl	%ebx, (%rdi,%rcx,4)
	cmovel	%r11d, %eax
	movl	%eax, 20(%rdi,%rdx,4)
	addq	%rcx, %rsi
	vpextrd	$2, %xmm1, %eax
	movl	(%rdi,%rsi,4), %ecx
	movl	24(%rdi,%rdx,4), %r11d
	testl	%eax, %eax
	movl	%r11d, %ebx
	cmovel	%ecx, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovel	%r11d, %ecx
	movl	%ecx, 24(%rdi,%rdx,4)
	addq	%rsi, %rax
	movslq	-20(%rbp), %r11
	testq	%r11, %r11
	movl	(%rdi,%rax,4), %esi
	movl	28(%rdi,%rdx,4), %ecx
	movl	%ecx, %ebx
	cmovel	%esi, %ebx
	movl	%ebx, (%rdi,%rax,4)
	cmovel	%ecx, %esi
	movl	%esi, 28(%rdi,%rdx,4)
	addq	%r11, %rax
	addq	$8, %rdx
	cmpq	%r9, %rdx
	jl	LBB21_12
## %bb.5:
	cmpq	%r8, %rdx
	jl	LBB21_6
	jmp	LBB21_10
LBB21_4:
	movq	%rax, %rdx
	cmpq	%r8, %rdx
	jge	LBB21_10
LBB21_6:
	movl	%r8d, %r11d
	subl	%edx, %r11d
	movq	%rdx, %r9
	notq	%r9
	addq	%r8, %r9
	andq	$3, %r11
	je	LBB21_8
	.p2align	4, 0x90
LBB21_7:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %ecx
	xorl	%ebx, %ebx
	cmpl	%ecx, %r10d
	setg	%bl
	movl	(%rdi,%rax,4), %r14d
	movl	%r14d, %esi
	cmovgl	%ecx, %esi
	movl	%esi, (%rdi,%rax,4)
	cmovgl	%r14d, %ecx
	movl	%ecx, (%rdi,%rdx,4)
	addq	%rbx, %rax
	incq	%rdx
	decq	%r11
	jne	LBB21_7
LBB21_8:
	cmpq	$3, %r9
	jb	LBB21_10
	.p2align	4, 0x90
LBB21_9:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %ecx
	xorl	%esi, %esi
	cmpl	%ecx, %r10d
	setg	%sil
	movl	(%rdi,%rax,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%ecx, %ebx
	movl	%ebx, (%rdi,%rax,4)
	cmovgl	%r9d, %ecx
	movl	%ecx, (%rdi,%rdx,4)
	addq	%rax, %rsi
	movl	4(%rdi,%rdx,4), %eax
	xorl	%ecx, %ecx
	cmpl	%eax, %r10d
	setg	%cl
	movl	(%rdi,%rsi,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%r9d, %eax
	movl	%eax, 4(%rdi,%rdx,4)
	addq	%rsi, %rcx
	movl	8(%rdi,%rdx,4), %eax
	xorl	%esi, %esi
	cmpl	%eax, %r10d
	setg	%sil
	movl	(%rdi,%rcx,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%rdi,%rcx,4)
	cmovgl	%r9d, %eax
	movl	%eax, 8(%rdi,%rdx,4)
	addq	%rcx, %rsi
	movl	12(%rdi,%rdx,4), %ecx
	xorl	%eax, %eax
	cmpl	%ecx, %r10d
	setg	%al
	movl	(%rdi,%rsi,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%ecx, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%r9d, %ecx
	movl	%ecx, 12(%rdi,%rdx,4)
	addq	%rsi, %rax
	addq	$4, %rdx
	cmpq	%rdx, %r8
	jne	LBB21_9
LBB21_10:
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r8,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r8,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_simd                ## -- Begin function sort_quick_simd
	.p2align	4, 0x90
_sort_quick_simd:                       ## @sort_quick_simd
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	%edx, %esi
	jge	LBB22_3
## %bb.1:
	movl	%edx, %r14d
	movl	%esi, %r12d
	movq	%rdi, %r15
	.p2align	4, 0x90
LBB22_2:                                ## =>This Inner Loop Header: Depth=1
	movq	%r15, %rdi
	movl	%r12d, %esi
	movl	%r14d, %edx
	callq	_partition_quick_simd
	movl	%eax, %ebx
	leal	-1(%rbx), %edx
	movq	%r15, %rdi
	movl	%r12d, %esi
	callq	_sort_quick_simd
	incl	%ebx
	movl	%ebx, %r12d
	cmpl	%r14d, %ebx
	jl	LBB22_2
LBB22_3:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_optimized_swap_arith ## -- Begin function partition_quick_optimized_swap_arith
	.p2align	4, 0x90
_partition_quick_optimized_swap_arith:  ## @partition_quick_optimized_swap_arith
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB23_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %r9d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r15d
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r11d
	cmpl	%r15d, %r9d
	movl	%r15d, %ebx
	cmovll	%r9d, %ebx
	movl	%r15d, %r14d
	cmovgl	%r9d, %r14d
	cmpl	%r11d, %ebx
	cmovgel	%r11d, %ebx
	cmpl	%r11d, %r14d
	cmovlel	%r11d, %r14d
	addl	%r9d, %r15d
	addl	%r11d, %r15d
	subl	%ebx, %r15d
	subl	%r14d, %r15d
	movl	%ebx, (%rdi,%rax,4)
	movl	%r15d, (%rdi,%r8,4)
	movl	%r14d, (%rdi,%r10,4)
	cmpl	%esi, %edx
	jg	LBB23_4
	jmp	LBB23_8
LBB23_2:
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r15d
	movslq	%esi, %rax
	cmpl	%esi, %edx
	jle	LBB23_8
LBB23_4:
	movl	%r8d, %r10d
	subl	%eax, %r10d
	movq	%rax, %r9
	notq	%r9
	addq	%r8, %r9
	movq	%rax, %rdx
	andq	$3, %r10
	je	LBB23_6
	.p2align	4, 0x90
LBB23_5:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %ecx
	xorl	%r11d, %r11d
	cmpl	%ecx, %r15d
	setg	%r11b
	movl	(%rdi,%rax,4), %esi
	movl	%ecx, %ebx
	cmovgl	%esi, %ebx
	cmovgl	%ecx, %esi
	movl	%ebx, (%rdi,%rdx,4)
	movl	%esi, (%rdi,%rax,4)
	addq	%r11, %rax
	incq	%rdx
	decq	%r10
	jne	LBB23_5
LBB23_6:
	cmpq	$3, %r9
	jb	LBB23_8
	.p2align	4, 0x90
LBB23_7:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %r9d
	xorl	%esi, %esi
	cmpl	%r9d, %r15d
	setg	%sil
	movl	(%rdi,%rax,4), %ebx
	movl	%r9d, %ecx
	cmovgl	%ebx, %ecx
	cmovgl	%r9d, %ebx
	movl	%ecx, (%rdi,%rdx,4)
	movl	%ebx, (%rdi,%rax,4)
	addq	%rax, %rsi
	movl	4(%rdi,%rdx,4), %r9d
	xorl	%ecx, %ecx
	cmpl	%r9d, %r15d
	setg	%cl
	movl	(%rdi,%rsi,4), %ebx
	movl	%r9d, %eax
	cmovgl	%ebx, %eax
	cmovgl	%r9d, %ebx
	movl	%eax, 4(%rdi,%rdx,4)
	movl	%ebx, (%rdi,%rsi,4)
	addq	%rsi, %rcx
	movl	8(%rdi,%rdx,4), %r9d
	xorl	%esi, %esi
	cmpl	%r9d, %r15d
	setg	%sil
	movl	(%rdi,%rcx,4), %ebx
	movl	%r9d, %eax
	cmovgl	%ebx, %eax
	cmovgl	%r9d, %ebx
	movl	%eax, 8(%rdi,%rdx,4)
	movl	%ebx, (%rdi,%rcx,4)
	addq	%rcx, %rsi
	movl	12(%rdi,%rdx,4), %r9d
	xorl	%eax, %eax
	cmpl	%r9d, %r15d
	setg	%al
	movl	(%rdi,%rsi,4), %ebx
	movl	%r9d, %ecx
	cmovgl	%ebx, %ecx
	cmovgl	%r9d, %ebx
	movl	%ecx, 12(%rdi,%rdx,4)
	movl	%ebx, (%rdi,%rsi,4)
	addq	%rsi, %rax
	addq	$4, %rdx
	cmpq	%rdx, %r8
	jne	LBB23_7
LBB23_8:
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r8,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r8,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_optimized_swap_arith ## -- Begin function sort_quick_optimized_swap_arith
	.p2align	4, 0x90
_sort_quick_optimized_swap_arith:       ## @sort_quick_optimized_swap_arith
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB24_11
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %r12
	movslq	%edx, %r15
	jmp	LBB24_2
	.p2align	4, 0x90
LBB24_10:                               ##   in Loop: Header=BB24_2 Depth=1
	movl	(%r12,%rbx,4), %eax
	movl	(%r12,%r15,4), %ecx
	movl	%ecx, (%r12,%rbx,4)
	movl	%eax, (%r12,%r15,4)
	leal	-1(%rbx), %edx
	movq	%r12, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	callq	_sort_quick_optimized_swap_arith
	incl	%ebx
	movl	%ebx, %esi
	cmpl	%r14d, %ebx
	jge	LBB24_11
LBB24_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB24_7 Depth 2
                                        ##     Child Loop BB24_9 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB24_11
## %bb.3:                               ##   in Loop: Header=BB24_2 Depth=1
	cmpl	$1, %eax
	jne	LBB24_4
## %bb.5:                               ##   in Loop: Header=BB24_2 Depth=1
	movl	(%r12,%r15,4), %r10d
	movslq	%esi, %rbx
	jmp	LBB24_6
	.p2align	4, 0x90
LBB24_4:                                ##   in Loop: Header=BB24_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rbx
	movl	(%r12,%rbx,4), %r9d
	movslq	%ecx, %r8
	movl	(%r12,%r8,4), %r10d
	movl	(%r12,%r15,4), %edi
	cmpl	%r10d, %r9d
	movl	%r10d, %ecx
	cmovll	%r9d, %ecx
	movl	%r10d, %edx
	cmovgl	%r9d, %edx
	cmpl	%edi, %ecx
	cmovgel	%edi, %ecx
	cmpl	%edi, %edx
	cmovlel	%edi, %edx
	addl	%r9d, %r10d
	addl	%edi, %r10d
	subl	%ecx, %r10d
	subl	%edx, %r10d
	movl	%ecx, (%r12,%rbx,4)
	movl	%r10d, (%r12,%r15,4)
	movl	%edx, (%r12,%r8,4)
LBB24_6:                                ##   in Loop: Header=BB24_2 Depth=1
	movl	%r14d, %r9d
	subl	%ebx, %r9d
	movq	%rbx, %r8
	notq	%r8
	addq	%r15, %r8
	movq	%rbx, %rcx
	andq	$3, %r9
	je	LBB24_8
	.p2align	4, 0x90
LBB24_7:                                ##   Parent Loop BB24_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r12,%rcx,4), %eax
	xorl	%r11d, %r11d
	cmpl	%eax, %r10d
	setg	%r11b
	movl	(%r12,%rbx,4), %edi
	movl	%eax, %edx
	cmovgl	%edi, %edx
	cmovgl	%eax, %edi
	movl	%edx, (%r12,%rcx,4)
	movl	%edi, (%r12,%rbx,4)
	addq	%r11, %rbx
	incq	%rcx
	decq	%r9
	jne	LBB24_7
LBB24_8:                                ##   in Loop: Header=BB24_2 Depth=1
	cmpq	$3, %r8
	jb	LBB24_10
	.p2align	4, 0x90
LBB24_9:                                ##   Parent Loop BB24_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r12,%rcx,4), %r8d
	xorl	%edx, %edx
	cmpl	%r8d, %r10d
	setg	%dl
	movl	(%r12,%rbx,4), %edi
	movl	%r8d, %eax
	cmovgl	%edi, %eax
	cmovgl	%r8d, %edi
	movl	%eax, (%r12,%rcx,4)
	movl	%edi, (%r12,%rbx,4)
	addq	%rbx, %rdx
	movl	4(%r12,%rcx,4), %r8d
	xorl	%edi, %edi
	cmpl	%r8d, %r10d
	setg	%dil
	movl	(%r12,%rdx,4), %ebx
	movl	%r8d, %eax
	cmovgl	%ebx, %eax
	cmovgl	%r8d, %ebx
	movl	%eax, 4(%r12,%rcx,4)
	movl	%ebx, (%r12,%rdx,4)
	addq	%rdx, %rdi
	movl	8(%r12,%rcx,4), %r8d
	xorl	%edx, %edx
	cmpl	%r8d, %r10d
	setg	%dl
	movl	(%r12,%rdi,4), %ebx
	movl	%r8d, %eax
	cmovgl	%ebx, %eax
	cmovgl	%r8d, %ebx
	movl	%eax, 8(%r12,%rcx,4)
	movl	%ebx, (%r12,%rdi,4)
	addq	%rdi, %rdx
	movl	12(%r12,%rcx,4), %r8d
	xorl	%ebx, %ebx
	cmpl	%r8d, %r10d
	setg	%bl
	movl	(%r12,%rdx,4), %edi
	movl	%r8d, %eax
	cmovgl	%edi, %eax
	cmovgl	%r8d, %edi
	movl	%eax, 12(%r12,%rcx,4)
	movl	%edi, (%r12,%rdx,4)
	addq	%rdx, %rbx
	addq	$4, %rcx
	cmpq	%rcx, %r15
	jne	LBB24_9
	jmp	LBB24_10
LBB24_11:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_optimized_swap_array ## -- Begin function partition_quick_optimized_swap_array
	.p2align	4, 0x90
_partition_quick_optimized_swap_array:  ## @partition_quick_optimized_swap_array
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB25_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %r9d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r15d
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r11d
	cmpl	%r15d, %r9d
	movl	%r15d, %ebx
	cmovll	%r9d, %ebx
	movl	%r15d, %r14d
	cmovgl	%r9d, %r14d
	cmpl	%r11d, %ebx
	cmovgel	%r11d, %ebx
	cmpl	%r11d, %r14d
	cmovlel	%r11d, %r14d
	addl	%r9d, %r15d
	addl	%r11d, %r15d
	subl	%ebx, %r15d
	subl	%r14d, %r15d
	movl	%ebx, (%rdi,%rax,4)
	movl	%r15d, (%rdi,%r8,4)
	movl	%r14d, (%rdi,%r10,4)
	cmpl	%esi, %edx
	jg	LBB25_4
	jmp	LBB25_10
LBB25_2:
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r15d
	movslq	%esi, %rax
	cmpl	%esi, %edx
	jle	LBB25_10
LBB25_4:
	movl	%r8d, %edx
	subl	%eax, %edx
	leaq	1(%rax), %r9
	testb	$1, %dl
	jne	LBB25_6
## %bb.5:
	movq	%rax, %rdx
	cmpq	%r9, %r8
	jne	LBB25_8
	jmp	LBB25_10
LBB25_6:
	movl	(%rdi,%rax,4), %edx
	xorl	%ebx, %ebx
	xorl	%esi, %esi
	cmpl	%edx, %r15d
	setg	%bl
	setle	%sil
	movq	_x@GOTPCREL(%rip), %r10
	movl	%edx, (%r10)
	movl	(%rdi,%rax,4), %edx
	movl	%edx, 4(%r10)
	movl	(%r10,%rsi,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	(%r10,%rbx,4), %edx
	movl	%edx, (%rdi,%rax,4)
	addq	%rbx, %rax
	movq	%r9, %rdx
	cmpq	%r9, %r8
	je	LBB25_10
LBB25_8:
	movq	_x@GOTPCREL(%rip), %r9
	.p2align	4, 0x90
LBB25_9:                                ## =>This Inner Loop Header: Depth=1
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	cmpl	(%rdi,%rdx,4), %r15d
	setg	%bl
	setle	%cl
	movl	(%rdi,%rax,4), %esi
	movl	%esi, (%r9)
	movl	(%rdi,%rdx,4), %esi
	movl	%esi, 4(%r9)
	movl	(%r9,%rcx,4), %ecx
	movl	%ecx, (%rdi,%rdx,4)
	movl	(%r9,%rbx,4), %ecx
	movl	%ecx, (%rdi,%rax,4)
	addq	%rbx, %rax
	xorl	%ecx, %ecx
	xorl	%esi, %esi
	cmpl	4(%rdi,%rdx,4), %r15d
	setg	%cl
	setle	%sil
	movl	(%rdi,%rax,4), %ebx
	movl	%ebx, (%r9)
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ebx, 4(%r9)
	movl	(%r9,%rsi,4), %esi
	movl	%esi, 4(%rdi,%rdx,4)
	movl	(%r9,%rcx,4), %esi
	movl	%esi, (%rdi,%rax,4)
	addq	%rcx, %rax
	addq	$2, %rdx
	cmpq	%rdx, %r8
	jne	LBB25_9
LBB25_10:
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r8,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r8,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_optimized_swap_array ## -- Begin function sort_quick_optimized_swap_array
	.p2align	4, 0x90
_sort_quick_optimized_swap_array:       ## @sort_quick_optimized_swap_array
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB26_11
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %rbx
	movslq	%edx, %r15
	movq	%r15, %rax
	negq	%rax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	movq	_x@GOTPCREL(%rip), %r13
	jmp	LBB26_2
	.p2align	4, 0x90
LBB26_10:                               ##   in Loop: Header=BB26_2 Depth=1
	movl	(%rbx,%r12,4), %eax
	movl	(%rbx,%r15,4), %ecx
	movl	%ecx, (%rbx,%r12,4)
	movl	%eax, (%rbx,%r15,4)
	leal	-1(%r12), %edx
	movq	%rbx, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	callq	_sort_quick_optimized_swap_array
	incl	%r12d
	movl	%r12d, %esi
	cmpl	%r14d, %r12d
	jge	LBB26_11
LBB26_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB26_9 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB26_11
## %bb.3:                               ##   in Loop: Header=BB26_2 Depth=1
	cmpl	$1, %eax
	jne	LBB26_4
## %bb.5:                               ##   in Loop: Header=BB26_2 Depth=1
	movl	(%rbx,%r15,4), %r11d
	movslq	%esi, %rcx
	jmp	LBB26_6
	.p2align	4, 0x90
LBB26_4:                                ##   in Loop: Header=BB26_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %edx
	shrl	$31, %edx
	addl	%eax, %edx
	sarl	%edx
	movslq	%esi, %rcx
	movl	(%rbx,%rcx,4), %r9d
	movslq	%edx, %r8
	movl	(%rbx,%r8,4), %r11d
	movl	(%rbx,%r15,4), %r10d
	cmpl	%r11d, %r9d
	movl	%r11d, %edi
	cmovll	%r9d, %edi
	movl	%r11d, %edx
	cmovgl	%r9d, %edx
	cmpl	%r10d, %edi
	cmovgel	%r10d, %edi
	cmpl	%r10d, %edx
	cmovlel	%r10d, %edx
	addl	%r9d, %r11d
	addl	%r10d, %r11d
	subl	%edi, %r11d
	subl	%edx, %r11d
	movl	%edi, (%rbx,%rcx,4)
	movl	%r11d, (%rbx,%r15,4)
	movl	%edx, (%rbx,%r8,4)
LBB26_6:                                ##   in Loop: Header=BB26_2 Depth=1
	movl	%r14d, %edi
	subl	%ecx, %edi
	movq	%rcx, %r12
	movq	%rcx, %rdx
	testb	$1, %dil
	je	LBB26_8
## %bb.7:                               ##   in Loop: Header=BB26_2 Depth=1
	movl	(%rbx,%rcx,4), %edx
	xorl	%r12d, %r12d
	xorl	%edi, %edi
	cmpl	%edx, %r11d
	setg	%r12b
	setle	%dil
	movl	%edx, (%r13)
	movl	(%rbx,%rcx,4), %edx
	movl	%edx, 4(%r13)
	movl	(%r13,%rdi,4), %edx
	movl	%edx, (%rbx,%rcx,4)
	movl	(%r13,%r12,4), %edx
	movl	%edx, (%rbx,%rcx,4)
	addq	%rcx, %r12
	leaq	1(%rcx), %rdx
LBB26_8:                                ##   in Loop: Header=BB26_2 Depth=1
	notq	%rcx
	cmpq	-48(%rbp), %rcx                 ## 8-byte Folded Reload
	je	LBB26_10
	.p2align	4, 0x90
LBB26_9:                                ##   Parent Loop BB26_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	xorl	%ecx, %ecx
	xorl	%edi, %edi
	cmpl	(%rbx,%rdx,4), %r11d
	setg	%cl
	setle	%dil
	movl	(%rbx,%r12,4), %eax
	movl	%eax, (%r13)
	movl	(%rbx,%rdx,4), %eax
	movl	%eax, 4(%r13)
	movl	(%r13,%rdi,4), %eax
	movl	%eax, (%rbx,%rdx,4)
	movl	(%r13,%rcx,4), %eax
	movl	%eax, (%rbx,%r12,4)
	addq	%rcx, %r12
	xorl	%eax, %eax
	xorl	%ecx, %ecx
	cmpl	4(%rbx,%rdx,4), %r11d
	setg	%al
	setle	%cl
	movl	(%rbx,%r12,4), %edi
	movl	%edi, (%r13)
	movl	4(%rbx,%rdx,4), %edi
	movl	%edi, 4(%r13)
	movl	(%r13,%rcx,4), %ecx
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	(%r13,%rax,4), %ecx
	movl	%ecx, (%rbx,%r12,4)
	addq	%rax, %r12
	addq	$2, %rdx
	cmpq	%rdx, %r15
	jne	LBB26_9
	jmp	LBB26_10
LBB26_11:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_optimized_swap_cmov ## -- Begin function partition_quick_optimized_swap_cmov
	.p2align	4, 0x90
_partition_quick_optimized_swap_cmov:   ## @partition_quick_optimized_swap_cmov
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB27_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %r9d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r15d
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r11d
	cmpl	%r15d, %r9d
	movl	%r15d, %ebx
	cmovll	%r9d, %ebx
	movl	%r15d, %r14d
	cmovgl	%r9d, %r14d
	cmpl	%r11d, %ebx
	cmovgel	%r11d, %ebx
	cmpl	%r11d, %r14d
	cmovlel	%r11d, %r14d
	addl	%r9d, %r15d
	addl	%r11d, %r15d
	subl	%ebx, %r15d
	subl	%r14d, %r15d
	movl	%ebx, (%rdi,%rax,4)
	movl	%r15d, (%rdi,%r8,4)
	movl	%r14d, (%rdi,%r10,4)
	cmpl	%esi, %edx
	jg	LBB27_4
	jmp	LBB27_8
LBB27_2:
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r15d
	movslq	%esi, %rax
	cmpl	%esi, %edx
	jle	LBB27_8
LBB27_4:
	movl	%r8d, %r10d
	subl	%eax, %r10d
	movq	%rax, %r9
	notq	%r9
	addq	%r8, %r9
	movq	%rax, %rdx
	andq	$3, %r10
	je	LBB27_6
	.p2align	4, 0x90
LBB27_5:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %ebx
	xorl	%ecx, %ecx
	cmpl	%ebx, %r15d
	setg	%cl
	movl	(%rdi,%rax,4), %r11d
	movl	%r11d, %esi
	cmovgl	%ebx, %esi
	movl	%esi, (%rdi,%rax,4)
	cmovgl	%r11d, %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	%rcx, %rax
	incq	%rdx
	decq	%r10
	jne	LBB27_5
LBB27_6:
	cmpq	$3, %r9
	jb	LBB27_8
	.p2align	4, 0x90
LBB27_7:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %ecx
	xorl	%esi, %esi
	cmpl	%ecx, %r15d
	setg	%sil
	movl	(%rdi,%rax,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%ecx, %ebx
	movl	%ebx, (%rdi,%rax,4)
	cmovgl	%r9d, %ecx
	movl	%ecx, (%rdi,%rdx,4)
	addq	%rax, %rsi
	movl	4(%rdi,%rdx,4), %eax
	xorl	%ecx, %ecx
	cmpl	%eax, %r15d
	setg	%cl
	movl	(%rdi,%rsi,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%r9d, %eax
	movl	%eax, 4(%rdi,%rdx,4)
	addq	%rsi, %rcx
	movl	8(%rdi,%rdx,4), %eax
	xorl	%esi, %esi
	cmpl	%eax, %r15d
	setg	%sil
	movl	(%rdi,%rcx,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%rdi,%rcx,4)
	cmovgl	%r9d, %eax
	movl	%eax, 8(%rdi,%rdx,4)
	addq	%rcx, %rsi
	movl	12(%rdi,%rdx,4), %ecx
	xorl	%eax, %eax
	cmpl	%ecx, %r15d
	setg	%al
	movl	(%rdi,%rsi,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%ecx, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%r9d, %ecx
	movl	%ecx, 12(%rdi,%rdx,4)
	addq	%rsi, %rax
	addq	$4, %rdx
	cmpq	%rdx, %r8
	jne	LBB27_7
LBB27_8:
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r8,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r8,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_optimized_swap_cmov ## -- Begin function sort_quick_optimized_swap_cmov
	.p2align	4, 0x90
_sort_quick_optimized_swap_cmov:        ## @sort_quick_optimized_swap_cmov
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB28_11
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %r12
	movslq	%edx, %r15
	jmp	LBB28_2
	.p2align	4, 0x90
LBB28_10:                               ##   in Loop: Header=BB28_2 Depth=1
	movl	(%r12,%rbx,4), %eax
	movl	(%r12,%r15,4), %ecx
	movl	%ecx, (%r12,%rbx,4)
	movl	%eax, (%r12,%r15,4)
	leal	-1(%rbx), %edx
	movq	%r12, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	callq	_sort_quick_optimized_swap_cmov
	incl	%ebx
	movl	%ebx, %esi
	cmpl	%r14d, %ebx
	jge	LBB28_11
LBB28_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB28_7 Depth 2
                                        ##     Child Loop BB28_9 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB28_11
## %bb.3:                               ##   in Loop: Header=BB28_2 Depth=1
	cmpl	$1, %eax
	jne	LBB28_4
## %bb.5:                               ##   in Loop: Header=BB28_2 Depth=1
	movl	(%r12,%r15,4), %r10d
	movslq	%esi, %rbx
	jmp	LBB28_6
	.p2align	4, 0x90
LBB28_4:                                ##   in Loop: Header=BB28_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rbx
	movl	(%r12,%rbx,4), %r9d
	movslq	%ecx, %r8
	movl	(%r12,%r8,4), %r10d
	movl	(%r12,%r15,4), %edi
	cmpl	%r10d, %r9d
	movl	%r10d, %ecx
	cmovll	%r9d, %ecx
	movl	%r10d, %edx
	cmovgl	%r9d, %edx
	cmpl	%edi, %ecx
	cmovgel	%edi, %ecx
	cmpl	%edi, %edx
	cmovlel	%edi, %edx
	addl	%r9d, %r10d
	addl	%edi, %r10d
	subl	%ecx, %r10d
	subl	%edx, %r10d
	movl	%ecx, (%r12,%rbx,4)
	movl	%r10d, (%r12,%r15,4)
	movl	%edx, (%r12,%r8,4)
LBB28_6:                                ##   in Loop: Header=BB28_2 Depth=1
	movl	%r14d, %r9d
	subl	%ebx, %r9d
	movq	%rbx, %r8
	notq	%r8
	addq	%r15, %r8
	movq	%rbx, %rcx
	andq	$3, %r9
	je	LBB28_8
	.p2align	4, 0x90
LBB28_7:                                ##   Parent Loop BB28_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r12,%rcx,4), %edx
	xorl	%eax, %eax
	cmpl	%edx, %r10d
	setg	%al
	movl	(%r12,%rbx,4), %r11d
	movl	%r11d, %edi
	cmovgl	%edx, %edi
	movl	%edi, (%r12,%rbx,4)
	cmovgl	%r11d, %edx
	movl	%edx, (%r12,%rcx,4)
	addq	%rax, %rbx
	incq	%rcx
	decq	%r9
	jne	LBB28_7
LBB28_8:                                ##   in Loop: Header=BB28_2 Depth=1
	cmpq	$3, %r8
	jb	LBB28_10
	.p2align	4, 0x90
LBB28_9:                                ##   Parent Loop BB28_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r12,%rcx,4), %eax
	xorl	%edx, %edx
	cmpl	%eax, %r10d
	setg	%dl
	movl	(%r12,%rbx,4), %r8d
	movl	%r8d, %edi
	cmovgl	%eax, %edi
	movl	%edi, (%r12,%rbx,4)
	cmovgl	%r8d, %eax
	movl	%eax, (%r12,%rcx,4)
	addq	%rbx, %rdx
	movl	4(%r12,%rcx,4), %eax
	xorl	%edi, %edi
	cmpl	%eax, %r10d
	setg	%dil
	movl	(%r12,%rdx,4), %r8d
	movl	%r8d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%r12,%rdx,4)
	cmovgl	%r8d, %eax
	movl	%eax, 4(%r12,%rcx,4)
	addq	%rdx, %rdi
	movl	8(%r12,%rcx,4), %eax
	xorl	%edx, %edx
	cmpl	%eax, %r10d
	setg	%dl
	movl	(%r12,%rdi,4), %r8d
	movl	%r8d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%r12,%rdi,4)
	cmovgl	%r8d, %eax
	movl	%eax, 8(%r12,%rcx,4)
	addq	%rdi, %rdx
	movl	12(%r12,%rcx,4), %eax
	xorl	%ebx, %ebx
	cmpl	%eax, %r10d
	setg	%bl
	movl	(%r12,%rdx,4), %r8d
	movl	%r8d, %edi
	cmovgl	%eax, %edi
	movl	%edi, (%r12,%rdx,4)
	cmovgl	%r8d, %eax
	movl	%eax, 12(%r12,%rcx,4)
	addq	%rdx, %rbx
	addq	$4, %rcx
	cmpq	%rcx, %r15
	jne	LBB28_9
	jmp	LBB28_10
LBB28_11:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_standard       ## -- Begin function partition_quick_standard
	.p2align	4, 0x90
_partition_quick_standard:              ## @partition_quick_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -32
	.cfi_offset %r14, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB29_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%rdi,%r8,4), %r14d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r9d
	movslq	%edx, %r11
	movl	(%rdi,%r11,4), %ecx
	cmpl	%r9d, %r14d
	movl	%r9d, %ebx
	cmovll	%r14d, %ebx
	movl	%r9d, %eax
	cmovgl	%r14d, %eax
	cmpl	%ecx, %ebx
	cmovgel	%ecx, %ebx
	cmpl	%ecx, %eax
	cmovlel	%ecx, %eax
	addl	%r14d, %r9d
	addl	%ecx, %r9d
	subl	%ebx, %r9d
	subl	%eax, %r9d
	movl	%ebx, (%rdi,%r8,4)
	movl	%r9d, (%rdi,%r11,4)
	movl	%eax, (%rdi,%r10,4)
	leal	-1(%rsi), %eax
	movl	%edx, %ecx
	subl	%esi, %ecx
	jg	LBB29_5
LBB29_4:
	movslq	%edx, %r10
	jmp	LBB29_19
LBB29_2:
	movslq	%edx, %rax
	movl	(%rdi,%rax,4), %r9d
	leal	-1(%rsi), %eax
	movl	%edx, %ecx
	subl	%esi, %ecx
	jle	LBB29_4
LBB29_5:
	movslq	%esi, %rsi
	movslq	%edx, %r10
	movq	%rsi, %r8
	notq	%r8
	addq	%r10, %r8
	andq	$3, %rcx
	jne	LBB29_6
LBB29_9:
	cmpq	$3, %r8
	jae	LBB29_10
LBB29_19:
	movslq	%eax, %rcx
	incl	%eax
	movl	4(%rdi,%rcx,4), %edx
	movl	(%rdi,%r10,4), %esi
	movl	%esi, 4(%rdi,%rcx,4)
	movl	%edx, (%rdi,%r10,4)
	popq	%rbx
	popq	%r14
	popq	%rbp
	retq
	.p2align	4, 0x90
LBB29_8:                                ##   in Loop: Header=BB29_6 Depth=1
	incq	%rsi
	decq	%rcx
	je	LBB29_9
LBB29_6:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rsi,4), %edx
	cmpl	%r9d, %edx
	jg	LBB29_8
## %bb.7:                               ##   in Loop: Header=BB29_6 Depth=1
	movslq	%eax, %rbx
	incl	%eax
	movl	4(%rdi,%rbx,4), %r11d
	movl	%edx, 4(%rdi,%rbx,4)
	movl	%r11d, (%rdi,%rsi,4)
	jmp	LBB29_8
	.p2align	4, 0x90
LBB29_18:                               ##   in Loop: Header=BB29_10 Depth=1
	addq	$4, %rsi
	cmpq	%rsi, %r10
	je	LBB29_19
LBB29_10:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB29_11
## %bb.12:                              ##   in Loop: Header=BB29_10 Depth=1
	movl	4(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB29_13
LBB29_14:                               ##   in Loop: Header=BB29_10 Depth=1
	movl	8(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB29_15
LBB29_16:                               ##   in Loop: Header=BB29_10 Depth=1
	movl	12(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB29_18
	jmp	LBB29_17
	.p2align	4, 0x90
LBB29_11:                               ##   in Loop: Header=BB29_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, (%rdi,%rsi,4)
	movl	4(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB29_14
LBB29_13:                               ##   in Loop: Header=BB29_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, 4(%rdi,%rsi,4)
	movl	8(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB29_16
LBB29_15:                               ##   in Loop: Header=BB29_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, 8(%rdi,%rsi,4)
	movl	12(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB29_18
LBB29_17:                               ##   in Loop: Header=BB29_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, 12(%rdi,%rsi,4)
	jmp	LBB29_18
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_standard            ## -- Begin function sort_quick_standard
	.p2align	4, 0x90
_sort_quick_standard:                   ## @sort_quick_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB30_21
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %rbx
	movslq	%edx, %r12
	jmp	LBB30_2
	.p2align	4, 0x90
LBB30_20:                               ##   in Loop: Header=BB30_2 Depth=1
	movslq	%r10d, %r15
	movl	4(%rbx,%r15,4), %eax
	movl	(%rbx,%r12,4), %ecx
	movl	%ecx, 4(%rbx,%r15,4)
	movl	%eax, (%rbx,%r12,4)
	movq	%rbx, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	movl	%r15d, %edx
	callq	_sort_quick_standard
	addl	$2, %r15d
	movl	%r15d, %esi
	cmpl	%r14d, %r15d
	jge	LBB30_21
LBB30_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB30_7 Depth 2
                                        ##     Child Loop BB30_11 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB30_21
## %bb.3:                               ##   in Loop: Header=BB30_2 Depth=1
	cmpl	$1, %eax
	jne	LBB30_4
## %bb.5:                               ##   in Loop: Header=BB30_2 Depth=1
	movl	(%rbx,%r12,4), %r9d
	movslq	%esi, %rax
	jmp	LBB30_6
	.p2align	4, 0x90
LBB30_4:                                ##   in Loop: Header=BB30_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rbx,%rax,4), %r10d
	movslq	%ecx, %r8
	movl	(%rbx,%r8,4), %r9d
	movl	(%rbx,%r12,4), %edi
	cmpl	%r9d, %r10d
	movl	%r9d, %ecx
	cmovll	%r10d, %ecx
	movl	%r9d, %edx
	cmovgl	%r10d, %edx
	cmpl	%edi, %ecx
	cmovgel	%edi, %ecx
	cmpl	%edi, %edx
	cmovlel	%edi, %edx
	addl	%r10d, %r9d
	addl	%edi, %r9d
	subl	%ecx, %r9d
	subl	%edx, %r9d
	movl	%ecx, (%rbx,%rax,4)
	movl	%r9d, (%rbx,%r12,4)
	movl	%edx, (%rbx,%r8,4)
LBB30_6:                                ##   in Loop: Header=BB30_2 Depth=1
	leal	-1(%rsi), %r10d
	movl	%r14d, %edi
	subl	%eax, %edi
	movq	%rax, %r8
	notq	%r8
	addq	%r12, %r8
	andq	$3, %rdi
	jne	LBB30_7
LBB30_10:                               ##   in Loop: Header=BB30_2 Depth=1
	cmpq	$3, %r8
	jae	LBB30_11
	jmp	LBB30_20
	.p2align	4, 0x90
LBB30_9:                                ##   in Loop: Header=BB30_7 Depth=2
	incq	%rax
	decq	%rdi
	je	LBB30_10
LBB30_7:                                ##   Parent Loop BB30_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB30_9
## %bb.8:                               ##   in Loop: Header=BB30_7 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %r11d
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%r11d, (%rbx,%rax,4)
	jmp	LBB30_9
	.p2align	4, 0x90
LBB30_19:                               ##   in Loop: Header=BB30_11 Depth=2
	addq	$4, %rax
	cmpq	%rax, %r12
	je	LBB30_20
LBB30_11:                               ##   Parent Loop BB30_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB30_12
## %bb.13:                              ##   in Loop: Header=BB30_11 Depth=2
	movl	4(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB30_14
LBB30_15:                               ##   in Loop: Header=BB30_11 Depth=2
	movl	8(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB30_16
LBB30_17:                               ##   in Loop: Header=BB30_11 Depth=2
	movl	12(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB30_19
	jmp	LBB30_18
	.p2align	4, 0x90
LBB30_12:                               ##   in Loop: Header=BB30_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, (%rbx,%rax,4)
	movl	4(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB30_15
LBB30_14:                               ##   in Loop: Header=BB30_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, 4(%rbx,%rax,4)
	movl	8(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB30_17
LBB30_16:                               ##   in Loop: Header=BB30_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, 8(%rbx,%rax,4)
	movl	12(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB30_19
LBB30_18:                               ##   in Loop: Header=BB30_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, 12(%rbx,%rax,4)
	jmp	LBB30_19
LBB30_21:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_shuffle_data                   ## -- Begin function shuffle_data
	.p2align	4, 0x90
_shuffle_data:                          ## @shuffle_data
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movl	%esi, %eax
	decl	%eax
	je	LBB31_6
## %bb.1:
	movl	%esi, %r14d
	movq	%rdi, %r13
	movslq	%eax, %r15
	movslq	%esi, %r12
	xorl	%ebx, %ebx
	jmp	LBB31_2
	.p2align	4, 0x90
LBB31_4:                                ##   in Loop: Header=BB31_2 Depth=1
	xorl	%edx, %edx
	divq	%r12
LBB31_5:                                ##   in Loop: Header=BB31_2 Depth=1
	movl	(%r13,%rdx,4), %eax
	movl	(%r13,%rbx,4), %ecx
	movl	%ecx, (%r13,%rdx,4)
	movl	%eax, (%r13,%rbx,4)
	incq	%rbx
	cmpq	%r15, %rbx
	jae	LBB31_6
LBB31_2:                                ## =>This Inner Loop Header: Depth=1
	callq	_rand
	cltq
	addq	%rbx, %rax
	movq	%rax, %rcx
	orq	%r12, %rcx
	shrq	$32, %rcx
	jne	LBB31_4
## %bb.3:                               ##   in Loop: Header=BB31_2 Depth=1
                                        ## kill: def $eax killed $eax killed $rax
	xorl	%edx, %edx
	divl	%r14d
                                        ## kill: def $edx killed $edx def $rdx
	jmp	LBB31_5
LBB31_6:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.section	__TEXT,__literal4,4byte_literals
	.p2align	2                               ## -- Begin function bench
LCPI32_0:
	.long	0x49742400                      ## float 1.0E+6
LCPI32_1:
	.long	0x447a0000                      ## float 1000
	.section	__TEXT,__text,regular,pure_instructions
	.globl	_bench
	.p2align	4, 0x90
_bench:                                 ## @bench
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$56, %rsp
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movq	%rsi, -64(%rbp)                 ## 8-byte Spill
	movq	%rdi, %rsi
	cmpl	$10, %edx
	jne	LBB32_1
## %bb.8:
	leaq	L_.str(%rip), %rdi
	xorl	%eax, %eax
	addq	$56, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	jmp	_printf                         ## TAILCALL
LBB32_1:
	movq	%rcx, %rbx
	movl	%edx, %r12d
	decl	%r12d
	je	LBB32_2
## %bb.9:
	movq	%rsi, -80(%rbp)                 ## 8-byte Spill
	movslq	%r12d, %r13
	movl	%edx, -52(%rbp)                 ## 4-byte Spill
	movslq	%edx, %r14
	movl	%r12d, %eax
	sarl	$31, %eax
	andnl	%r12d, %eax, %r15d
	xorl	%edx, %edx
	xorl	%eax, %eax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	movl	%r12d, -56(%rbp)                ## 4-byte Spill
	.p2align	4, 0x90
LBB32_10:                               ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB32_11 Depth 2
                                        ##     Child Loop BB32_20 Depth 2
	movq	%rdx, -72(%rbp)                 ## 8-byte Spill
	xorl	%r12d, %r12d
	jmp	LBB32_11
	.p2align	4, 0x90
LBB32_12:                               ##   in Loop: Header=BB32_11 Depth=2
                                        ## kill: def $eax killed $eax killed $rax
	xorl	%edx, %edx
	divl	-52(%rbp)                       ## 4-byte Folded Reload
                                        ## kill: def $edx killed $edx def $rdx
LBB32_14:                               ##   in Loop: Header=BB32_11 Depth=2
	movl	(%rbx,%rdx,4), %eax
	movl	(%rbx,%r12,4), %ecx
	movl	%ecx, (%rbx,%rdx,4)
	movl	%eax, (%rbx,%r12,4)
	incq	%r12
	cmpq	%r13, %r12
	jae	LBB32_15
LBB32_11:                               ##   Parent Loop BB32_10 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	callq	_rand
	cltq
	addq	%r12, %rax
	movq	%rax, %rcx
	orq	%r14, %rcx
	shrq	$32, %rcx
	je	LBB32_12
## %bb.13:                              ##   in Loop: Header=BB32_11 Depth=2
	xorl	%edx, %edx
	divq	%r14
	jmp	LBB32_14
	.p2align	4, 0x90
LBB32_15:                               ##   in Loop: Header=BB32_10 Depth=1
	movl	$12, %edi
	callq	_clock_gettime_nsec_np
	movq	%rax, -88(%rbp)                 ## 8-byte Spill
	movq	%rbx, %rdi
	xorl	%esi, %esi
	movl	-56(%rbp), %edx                 ## 4-byte Reload
	callq	*-64(%rbp)                      ## 8-byte Folded Reload
	movl	$12, %edi
	callq	_clock_gettime_nsec_np
	subq	-88(%rbp), %rax                 ## 8-byte Folded Reload
	js	LBB32_16
## %bb.17:                              ##   in Loop: Header=BB32_10 Depth=1
	vcvtsi2ss	%rax, %xmm1, %xmm0
	jmp	LBB32_18
	.p2align	4, 0x90
LBB32_16:                               ##   in Loop: Header=BB32_10 Depth=1
	movq	%rax, %rcx
	shrq	%rcx
	movl	%eax, %edx
	andl	$1, %edx
	orq	%rcx, %rdx
	vcvtsi2ss	%rdx, %xmm1, %xmm0
	vaddss	%xmm0, %xmm0, %xmm0
LBB32_18:                               ##   in Loop: Header=BB32_10 Depth=1
	movq	-72(%rbp), %rdi                 ## 8-byte Reload
	vdivss	LCPI32_0(%rip), %xmm0, %xmm0
	vmulss	LCPI32_1(%rip), %xmm0, %xmm0
	movq	_individual_times@GOTPCREL(%rip), %rcx
	vmovss	%xmm0, (%rcx,%rdi,4)
	testq	%rdi, %rdi
	je	LBB32_19
LBB32_23:                               ##   in Loop: Header=BB32_10 Depth=1
	leaq	1(%rdi), %rcx
	movq	-48(%rbp), %rdx                 ## 8-byte Reload
	addq	%rax, %rdx
	movq	%rdx, %rax
	movq	%rdx, -48(%rbp)                 ## 8-byte Spill
	cmpq	$200000000, %rdx                ## imm = 0xBEBC200
	setb	%al
	cmpq	$9, %rdi
	setb	%dl
	cmpq	$998, %rdi                      ## imm = 0x3E6
	ja	LBB32_25
## %bb.24:                              ##   in Loop: Header=BB32_10 Depth=1
	orb	%al, %dl
	movq	%rcx, %rdx
	jne	LBB32_10
	jmp	LBB32_25
	.p2align	4, 0x90
LBB32_19:                               ##   in Loop: Header=BB32_10 Depth=1
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB32_20:                               ##   Parent Loop BB32_10 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	cmpq	%rcx, %r15
	je	LBB32_23
## %bb.21:                              ##   in Loop: Header=BB32_20 Depth=2
	movl	(%rbx,%rcx,4), %edx
	leaq	1(%rcx), %rsi
	cmpl	4(%rbx,%rcx,4), %edx
	movq	%rsi, %rcx
	jle	LBB32_20
## %bb.22:
	leaq	L_.str.3(%rip), %rdi
	movq	-80(%rbp), %rsi                 ## 8-byte Reload
	xorl	%eax, %eax
	callq	_printf
	movl	$1, %edi
	callq	_exit
LBB32_2:
	xorl	%r12d, %r12d
	movq	_individual_times@GOTPCREL(%rip), %r14
	xorl	%eax, %eax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	.p2align	4, 0x90
LBB32_3:                                ## =>This Inner Loop Header: Depth=1
	movl	$12, %edi
	callq	_clock_gettime_nsec_np
	movq	%rax, %r15
	movq	%rbx, %rdi
	xorl	%esi, %esi
	xorl	%edx, %edx
	callq	*-64(%rbp)                      ## 8-byte Folded Reload
	movl	$12, %edi
	callq	_clock_gettime_nsec_np
	subq	%r15, %rax
	movq	-48(%rbp), %rdx                 ## 8-byte Reload
	addq	%rax, %rdx
	testq	%rax, %rax
	js	LBB32_4
## %bb.5:                               ##   in Loop: Header=BB32_3 Depth=1
	vcvtsi2ss	%rax, %xmm1, %xmm0
	jmp	LBB32_6
	.p2align	4, 0x90
LBB32_4:                                ##   in Loop: Header=BB32_3 Depth=1
	movq	%rax, %rcx
	shrq	%rcx
	andl	$1, %eax
	orq	%rcx, %rax
	vcvtsi2ss	%rax, %xmm1, %xmm0
	vaddss	%xmm0, %xmm0, %xmm0
LBB32_6:                                ##   in Loop: Header=BB32_3 Depth=1
	vdivss	LCPI32_0(%rip), %xmm0, %xmm0
	vmulss	LCPI32_1(%rip), %xmm0, %xmm0
	vmovss	%xmm0, (%r14,%r12,4)
	leaq	1(%r12), %rcx
	movq	%rdx, %rax
	movq	%rdx, -48(%rbp)                 ## 8-byte Spill
	cmpq	$200000000, %rdx                ## imm = 0xBEBC200
	setb	%al
	cmpq	$9, %r12
	setb	%dl
	cmpq	$998, %r12                      ## imm = 0x3E6
	ja	LBB32_25
## %bb.7:                               ##   in Loop: Header=BB32_3 Depth=1
	orb	%al, %dl
	movq	%rcx, %r12
	jne	LBB32_3
LBB32_25:
	movq	-48(%rbp), %rdx                 ## 8-byte Reload
	testq	%rdx, %rdx
	js	LBB32_26
## %bb.27:
	vcvtsi2ss	%rdx, %xmm1, %xmm0
	jmp	LBB32_28
LBB32_26:
	movq	%rdx, %rax
	shrq	%rax
	andl	$1, %edx
	orq	%rax, %rdx
	vcvtsi2ss	%rdx, %xmm1, %xmm0
	vaddss	%xmm0, %xmm0, %xmm0
LBB32_28:
	vmulss	LCPI32_1(%rip), %xmm0, %xmm0
	vdivss	LCPI32_0(%rip), %xmm0, %xmm1
	vcvtsi2ss	%ecx, %xmm2, %xmm0
	vdivss	%xmm0, %xmm1, %xmm3
	leaq	-1(%rcx), %rdx
	movl	%ecx, %eax
	andl	$7, %eax
	cmpq	$7, %rdx
	jae	LBB32_72
## %bb.29:
	vxorps	%xmm1, %xmm1, %xmm1
	xorl	%edx, %edx
	jmp	LBB32_30
LBB32_72:
	andq	$-8, %rcx
	vxorps	%xmm1, %xmm1, %xmm1
	xorl	%edx, %edx
	movq	_individual_times@GOTPCREL(%rip), %rsi
	.p2align	4, 0x90
LBB32_73:                               ## =>This Inner Loop Header: Depth=1
	vsubss	(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	4(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	8(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	12(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	16(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	20(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	24(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	28(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB32_73
LBB32_30:
	testq	%rax, %rax
	je	LBB32_33
## %bb.31:
	shlq	$2, %rdx
	addq	_individual_times@GOTPCREL(%rip), %rdx
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB32_32:                               ## =>This Inner Loop Header: Depth=1
	vsubss	(%rdx,%rcx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	incq	%rcx
	cmpq	%rcx, %rax
	jne	LBB32_32
LBB32_33:
	vdivss	%xmm0, %xmm1, %xmm0
	vsqrtss	%xmm0, %xmm0, %xmm0
	vmovss	%xmm0, -52(%rbp)                ## 4-byte Spill
	movl	$20, %edi
	vmovss	%xmm3, -48(%rbp)                ## 4-byte Spill
	callq	_malloc
	movq	%rax, %rbx
	vmovss	-48(%rbp), %xmm0                ## 4-byte Reload
                                        ## xmm0 = mem[0],zero,zero,zero
	vcvtss2sd	%xmm0, %xmm0, %xmm0
	vmovss	-52(%rbp), %xmm1                ## 4-byte Reload
                                        ## xmm1 = mem[0],zero,zero,zero
	vcvtss2sd	%xmm1, %xmm1, %xmm1
	leaq	L_.str.4(%rip), %rcx
	movl	$20, %edx
	movq	%rax, %rdi
	xorl	%esi, %esi
	movb	$2, %al
	callq	___sprintf_chk
	cmpb	$0, (%rbx)
	je	LBB32_34
## %bb.35:
	cmpb	$0, 1(%rbx)
	je	LBB32_36
LBB32_37:
	cmpb	$0, 2(%rbx)
	je	LBB32_38
LBB32_39:
	cmpb	$0, 3(%rbx)
	je	LBB32_40
LBB32_41:
	cmpb	$0, 4(%rbx)
	je	LBB32_42
LBB32_43:
	cmpb	$0, 5(%rbx)
	je	LBB32_44
LBB32_45:
	cmpb	$0, 6(%rbx)
	je	LBB32_46
LBB32_47:
	cmpb	$0, 7(%rbx)
	je	LBB32_48
LBB32_49:
	cmpb	$0, 8(%rbx)
	je	LBB32_50
LBB32_51:
	cmpb	$0, 9(%rbx)
	je	LBB32_52
LBB32_53:
	cmpb	$0, 10(%rbx)
	je	LBB32_54
LBB32_55:
	cmpb	$0, 11(%rbx)
	je	LBB32_56
LBB32_57:
	cmpb	$0, 12(%rbx)
	je	LBB32_58
LBB32_59:
	cmpb	$0, 13(%rbx)
	je	LBB32_60
LBB32_61:
	cmpb	$0, 14(%rbx)
	je	LBB32_62
LBB32_63:
	cmpb	$0, 15(%rbx)
	je	LBB32_64
LBB32_65:
	cmpb	$0, 16(%rbx)
	je	LBB32_66
LBB32_67:
	cmpb	$0, 17(%rbx)
	je	LBB32_68
LBB32_69:
	cmpb	$0, 18(%rbx)
	je	LBB32_70
LBB32_71:
	leaq	L_.str(%rip), %rdi
	movq	%rbx, %rsi
	xorl	%eax, %eax
	callq	_printf
	movq	%rbx, %rdi
	addq	$56, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	jmp	_free                           ## TAILCALL
LBB32_34:
	movb	$32, (%rbx)
	cmpb	$0, 1(%rbx)
	jne	LBB32_37
LBB32_36:
	movb	$32, 1(%rbx)
	cmpb	$0, 2(%rbx)
	jne	LBB32_39
LBB32_38:
	movb	$32, 2(%rbx)
	cmpb	$0, 3(%rbx)
	jne	LBB32_41
LBB32_40:
	movb	$32, 3(%rbx)
	cmpb	$0, 4(%rbx)
	jne	LBB32_43
LBB32_42:
	movb	$32, 4(%rbx)
	cmpb	$0, 5(%rbx)
	jne	LBB32_45
LBB32_44:
	movb	$32, 5(%rbx)
	cmpb	$0, 6(%rbx)
	jne	LBB32_47
LBB32_46:
	movb	$32, 6(%rbx)
	cmpb	$0, 7(%rbx)
	jne	LBB32_49
LBB32_48:
	movb	$32, 7(%rbx)
	cmpb	$0, 8(%rbx)
	jne	LBB32_51
LBB32_50:
	movb	$32, 8(%rbx)
	cmpb	$0, 9(%rbx)
	jne	LBB32_53
LBB32_52:
	movb	$32, 9(%rbx)
	cmpb	$0, 10(%rbx)
	jne	LBB32_55
LBB32_54:
	movb	$32, 10(%rbx)
	cmpb	$0, 11(%rbx)
	jne	LBB32_57
LBB32_56:
	movb	$32, 11(%rbx)
	cmpb	$0, 12(%rbx)
	jne	LBB32_59
LBB32_58:
	movb	$32, 12(%rbx)
	cmpb	$0, 13(%rbx)
	jne	LBB32_61
LBB32_60:
	movb	$32, 13(%rbx)
	cmpb	$0, 14(%rbx)
	jne	LBB32_63
LBB32_62:
	movb	$32, 14(%rbx)
	cmpb	$0, 15(%rbx)
	jne	LBB32_65
LBB32_64:
	movb	$32, 15(%rbx)
	cmpb	$0, 16(%rbx)
	jne	LBB32_67
LBB32_66:
	movb	$32, 16(%rbx)
	cmpb	$0, 17(%rbx)
	jne	LBB32_69
LBB32_68:
	movb	$32, 17(%rbx)
	cmpb	$0, 18(%rbx)
	jne	LBB32_71
LBB32_70:
	movb	$32, 18(%rbx)
	jmp	LBB32_71
	.cfi_endproc
                                        ## -- End function
	.globl	_main                           ## -- Begin function main
	.p2align	4, 0x90
_main:                                  ## @main
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	movl	$8000008, %eax                  ## imm = 0x7A1208
	callq	____chkstk_darwin
	subq	%rax, %rsp
	popq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	movq	%rax, -48(%rbp)
	leaq	L_str(%rip), %rdi
	callq	_puts
	leaq	L_str.16(%rip), %rdi
	callq	_puts
	callq	_clock
	movl	%eax, %edi
	callq	_srand
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB33_1:                                ## =>This Inner Loop Header: Depth=1
	callq	_rand
	movl	%eax, -8000048(%rbp,%rbx,4)
	incq	%rbx
	cmpq	$2000000, %rbx                  ## imm = 0x1E8480
	jne	LBB33_1
## %bb.2:
	xorl	%r13d, %r13d
	leaq	-8000048(%rbp), %rbx
	leaq	L_.str.15(%rip), %r14
	leaq	_sort_merge_optimized(%rip), %r15
	.p2align	4, 0x90
LBB33_3:                                ## =>This Inner Loop Header: Depth=1
	leaq	l___const.main.array_sizes(%rip), %rax
	movl	(%r13,%rax), %r12d
	leaq	L_.str.7(%rip), %rdi
	leaq	_sort_quick_standard(%rip), %rsi
	movl	%r12d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.8(%rip), %rdi
	leaq	_sort_quick_simd(%rip), %rsi
	movl	%r12d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.9(%rip), %rdi
	leaq	_sort_quick_optimized_swap_arith(%rip), %rsi
	movl	%r12d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.10(%rip), %rdi
	leaq	_sort_quick_optimized_swap_cmov(%rip), %rsi
	movl	%r12d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.11(%rip), %rdi
	leaq	_sort_quick_optimized_swap_array(%rip), %rsi
	movl	%r12d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.12(%rip), %rdi
	leaq	_sort_quick_multi(%rip), %rsi
	movl	%r12d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.13(%rip), %rdi
	leaq	_sort_quick_block(%rip), %rsi
	movl	%r12d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.14(%rip), %rdi
	leaq	_sort_merge_standard(%rip), %rsi
	movl	%r12d, %edx
	movq	%rbx, %rcx
	callq	_bench
	movq	%r14, %rdi
	movq	%r15, %rsi
	movl	%r12d, %edx
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	addq	$4, %r13
	cmpq	$24, %r13
	jne	LBB33_3
## %bb.4:
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB33_6
## %bb.5:
	xorl	%eax, %eax
	addq	$8000008, %rsp                  ## imm = 0x7A1208
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB33_6:
	callq	___stack_chk_fail
	.cfi_endproc
                                        ## -- End function
	.section	__TEXT,__const
	.globl	_INSERTION_SORT_THRESH_BLOCK    ## @INSERTION_SORT_THRESH_BLOCK
	.p2align	2
_INSERTION_SORT_THRESH_BLOCK:
	.long	20                              ## 0x14

	.globl	_blocksize                      ## @blocksize
	.p2align	2
_blocksize:
	.long	128                             ## 0x80

	.comm	_b,4000000,4                    ## @b
	.comm	_x,8,2                          ## @x
	.comm	_tmp,36000000,4                 ## @tmp
	.globl	_DATA_AMOUNT                    ## @DATA_AMOUNT
	.p2align	2
_DATA_AMOUNT:
	.long	2000000                         ## 0x1e8480

	.globl	_MIN_RUNS_PER_BENCH             ## @MIN_RUNS_PER_BENCH
	.p2align	2
_MIN_RUNS_PER_BENCH:
	.long	10                              ## 0xa

	.globl	_MAX_RUNS_PER_BENCH             ## @MAX_RUNS_PER_BENCH
	.p2align	2
_MAX_RUNS_PER_BENCH:
	.long	1000                            ## 0x3e8

	.section	__TEXT,__cstring,cstring_literals
L_.str:                                 ## @.str
	.asciz	"%s"

	.comm	_individual_times,4000,4        ## @individual_times
L_.str.3:                               ## @.str.3
	.asciz	"Integrity check failed for %s\n"

L_.str.4:                               ## @.str.4
	.asciz	"%.2f\302\261%.2f"

	.section	__TEXT,__const
	.p2align	4                               ## @__const.main.array_sizes
l___const.main.array_sizes:
	.long	10                              ## 0xa
	.long	100                             ## 0x64
	.long	1000                            ## 0x3e8
	.long	10000                           ## 0x2710
	.long	100000                          ## 0x186a0
	.long	1000000                         ## 0xf4240

	.section	__TEXT,__cstring,cstring_literals
L_.str.7:                               ## @.str.7
	.asciz	"QStd              "

L_.str.8:                               ## @.str.8
	.asciz	"QSIMD             "

L_.str.9:                               ## @.str.9
	.asciz	"QArith            "

L_.str.10:                              ## @.str.10
	.asciz	"QCMov             "

L_.str.11:                              ## @.str.11
	.asciz	"QArray            "

L_.str.12:                              ## @.str.12
	.asciz	"QMult             "

L_.str.13:                              ## @.str.13
	.asciz	"QBlock            "

L_.str.14:                              ## @.str.14
	.asciz	"MSStd             "

L_.str.15:                              ## @.str.15
	.asciz	"MSOpt             "

L_str:                                  ## @str
	.asciz	"Starting"

L_str.16:                               ## @str.16
	.asciz	"Generating random data"

.subsections_via_symbols
