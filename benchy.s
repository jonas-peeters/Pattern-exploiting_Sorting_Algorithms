	.section	__TEXT,__text,regular,pure_instructions
	.build_version macos, 11, 3	sdk_version 11, 3
	.globl	_partition_quick_block          ## -- Begin function partition_quick_block
	.p2align	4, 0x90
_partition_quick_block:                 ## @partition_quick_block
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$1128, %rsp                     ## imm = 0x468
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movq	%rdi, %r13
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	movq	%rax, -48(%rbp)
	movl	%edx, %eax
	subl	%esi, %eax
	movslq	%edx, %r11
	cmpl	$3, %eax
	jl	LBB0_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%r13,%r8,4), %edi
	movslq	%ecx, %r9
	movl	(%r13,%r9,4), %r10d
	movl	(%r13,%r11,4), %ecx
	cmpl	%r10d, %edi
	movl	%r10d, %ebx
	cmovll	%edi, %ebx
	movl	%r10d, %eax
	cmovgl	%edi, %eax
	cmpl	%ecx, %ebx
	cmovgel	%ecx, %ebx
	cmpl	%ecx, %eax
	cmovlel	%ecx, %eax
	addl	%edi, %r10d
	addl	%ecx, %r10d
	subl	%ebx, %r10d
	subl	%eax, %r10d
	movl	%ebx, (%r13,%r8,4)
	movl	%r10d, (%r13,%r11,4)
	movl	%eax, (%r13,%r9,4)
	jmp	LBB0_3
LBB0_2:
	movl	(%r13,%r11,4), %r10d
LBB0_3:
	movq	%r11, -1112(%rbp)               ## 8-byte Spill
	decl	%edx
	movq	%rdx, %r9
	movl	%edx, %ebx
	subl	%esi, %ebx
	cmpl	$256, %ebx                      ## imm = 0x100
	movq	%r13, -1080(%rbp)               ## 8-byte Spill
	movq	%rsi, %rdi
	jl	LBB0_4
## %bb.12:
	leaq	12(%r13), %rax
	movq	%rax, -1136(%rbp)               ## 8-byte Spill
	xorl	%ecx, %ecx
	xorl	%r11d, %r11d
	xorl	%r12d, %r12d
	xorl	%r8d, %r8d
	movq	%r9, %rsi
	jmp	LBB0_13
	.p2align	4, 0x90
LBB0_25:                                ##   in Loop: Header=BB0_13 Depth=1
	addl	%ebx, %r8d
	addl	%ebx, %r12d
	leal	128(%rdi), %eax
	subl	%ebx, %r11d
	cmovel	%eax, %edi
	leal	-128(%rsi), %eax
	subl	%ebx, %ecx
	cmovel	%eax, %esi
	movl	%esi, %ebx
	subl	%edi, %ebx
	cmpl	$255, %ebx
	jle	LBB0_26
LBB0_13:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_15 Depth 2
                                        ##     Child Loop BB0_19 Depth 2
                                        ##     Child Loop BB0_36 Depth 2
	testl	%r11d, %r11d
	je	LBB0_14
## %bb.17:                              ##   in Loop: Header=BB0_13 Depth=1
	testl	%ecx, %ecx
	jne	LBB0_20
	jmp	LBB0_18
	.p2align	4, 0x90
LBB0_14:                                ##   in Loop: Header=BB0_13 Depth=1
	movq	%rsi, %r14
	movslq	%edi, %rax
	movq	-1136(%rbp), %rdx               ## 8-byte Reload
	leaq	(%rdx,%rax,4), %rax
	xorl	%r8d, %r8d
	xorl	%ebx, %ebx
	xorl	%r11d, %r11d
	.p2align	4, 0x90
LBB0_15:                                ##   Parent Loop BB0_13 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	%r11d, %edx
	movl	%ebx, -560(%rbp,%rdx,4)
	xorl	%edx, %edx
	cmpl	-12(%rax,%rbx,4), %r10d
	setle	%dl
	addl	%r11d, %edx
	leal	1(%rbx), %esi
	movl	%esi, -560(%rbp,%rdx,4)
	xorl	%esi, %esi
	cmpl	-8(%rax,%rbx,4), %r10d
	setle	%sil
	addl	%edx, %esi
	leal	2(%rbx), %edx
	movl	%edx, -560(%rbp,%rsi,4)
	xorl	%edx, %edx
	cmpl	-4(%rax,%rbx,4), %r10d
	setle	%dl
	addl	%esi, %edx
	leal	3(%rbx), %esi
	movl	%esi, -560(%rbp,%rdx,4)
	xorl	%r11d, %r11d
	cmpl	(%rax,%rbx,4), %r10d
	setle	%r11b
	addl	%edx, %r11d
	addq	$4, %rbx
	cmpq	$128, %rbx
	jne	LBB0_15
## %bb.16:                              ##   in Loop: Header=BB0_13 Depth=1
	movq	%r14, %rsi
	testl	%ecx, %ecx
	jne	LBB0_20
LBB0_18:                                ##   in Loop: Header=BB0_13 Depth=1
	movslq	%esi, %rax
	leaq	(,%rax,4), %rax
	addq	%r13, %rax
	xorl	%r12d, %r12d
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_19:                                ##   Parent Loop BB0_13 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	%ecx, %edx
	movl	%ebx, -1072(%rbp,%rdx,4)
	xorl	%edx, %edx
	cmpl	(%rax), %r10d
	setge	%dl
	addl	%ecx, %edx
	movl	%ebx, %ecx
	orl	$1, %ecx
	movl	%ecx, -1072(%rbp,%rdx,4)
	xorl	%ecx, %ecx
	cmpl	-4(%rax), %r10d
	setge	%cl
	addl	%edx, %ecx
	movl	%ebx, %edx
	orl	$2, %edx
	movl	%edx, -1072(%rbp,%rcx,4)
	xorl	%edx, %edx
	cmpl	-8(%rax), %r10d
	setge	%dl
	addl	%ecx, %edx
	movl	%ebx, %ecx
	orl	$3, %ecx
	movl	%ecx, -1072(%rbp,%rdx,4)
	xorl	%ecx, %ecx
	cmpl	-12(%rax), %r10d
	setge	%cl
	addl	%edx, %ecx
	addq	$4, %rbx
	addq	$-16, %rax
	cmpq	$128, %rbx
	jne	LBB0_19
LBB0_20:                                ##   in Loop: Header=BB0_13 Depth=1
	cmpl	%ecx, %r11d
	movl	%ecx, %ebx
	cmovll	%r11d, %ebx
	testl	%ebx, %ebx
	jle	LBB0_25
## %bb.21:                              ##   in Loop: Header=BB0_13 Depth=1
	movq	%r8, -1128(%rbp)                ## 8-byte Spill
	movq	%rsi, %rax
	movslq	%r8d, %rsi
	movq	%r12, -1104(%rbp)               ## 8-byte Spill
	movslq	%r12d, %rdx
	movl	%ebx, %r8d
	movq	%rdi, -1160(%rbp)               ## 8-byte Spill
	movslq	%edi, %r15
	movq	%rax, -1120(%rbp)               ## 8-byte Spill
	movslq	%eax, %r14
	movl	%ebx, -1084(%rbp)               ## 4-byte Spill
	cmpl	$1, %ebx
	movq	%rdx, -1152(%rbp)               ## 8-byte Spill
	movq	%rsi, -1144(%rbp)               ## 8-byte Spill
	movq	%r8, -1096(%rbp)                ## 8-byte Spill
	jne	LBB0_35
## %bb.22:                              ##   in Loop: Header=BB0_13 Depth=1
	xorl	%r9d, %r9d
	jmp	LBB0_23
	.p2align	4, 0x90
LBB0_35:                                ##   in Loop: Header=BB0_13 Depth=1
                                        ## kill: def $r8d killed $r8d killed $r8 def $r8
	andl	$-2, %r8d
	leaq	-556(%rbp), %rax
	leaq	(%rax,%rsi,4), %rsi
	leaq	-1068(%rbp), %rax
	leaq	(%rax,%rdx,4), %r12
	xorl	%r9d, %r9d
	.p2align	4, 0x90
LBB0_36:                                ##   Parent Loop BB0_13 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movslq	-4(%rsi,%r9,4), %rdx
	addq	%r15, %rdx
	movslq	-4(%r12,%r9,4), %r13
	movq	%r14, %rax
	subq	%r13, %rax
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	movl	(%r13,%rdx,4), %ebx
	movl	(%r13,%rax,4), %edi
	movl	%edi, (%r13,%rdx,4)
	movl	%ebx, (%r13,%rax,4)
	movslq	(%rsi,%r9,4), %rax
	addq	%r15, %rax
	movslq	(%r12,%r9,4), %rdx
	movq	%r14, %rdi
	subq	%rdx, %rdi
	movl	(%r13,%rax,4), %edx
	movl	(%r13,%rdi,4), %ebx
	movl	%ebx, (%r13,%rax,4)
	movl	%edx, (%r13,%rdi,4)
	addq	$2, %r9
	cmpq	%r9, %r8
	jne	LBB0_36
LBB0_23:                                ##   in Loop: Header=BB0_13 Depth=1
	testb	$1, -1096(%rbp)                 ## 1-byte Folded Reload
	movq	-1120(%rbp), %rsi               ## 8-byte Reload
	movq	-1160(%rbp), %rdi               ## 8-byte Reload
	movq	-1128(%rbp), %r8                ## 8-byte Reload
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	-1084(%rbp), %ebx               ## 4-byte Reload
	je	LBB0_25
## %bb.24:                              ##   in Loop: Header=BB0_13 Depth=1
	movq	-1144(%rbp), %rax               ## 8-byte Reload
	addq	%r9, %rax
	movslq	-560(%rbp,%rax,4), %rdx
	addq	%r15, %rdx
	movq	-1152(%rbp), %rax               ## 8-byte Reload
	addq	%r9, %rax
	movq	%rsi, %r9
	movslq	-1072(%rbp,%rax,4), %rsi
	subq	%rsi, %r14
	movl	(%r13,%rdx,4), %r8d
	movl	(%r13,%r14,4), %esi
	movl	%esi, (%r13,%rdx,4)
	movq	%r9, %rsi
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	%r8d, (%r13,%r14,4)
	movq	-1128(%rbp), %r8                ## 8-byte Reload
	jmp	LBB0_25
LBB0_4:
	movq	%r9, %rsi
	jmp	LBB0_5
LBB0_26:
	movl	%ecx, %eax
	orl	%r11d, %eax
	je	LBB0_5
## %bb.27:
	leal	-127(%rbx), %r9d
	testl	%ecx, %ecx
	movq	%rsi, -1120(%rbp)               ## 8-byte Spill
	je	LBB0_43
## %bb.28:
	xorl	%r8d, %r8d
	cmpl	$128, %ebx
	jl	LBB0_34
## %bb.29:
	movslq	%edi, %r14
	movl	%r9d, %r13d
	leaq	-1(%r13), %rax
	movl	%r13d, %r15d
	andl	$3, %r15d
	xorl	%r8d, %r8d
	cmpq	$3, %rax
	jae	LBB0_40
## %bb.30:
	xorl	%ebx, %ebx
	jmp	LBB0_31
LBB0_5:
	leal	1(%rbx), %r14d
	movl	%r14d, %eax
	shrl	$31, %eax
	leal	(%rbx,%rax), %edx
	incl	%edx
	sarl	%edx
	subl	%edx, %r14d
	xorl	%r8d, %r8d
	movl	$0, %r11d
	movl	$0, %ecx
	testl	%ebx, %ebx
	movq	%rsi, -1120(%rbp)               ## 8-byte Spill
	jle	LBB0_10
## %bb.6:
	movq	%rsi, %r9
	movq	%rdi, %rsi
	movslq	%edi, %r15
	movslq	%r9d, %rcx
	testl	%edx, %edx
	movl	$1, %r8d
	movl	%edx, -1084(%rbp)               ## 4-byte Spill
	cmovgl	%edx, %r8d
	cmpl	$3, %ebx
	movq	%rcx, -1104(%rbp)               ## 8-byte Spill
	jge	LBB0_37
## %bb.7:
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	xorl	%r11d, %r11d
	jmp	LBB0_8
LBB0_37:
	movq	%r13, %rax
	movl	%r8d, %r13d
	andl	$2147483646, %r13d              ## imm = 0x7FFFFFFE
	movq	%r15, %rdi
	leaq	(%rax,%r15,4), %r15
	addq	$4, %r15
	leaq	(%rax,%rcx,4), %r12
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	xorl	%r11d, %r11d
	.p2align	4, 0x90
LBB0_38:                                ## =>This Inner Loop Header: Depth=1
	movl	%r11d, %eax
	movl	%ebx, -560(%rbp,%rax,4)
	xorl	%eax, %eax
	cmpl	-4(%r15,%rbx,4), %r10d
	setle	%al
	addl	%r11d, %eax
	movl	%ecx, %edx
	movl	%ebx, -1072(%rbp,%rdx,4)
	xorl	%edx, %edx
	cmpl	(%r12), %r10d
	setge	%dl
	addl	%ecx, %edx
	leal	1(%rbx), %ecx
	movl	%ecx, -560(%rbp,%rax,4)
	xorl	%r11d, %r11d
	cmpl	(%r15,%rbx,4), %r10d
	setle	%r11b
	addl	%eax, %r11d
	movl	%ecx, -1072(%rbp,%rdx,4)
	xorl	%ecx, %ecx
	cmpl	-4(%r12), %r10d
	setge	%cl
	addl	%edx, %ecx
	addq	$2, %rbx
	addq	$-8, %r12
	cmpq	%rbx, %r13
	jne	LBB0_38
## %bb.39:
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	movq	-1120(%rbp), %r9                ## 8-byte Reload
	movq	%rdi, %r15
LBB0_8:
	testb	$1, %r8b
	movl	$0, %r8d
	movq	%rsi, %rdi
	movq	%r9, %rsi
	movl	-1084(%rbp), %edx               ## 4-byte Reload
	je	LBB0_10
## %bb.9:
	movl	%r11d, %eax
	movl	%ebx, -560(%rbp,%rax,4)
	addq	%rbx, %r15
	movl	%ecx, %eax
	movq	-1104(%rbp), %rsi               ## 8-byte Reload
	subq	%rbx, %rsi
	xorl	%r12d, %r12d
	cmpl	(%r13,%r15,4), %r10d
	movl	%ebx, -1072(%rbp,%rax,4)
	setle	%r12b
	xorl	%eax, %eax
	cmpl	(%r13,%rsi,4), %r10d
	movq	%r9, %rsi
	setge	%al
	addl	%ecx, %eax
	addl	%r11d, %r12d
	movl	%r12d, %r11d
	movl	%eax, %ecx
LBB0_10:
	cmpl	%r14d, %edx
	movl	%edx, %ebx
	movq	%r14, -1096(%rbp)               ## 8-byte Spill
	jge	LBB0_55
## %bb.11:
	leal	-1(%r14), %eax
	movl	%ecx, %edx
	movl	%eax, -1072(%rbp,%rdx,4)
	movl	%esi, %eax
	subl	%r14d, %eax
	incl	%eax
	cltq
	xorl	%edx, %edx
	cmpl	(%r13,%rax,4), %r10d
	setge	%dl
	addl	%ecx, %edx
	xorl	%r12d, %r12d
	movl	%edx, %ecx
	jmp	LBB0_56
LBB0_43:
	xorl	%r12d, %r12d
	cmpl	$128, %ebx
	jl	LBB0_44
## %bb.45:
	movq	%rdi, %rdx
	movq	%r8, %rdi
	movslq	%esi, %r13
	movl	%r9d, %r8d
	leaq	-1(%r8), %rax
	movl	%r8d, %r14d
	andl	$3, %r14d
	xorl	%r12d, %r12d
	cmpq	$3, %rax
	jae	LBB0_47
## %bb.46:
	movl	%r9d, %ebx
	xorl	%r15d, %r15d
	xorl	%ecx, %ecx
	testq	%r14, %r14
	movq	%rdi, %r8
	movq	%rdx, %rdi
	je	LBB0_51
LBB0_52:
	leaq	(,%r15,4), %rax
	movq	-1080(%rbp), %rdx               ## 8-byte Reload
	subq	%rax, %rdx
	leaq	(%rdx,%r13,4), %rax
	negq	%r14
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB0_53:                                ## =>This Inner Loop Header: Depth=1
	movl	%ecx, %esi
	movl	%ecx, %ecx
	movl	%r15d, -1072(%rbp,%rcx,4)
	xorl	%ecx, %ecx
	cmpl	(%rax,%rdx,4), %r10d
	setge	%cl
	addl	%esi, %ecx
	decq	%rdx
	incl	%r15d
	cmpq	%rdx, %r14
	jne	LBB0_53
## %bb.54:
	movl	%ebx, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	$128, %ebx
	movq	-1080(%rbp), %r13               ## 8-byte Reload
LBB0_55:
	xorl	%r12d, %r12d
	jmp	LBB0_56
LBB0_44:
	xorl	%ecx, %ecx
	movl	%r9d, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	$128, %ebx
	jmp	LBB0_56
LBB0_40:
	andl	$-4, %r13d
	movq	-1080(%rbp), %rax               ## 8-byte Reload
	leaq	(%rax,%r14,4), %r8
	addq	$12, %r8
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB0_41:                                ## =>This Inner Loop Header: Depth=1
	movslq	%r11d, %rax
	movl	%ebx, -560(%rbp,%rax,4)
	xorl	%edx, %edx
	cmpl	-12(%r8,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %eax
	cltq
	leal	1(%rbx), %edx
	movl	%edx, -560(%rbp,%rax,4)
	xorl	%edx, %edx
	cmpl	-8(%r8,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %eax
	cltq
	leal	2(%rbx), %edx
	movl	%edx, -560(%rbp,%rax,4)
	xorl	%edx, %edx
	cmpl	-4(%r8,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %eax
	movslq	%eax, %r11
	leal	3(%rbx), %eax
	movl	%eax, -560(%rbp,%r11,4)
	xorl	%eax, %eax
	cmpl	(%r8,%rbx,4), %r10d
	setle	%al
	addl	%eax, %r11d
	addq	$4, %rbx
	cmpq	%rbx, %r13
	jne	LBB0_41
## %bb.42:
	xorl	%r8d, %r8d
LBB0_31:
	testq	%r15, %r15
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	je	LBB0_34
## %bb.32:
	leaq	(,%r14,4), %rax
	addq	%r13, %rax
	.p2align	4, 0x90
LBB0_33:                                ## =>This Inner Loop Header: Depth=1
	movslq	%r11d, %r11
	movl	%ebx, -560(%rbp,%r11,4)
	xorl	%edx, %edx
	cmpl	(%rax,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %r11d
	incq	%rbx
	decq	%r15
	jne	LBB0_33
LBB0_34:
	movl	$128, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	%r9d, %ebx
LBB0_56:
	cmpl	%ecx, %r11d
	movl	%ecx, %r10d
	cmovll	%r11d, %r10d
	testl	%r10d, %r10d
	jle	LBB0_61
## %bb.57:
	movl	%ebx, -1084(%rbp)               ## 4-byte Spill
	movq	%r8, -1128(%rbp)                ## 8-byte Spill
	movslq	%r8d, %rdx
	movq	%r12, -1104(%rbp)               ## 8-byte Spill
	movslq	%r12d, %rax
	movl	%r10d, %r12d
	movq	%rdi, -1160(%rbp)               ## 8-byte Spill
	movslq	%edi, %r9
	movslq	-1120(%rbp), %r14               ## 4-byte Folded Reload
	movq	%r10, -1152(%rbp)               ## 8-byte Spill
	cmpl	$1, %r10d
	movq	%rax, -1136(%rbp)               ## 8-byte Spill
	movq	%rdx, -1168(%rbp)               ## 8-byte Spill
	movq	%r12, -1144(%rbp)               ## 8-byte Spill
	jne	LBB0_64
## %bb.58:
	xorl	%eax, %eax
	jmp	LBB0_59
LBB0_64:
                                        ## kill: def $r12d killed $r12d killed $r12 def $r12
	andl	$-2, %r12d
	leaq	-556(,%rdx,4), %r15
	addq	%rbp, %r15
	leaq	-1068(,%rax,4), %r10
	addq	%rbp, %r10
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB0_65:                                ## =>This Inner Loop Header: Depth=1
	movslq	-4(%r15,%rax,4), %rdx
	addq	%r9, %rdx
	movslq	-4(%r10,%rax,4), %rdi
	movq	%r14, %r13
	subq	%rdi, %r13
	movq	-1080(%rbp), %rsi               ## 8-byte Reload
	movl	(%rsi,%rdx,4), %edi
	movq	-1080(%rbp), %rsi               ## 8-byte Reload
	movl	(%rsi,%r13,4), %r8d
	movq	-1080(%rbp), %rsi               ## 8-byte Reload
	movl	%r8d, (%rsi,%rdx,4)
	movq	-1080(%rbp), %rdx               ## 8-byte Reload
	movl	%edi, (%rdx,%r13,4)
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	movslq	(%r15,%rax,4), %rdx
	addq	%r9, %rdx
	movslq	(%r10,%rax,4), %rdi
	movq	%r14, %rsi
	subq	%rdi, %rsi
	movl	(%r13,%rdx,4), %edi
	movl	(%r13,%rsi,4), %ebx
	movl	%ebx, (%r13,%rdx,4)
	movl	%edi, (%r13,%rsi,4)
	addq	$2, %rax
	cmpq	%rax, %r12
	jne	LBB0_65
LBB0_59:
	testb	$1, -1144(%rbp)                 ## 1-byte Folded Reload
	movq	-1160(%rbp), %rdi               ## 8-byte Reload
	movq	-1128(%rbp), %r8                ## 8-byte Reload
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	-1084(%rbp), %ebx               ## 4-byte Reload
	movq	-1152(%rbp), %r10               ## 8-byte Reload
	je	LBB0_61
## %bb.60:
	movq	-1168(%rbp), %rdx               ## 8-byte Reload
	addq	%rax, %rdx
	movslq	-560(%rbp,%rdx,4), %rdx
	addq	%r9, %rdx
	movq	-1136(%rbp), %rsi               ## 8-byte Reload
	addq	%rax, %rsi
	movslq	-1072(%rbp,%rsi,4), %rax
	subq	%rax, %r14
	movl	(%r13,%rdx,4), %eax
	movl	(%r13,%r14,4), %esi
	movl	%esi, (%r13,%rdx,4)
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	%eax, (%r13,%r14,4)
LBB0_61:
	leal	(%r10,%r12), %r9d
	addl	%edi, %ebx
	xorl	%eax, %eax
	cmpl	%ecx, %r11d
	movq	-1096(%rbp), %rdx               ## 8-byte Reload
	cmovll	%eax, %edx
	movq	-1120(%rbp), %r15               ## 8-byte Reload
	subl	%edx, %r15d
	cmpl	%ecx, %r11d
	cmovlel	%ebx, %edi
	jle	LBB0_79
## %bb.62:
	addl	%r8d, %r10d
	leal	(%r11,%r8), %eax
	subl	%edi, %r15d
	movslq	%r10d, %r14
	cmpl	%r10d, %eax
	jle	LBB0_63
## %bb.66:
	movslq	%eax, %rcx
	leal	-1(%r10), %eax
	leal	(%r11,%r8), %ebx
	decl	%ebx
	movq	-1112(%rbp), %rdx               ## 8-byte Reload
	.p2align	4, 0x90
LBB0_67:                                ## =>This Inner Loop Header: Depth=1
	cmpl	-564(%rbp,%rcx,4), %r15d
	jne	LBB0_70
## %bb.68:                              ##   in Loop: Header=BB0_67 Depth=1
	decq	%rcx
	decl	%r15d
	decl	%ebx
	cmpq	%r14, %rcx
	jg	LBB0_67
## %bb.69:
	movl	%eax, %ebx
	jmp	LBB0_70
LBB0_79:
	jge	LBB0_95
## %bb.80:
	leal	(%rcx,%r12), %edx
	movl	%r15d, %eax
	subl	%edi, %eax
	movslq	%r9d, %r10
	cmpl	%r9d, %edx
	movq	-1112(%rbp), %r11               ## 8-byte Reload
	jle	LBB0_81
## %bb.82:
	movslq	%edx, %rsi
	leal	-1(%r9), %edx
	addl	%r12d, %ecx
	decl	%ecx
	.p2align	4, 0x90
LBB0_83:                                ## =>This Inner Loop Header: Depth=1
	cmpl	-1076(%rbp,%rsi,4), %eax
	jne	LBB0_86
## %bb.84:                              ##   in Loop: Header=BB0_83 Depth=1
	decq	%rsi
	decl	%eax
	decl	%ecx
	cmpq	%r10, %rsi
	jg	LBB0_83
## %bb.85:
	movl	%edx, %ecx
	jmp	LBB0_86
LBB0_63:
	leal	(%r11,%r8), %ebx
	decl	%ebx
	movq	-1112(%rbp), %rdx               ## 8-byte Reload
LBB0_70:
	movl	%ebx, %ecx
	subl	%r10d, %ecx
	jl	LBB0_78
## %bb.71:
	movslq	%r15d, %rax
	movq	%rdi, %r12
	movslq	%edi, %r9
	movslq	%ebx, %rbx
	incl	%ecx
	movq	%rbx, %r8
	subq	%r14, %r8
	andq	$3, %rcx
	je	LBB0_74
## %bb.72:
	leaq	(,%r9,4), %r10
	addq	%r13, %r10
	negq	%rcx
	movq	%rax, %rsi
	.p2align	4, 0x90
LBB0_73:                                ## =>This Inner Loop Header: Depth=1
	leaq	-1(%rsi), %rax
	movslq	-560(%rbp,%rbx,4), %rdi
	decq	%rbx
	addq	%r9, %rdi
	movl	(%r10,%rsi,4), %r11d
	movl	(%r13,%rdi,4), %edx
	movl	%edx, (%r10,%rsi,4)
	movl	%r11d, (%r13,%rdi,4)
	movq	%rax, %rsi
	incq	%rcx
	jne	LBB0_73
LBB0_74:
	movq	%rax, %r15
	cmpq	$3, %r8
	jb	LBB0_77
## %bb.75:
	incq	%rbx
	leaq	(,%r9,4), %rcx
	addq	%r13, %rcx
	.p2align	4, 0x90
LBB0_76:                                ## =>This Inner Loop Header: Depth=1
	movslq	-564(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, (%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	movslq	-568(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	-4(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, -4(%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	movslq	-572(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	-8(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, -8(%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	leaq	-4(%rax), %r15
	movslq	-576(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	-12(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, -12(%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	addq	$-4, %rbx
	movq	%r15, %rax
	cmpq	%r14, %rbx
	jg	LBB0_76
LBB0_77:
	movq	-1112(%rbp), %rdx               ## 8-byte Reload
	movq	%r12, %rdi
LBB0_78:
	leaq	(,%rdx,4), %rcx
	addq	%r13, %rcx
	addl	%r15d, %edi
	incl	%edi
	movl	%edi, %ebx
	jmp	LBB0_96
LBB0_95:
	movq	-1112(%rbp), %rax               ## 8-byte Reload
	leaq	(,%rax,4), %rcx
	addq	%r13, %rcx
	jmp	LBB0_96
LBB0_81:
	addl	%r12d, %ecx
	decl	%ecx
LBB0_86:
	movl	%ecx, %edx
	subl	%r9d, %edx
	jl	LBB0_94
## %bb.87:
	movq	%r9, %rsi
	movl	%eax, %r9d
	movslq	%ecx, %rbx
	incl	%edx
	movslq	%r15d, %r14
	testb	$1, %dl
	je	LBB0_89
## %bb.88:
	decq	%r9
	movl	%r15d, %edx
	subl	%eax, %edx
	decl	%eax
	movslq	%edx, %r11
	movslq	-1072(%rbp,%rbx,4), %r8
	decq	%rbx
	movq	%r14, %rdi
	subq	%r8, %rdi
	movl	(%r13,%r11,4), %r8d
	movl	(%r13,%rdi,4), %edx
	movl	%edx, (%r13,%r11,4)
	movq	-1112(%rbp), %r11               ## 8-byte Reload
	movl	%r8d, (%r13,%rdi,4)
LBB0_89:
	cmpl	%esi, %ecx
	je	LBB0_93
## %bb.90:
	incq	%rbx
	cltq
	movq	%r14, %rcx
	subq	%rax, %rcx
	leaq	4(,%rcx,4), %rcx
	addq	%r13, %rcx
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB0_91:                                ## =>This Inner Loop Header: Depth=1
	movslq	-1076(%rbp,%rbx,4), %rdx
	movq	%r14, %rdi
	subq	%rdx, %rdi
	movl	-4(%rcx,%rax,4), %edx
	movl	(%r13,%rdi,4), %esi
	movl	%esi, -4(%rcx,%rax,4)
	movl	%edx, (%r13,%rdi,4)
	movslq	-1080(%rbp,%rbx,4), %rdx
	movq	%r14, %rsi
	subq	%rdx, %rsi
	movl	(%rcx,%rax,4), %edx
	movl	(%r13,%rsi,4), %edi
	movl	%edi, (%rcx,%rax,4)
	movl	%edx, (%r13,%rsi,4)
	addq	$-2, %rbx
	addq	$2, %rax
	cmpq	%r10, %rbx
	jg	LBB0_91
## %bb.92:
	subq	%rax, %r9
LBB0_93:
	movl	%r9d, %eax
LBB0_94:
	leaq	(,%r11,4), %rcx
	addq	%r13, %rcx
	subl	%eax, %r15d
	movl	%r15d, %edi
	movl	%r15d, %ebx
LBB0_96:
	movslq	%edi, %rax
	movl	(%rcx), %edx
	movl	(%r13,%rax,4), %esi
	movl	%esi, (%rcx)
	movl	%edx, (%r13,%rax,4)
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB0_98
## %bb.97:
	movl	%ebx, %eax
	addq	$1128, %rsp                     ## imm = 0x468
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB0_47:
	andl	$-4, %r8d
	movq	-1080(%rbp), %rax               ## 8-byte Reload
	leaq	(%rax,%r13,4), %rbx
	xorl	%r15d, %r15d
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_48:                                ## =>This Inner Loop Header: Depth=1
	movl	%ecx, %eax
	movl	%r15d, -1072(%rbp,%rax,4)
	xorl	%eax, %eax
	cmpl	(%rbx), %r10d
	setge	%al
	addl	%ecx, %eax
	leal	1(%r15), %ecx
	movl	%ecx, -1072(%rbp,%rax,4)
	xorl	%ecx, %ecx
	cmpl	-4(%rbx), %r10d
	setge	%cl
	addl	%eax, %ecx
	leal	2(%r15), %eax
	movl	%eax, -1072(%rbp,%rcx,4)
	xorl	%eax, %eax
	cmpl	-8(%rbx), %r10d
	setge	%al
	addl	%ecx, %eax
	leal	3(%r15), %ecx
	movl	%ecx, -1072(%rbp,%rax,4)
	xorl	%ecx, %ecx
	cmpl	-12(%rbx), %r10d
	setge	%cl
	addl	%eax, %ecx
	addq	$4, %r15
	addq	$-16, %rbx
	cmpq	%r15, %r8
	jne	LBB0_48
## %bb.49:
	movl	%r9d, %ebx
	testq	%r14, %r14
	movq	%rdi, %r8
	movq	%rdx, %rdi
	jne	LBB0_52
LBB0_51:
	movl	%ebx, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	$128, %ebx
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	jmp	LBB0_56
LBB0_98:
	callq	___stack_chk_fail
	.cfi_endproc
                                        ## -- End function
	.globl	_median_of_three                ## -- Begin function median_of_three
	.p2align	4, 0x90
_median_of_three:                       ## @median_of_three
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%rdi,%r8,4), %r11d
	movslq	%ecx, %r9
	movl	(%rdi,%r9,4), %eax
	movslq	%edx, %r10
	movl	(%rdi,%r10,4), %ecx
	cmpl	%eax, %r11d
	movl	%eax, %edx
	cmovll	%r11d, %edx
	movl	%eax, %esi
	cmovgl	%r11d, %esi
	cmpl	%ecx, %edx
	cmovgel	%ecx, %edx
	cmpl	%ecx, %esi
	cmovlel	%ecx, %esi
	addl	%r11d, %eax
	addl	%ecx, %eax
	subl	%edx, %eax
	subl	%esi, %eax
	movl	%edx, (%rdi,%r8,4)
	movl	%eax, (%rdi,%r10,4)
	movl	%esi, (%rdi,%r9,4)
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_min                            ## -- Begin function min
	.p2align	4, 0x90
_min:                                   ## @min
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	%esi, %eax
	cmpl	%esi, %edi
	cmovll	%edi, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_swap                           ## -- Begin function swap
	.p2align	4, 0x90
_swap:                                  ## @swap
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	(%rdi), %eax
	movl	(%rsi), %ecx
	movl	%ecx, (%rdi)
	movl	%eax, (%rsi)
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_block               ## -- Begin function sort_quick_block
	.p2align	4, 0x90
_sort_quick_block:                      ## @sort_quick_block
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	%esi, %edx
	jle	LBB4_22
## %bb.1:
	movl	%edx, %r15d
	movl	%esi, %r12d
	movq	%rdi, %r14
	.p2align	4, 0x90
LBB4_2:                                 ## =>This Inner Loop Header: Depth=1
	movl	%r15d, %esi
	subl	%r12d, %esi
	cmpl	$21, %esi
	jl	LBB4_4
## %bb.3:                               ##   in Loop: Header=BB4_2 Depth=1
	movq	%r14, %rdi
	movl	%r12d, %esi
	movl	%r15d, %edx
	callq	_partition_quick_block
	movl	%eax, %ebx
	leal	-1(%rbx), %edx
	movq	%r14, %rdi
	movl	%r12d, %esi
	callq	_sort_quick_block
	incl	%ebx
	movl	%ebx, %r12d
	cmpl	%r15d, %ebx
	jl	LBB4_2
	jmp	LBB4_22
LBB4_4:
	testl	%esi, %esi
	jle	LBB4_22
## %bb.5:
	movslq	%r12d, %rax
	leaq	(%r14,%rax,4), %rax
	movabsq	$-4294967296, %rcx              ## imm = 0xFFFFFFFF00000000
	movl	%esi, %r8d
	movl	$1, %r15d
	cmpl	$1, %esi
	jne	LBB4_6
LBB4_16:
	testb	$1, %r8b
	je	LBB4_22
## %bb.17:
	movl	(%rax,%r15,4), %esi
	movq	%r15, %rdi
	shlq	$32, %rdi
	addq	%rcx, %rdi
	.p2align	4, 0x90
LBB4_18:                                ## =>This Inner Loop Header: Depth=1
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB4_21
## %bb.19:                              ##   in Loop: Header=BB4_18 Depth=1
	movl	%edx, (%rax,%r15,4)
	leaq	-1(%r15), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %r15
	movq	%rdx, %r15
	jg	LBB4_18
## %bb.20:
	xorl	%r15d, %r15d
LBB4_21:
	movslq	%r15d, %rcx
	movl	%esi, (%rax,%rcx,4)
LBB4_22:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB4_6:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movl	%r8d, %r10d
	andl	$-2, %r10d
	movl	$1, %r15d
	movabsq	$4294967296, %r11               ## imm = 0x100000000
	xorl	%r14d, %r14d
	jmp	LBB4_7
	.p2align	4, 0x90
LBB4_15:                                ##   in Loop: Header=BB4_7 Depth=1
	movslq	%ebx, %rdx
	movl	%esi, (%rax,%rdx,4)
	addq	$2, %r15
	addq	%r9, %r14
	addq	%r9, %r11
	addq	$-2, %r10
	je	LBB4_16
LBB4_7:                                 ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB4_8 Depth 2
                                        ##     Child Loop BB4_12 Depth 2
	movl	(%rax,%r15,4), %esi
	movq	%r14, %rdi
	movq	%r15, %rbx
	.p2align	4, 0x90
LBB4_8:                                 ##   Parent Loop BB4_7 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB4_11
## %bb.9:                               ##   in Loop: Header=BB4_8 Depth=2
	movl	%edx, (%rax,%rbx,4)
	leaq	-1(%rbx), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %rbx
	movq	%rdx, %rbx
	jg	LBB4_8
## %bb.10:                              ##   in Loop: Header=BB4_7 Depth=1
	xorl	%ebx, %ebx
LBB4_11:                                ##   in Loop: Header=BB4_7 Depth=1
	movslq	%ebx, %rdx
	movl	%esi, (%rax,%rdx,4)
	leaq	1(%r15), %rbx
	movl	4(%rax,%r15,4), %esi
	movq	%r11, %rdi
	.p2align	4, 0x90
LBB4_12:                                ##   Parent Loop BB4_7 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB4_15
## %bb.13:                              ##   in Loop: Header=BB4_12 Depth=2
	movl	%edx, (%rax,%rbx,4)
	leaq	-1(%rbx), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %rbx
	movq	%rdx, %rbx
	jg	LBB4_12
## %bb.14:                              ##   in Loop: Header=BB4_7 Depth=1
	xorl	%ebx, %ebx
	jmp	LBB4_15
	.cfi_endproc
                                        ## -- End function
	.globl	_insertionSort                  ## -- Begin function insertionSort
	.p2align	4, 0x90
_insertionSort:                         ## @insertionSort
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	$2, %esi
	jl	LBB5_18
## %bb.1:
	movabsq	$-4294967296, %rax              ## imm = 0xFFFFFFFF00000000
	movl	%esi, %r8d
	decq	%r8
	movl	$1, %r15d
	cmpl	$2, %esi
	jne	LBB5_2
LBB5_12:
	testb	$1, %r8b
	je	LBB5_18
## %bb.13:
	movl	(%rdi,%r15,4), %edx
	movq	%r15, %rsi
	shlq	$32, %rsi
	addq	%rax, %rsi
	.p2align	4, 0x90
LBB5_14:                                ## =>This Inner Loop Header: Depth=1
	movq	%rsi, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%edx, %ecx
	jle	LBB5_17
## %bb.15:                              ##   in Loop: Header=BB5_14 Depth=1
	movl	%ecx, (%rdi,%r15,4)
	leaq	-1(%r15), %rcx
	addq	%rax, %rsi
	cmpq	$1, %r15
	movq	%rcx, %r15
	jg	LBB5_14
## %bb.16:
	xorl	%r15d, %r15d
LBB5_17:
	movslq	%r15d, %rax
	movl	%edx, (%rdi,%rax,4)
LBB5_18:
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB5_2:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movq	%r8, %r10
	andq	$-2, %r10
	movl	$1, %r15d
	movabsq	$4294967296, %r11               ## imm = 0x100000000
	xorl	%r14d, %r14d
	jmp	LBB5_3
	.p2align	4, 0x90
LBB5_11:                                ##   in Loop: Header=BB5_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	addq	$2, %r15
	addq	%r9, %r14
	addq	%r9, %r11
	addq	$-2, %r10
	je	LBB5_12
LBB5_3:                                 ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB5_4 Depth 2
                                        ##     Child Loop BB5_8 Depth 2
	movl	(%rdi,%r15,4), %esi
	movq	%r14, %rdx
	movq	%r15, %rbx
	.p2align	4, 0x90
LBB5_4:                                 ##   Parent Loop BB5_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB5_7
## %bb.5:                               ##   in Loop: Header=BB5_4 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB5_4
## %bb.6:                               ##   in Loop: Header=BB5_3 Depth=1
	xorl	%ebx, %ebx
LBB5_7:                                 ##   in Loop: Header=BB5_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	leaq	1(%r15), %rbx
	movl	4(%rdi,%r15,4), %esi
	movq	%r11, %rdx
	.p2align	4, 0x90
LBB5_8:                                 ##   Parent Loop BB5_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB5_11
## %bb.9:                               ##   in Loop: Header=BB5_8 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB5_8
## %bb.10:                              ##   in Loop: Header=BB5_3 Depth=1
	xorl	%ebx, %ebx
	jmp	LBB5_11
	.cfi_endproc
                                        ## -- End function
	.section	__TEXT,__const
	.p2align	5                               ## -- Begin function random_data
LCPI6_0:
	.long	0                               ## 0x0
	.long	1                               ## 0x1
	.long	2                               ## 0x2
	.long	3                               ## 0x3
	.long	4                               ## 0x4
	.long	5                               ## 0x5
	.long	6                               ## 0x6
	.long	7                               ## 0x7
LCPI6_1:
	.quad	4                               ## 0x4
	.quad	5                               ## 0x5
	.quad	6                               ## 0x6
	.quad	7                               ## 0x7
LCPI6_2:
	.quad	0                               ## 0x0
	.quad	1                               ## 0x1
	.quad	2                               ## 0x2
	.quad	3                               ## 0x3
LCPI6_3:
	.long	0                               ## 0x0
	.long	2                               ## 0x2
	.long	4                               ## 0x4
	.long	6                               ## 0x6
	.long	4                               ## 0x4
	.long	6                               ## 0x6
	.long	6                               ## 0x6
	.long	7                               ## 0x7
	.section	__TEXT,__literal4,4byte_literals
	.p2align	2
LCPI6_4:
	.long	9                               ## 0x9
LCPI6_5:
	.long	17                              ## 0x11
LCPI6_6:
	.long	25                              ## 0x19
LCPI6_7:
	.long	33                              ## 0x21
LCPI6_8:
	.long	41                              ## 0x29
LCPI6_9:
	.long	49                              ## 0x31
LCPI6_10:
	.long	57                              ## 0x39
	.section	__TEXT,__literal8,8byte_literals
	.p2align	3
LCPI6_11:
	.quad	64                              ## 0x40
	.section	__TEXT,__text,regular,pure_instructions
	.globl	_random_data
	.p2align	4, 0x90
_random_data:                           ## @random_data
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -32
	.cfi_offset %r14, -24
	movl	%esi, %r14d
	movq	%rdi, %rbx
	callq	_clock
	movl	%eax, %edi
	callq	_srand
	testl	%r14d, %r14d
	jle	LBB6_12
## %bb.1:
	movl	%r14d, %eax
	cmpl	$32, %r14d
	jae	LBB6_3
## %bb.2:
	xorl	%ecx, %ecx
	jmp	LBB6_11
LBB6_3:
	movl	%eax, %ecx
	andl	$-32, %ecx
	leaq	-32(%rcx), %rsi
	movq	%rsi, %rdx
	shrq	$5, %rdx
	incq	%rdx
	testq	%rsi, %rsi
	je	LBB6_4
## %bb.5:
	movq	%rdx, %rdi
	andq	$-2, %rdi
	negq	%rdi
	vmovdqa	LCPI6_1(%rip), %ymm0            ## ymm0 = [4,5,6,7]
	vmovdqa	LCPI6_2(%rip), %ymm1            ## ymm1 = [0,1,2,3]
	xorl	%esi, %esi
	vmovdqa	LCPI6_3(%rip), %ymm2            ## ymm2 = [0,2,4,6,4,6,6,7]
	vpcmpeqd	%ymm3, %ymm3, %ymm3
	vpbroadcastd	LCPI6_4(%rip), %ymm4    ## ymm4 = [9,9,9,9,9,9,9,9]
	vpbroadcastd	LCPI6_5(%rip), %ymm5    ## ymm5 = [17,17,17,17,17,17,17,17]
	vpbroadcastd	LCPI6_6(%rip), %ymm6    ## ymm6 = [25,25,25,25,25,25,25,25]
	vpbroadcastd	LCPI6_7(%rip), %ymm7    ## ymm7 = [33,33,33,33,33,33,33,33]
	vpbroadcastd	LCPI6_8(%rip), %ymm8    ## ymm8 = [41,41,41,41,41,41,41,41]
	vpbroadcastd	LCPI6_9(%rip), %ymm9    ## ymm9 = [49,49,49,49,49,49,49,49]
	vpbroadcastd	LCPI6_10(%rip), %ymm10  ## ymm10 = [57,57,57,57,57,57,57,57]
	vpbroadcastq	LCPI6_11(%rip), %ymm11  ## ymm11 = [64,64,64,64]
	.p2align	4, 0x90
LBB6_6:                                 ## =>This Inner Loop Header: Depth=1
	vpermd	%ymm1, %ymm2, %ymm12
	vpermd	%ymm0, %ymm2, %ymm13
	vinserti128	$1, %xmm13, %ymm12, %ymm12
	vpsubd	%ymm3, %ymm12, %ymm13
	vmovdqu	%ymm13, (%rbx,%rsi,4)
	vpaddd	%ymm4, %ymm12, %ymm13
	vmovdqu	%ymm13, 32(%rbx,%rsi,4)
	vpaddd	%ymm5, %ymm12, %ymm13
	vmovdqu	%ymm13, 64(%rbx,%rsi,4)
	vpaddd	%ymm6, %ymm12, %ymm13
	vmovdqu	%ymm13, 96(%rbx,%rsi,4)
	vpaddd	%ymm7, %ymm12, %ymm13
	vmovdqu	%ymm13, 128(%rbx,%rsi,4)
	vpaddd	%ymm8, %ymm12, %ymm13
	vmovdqu	%ymm13, 160(%rbx,%rsi,4)
	vpaddd	%ymm9, %ymm12, %ymm13
	vmovdqu	%ymm13, 192(%rbx,%rsi,4)
	vpaddd	%ymm10, %ymm12, %ymm12
	vmovdqu	%ymm12, 224(%rbx,%rsi,4)
	addq	$64, %rsi
	vpaddq	%ymm1, %ymm11, %ymm1
	vpaddq	%ymm0, %ymm11, %ymm0
	addq	$2, %rdi
	jne	LBB6_6
## %bb.7:
	vpermd	%ymm1, %ymm2, %ymm1
	vpermd	%ymm0, %ymm2, %ymm0
	vinserti128	$1, %xmm0, %ymm1, %ymm0
	testb	$1, %dl
	je	LBB6_10
LBB6_9:
	vpcmpeqd	%ymm1, %ymm1, %ymm1
	vpsubd	%ymm1, %ymm0, %ymm1
	vpbroadcastd	LCPI6_4(%rip), %ymm2    ## ymm2 = [9,9,9,9,9,9,9,9]
	vpaddd	%ymm2, %ymm0, %ymm2
	vpbroadcastd	LCPI6_5(%rip), %ymm3    ## ymm3 = [17,17,17,17,17,17,17,17]
	vpaddd	%ymm3, %ymm0, %ymm3
	vpbroadcastd	LCPI6_6(%rip), %ymm4    ## ymm4 = [25,25,25,25,25,25,25,25]
	vpaddd	%ymm4, %ymm0, %ymm0
	vmovdqu	%ymm1, (%rbx,%rsi,4)
	vmovdqu	%ymm2, 32(%rbx,%rsi,4)
	vmovdqu	%ymm3, 64(%rbx,%rsi,4)
	vmovdqu	%ymm0, 96(%rbx,%rsi,4)
LBB6_10:
	cmpq	%rax, %rcx
	je	LBB6_12
	.p2align	4, 0x90
LBB6_11:                                ## =>This Inner Loop Header: Depth=1
	leaq	1(%rcx), %rdx
	movl	%edx, (%rbx,%rcx,4)
	movq	%rdx, %rcx
	cmpq	%rdx, %rax
	jne	LBB6_11
LBB6_12:
	popq	%rbx
	popq	%r14
	popq	%rbp
	vzeroupper
	retq
LBB6_4:
	vmovdqa	LCPI6_0(%rip), %ymm0            ## ymm0 = [0,1,2,3,4,5,6,7]
	xorl	%esi, %esi
	testb	$1, %dl
	jne	LBB6_9
	jmp	LBB6_10
	.cfi_endproc
                                        ## -- End function
	.globl	_insertionSortOptimized         ## -- Begin function insertionSortOptimized
	.p2align	4, 0x90
_insertionSortOptimized:                ## @insertionSortOptimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	$2, %esi
	jl	LBB7_18
## %bb.1:
	movabsq	$-4294967296, %rax              ## imm = 0xFFFFFFFF00000000
	movl	%esi, %r8d
	decq	%r8
	movl	$1, %r15d
	cmpl	$2, %esi
	jne	LBB7_2
LBB7_12:
	testb	$1, %r8b
	je	LBB7_18
## %bb.13:
	movl	(%rdi,%r15,4), %edx
	movq	%r15, %rsi
	shlq	$32, %rsi
	addq	%rax, %rsi
	.p2align	4, 0x90
LBB7_14:                                ## =>This Inner Loop Header: Depth=1
	movq	%rsi, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%edx, %ecx
	jle	LBB7_17
## %bb.15:                              ##   in Loop: Header=BB7_14 Depth=1
	movl	%ecx, (%rdi,%r15,4)
	leaq	-1(%r15), %rcx
	addq	%rax, %rsi
	cmpq	$1, %r15
	movq	%rcx, %r15
	jg	LBB7_14
## %bb.16:
	xorl	%r15d, %r15d
LBB7_17:
	movslq	%r15d, %rax
	movl	%edx, (%rdi,%rax,4)
LBB7_18:
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB7_2:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movq	%r8, %r10
	andq	$-2, %r10
	movl	$1, %r15d
	movabsq	$4294967296, %r11               ## imm = 0x100000000
	xorl	%r14d, %r14d
	jmp	LBB7_3
	.p2align	4, 0x90
LBB7_11:                                ##   in Loop: Header=BB7_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	addq	$2, %r15
	addq	%r9, %r14
	addq	%r9, %r11
	addq	$-2, %r10
	je	LBB7_12
LBB7_3:                                 ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB7_4 Depth 2
                                        ##     Child Loop BB7_8 Depth 2
	movl	(%rdi,%r15,4), %esi
	movq	%r14, %rdx
	movq	%r15, %rbx
	.p2align	4, 0x90
LBB7_4:                                 ##   Parent Loop BB7_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB7_7
## %bb.5:                               ##   in Loop: Header=BB7_4 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB7_4
## %bb.6:                               ##   in Loop: Header=BB7_3 Depth=1
	xorl	%ebx, %ebx
LBB7_7:                                 ##   in Loop: Header=BB7_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	leaq	1(%r15), %rbx
	movl	4(%rdi,%r15,4), %esi
	movq	%r11, %rdx
	.p2align	4, 0x90
LBB7_8:                                 ##   Parent Loop BB7_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB7_11
## %bb.9:                               ##   in Loop: Header=BB7_8 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB7_8
## %bb.10:                              ##   in Loop: Header=BB7_3 Depth=1
	xorl	%ebx, %ebx
	jmp	LBB7_11
	.cfi_endproc
                                        ## -- End function
	.globl	_max                            ## -- Begin function max
	.p2align	4, 0x90
_max:                                   ## @max
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	%esi, %eax
	cmpl	%esi, %edi
	cmovgl	%edi, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sign                           ## -- Begin function sign
	.p2align	4, 0x90
_sign:                                  ## @sign
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	%edi, %ecx
	sarl	$31, %ecx
	xorl	%eax, %eax
	testl	%edi, %edi
	setne	%al
	orl	%ecx, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_merging_optimzed               ## -- Begin function merging_optimzed
	.p2align	4, 0x90
_merging_optimzed:                      ## @merging_optimzed
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $ecx killed $ecx def $rcx
                                        ## kill: def $edx killed $edx def $rdx
	movl	%esi, %r13d
	leal	1(%rdx), %r11d
	cmpl	%ecx, %edx
	jge	LBB10_1
## %bb.8:
	cmpl	%edx, %r13d
	jg	LBB10_1
## %bb.9:
	movslq	%r13d, %rax
	leaq	(%r8,%rax,4), %r14
	movl	%r13d, %r9d
	movl	%r13d, %ebx
	.p2align	4, 0x90
LBB10_10:                               ## =>This Inner Loop Header: Depth=1
	movslq	%r11d, %r11
	movl	(%rdi,%r11,4), %r10d
	movslq	%ebx, %rbx
	movl	(%rdi,%rbx,4), %esi
	xorl	%eax, %eax
	xorl	%r15d, %r15d
	cmpl	%r10d, %esi
	setle	%al
	setg	%r15b
	cmovgl	%r10d, %esi
	addl	%eax, %ebx
	addl	%r15d, %r11d
	movl	%esi, (%r14)
	incl	%r9d
	cmpl	%ecx, %r11d
	jg	LBB10_2
## %bb.11:                              ##   in Loop: Header=BB10_10 Depth=1
	addq	$4, %r14
	cmpl	%edx, %ebx
	jle	LBB10_10
	jmp	LBB10_2
LBB10_1:
	movl	%r13d, %r9d
	movl	%r13d, %ebx
LBB10_2:
	cmpl	%edx, %ebx
	jg	LBB10_25
## %bb.3:
	movslq	%ebx, %r10
	movslq	%r9d, %r9
	movl	%edx, %r14d
	subl	%ebx, %r14d
	cmpl	$31, %r14d
	jb	LBB10_19
## %bb.4:
	leaq	(%r8,%r9,4), %rax
	leaq	(%r10,%r14), %rsi
	leaq	(%rdi,%rsi,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rax
	jae	LBB10_6
## %bb.5:
	leaq	(%r9,%r14), %rax
	leaq	(%r8,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r10,4), %rsi
	cmpq	%rax, %rsi
	jb	LBB10_19
LBB10_6:
	movl	%r13d, %esi
	incq	%r14
	movq	%r14, -56(%rbp)                 ## 8-byte Spill
	andq	$-32, %r14
	movq	%r14, -48(%rbp)                 ## 8-byte Spill
	leaq	-32(%r14), %rax
	movq	%rax, %r12
	shrq	$5, %r12
	incq	%r12
	movl	%r12d, %r15d
	andl	$3, %r15d
	cmpq	$96, %rax
	jae	LBB10_12
## %bb.7:
	xorl	%ebx, %ebx
	jmp	LBB10_14
LBB10_12:
	leaq	(%r8,%r9,4), %r13
	addq	$480, %r13                      ## imm = 0x1E0
	leaq	(%rdi,%r10,4), %r14
	addq	$480, %r14                      ## imm = 0x1E0
	andq	$-4, %r12
	negq	%r12
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB10_13:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%r14,%rbx,4), %ymm0
	vmovups	-448(%r14,%rbx,4), %ymm1
	vmovups	-416(%r14,%rbx,4), %ymm2
	vmovups	-384(%r14,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%r13,%rbx,4)
	vmovups	%ymm1, -448(%r13,%rbx,4)
	vmovups	%ymm2, -416(%r13,%rbx,4)
	vmovups	%ymm3, -384(%r13,%rbx,4)
	vmovups	-352(%r14,%rbx,4), %ymm0
	vmovups	-320(%r14,%rbx,4), %ymm1
	vmovups	-288(%r14,%rbx,4), %ymm2
	vmovups	-256(%r14,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%r13,%rbx,4)
	vmovups	%ymm1, -320(%r13,%rbx,4)
	vmovups	%ymm2, -288(%r13,%rbx,4)
	vmovups	%ymm3, -256(%r13,%rbx,4)
	vmovups	-224(%r14,%rbx,4), %ymm0
	vmovups	-192(%r14,%rbx,4), %ymm1
	vmovups	-160(%r14,%rbx,4), %ymm2
	vmovups	-128(%r14,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%r13,%rbx,4)
	vmovups	%ymm1, -192(%r13,%rbx,4)
	vmovups	%ymm2, -160(%r13,%rbx,4)
	vmovups	%ymm3, -128(%r13,%rbx,4)
	vmovups	-96(%r14,%rbx,4), %ymm0
	vmovups	-64(%r14,%rbx,4), %ymm1
	vmovups	-32(%r14,%rbx,4), %ymm2
	vmovups	(%r14,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%r13,%rbx,4)
	vmovups	%ymm1, -64(%r13,%rbx,4)
	vmovups	%ymm2, -32(%r13,%rbx,4)
	vmovups	%ymm3, (%r13,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %r12
	jne	LBB10_13
LBB10_14:
	testq	%r15, %r15
	movl	%esi, %r13d
	je	LBB10_17
## %bb.15:
	leaq	(%rbx,%r10), %rax
	leaq	(%rdi,%rax,4), %rax
	addq	$96, %rax
	addq	%r9, %rbx
	leaq	(%r8,%rbx,4), %rbx
	addq	$96, %rbx
	shlq	$7, %r15
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB10_16:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rax,%rsi), %ymm0
	vmovups	-64(%rax,%rsi), %ymm1
	vmovups	-32(%rax,%rsi), %ymm2
	vmovups	(%rax,%rsi), %ymm3
	vmovups	%ymm0, -96(%rbx,%rsi)
	vmovups	%ymm1, -64(%rbx,%rsi)
	vmovups	%ymm2, -32(%rbx,%rsi)
	vmovups	%ymm3, (%rbx,%rsi)
	subq	$-128, %rsi
	cmpq	%rsi, %r15
	jne	LBB10_16
LBB10_17:
	movq	-48(%rbp), %rax                 ## 8-byte Reload
	addq	%rax, %r9
	cmpq	%rax, -56(%rbp)                 ## 8-byte Folded Reload
	je	LBB10_25
## %bb.18:
	addq	%rax, %r10
LBB10_19:
	movl	%edx, %eax
	subl	%r10d, %eax
	leal	1(%rax), %ebx
	andl	$7, %ebx
	je	LBB10_21
	.p2align	4, 0x90
LBB10_20:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r10,4), %esi
	incq	%r10
	movl	%esi, (%r8,%r9,4)
	incq	%r9
	decl	%ebx
	jne	LBB10_20
LBB10_21:
	cmpl	$7, %eax
	jb	LBB10_25
## %bb.22:
	leaq	(%r8,%r9,4), %r14
	addq	$28, %r14
	subl	%r10d, %edx
	incl	%edx
	leaq	(%rdi,%r10,4), %rax
	addq	$28, %rax
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB10_23:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rax,%rbx,4), %esi
	movl	%esi, -28(%r14,%rbx,4)
	movl	-24(%rax,%rbx,4), %esi
	movl	%esi, -24(%r14,%rbx,4)
	movl	-20(%rax,%rbx,4), %esi
	movl	%esi, -20(%r14,%rbx,4)
	movl	-16(%rax,%rbx,4), %esi
	movl	%esi, -16(%r14,%rbx,4)
	movl	-12(%rax,%rbx,4), %esi
	movl	%esi, -12(%r14,%rbx,4)
	movl	-8(%rax,%rbx,4), %esi
	movl	%esi, -8(%r14,%rbx,4)
	movl	-4(%rax,%rbx,4), %esi
	movl	%esi, -4(%r14,%rbx,4)
	movl	(%rax,%rbx,4), %esi
	movl	%esi, (%r14,%rbx,4)
	addq	$8, %rbx
	cmpl	%ebx, %edx
	jne	LBB10_23
## %bb.24:
	addq	%rbx, %r9
LBB10_25:
	cmpl	%ecx, %r11d
	jg	LBB10_43
## %bb.26:
	movslq	%r9d, %r9
	movslq	%r11d, %r12
	movl	%ecx, %r10d
	subl	%r11d, %r10d
	cmpl	$31, %r10d
	jb	LBB10_38
## %bb.27:
	leaq	(%r8,%r9,4), %rax
	leaq	(%r12,%r10), %rdx
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	cmpq	%rdx, %rax
	jae	LBB10_29
## %bb.28:
	leaq	(%r9,%r10), %rax
	leaq	(%r8,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r12,4), %rdx
	cmpq	%rax, %rdx
	jb	LBB10_38
LBB10_29:
	incq	%r10
	movq	%r10, %r11
	andq	$-32, %r11
	leaq	-32(%r11), %rax
	movq	%rax, %r15
	shrq	$5, %r15
	incq	%r15
	movl	%r15d, %r14d
	andl	$3, %r14d
	cmpq	$96, %rax
	jae	LBB10_31
## %bb.30:
	xorl	%eax, %eax
	jmp	LBB10_33
LBB10_31:
	leaq	(%rdi,%r12,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r8,%r9,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	andq	$-4, %r15
	negq	%r15
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB10_32:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rax,4), %ymm0
	vmovups	-448(%rbx,%rax,4), %ymm1
	vmovups	-416(%rbx,%rax,4), %ymm2
	vmovups	-384(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rax,4)
	vmovups	%ymm1, -448(%rdx,%rax,4)
	vmovups	%ymm2, -416(%rdx,%rax,4)
	vmovups	%ymm3, -384(%rdx,%rax,4)
	vmovups	-352(%rbx,%rax,4), %ymm0
	vmovups	-320(%rbx,%rax,4), %ymm1
	vmovups	-288(%rbx,%rax,4), %ymm2
	vmovups	-256(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rax,4)
	vmovups	%ymm1, -320(%rdx,%rax,4)
	vmovups	%ymm2, -288(%rdx,%rax,4)
	vmovups	%ymm3, -256(%rdx,%rax,4)
	vmovups	-224(%rbx,%rax,4), %ymm0
	vmovups	-192(%rbx,%rax,4), %ymm1
	vmovups	-160(%rbx,%rax,4), %ymm2
	vmovups	-128(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rax,4)
	vmovups	%ymm1, -192(%rdx,%rax,4)
	vmovups	%ymm2, -160(%rdx,%rax,4)
	vmovups	%ymm3, -128(%rdx,%rax,4)
	vmovups	-96(%rbx,%rax,4), %ymm0
	vmovups	-64(%rbx,%rax,4), %ymm1
	vmovups	-32(%rbx,%rax,4), %ymm2
	vmovups	(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rax,4)
	vmovups	%ymm1, -64(%rdx,%rax,4)
	vmovups	%ymm2, -32(%rdx,%rax,4)
	vmovups	%ymm3, (%rdx,%rax,4)
	subq	$-128, %rax
	addq	$4, %r15
	jne	LBB10_32
LBB10_33:
	testq	%r14, %r14
	je	LBB10_36
## %bb.34:
	leaq	(%rax,%r9), %rdx
	leaq	(%r8,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%r12, %rax
	leaq	(%rdi,%rax,4), %rax
	addq	$96, %rax
	shlq	$7, %r14
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB10_35:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rax,%rsi), %ymm0
	vmovups	-64(%rax,%rsi), %ymm1
	vmovups	-32(%rax,%rsi), %ymm2
	vmovups	(%rax,%rsi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rsi)
	vmovups	%ymm1, -64(%rdx,%rsi)
	vmovups	%ymm2, -32(%rdx,%rsi)
	vmovups	%ymm3, (%rdx,%rsi)
	subq	$-128, %rsi
	cmpq	%rsi, %r14
	jne	LBB10_35
LBB10_36:
	cmpq	%r11, %r10
	je	LBB10_43
## %bb.37:
	addq	%r11, %r12
	addq	%r11, %r9
LBB10_38:
	movl	%ecx, %eax
	subl	%r12d, %eax
	leal	1(%rax), %edx
	andl	$7, %edx
	je	LBB10_40
	.p2align	4, 0x90
LBB10_39:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r12,4), %esi
	incq	%r12
	movl	%esi, (%r8,%r9,4)
	incq	%r9
	decl	%edx
	jne	LBB10_39
LBB10_40:
	cmpl	$7, %eax
	jb	LBB10_43
## %bb.41:
	movl	%ecx, %r10d
	subl	%r12d, %r10d
	incl	%r10d
	leaq	(%rdi,%r12,4), %rdx
	addq	$28, %rdx
	leaq	(%r8,%r9,4), %rbx
	addq	$28, %rbx
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB10_42:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rdx,%rax,4), %esi
	movl	%esi, -28(%rbx,%rax,4)
	movl	-24(%rdx,%rax,4), %esi
	movl	%esi, -24(%rbx,%rax,4)
	movl	-20(%rdx,%rax,4), %esi
	movl	%esi, -20(%rbx,%rax,4)
	movl	-16(%rdx,%rax,4), %esi
	movl	%esi, -16(%rbx,%rax,4)
	movl	-12(%rdx,%rax,4), %esi
	movl	%esi, -12(%rbx,%rax,4)
	movl	-8(%rdx,%rax,4), %esi
	movl	%esi, -8(%rbx,%rax,4)
	movl	-4(%rdx,%rax,4), %esi
	movl	%esi, -4(%rbx,%rax,4)
	movl	(%rdx,%rax,4), %esi
	movl	%esi, (%rbx,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %r10d
	jne	LBB10_42
LBB10_43:
	movl	%ecx, %r11d
	subl	%r13d, %r11d
	jl	LBB10_61
## %bb.44:
	movslq	%r13d, %rax
	cmpl	$31, %r11d
	jb	LBB10_56
## %bb.45:
	leaq	(%rdi,%rax,4), %rsi
	leaq	(%r11,%rax), %rdx
	leaq	(%r8,%rdx,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rsi
	jae	LBB10_47
## %bb.46:
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r8,%rax,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB10_56
LBB10_47:
	incq	%r11
	movq	%r11, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %r14
	shrq	$5, %r14
	incq	%r14
	movl	%r14d, %r10d
	andl	$3, %r10d
	cmpq	$96, %rdx
	jae	LBB10_49
## %bb.48:
	xorl	%esi, %esi
	jmp	LBB10_51
LBB10_49:
	leaq	(%rdi,%rax,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	(%r8,%rax,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	andq	$-4, %r14
	negq	%r14
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB10_50:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rsi,4), %ymm0
	vmovups	-448(%rbx,%rsi,4), %ymm1
	vmovups	-416(%rbx,%rsi,4), %ymm2
	vmovups	-384(%rbx,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rsi,4)
	vmovups	%ymm1, -448(%rdx,%rsi,4)
	vmovups	%ymm2, -416(%rdx,%rsi,4)
	vmovups	%ymm3, -384(%rdx,%rsi,4)
	vmovups	-352(%rbx,%rsi,4), %ymm0
	vmovups	-320(%rbx,%rsi,4), %ymm1
	vmovups	-288(%rbx,%rsi,4), %ymm2
	vmovups	-256(%rbx,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rsi,4)
	vmovups	%ymm1, -320(%rdx,%rsi,4)
	vmovups	%ymm2, -288(%rdx,%rsi,4)
	vmovups	%ymm3, -256(%rdx,%rsi,4)
	vmovups	-224(%rbx,%rsi,4), %ymm0
	vmovups	-192(%rbx,%rsi,4), %ymm1
	vmovups	-160(%rbx,%rsi,4), %ymm2
	vmovups	-128(%rbx,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rsi,4)
	vmovups	%ymm1, -192(%rdx,%rsi,4)
	vmovups	%ymm2, -160(%rdx,%rsi,4)
	vmovups	%ymm3, -128(%rdx,%rsi,4)
	vmovups	-96(%rbx,%rsi,4), %ymm0
	vmovups	-64(%rbx,%rsi,4), %ymm1
	vmovups	-32(%rbx,%rsi,4), %ymm2
	vmovups	(%rbx,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rsi,4)
	vmovups	%ymm1, -64(%rdx,%rsi,4)
	vmovups	%ymm2, -32(%rdx,%rsi,4)
	vmovups	%ymm3, (%rdx,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %r14
	jne	LBB10_50
LBB10_51:
	testq	%r10, %r10
	je	LBB10_54
## %bb.52:
	addq	%rax, %rsi
	leaq	(%rdi,%rsi,4), %rdx
	addq	$96, %rdx
	leaq	(%r8,%rsi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r10
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB10_53:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rbx), %ymm0
	vmovups	-64(%rsi,%rbx), %ymm1
	vmovups	-32(%rsi,%rbx), %ymm2
	vmovups	(%rsi,%rbx), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx)
	vmovups	%ymm1, -64(%rdx,%rbx)
	vmovups	%ymm2, -32(%rdx,%rbx)
	vmovups	%ymm3, (%rdx,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r10
	jne	LBB10_53
LBB10_54:
	cmpq	%r9, %r11
	je	LBB10_61
## %bb.55:
	addq	%r9, %rax
LBB10_56:
	leal	1(%rcx), %edx
	movl	%edx, %esi
	subl	%eax, %esi
	subl	%eax, %ecx
	andl	$7, %esi
	je	LBB10_58
	.p2align	4, 0x90
LBB10_57:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rax,4), %ebx
	movl	%ebx, (%rdi,%rax,4)
	incq	%rax
	decl	%esi
	jne	LBB10_57
LBB10_58:
	cmpl	$7, %ecx
	jb	LBB10_61
## %bb.59:
	movl	%edx, %ecx
	.p2align	4, 0x90
LBB10_60:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rax,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	4(%r8,%rax,4), %edx
	movl	%edx, 4(%rdi,%rax,4)
	movl	8(%r8,%rax,4), %edx
	movl	%edx, 8(%rdi,%rax,4)
	movl	12(%r8,%rax,4), %edx
	movl	%edx, 12(%rdi,%rax,4)
	movl	16(%r8,%rax,4), %edx
	movl	%edx, 16(%rdi,%rax,4)
	movl	20(%r8,%rax,4), %edx
	movl	%edx, 20(%rdi,%rax,4)
	movl	24(%r8,%rax,4), %edx
	movl	%edx, 24(%rdi,%rax,4)
	movl	28(%r8,%rax,4), %edx
	movl	%edx, 28(%rdi,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %ecx
	jne	LBB10_60
LBB10_61:
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_merge_o                   ## -- Begin function sort_merge_o
	.p2align	4, 0x90
_sort_merge_o:                          ## @sort_merge_o
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB11_64
## %bb.1:
	movq	%rcx, %r14
	movl	%edx, %ebx
	movq	%rdi, %r13
	leal	(%rbx,%rsi), %eax
	movl	%eax, %r12d
	shrl	$31, %r12d
	addl	%eax, %r12d
	sarl	%r12d
	movl	%r12d, %edx
	movq	%rbx, -48(%rbp)                 ## 8-byte Spill
	movq	%rsi, %rbx
	callq	_sort_merge_o
	leal	1(%r12), %r15d
	movq	%r13, %rdi
	movl	%r15d, %esi
	movq	-48(%rbp), %rdx                 ## 8-byte Reload
                                        ## kill: def $edx killed $edx killed $rdx
	movq	%r14, %rcx
	callq	_sort_merge_o
	movq	-48(%rbp), %r11                 ## 8-byte Reload
	cmpl	%r11d, %r12d
	jge	LBB11_2
## %bb.3:
	cmpl	%ebx, %r12d
	movq	%rbx, %r9
	jl	LBB11_4
## %bb.31:
	movslq	%r9d, %rax
	leaq	(%r14,%rax,4), %rdx
	movl	%r9d, %r8d
	movl	%r9d, %ecx
	.p2align	4, 0x90
LBB11_32:                               ## =>This Inner Loop Header: Depth=1
	movslq	%r15d, %r15
	movl	(%r13,%r15,4), %esi
	movslq	%ecx, %rcx
	movl	(%r13,%rcx,4), %edi
	xorl	%eax, %eax
	xorl	%ebx, %ebx
	cmpl	%esi, %edi
	setle	%al
	setg	%bl
	cmovgl	%esi, %edi
	addl	%eax, %ecx
	addl	%ebx, %r15d
	movl	%edi, (%rdx)
	incl	%r8d
	cmpl	%r11d, %r15d
	jg	LBB11_5
## %bb.33:                              ##   in Loop: Header=BB11_32 Depth=1
	addq	$4, %rdx
	cmpl	%r12d, %ecx
	jle	LBB11_32
	jmp	LBB11_5
LBB11_4:
	movl	%r9d, %r8d
	movl	%r9d, %ecx
LBB11_5:
	movl	%r12d, %r10d
	subl	%ecx, %r10d
	jl	LBB11_18
LBB11_6:
	movslq	%ecx, %rcx
	movslq	%r8d, %r8
	cmpl	$31, %r10d
	jb	LBB11_25
## %bb.7:
	leaq	(%r14,%r8,4), %rdx
	leaq	(%rcx,%r10), %rsi
	leaq	4(,%rsi,4), %rsi
	addq	%r13, %rsi
	cmpq	%rsi, %rdx
	jae	LBB11_9
## %bb.8:
	leaq	(%r8,%r10), %rdx
	leaq	(%r14,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(,%rcx,4), %rsi
	addq	%r13, %rsi
	cmpq	%rdx, %rsi
	jb	LBB11_25
LBB11_9:
	movq	%r9, %rbx
	incq	%r10
	movq	%r10, %rax
	andq	$-32, %rax
	leaq	-32(%rax), %rdx
	movq	%rdx, %r11
	shrq	$5, %r11
	incq	%r11
	movl	%r11d, %r9d
	andl	$3, %r9d
	cmpq	$96, %rdx
	jae	LBB11_11
## %bb.10:
	xorl	%esi, %esi
	jmp	LBB11_13
LBB11_2:
	movl	%ebx, %r8d
	movl	%ebx, %ecx
	movq	%rbx, %r9
	movl	%r12d, %r10d
	subl	%ecx, %r10d
	jge	LBB11_6
	jmp	LBB11_18
LBB11_11:
	leaq	(%r14,%r8,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	480(,%rcx,4), %rdi
	addq	%r13, %rdi
	andq	$-4, %r11
	negq	%r11
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB11_12:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdi,%rsi,4), %ymm0
	vmovups	-448(%rdi,%rsi,4), %ymm1
	vmovups	-416(%rdi,%rsi,4), %ymm2
	vmovups	-384(%rdi,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rsi,4)
	vmovups	%ymm1, -448(%rdx,%rsi,4)
	vmovups	%ymm2, -416(%rdx,%rsi,4)
	vmovups	%ymm3, -384(%rdx,%rsi,4)
	vmovups	-352(%rdi,%rsi,4), %ymm0
	vmovups	-320(%rdi,%rsi,4), %ymm1
	vmovups	-288(%rdi,%rsi,4), %ymm2
	vmovups	-256(%rdi,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rsi,4)
	vmovups	%ymm1, -320(%rdx,%rsi,4)
	vmovups	%ymm2, -288(%rdx,%rsi,4)
	vmovups	%ymm3, -256(%rdx,%rsi,4)
	vmovups	-224(%rdi,%rsi,4), %ymm0
	vmovups	-192(%rdi,%rsi,4), %ymm1
	vmovups	-160(%rdi,%rsi,4), %ymm2
	vmovups	-128(%rdi,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rsi,4)
	vmovups	%ymm1, -192(%rdx,%rsi,4)
	vmovups	%ymm2, -160(%rdx,%rsi,4)
	vmovups	%ymm3, -128(%rdx,%rsi,4)
	vmovups	-96(%rdi,%rsi,4), %ymm0
	vmovups	-64(%rdi,%rsi,4), %ymm1
	vmovups	-32(%rdi,%rsi,4), %ymm2
	vmovups	(%rdi,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rsi,4)
	vmovups	%ymm1, -64(%rdx,%rsi,4)
	vmovups	%ymm2, -32(%rdx,%rsi,4)
	vmovups	%ymm3, (%rdx,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %r11
	jne	LBB11_12
LBB11_13:
	testq	%r9, %r9
	je	LBB11_16
## %bb.14:
	leaq	(%rsi,%rcx), %rdx
	leaq	96(,%rdx,4), %rdx
	addq	%r13, %rdx
	addq	%r8, %rsi
	leaq	(%r14,%rsi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r9
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB11_15:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rdx,%rdi), %ymm0
	vmovups	-64(%rdx,%rdi), %ymm1
	vmovups	-32(%rdx,%rdi), %ymm2
	vmovups	(%rdx,%rdi), %ymm3
	vmovups	%ymm0, -96(%rsi,%rdi)
	vmovups	%ymm1, -64(%rsi,%rdi)
	vmovups	%ymm2, -32(%rsi,%rdi)
	vmovups	%ymm3, (%rsi,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r9
	jne	LBB11_15
LBB11_16:
	addq	%rax, %r8
	cmpq	%rax, %r10
	movq	-48(%rbp), %r11                 ## 8-byte Reload
	jne	LBB11_24
## %bb.17:
	movq	%rbx, %r9
	jmp	LBB11_18
LBB11_24:
	addq	%rax, %rcx
	movq	%rbx, %r9
LBB11_25:
	movl	%r12d, %edx
	subl	%ecx, %edx
	leal	1(%rdx), %esi
	andl	$7, %esi
	je	LBB11_27
	.p2align	4, 0x90
LBB11_26:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r13,%rcx,4), %edi
	incq	%rcx
	movl	%edi, (%r14,%r8,4)
	incq	%r8
	decl	%esi
	jne	LBB11_26
LBB11_27:
	cmpl	$7, %edx
	jb	LBB11_18
## %bb.28:
	leaq	(%r14,%r8,4), %rdx
	addq	$28, %rdx
	subl	%ecx, %r12d
	incl	%r12d
	leaq	28(,%rcx,4), %rsi
	addq	%r13, %rsi
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB11_29:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rcx,4), %eax
	movl	%eax, -28(%rdx,%rcx,4)
	movl	-24(%rsi,%rcx,4), %eax
	movl	%eax, -24(%rdx,%rcx,4)
	movl	-20(%rsi,%rcx,4), %eax
	movl	%eax, -20(%rdx,%rcx,4)
	movl	-16(%rsi,%rcx,4), %eax
	movl	%eax, -16(%rdx,%rcx,4)
	movl	-12(%rsi,%rcx,4), %eax
	movl	%eax, -12(%rdx,%rcx,4)
	movl	-8(%rsi,%rcx,4), %eax
	movl	%eax, -8(%rdx,%rcx,4)
	movl	-4(%rsi,%rcx,4), %eax
	movl	%eax, -4(%rdx,%rcx,4)
	movl	(%rsi,%rcx,4), %eax
	movl	%eax, (%rdx,%rcx,4)
	addq	$8, %rcx
	cmpl	%ecx, %r12d
	jne	LBB11_29
## %bb.30:
	addq	%rcx, %r8
LBB11_18:
	cmpl	%r11d, %r15d
	jg	LBB11_46
## %bb.19:
	movq	%r9, %r12
	movslq	%r8d, %rax
	movslq	%r15d, %rcx
	movl	%r11d, %r9d
	subl	%r15d, %r9d
	cmpl	$31, %r9d
	jb	LBB11_41
## %bb.20:
	leaq	(%r14,%rax,4), %rdx
	leaq	(%rcx,%r9), %rsi
	leaq	4(,%rsi,4), %rsi
	addq	%r13, %rsi
	cmpq	%rsi, %rdx
	jae	LBB11_22
## %bb.21:
	leaq	(%rax,%r9), %rdx
	leaq	(%r14,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(,%rcx,4), %rsi
	addq	%r13, %rsi
	cmpq	%rdx, %rsi
	jb	LBB11_41
LBB11_22:
	incq	%r9
	movq	%r9, %r8
	andq	$-32, %r8
	leaq	-32(%r8), %rdx
	movq	%rdx, %rdi
	shrq	$5, %rdi
	incq	%rdi
	movl	%edi, %r10d
	andl	$3, %r10d
	cmpq	$96, %rdx
	jae	LBB11_34
## %bb.23:
	xorl	%esi, %esi
	jmp	LBB11_36
LBB11_34:
	leaq	480(,%rcx,4), %rdx
	addq	%r13, %rdx
	leaq	(%r14,%rax,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	andq	$-4, %rdi
	negq	%rdi
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB11_35:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdx,%rsi,4), %ymm0
	vmovups	-448(%rdx,%rsi,4), %ymm1
	vmovups	-416(%rdx,%rsi,4), %ymm2
	vmovups	-384(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%rbx,%rsi,4)
	vmovups	%ymm1, -448(%rbx,%rsi,4)
	vmovups	%ymm2, -416(%rbx,%rsi,4)
	vmovups	%ymm3, -384(%rbx,%rsi,4)
	vmovups	-352(%rdx,%rsi,4), %ymm0
	vmovups	-320(%rdx,%rsi,4), %ymm1
	vmovups	-288(%rdx,%rsi,4), %ymm2
	vmovups	-256(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%rbx,%rsi,4)
	vmovups	%ymm1, -320(%rbx,%rsi,4)
	vmovups	%ymm2, -288(%rbx,%rsi,4)
	vmovups	%ymm3, -256(%rbx,%rsi,4)
	vmovups	-224(%rdx,%rsi,4), %ymm0
	vmovups	-192(%rdx,%rsi,4), %ymm1
	vmovups	-160(%rdx,%rsi,4), %ymm2
	vmovups	-128(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%rbx,%rsi,4)
	vmovups	%ymm1, -192(%rbx,%rsi,4)
	vmovups	%ymm2, -160(%rbx,%rsi,4)
	vmovups	%ymm3, -128(%rbx,%rsi,4)
	vmovups	-96(%rdx,%rsi,4), %ymm0
	vmovups	-64(%rdx,%rsi,4), %ymm1
	vmovups	-32(%rdx,%rsi,4), %ymm2
	vmovups	(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%rbx,%rsi,4)
	vmovups	%ymm1, -64(%rbx,%rsi,4)
	vmovups	%ymm2, -32(%rbx,%rsi,4)
	vmovups	%ymm3, (%rbx,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %rdi
	jne	LBB11_35
LBB11_36:
	testq	%r10, %r10
	je	LBB11_39
## %bb.37:
	leaq	(%rsi,%rax), %rdx
	leaq	(%r14,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%rcx, %rsi
	leaq	96(,%rsi,4), %rsi
	addq	%r13, %rsi
	shlq	$7, %r10
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB11_38:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r10
	jne	LBB11_38
LBB11_39:
	cmpq	%r8, %r9
	movq	%r12, %r9
	je	LBB11_46
## %bb.40:
	addq	%r8, %rcx
	addq	%r8, %rax
LBB11_41:
	movl	%r11d, %edx
	subl	%ecx, %edx
	leal	1(%rdx), %esi
	movq	%r12, %r9
	andl	$7, %esi
	je	LBB11_43
	.p2align	4, 0x90
LBB11_42:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r13,%rcx,4), %edi
	incq	%rcx
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	decl	%esi
	jne	LBB11_42
LBB11_43:
	cmpl	$7, %edx
	jb	LBB11_46
## %bb.44:
	movl	%r11d, %edx
	subl	%ecx, %edx
	incl	%edx
	leaq	28(,%rcx,4), %rcx
	addq	%r13, %rcx
	leaq	(%r14,%rax,4), %rax
	addq	$28, %rax
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB11_45:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rcx,%rsi,4), %edi
	movl	%edi, -28(%rax,%rsi,4)
	movl	-24(%rcx,%rsi,4), %edi
	movl	%edi, -24(%rax,%rsi,4)
	movl	-20(%rcx,%rsi,4), %edi
	movl	%edi, -20(%rax,%rsi,4)
	movl	-16(%rcx,%rsi,4), %edi
	movl	%edi, -16(%rax,%rsi,4)
	movl	-12(%rcx,%rsi,4), %edi
	movl	%edi, -12(%rax,%rsi,4)
	movl	-8(%rcx,%rsi,4), %edi
	movl	%edi, -8(%rax,%rsi,4)
	movl	-4(%rcx,%rsi,4), %edi
	movl	%edi, -4(%rax,%rsi,4)
	movl	(%rcx,%rsi,4), %edi
	movl	%edi, (%rax,%rsi,4)
	addq	$8, %rsi
	cmpl	%esi, %edx
	jne	LBB11_45
LBB11_46:
	movl	%r11d, %ecx
	subl	%r9d, %ecx
	jl	LBB11_64
## %bb.47:
	movslq	%r9d, %rax
	cmpl	$31, %ecx
	jb	LBB11_59
## %bb.48:
	leaq	(,%rax,4), %rsi
	addq	%r13, %rsi
	leaq	(%rcx,%rax), %rdx
	leaq	(%r14,%rdx,4), %rdi
	addq	$4, %rdi
	cmpq	%rdi, %rsi
	jae	LBB11_50
## %bb.49:
	leaq	4(,%rdx,4), %rdx
	addq	%r13, %rdx
	leaq	(%r14,%rax,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB11_59
LBB11_50:
	incq	%rcx
	movq	%rcx, %r8
	andq	$-32, %r8
	leaq	-32(%r8), %rdx
	movq	%rdx, %rdi
	shrq	$5, %rdi
	incq	%rdi
	movl	%edi, %r9d
	andl	$3, %r9d
	cmpq	$96, %rdx
	jae	LBB11_52
## %bb.51:
	xorl	%ebx, %ebx
	jmp	LBB11_54
LBB11_52:
	leaq	480(,%rax,4), %rdx
	addq	%r13, %rdx
	leaq	(%r14,%rax,4), %rsi
	addq	$480, %rsi                      ## imm = 0x1E0
	andq	$-4, %rdi
	negq	%rdi
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB11_53:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rsi,%rbx,4), %ymm0
	vmovups	-448(%rsi,%rbx,4), %ymm1
	vmovups	-416(%rsi,%rbx,4), %ymm2
	vmovups	-384(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rbx,4)
	vmovups	%ymm1, -448(%rdx,%rbx,4)
	vmovups	%ymm2, -416(%rdx,%rbx,4)
	vmovups	%ymm3, -384(%rdx,%rbx,4)
	vmovups	-352(%rsi,%rbx,4), %ymm0
	vmovups	-320(%rsi,%rbx,4), %ymm1
	vmovups	-288(%rsi,%rbx,4), %ymm2
	vmovups	-256(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rbx,4)
	vmovups	%ymm1, -320(%rdx,%rbx,4)
	vmovups	%ymm2, -288(%rdx,%rbx,4)
	vmovups	%ymm3, -256(%rdx,%rbx,4)
	vmovups	-224(%rsi,%rbx,4), %ymm0
	vmovups	-192(%rsi,%rbx,4), %ymm1
	vmovups	-160(%rsi,%rbx,4), %ymm2
	vmovups	-128(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rbx,4)
	vmovups	%ymm1, -192(%rdx,%rbx,4)
	vmovups	%ymm2, -160(%rdx,%rbx,4)
	vmovups	%ymm3, -128(%rdx,%rbx,4)
	vmovups	-96(%rsi,%rbx,4), %ymm0
	vmovups	-64(%rsi,%rbx,4), %ymm1
	vmovups	-32(%rsi,%rbx,4), %ymm2
	vmovups	(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx,4)
	vmovups	%ymm1, -64(%rdx,%rbx,4)
	vmovups	%ymm2, -32(%rdx,%rbx,4)
	vmovups	%ymm3, (%rdx,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %rdi
	jne	LBB11_53
LBB11_54:
	testq	%r9, %r9
	je	LBB11_57
## %bb.55:
	addq	%rax, %rbx
	leaq	96(,%rbx,4), %rdx
	addq	%r13, %rdx
	leaq	(%r14,%rbx,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r9
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB11_56:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r9
	jne	LBB11_56
LBB11_57:
	cmpq	%r8, %rcx
	je	LBB11_64
## %bb.58:
	addq	%r8, %rax
LBB11_59:
	leal	1(%r11), %ecx
	movl	%ecx, %edx
	subl	%eax, %edx
	subl	%eax, %r11d
	andl	$7, %edx
	je	LBB11_61
	.p2align	4, 0x90
LBB11_60:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r14,%rax,4), %esi
	movl	%esi, (%r13,%rax,4)
	incq	%rax
	decl	%edx
	jne	LBB11_60
LBB11_61:
	cmpl	$7, %r11d
	jb	LBB11_64
## %bb.62:
	movl	%ecx, %ecx
	.p2align	4, 0x90
LBB11_63:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r14,%rax,4), %edx
	movl	%edx, (%r13,%rax,4)
	movl	4(%r14,%rax,4), %edx
	movl	%edx, 4(%r13,%rax,4)
	movl	8(%r14,%rax,4), %edx
	movl	%edx, 8(%r13,%rax,4)
	movl	12(%r14,%rax,4), %edx
	movl	%edx, 12(%r13,%rax,4)
	movl	16(%r14,%rax,4), %edx
	movl	%edx, 16(%r13,%rax,4)
	movl	20(%r14,%rax,4), %edx
	movl	%edx, 20(%r13,%rax,4)
	movl	24(%r14,%rax,4), %edx
	movl	%edx, 24(%r13,%rax,4)
	movl	28(%r14,%rax,4), %edx
	movl	%edx, 28(%r13,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %ecx
	jne	LBB11_63
LBB11_64:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_merge_optimized           ## -- Begin function sort_merge_optimized
	.p2align	4, 0x90
_sort_merge_optimized:                  ## @sort_merge_optimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movl	%edx, %r14d
	movl	%esi, %r12d
	movq	%rdi, %r15
	movl	%edx, %eax
	subl	%esi, %eax
	movslq	%eax, %rdi
	shlq	$2, %rdi
	callq	_malloc
	movq	%rax, %rbx
	movq	%r15, %rdi
	movl	%r12d, %esi
	movl	%r14d, %edx
	movq	%rax, %rcx
	callq	_sort_merge_o
	movq	%rbx, %rdi
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	jmp	_free                           ## TAILCALL
	.cfi_endproc
                                        ## -- End function
	.globl	_merging_standard               ## -- Begin function merging_standard
	.p2align	4, 0x90
_merging_standard:                      ## @merging_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $ecx killed $ecx def $rcx
                                        ## kill: def $edx killed $edx def $rdx
	leal	1(%rdx), %r14d
	cmpl	%edx, %esi
	jg	LBB13_1
## %bb.8:
	cmpl	%ecx, %edx
	jge	LBB13_1
## %bb.9:
	movslq	%esi, %r9
	shlq	$2, %r9
	addq	_b@GOTPCREL(%rip), %r9
	movl	%esi, %r8d
	movl	%esi, %ebx
	.p2align	4, 0x90
LBB13_10:                               ## =>This Inner Loop Header: Depth=1
	movslq	%ebx, %rbx
	movl	(%rdi,%rbx,4), %r15d
	movslq	%r14d, %r14
	movl	(%rdi,%r14,4), %r10d
	xorl	%r11d, %r11d
	xorl	%eax, %eax
	cmpl	%r10d, %r15d
	setg	%r11b
	setle	%al
	cmovgl	%r10d, %r15d
	addl	%eax, %ebx
	addl	%r11d, %r14d
	movl	%r15d, (%r9)
	incl	%r8d
	cmpl	%edx, %ebx
	jg	LBB13_2
## %bb.11:                              ##   in Loop: Header=BB13_10 Depth=1
	addq	$4, %r9
	cmpl	%ecx, %r14d
	jle	LBB13_10
	jmp	LBB13_2
LBB13_1:
	movl	%esi, %ebx
	movl	%esi, %r8d
LBB13_2:
	cmpl	%edx, %ebx
	jg	LBB13_26
## %bb.3:
	movslq	%r8d, %r8
	movslq	%ebx, %r9
	movl	%edx, %r10d
	subl	%ebx, %r10d
	cmpl	$31, %r10d
	jb	LBB13_19
## %bb.4:
	movq	_b@GOTPCREL(%rip), %r11
	leaq	(%r11,%r8,4), %rax
	leaq	(%r9,%r10), %rbx
	leaq	(%rdi,%rbx,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rax
	jae	LBB13_6
## %bb.5:
	leaq	(%r8,%r10), %rax
	leaq	(%r11,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r9,4), %rbx
	cmpq	%rax, %rbx
	jb	LBB13_19
LBB13_6:
	incq	%r10
	movq	%r10, %rax
	andq	$-32, %rax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	addq	$-32, %rax
	movq	%rax, %r12
	shrq	$5, %r12
	incq	%r12
	movl	%r12d, %r15d
	andl	$3, %r15d
	cmpq	$96, %rax
	jae	LBB13_12
## %bb.7:
	xorl	%r11d, %r11d
	jmp	LBB13_14
LBB13_12:
	leaq	(%rdi,%r9,4), %r13
	addq	$480, %r13                      ## imm = 0x1E0
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r8,4), %rax
	addq	$480, %rax                      ## imm = 0x1E0
	andq	$-4, %r12
	negq	%r12
	xorl	%r11d, %r11d
	.p2align	4, 0x90
LBB13_13:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%r13,%r11,4), %ymm0
	vmovups	-448(%r13,%r11,4), %ymm1
	vmovups	-416(%r13,%r11,4), %ymm2
	vmovups	-384(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -480(%rax,%r11,4)
	vmovups	%ymm1, -448(%rax,%r11,4)
	vmovups	%ymm2, -416(%rax,%r11,4)
	vmovups	%ymm3, -384(%rax,%r11,4)
	vmovups	-352(%r13,%r11,4), %ymm0
	vmovups	-320(%r13,%r11,4), %ymm1
	vmovups	-288(%r13,%r11,4), %ymm2
	vmovups	-256(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -352(%rax,%r11,4)
	vmovups	%ymm1, -320(%rax,%r11,4)
	vmovups	%ymm2, -288(%rax,%r11,4)
	vmovups	%ymm3, -256(%rax,%r11,4)
	vmovups	-224(%r13,%r11,4), %ymm0
	vmovups	-192(%r13,%r11,4), %ymm1
	vmovups	-160(%r13,%r11,4), %ymm2
	vmovups	-128(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -224(%rax,%r11,4)
	vmovups	%ymm1, -192(%rax,%r11,4)
	vmovups	%ymm2, -160(%rax,%r11,4)
	vmovups	%ymm3, -128(%rax,%r11,4)
	vmovups	-96(%r13,%r11,4), %ymm0
	vmovups	-64(%r13,%r11,4), %ymm1
	vmovups	-32(%r13,%r11,4), %ymm2
	vmovups	(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -96(%rax,%r11,4)
	vmovups	%ymm1, -64(%rax,%r11,4)
	vmovups	%ymm2, -32(%rax,%r11,4)
	vmovups	%ymm3, (%rax,%r11,4)
	subq	$-128, %r11
	addq	$4, %r12
	jne	LBB13_13
LBB13_14:
	testq	%r15, %r15
	je	LBB13_17
## %bb.15:
	leaq	(%r11,%r8), %rax
	movq	_b@GOTPCREL(%rip), %rbx
	leaq	(%rbx,%rax,4), %r12
	addq	$96, %r12
	addq	%r9, %r11
	leaq	(%rdi,%r11,4), %rbx
	addq	$96, %rbx
	shlq	$7, %r15
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB13_16:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rbx,%rax), %ymm0
	vmovups	-64(%rbx,%rax), %ymm1
	vmovups	-32(%rbx,%rax), %ymm2
	vmovups	(%rbx,%rax), %ymm3
	vmovups	%ymm0, -96(%r12,%rax)
	vmovups	%ymm1, -64(%r12,%rax)
	vmovups	%ymm2, -32(%r12,%rax)
	vmovups	%ymm3, (%r12,%rax)
	subq	$-128, %rax
	cmpq	%rax, %r15
	jne	LBB13_16
LBB13_17:
	movq	-48(%rbp), %rax                 ## 8-byte Reload
	addq	%rax, %r8
	cmpq	%rax, %r10
	je	LBB13_26
## %bb.18:
	addq	%rax, %r9
LBB13_19:
	movl	%edx, %r10d
	subl	%r9d, %r10d
	leal	1(%r10), %ebx
	andl	$7, %ebx
	je	LBB13_22
## %bb.20:
	movq	_b@GOTPCREL(%rip), %r11
	.p2align	4, 0x90
LBB13_21:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r9,4), %eax
	incq	%r9
	movl	%eax, (%r11,%r8,4)
	incq	%r8
	decl	%ebx
	jne	LBB13_21
LBB13_22:
	cmpl	$7, %r10d
	jb	LBB13_26
## %bb.23:
	subl	%r9d, %edx
	incl	%edx
	leaq	(%rdi,%r9,4), %r9
	addq	$28, %r9
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r8,4), %r10
	addq	$28, %r10
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB13_24:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%r9,%rbx,4), %eax
	movl	%eax, -28(%r10,%rbx,4)
	movl	-24(%r9,%rbx,4), %eax
	movl	%eax, -24(%r10,%rbx,4)
	movl	-20(%r9,%rbx,4), %eax
	movl	%eax, -20(%r10,%rbx,4)
	movl	-16(%r9,%rbx,4), %eax
	movl	%eax, -16(%r10,%rbx,4)
	movl	-12(%r9,%rbx,4), %eax
	movl	%eax, -12(%r10,%rbx,4)
	movl	-8(%r9,%rbx,4), %eax
	movl	%eax, -8(%r10,%rbx,4)
	movl	-4(%r9,%rbx,4), %eax
	movl	%eax, -4(%r10,%rbx,4)
	movl	(%r9,%rbx,4), %eax
	movl	%eax, (%r10,%rbx,4)
	addq	$8, %rbx
	cmpl	%ebx, %edx
	jne	LBB13_24
## %bb.25:
	addq	%rbx, %r8
LBB13_26:
	cmpl	%ecx, %r14d
	jg	LBB13_45
## %bb.27:
	movslq	%r8d, %r8
	movslq	%r14d, %r12
	movl	%ecx, %r9d
	subl	%r14d, %r9d
	cmpl	$31, %r9d
	jb	LBB13_39
## %bb.28:
	movq	_b@GOTPCREL(%rip), %r10
	leaq	(%r10,%r8,4), %rax
	leaq	(%r12,%r9), %rdx
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	cmpq	%rdx, %rax
	jae	LBB13_30
## %bb.29:
	leaq	(%r8,%r9), %rax
	leaq	(%r10,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r12,4), %rdx
	cmpq	%rax, %rdx
	jb	LBB13_39
LBB13_30:
	incq	%r9
	movq	%r9, %r11
	andq	$-32, %r11
	leaq	-32(%r11), %rax
	movq	%rax, %r15
	shrq	$5, %r15
	incq	%r15
	movl	%r15d, %r14d
	andl	$3, %r14d
	cmpq	$96, %rax
	jae	LBB13_32
## %bb.31:
	xorl	%eax, %eax
	jmp	LBB13_34
LBB13_32:
	leaq	(%rdi,%r12,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r10,%r8,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	andq	$-4, %r15
	negq	%r15
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB13_33:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rax,4), %ymm0
	vmovups	-448(%rbx,%rax,4), %ymm1
	vmovups	-416(%rbx,%rax,4), %ymm2
	vmovups	-384(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rax,4)
	vmovups	%ymm1, -448(%rdx,%rax,4)
	vmovups	%ymm2, -416(%rdx,%rax,4)
	vmovups	%ymm3, -384(%rdx,%rax,4)
	vmovups	-352(%rbx,%rax,4), %ymm0
	vmovups	-320(%rbx,%rax,4), %ymm1
	vmovups	-288(%rbx,%rax,4), %ymm2
	vmovups	-256(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rax,4)
	vmovups	%ymm1, -320(%rdx,%rax,4)
	vmovups	%ymm2, -288(%rdx,%rax,4)
	vmovups	%ymm3, -256(%rdx,%rax,4)
	vmovups	-224(%rbx,%rax,4), %ymm0
	vmovups	-192(%rbx,%rax,4), %ymm1
	vmovups	-160(%rbx,%rax,4), %ymm2
	vmovups	-128(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rax,4)
	vmovups	%ymm1, -192(%rdx,%rax,4)
	vmovups	%ymm2, -160(%rdx,%rax,4)
	vmovups	%ymm3, -128(%rdx,%rax,4)
	vmovups	-96(%rbx,%rax,4), %ymm0
	vmovups	-64(%rbx,%rax,4), %ymm1
	vmovups	-32(%rbx,%rax,4), %ymm2
	vmovups	(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rax,4)
	vmovups	%ymm1, -64(%rdx,%rax,4)
	vmovups	%ymm2, -32(%rdx,%rax,4)
	vmovups	%ymm3, (%rdx,%rax,4)
	subq	$-128, %rax
	addq	$4, %r15
	jne	LBB13_33
LBB13_34:
	testq	%r14, %r14
	je	LBB13_37
## %bb.35:
	leaq	(%rax,%r8), %rdx
	leaq	(%r10,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%r12, %rax
	leaq	(%rdi,%rax,4), %rax
	addq	$96, %rax
	shlq	$7, %r14
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB13_36:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rax,%rbx), %ymm0
	vmovups	-64(%rax,%rbx), %ymm1
	vmovups	-32(%rax,%rbx), %ymm2
	vmovups	(%rax,%rbx), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx)
	vmovups	%ymm1, -64(%rdx,%rbx)
	vmovups	%ymm2, -32(%rdx,%rbx)
	vmovups	%ymm3, (%rdx,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r14
	jne	LBB13_36
LBB13_37:
	cmpq	%r11, %r9
	je	LBB13_45
## %bb.38:
	addq	%r11, %r12
	addq	%r11, %r8
LBB13_39:
	movl	%ecx, %r9d
	subl	%r12d, %r9d
	leal	1(%r9), %edx
	andl	$7, %edx
	je	LBB13_42
## %bb.40:
	movq	_b@GOTPCREL(%rip), %rbx
	.p2align	4, 0x90
LBB13_41:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r12,4), %eax
	incq	%r12
	movl	%eax, (%rbx,%r8,4)
	incq	%r8
	decl	%edx
	jne	LBB13_41
LBB13_42:
	cmpl	$7, %r9d
	jb	LBB13_45
## %bb.43:
	movl	%ecx, %r9d
	subl	%r12d, %r9d
	incl	%r9d
	leaq	(%rdi,%r12,4), %r10
	addq	$28, %r10
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r8,4), %rbx
	addq	$28, %rbx
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB13_44:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%r10,%rax,4), %edx
	movl	%edx, -28(%rbx,%rax,4)
	movl	-24(%r10,%rax,4), %edx
	movl	%edx, -24(%rbx,%rax,4)
	movl	-20(%r10,%rax,4), %edx
	movl	%edx, -20(%rbx,%rax,4)
	movl	-16(%r10,%rax,4), %edx
	movl	%edx, -16(%rbx,%rax,4)
	movl	-12(%r10,%rax,4), %edx
	movl	%edx, -12(%rbx,%rax,4)
	movl	-8(%r10,%rax,4), %edx
	movl	%edx, -8(%rbx,%rax,4)
	movl	-4(%r10,%rax,4), %edx
	movl	%edx, -4(%rbx,%rax,4)
	movl	(%r10,%rax,4), %edx
	movl	%edx, (%rbx,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %r9d
	jne	LBB13_44
LBB13_45:
	movl	%ecx, %r10d
	subl	%esi, %r10d
	jl	LBB13_64
## %bb.46:
	movslq	%esi, %rax
	cmpl	$31, %r10d
	jb	LBB13_58
## %bb.47:
	leaq	(%rdi,%rax,4), %rbx
	leaq	(%r10,%rax), %rdx
	movq	_b@GOTPCREL(%rip), %r8
	leaq	(%r8,%rdx,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rbx
	jae	LBB13_49
## %bb.48:
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r8,%rax,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB13_58
LBB13_49:
	incq	%r10
	movq	%r10, %r8
	andq	$-32, %r8
	leaq	-32(%r8), %rdx
	movq	%rdx, %r11
	shrq	$5, %r11
	incq	%r11
	movl	%r11d, %r9d
	andl	$3, %r9d
	cmpq	$96, %rdx
	jae	LBB13_51
## %bb.50:
	xorl	%ebx, %ebx
	jmp	LBB13_53
LBB13_51:
	leaq	(%rdi,%rax,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	480(,%rax,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	andq	$-4, %r11
	negq	%r11
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB13_52:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rsi,%rbx,4), %ymm0
	vmovups	-448(%rsi,%rbx,4), %ymm1
	vmovups	-416(%rsi,%rbx,4), %ymm2
	vmovups	-384(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rbx,4)
	vmovups	%ymm1, -448(%rdx,%rbx,4)
	vmovups	%ymm2, -416(%rdx,%rbx,4)
	vmovups	%ymm3, -384(%rdx,%rbx,4)
	vmovups	-352(%rsi,%rbx,4), %ymm0
	vmovups	-320(%rsi,%rbx,4), %ymm1
	vmovups	-288(%rsi,%rbx,4), %ymm2
	vmovups	-256(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rbx,4)
	vmovups	%ymm1, -320(%rdx,%rbx,4)
	vmovups	%ymm2, -288(%rdx,%rbx,4)
	vmovups	%ymm3, -256(%rdx,%rbx,4)
	vmovups	-224(%rsi,%rbx,4), %ymm0
	vmovups	-192(%rsi,%rbx,4), %ymm1
	vmovups	-160(%rsi,%rbx,4), %ymm2
	vmovups	-128(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rbx,4)
	vmovups	%ymm1, -192(%rdx,%rbx,4)
	vmovups	%ymm2, -160(%rdx,%rbx,4)
	vmovups	%ymm3, -128(%rdx,%rbx,4)
	vmovups	-96(%rsi,%rbx,4), %ymm0
	vmovups	-64(%rsi,%rbx,4), %ymm1
	vmovups	-32(%rsi,%rbx,4), %ymm2
	vmovups	(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx,4)
	vmovups	%ymm1, -64(%rdx,%rbx,4)
	vmovups	%ymm2, -32(%rdx,%rbx,4)
	vmovups	%ymm3, (%rdx,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %r11
	jne	LBB13_52
LBB13_53:
	testq	%r9, %r9
	je	LBB13_56
## %bb.54:
	addq	%rax, %rbx
	leaq	(%rdi,%rbx,4), %rdx
	addq	$96, %rdx
	leaq	96(,%rbx,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	shlq	$7, %r9
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB13_55:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rbx), %ymm0
	vmovups	-64(%rsi,%rbx), %ymm1
	vmovups	-32(%rsi,%rbx), %ymm2
	vmovups	(%rsi,%rbx), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx)
	vmovups	%ymm1, -64(%rdx,%rbx)
	vmovups	%ymm2, -32(%rdx,%rbx)
	vmovups	%ymm3, (%rdx,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r9
	jne	LBB13_55
LBB13_56:
	cmpq	%r8, %r10
	je	LBB13_64
## %bb.57:
	addq	%r8, %rax
LBB13_58:
	leal	1(%rcx), %r8d
	movl	%r8d, %esi
	subl	%eax, %esi
	subl	%eax, %ecx
	andl	$7, %esi
	je	LBB13_61
## %bb.59:
	movq	_b@GOTPCREL(%rip), %rbx
	.p2align	4, 0x90
LBB13_60:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rbx,%rax,4), %edx
	movl	%edx, (%rdi,%rax,4)
	incq	%rax
	decl	%esi
	jne	LBB13_60
LBB13_61:
	cmpl	$7, %ecx
	jb	LBB13_64
## %bb.62:
	movl	%r8d, %ecx
	movq	_b@GOTPCREL(%rip), %rdx
	.p2align	4, 0x90
LBB13_63:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdx,%rax,4), %esi
	movl	%esi, (%rdi,%rax,4)
	movl	4(%rdx,%rax,4), %esi
	movl	%esi, 4(%rdi,%rax,4)
	movl	8(%rdx,%rax,4), %esi
	movl	%esi, 8(%rdi,%rax,4)
	movl	12(%rdx,%rax,4), %esi
	movl	%esi, 12(%rdi,%rax,4)
	movl	16(%rdx,%rax,4), %esi
	movl	%esi, 16(%rdi,%rax,4)
	movl	20(%rdx,%rax,4), %esi
	movl	%esi, 20(%rdi,%rax,4)
	movl	24(%rdx,%rax,4), %esi
	movl	%esi, 24(%rdi,%rax,4)
	movl	28(%rdx,%rax,4), %esi
	movl	%esi, 28(%rdi,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %ecx
	jne	LBB13_63
LBB13_64:
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_merge_standard            ## -- Begin function sort_merge_standard
	.p2align	4, 0x90
_sort_merge_standard:                   ## @sort_merge_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	%esi, %edx
	jle	LBB14_70
## %bb.1:
	movl	%edx, %r15d
	movl	%esi, %ebx
	movq	%rdi, %r12
	leal	(%r15,%rbx), %eax
	movl	%eax, %r13d
	shrl	$31, %r13d
	addl	%eax, %r13d
	sarl	%r13d
	movl	%r13d, %edx
	callq	_sort_merge_standard
	leal	1(%r13), %r14d
	movq	%r12, %rdi
	movl	%r14d, %esi
	movl	%r15d, %edx
	callq	_sort_merge_standard
	cmpl	%ebx, %r13d
	movq	%rbx, -48(%rbp)                 ## 8-byte Spill
	jl	LBB14_7
## %bb.2:
	cmpl	%r15d, %r13d
	movq	%r15, %r10
	jge	LBB14_6
## %bb.3:
	movslq	%ebx, %rdx
	shlq	$2, %rdx
	addq	_b@GOTPCREL(%rip), %rdx
	movl	%ebx, %r15d
	movl	%ebx, %ecx
	.p2align	4, 0x90
LBB14_4:                                ## =>This Inner Loop Header: Depth=1
	movslq	%ecx, %rcx
	movl	(%r12,%rcx,4), %esi
	movslq	%r14d, %r14
	movl	(%r12,%r14,4), %edi
	xorl	%eax, %eax
	xorl	%ebx, %ebx
	cmpl	%edi, %esi
	setg	%al
	setle	%bl
	cmovgl	%edi, %esi
	addl	%ebx, %ecx
	addl	%eax, %r14d
	movl	%esi, (%rdx)
	incl	%r15d
	cmpl	%r13d, %ecx
	jg	LBB14_9
## %bb.5:                               ##   in Loop: Header=BB14_4 Depth=1
	addq	$4, %rdx
	cmpl	%r10d, %r14d
	jle	LBB14_4
	jmp	LBB14_9
LBB14_6:
	movl	%ebx, %ecx
	jmp	LBB14_8
LBB14_7:
	movl	%ebx, %ecx
	movq	%r15, %r10
LBB14_8:
	movl	%ebx, %r15d
LBB14_9:
	movl	%r13d, %r11d
	subl	%ecx, %r11d
	jl	LBB14_30
## %bb.10:
	movslq	%r15d, %r15
	movslq	%ecx, %rcx
	cmpl	$31, %r11d
	jb	LBB14_23
## %bb.11:
	movq	_b@GOTPCREL(%rip), %rbx
	leaq	(%rbx,%r15,4), %rdx
	leaq	(%rcx,%r11), %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rdx
	jae	LBB14_13
## %bb.12:
	leaq	(%r15,%r11), %rdx
	leaq	(%rbx,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r12,%rcx,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB14_23
LBB14_13:
	movq	%r10, %rax
	incq	%r11
	movq	%r11, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rdi
	shrq	$5, %rdi
	incq	%rdi
	movl	%edi, %r10d
	andl	$3, %r10d
	cmpq	$96, %rdx
	jae	LBB14_15
## %bb.14:
	xorl	%esi, %esi
	jmp	LBB14_17
LBB14_15:
	leaq	(%r12,%rcx,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	(%rbx,%r15,4), %r8
	addq	$480, %r8                       ## imm = 0x1E0
	andq	$-4, %rdi
	negq	%rdi
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB14_16:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdx,%rsi,4), %ymm0
	vmovups	-448(%rdx,%rsi,4), %ymm1
	vmovups	-416(%rdx,%rsi,4), %ymm2
	vmovups	-384(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%r8,%rsi,4)
	vmovups	%ymm1, -448(%r8,%rsi,4)
	vmovups	%ymm2, -416(%r8,%rsi,4)
	vmovups	%ymm3, -384(%r8,%rsi,4)
	vmovups	-352(%rdx,%rsi,4), %ymm0
	vmovups	-320(%rdx,%rsi,4), %ymm1
	vmovups	-288(%rdx,%rsi,4), %ymm2
	vmovups	-256(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%r8,%rsi,4)
	vmovups	%ymm1, -320(%r8,%rsi,4)
	vmovups	%ymm2, -288(%r8,%rsi,4)
	vmovups	%ymm3, -256(%r8,%rsi,4)
	vmovups	-224(%rdx,%rsi,4), %ymm0
	vmovups	-192(%rdx,%rsi,4), %ymm1
	vmovups	-160(%rdx,%rsi,4), %ymm2
	vmovups	-128(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%r8,%rsi,4)
	vmovups	%ymm1, -192(%r8,%rsi,4)
	vmovups	%ymm2, -160(%r8,%rsi,4)
	vmovups	%ymm3, -128(%r8,%rsi,4)
	vmovups	-96(%rdx,%rsi,4), %ymm0
	vmovups	-64(%rdx,%rsi,4), %ymm1
	vmovups	-32(%rdx,%rsi,4), %ymm2
	vmovups	(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%r8,%rsi,4)
	vmovups	%ymm1, -64(%r8,%rsi,4)
	vmovups	%ymm2, -32(%r8,%rsi,4)
	vmovups	%ymm3, (%r8,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %rdi
	jne	LBB14_16
LBB14_17:
	testq	%r10, %r10
	je	LBB14_20
## %bb.18:
	leaq	(%rsi,%r15), %rdx
	leaq	(%rbx,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%rcx, %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r10
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB14_19:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r10
	jne	LBB14_19
LBB14_20:
	addq	%r9, %r15
	cmpq	%r9, %r11
	jne	LBB14_22
## %bb.21:
	movq	%rax, %r10
	jmp	LBB14_30
LBB14_22:
	addq	%r9, %rcx
	movq	%rax, %r10
LBB14_23:
	movl	%r13d, %r8d
	subl	%ecx, %r8d
	leal	1(%r8), %esi
	andl	$7, %esi
	je	LBB14_26
## %bb.24:
	movq	_b@GOTPCREL(%rip), %rdi
	.p2align	4, 0x90
LBB14_25:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r12,%rcx,4), %edx
	incq	%rcx
	movl	%edx, (%rdi,%r15,4)
	incq	%r15
	decl	%esi
	jne	LBB14_25
LBB14_26:
	cmpl	$7, %r8d
	jb	LBB14_30
## %bb.27:
	subl	%ecx, %r13d
	incl	%r13d
	leaq	(%r12,%rcx,4), %rcx
	addq	$28, %rcx
	movq	_b@GOTPCREL(%rip), %rdx
	leaq	(%rdx,%r15,4), %rsi
	addq	$28, %rsi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB14_28:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rcx,%rdx,4), %eax
	movl	%eax, -28(%rsi,%rdx,4)
	movl	-24(%rcx,%rdx,4), %eax
	movl	%eax, -24(%rsi,%rdx,4)
	movl	-20(%rcx,%rdx,4), %eax
	movl	%eax, -20(%rsi,%rdx,4)
	movl	-16(%rcx,%rdx,4), %eax
	movl	%eax, -16(%rsi,%rdx,4)
	movl	-12(%rcx,%rdx,4), %eax
	movl	%eax, -12(%rsi,%rdx,4)
	movl	-8(%rcx,%rdx,4), %eax
	movl	%eax, -8(%rsi,%rdx,4)
	movl	-4(%rcx,%rdx,4), %eax
	movl	%eax, -4(%rsi,%rdx,4)
	movl	(%rcx,%rdx,4), %eax
	movl	%eax, (%rsi,%rdx,4)
	addq	$8, %rdx
	cmpl	%edx, %r13d
	jne	LBB14_28
## %bb.29:
	addq	%rdx, %r15
LBB14_30:
	cmpl	%r10d, %r14d
	jg	LBB14_51
## %bb.31:
	movslq	%r15d, %rax
	movslq	%r14d, %rcx
	movq	%r10, %r15
                                        ## kill: def $r10d killed $r10d killed $r10 def $r10
	subl	%r14d, %r10d
	cmpl	$31, %r10d
	jb	LBB14_32
## %bb.33:
	movq	_b@GOTPCREL(%rip), %r8
	leaq	(%r8,%rax,4), %rdx
	leaq	(%rcx,%r10), %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rdx
	jae	LBB14_36
## %bb.34:
	leaq	(%rax,%r10), %rdx
	leaq	(%r8,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r12,%rcx,4), %rsi
	cmpq	%rdx, %rsi
	jae	LBB14_36
LBB14_32:
	movq	%r15, %r10
LBB14_45:
	movl	%r10d, %edx
	subl	%ecx, %edx
	leal	1(%rdx), %esi
	andl	$7, %esi
	je	LBB14_48
## %bb.46:
	movq	_b@GOTPCREL(%rip), %rdi
	.p2align	4, 0x90
LBB14_47:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r12,%rcx,4), %ebx
	incq	%rcx
	movl	%ebx, (%rdi,%rax,4)
	incq	%rax
	decl	%esi
	jne	LBB14_47
LBB14_48:
	cmpl	$7, %edx
	jb	LBB14_51
## %bb.49:
	movl	%r10d, %edx
	subl	%ecx, %edx
	incl	%edx
	leaq	(%r12,%rcx,4), %rcx
	addq	$28, %rcx
	movq	_b@GOTPCREL(%rip), %rsi
	leaq	(%rsi,%rax,4), %rax
	addq	$28, %rax
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB14_50:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rcx,%rsi,4), %edi
	movl	%edi, -28(%rax,%rsi,4)
	movl	-24(%rcx,%rsi,4), %edi
	movl	%edi, -24(%rax,%rsi,4)
	movl	-20(%rcx,%rsi,4), %edi
	movl	%edi, -20(%rax,%rsi,4)
	movl	-16(%rcx,%rsi,4), %edi
	movl	%edi, -16(%rax,%rsi,4)
	movl	-12(%rcx,%rsi,4), %edi
	movl	%edi, -12(%rax,%rsi,4)
	movl	-8(%rcx,%rsi,4), %edi
	movl	%edi, -8(%rax,%rsi,4)
	movl	-4(%rcx,%rsi,4), %edi
	movl	%edi, -4(%rax,%rsi,4)
	movl	(%rcx,%rsi,4), %edi
	movl	%edi, (%rax,%rsi,4)
	addq	$8, %rsi
	cmpl	%esi, %edx
	jne	LBB14_50
	jmp	LBB14_51
LBB14_36:
	incq	%r10
	movq	%r10, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rbx
	shrq	$5, %rbx
	incq	%rbx
	movl	%ebx, %r11d
	andl	$3, %r11d
	cmpq	$96, %rdx
	jae	LBB14_38
## %bb.37:
	xorl	%esi, %esi
	jmp	LBB14_40
LBB14_38:
	leaq	(%r12,%rcx,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	(%r8,%rax,4), %rdi
	addq	$480, %rdi                      ## imm = 0x1E0
	andq	$-4, %rbx
	negq	%rbx
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB14_39:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdx,%rsi,4), %ymm0
	vmovups	-448(%rdx,%rsi,4), %ymm1
	vmovups	-416(%rdx,%rsi,4), %ymm2
	vmovups	-384(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%rdi,%rsi,4)
	vmovups	%ymm1, -448(%rdi,%rsi,4)
	vmovups	%ymm2, -416(%rdi,%rsi,4)
	vmovups	%ymm3, -384(%rdi,%rsi,4)
	vmovups	-352(%rdx,%rsi,4), %ymm0
	vmovups	-320(%rdx,%rsi,4), %ymm1
	vmovups	-288(%rdx,%rsi,4), %ymm2
	vmovups	-256(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%rdi,%rsi,4)
	vmovups	%ymm1, -320(%rdi,%rsi,4)
	vmovups	%ymm2, -288(%rdi,%rsi,4)
	vmovups	%ymm3, -256(%rdi,%rsi,4)
	vmovups	-224(%rdx,%rsi,4), %ymm0
	vmovups	-192(%rdx,%rsi,4), %ymm1
	vmovups	-160(%rdx,%rsi,4), %ymm2
	vmovups	-128(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%rdi,%rsi,4)
	vmovups	%ymm1, -192(%rdi,%rsi,4)
	vmovups	%ymm2, -160(%rdi,%rsi,4)
	vmovups	%ymm3, -128(%rdi,%rsi,4)
	vmovups	-96(%rdx,%rsi,4), %ymm0
	vmovups	-64(%rdx,%rsi,4), %ymm1
	vmovups	-32(%rdx,%rsi,4), %ymm2
	vmovups	(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%rdi,%rsi,4)
	vmovups	%ymm1, -64(%rdi,%rsi,4)
	vmovups	%ymm2, -32(%rdi,%rsi,4)
	vmovups	%ymm3, (%rdi,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %rbx
	jne	LBB14_39
LBB14_40:
	testq	%r11, %r11
	je	LBB14_43
## %bb.41:
	leaq	(%rsi,%rax), %rdx
	leaq	(%r8,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%rcx, %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r11
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB14_42:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r11
	jne	LBB14_42
LBB14_43:
	cmpq	%r9, %r10
	movq	%r15, %r10
	jne	LBB14_44
LBB14_51:
	movl	%r10d, %ecx
	movq	-48(%rbp), %rax                 ## 8-byte Reload
	subl	%eax, %ecx
	jl	LBB14_70
## %bb.52:
	cltq
	cmpl	$31, %ecx
	jb	LBB14_64
## %bb.53:
	leaq	(%r12,%rax,4), %rdi
	leaq	(%rcx,%rax), %rdx
	movq	_b@GOTPCREL(%rip), %rsi
	leaq	(%rsi,%rdx,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rdi
	jae	LBB14_55
## %bb.54:
	leaq	(%r12,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%rsi,%rax,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB14_64
LBB14_55:
	incq	%rcx
	movq	%rcx, %r8
	andq	$-32, %r8
	leaq	-32(%r8), %rdx
	movq	%rdx, %rdi
	shrq	$5, %rdi
	incq	%rdi
	movl	%edi, %r9d
	andl	$3, %r9d
	cmpq	$96, %rdx
	jae	LBB14_57
## %bb.56:
	xorl	%ebx, %ebx
	jmp	LBB14_59
LBB14_44:
	addq	%r9, %rcx
	addq	%r9, %rax
	jmp	LBB14_45
LBB14_57:
	leaq	(%r12,%rax,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	480(,%rax,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	andq	$-4, %rdi
	negq	%rdi
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB14_58:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rsi,%rbx,4), %ymm0
	vmovups	-448(%rsi,%rbx,4), %ymm1
	vmovups	-416(%rsi,%rbx,4), %ymm2
	vmovups	-384(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rbx,4)
	vmovups	%ymm1, -448(%rdx,%rbx,4)
	vmovups	%ymm2, -416(%rdx,%rbx,4)
	vmovups	%ymm3, -384(%rdx,%rbx,4)
	vmovups	-352(%rsi,%rbx,4), %ymm0
	vmovups	-320(%rsi,%rbx,4), %ymm1
	vmovups	-288(%rsi,%rbx,4), %ymm2
	vmovups	-256(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rbx,4)
	vmovups	%ymm1, -320(%rdx,%rbx,4)
	vmovups	%ymm2, -288(%rdx,%rbx,4)
	vmovups	%ymm3, -256(%rdx,%rbx,4)
	vmovups	-224(%rsi,%rbx,4), %ymm0
	vmovups	-192(%rsi,%rbx,4), %ymm1
	vmovups	-160(%rsi,%rbx,4), %ymm2
	vmovups	-128(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rbx,4)
	vmovups	%ymm1, -192(%rdx,%rbx,4)
	vmovups	%ymm2, -160(%rdx,%rbx,4)
	vmovups	%ymm3, -128(%rdx,%rbx,4)
	vmovups	-96(%rsi,%rbx,4), %ymm0
	vmovups	-64(%rsi,%rbx,4), %ymm1
	vmovups	-32(%rsi,%rbx,4), %ymm2
	vmovups	(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx,4)
	vmovups	%ymm1, -64(%rdx,%rbx,4)
	vmovups	%ymm2, -32(%rdx,%rbx,4)
	vmovups	%ymm3, (%rdx,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %rdi
	jne	LBB14_58
LBB14_59:
	testq	%r9, %r9
	je	LBB14_62
## %bb.60:
	addq	%rax, %rbx
	leaq	(%r12,%rbx,4), %rdx
	addq	$96, %rdx
	leaq	96(,%rbx,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	shlq	$7, %r9
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB14_61:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r9
	jne	LBB14_61
LBB14_62:
	cmpq	%r8, %rcx
	je	LBB14_70
## %bb.63:
	addq	%r8, %rax
LBB14_64:
	leal	1(%r10), %ecx
	movl	%ecx, %edx
	subl	%eax, %edx
	subl	%eax, %r10d
	andl	$7, %edx
	je	LBB14_67
## %bb.65:
	movq	_b@GOTPCREL(%rip), %rsi
	.p2align	4, 0x90
LBB14_66:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rsi,%rax,4), %edi
	movl	%edi, (%r12,%rax,4)
	incq	%rax
	decl	%edx
	jne	LBB14_66
LBB14_67:
	cmpl	$7, %r10d
	jb	LBB14_70
## %bb.68:
	movl	%ecx, %ecx
	movq	_b@GOTPCREL(%rip), %rdx
	.p2align	4, 0x90
LBB14_69:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdx,%rax,4), %esi
	movl	%esi, (%r12,%rax,4)
	movl	4(%rdx,%rax,4), %esi
	movl	%esi, 4(%r12,%rax,4)
	movl	8(%rdx,%rax,4), %esi
	movl	%esi, 8(%r12,%rax,4)
	movl	12(%rdx,%rax,4), %esi
	movl	%esi, 12(%r12,%rax,4)
	movl	16(%rdx,%rax,4), %esi
	movl	%esi, 16(%r12,%rax,4)
	movl	20(%rdx,%rax,4), %esi
	movl	%esi, 20(%r12,%rax,4)
	movl	24(%rdx,%rax,4), %esi
	movl	%esi, 24(%r12,%rax,4)
	movl	28(%rdx,%rax,4), %esi
	movl	%esi, 28(%r12,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %ecx
	jne	LBB14_69
LBB14_70:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_optimized      ## -- Begin function partition_quick_optimized
	.p2align	4, 0x90
_partition_quick_optimized:             ## @partition_quick_optimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB15_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %r9d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r15d
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r11d
	cmpl	%r15d, %r9d
	movl	%r15d, %ebx
	cmovll	%r9d, %ebx
	movl	%r15d, %r14d
	cmovgl	%r9d, %r14d
	cmpl	%r11d, %ebx
	cmovgel	%r11d, %ebx
	cmpl	%r11d, %r14d
	cmovlel	%r11d, %r14d
	addl	%r9d, %r15d
	addl	%r11d, %r15d
	subl	%ebx, %r15d
	subl	%r14d, %r15d
	movl	%ebx, (%rdi,%rax,4)
	movl	%r15d, (%rdi,%r8,4)
	movl	%r14d, (%rdi,%r10,4)
	cmpl	%esi, %edx
	jg	LBB15_4
	jmp	LBB15_10
LBB15_2:
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r15d
	movslq	%esi, %rax
	cmpl	%esi, %edx
	jle	LBB15_10
LBB15_4:
	movl	%r8d, %edx
	subl	%eax, %edx
	leaq	1(%rax), %r9
	testb	$1, %dl
	jne	LBB15_6
## %bb.5:
	movq	%rax, %rdx
	cmpq	%r9, %r8
	jne	LBB15_8
	jmp	LBB15_10
LBB15_6:
	movl	(%rdi,%rax,4), %edx
	xorl	%ebx, %ebx
	xorl	%esi, %esi
	cmpl	%edx, %r15d
	setg	%bl
	setle	%sil
	movq	_x@GOTPCREL(%rip), %r10
	movl	%edx, (%r10)
	movl	(%rdi,%rax,4), %edx
	movl	%edx, 4(%r10)
	movl	(%r10,%rsi,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	(%r10,%rbx,4), %edx
	movl	%edx, (%rdi,%rax,4)
	addq	%rbx, %rax
	movq	%r9, %rdx
	cmpq	%r9, %r8
	je	LBB15_10
LBB15_8:
	movq	_x@GOTPCREL(%rip), %r9
	.p2align	4, 0x90
LBB15_9:                                ## =>This Inner Loop Header: Depth=1
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	cmpl	(%rdi,%rdx,4), %r15d
	setg	%bl
	setle	%cl
	movl	(%rdi,%rax,4), %esi
	movl	%esi, (%r9)
	movl	(%rdi,%rdx,4), %esi
	movl	%esi, 4(%r9)
	movl	(%r9,%rcx,4), %ecx
	movl	%ecx, (%rdi,%rdx,4)
	movl	(%r9,%rbx,4), %ecx
	movl	%ecx, (%rdi,%rax,4)
	addq	%rbx, %rax
	xorl	%ecx, %ecx
	xorl	%esi, %esi
	cmpl	4(%rdi,%rdx,4), %r15d
	setg	%cl
	setle	%sil
	movl	(%rdi,%rax,4), %ebx
	movl	%ebx, (%r9)
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ebx, 4(%r9)
	movl	(%r9,%rsi,4), %esi
	movl	%esi, 4(%rdi,%rdx,4)
	movl	(%r9,%rcx,4), %esi
	movl	%esi, (%rdi,%rax,4)
	addq	%rcx, %rax
	addq	$2, %rdx
	cmpq	%rdx, %r8
	jne	LBB15_9
LBB15_10:
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r8,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r8,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_optimized           ## -- Begin function sort_quick_optimized
	.p2align	4, 0x90
_sort_quick_optimized:                  ## @sort_quick_optimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB16_11
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %rbx
	movslq	%edx, %r15
	movq	%r15, %rax
	negq	%rax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	movq	_x@GOTPCREL(%rip), %r13
	jmp	LBB16_2
	.p2align	4, 0x90
LBB16_10:                               ##   in Loop: Header=BB16_2 Depth=1
	movl	(%rbx,%r12,4), %eax
	movl	(%rbx,%r15,4), %ecx
	movl	%ecx, (%rbx,%r12,4)
	movl	%eax, (%rbx,%r15,4)
	leal	-1(%r12), %edx
	movq	%rbx, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	callq	_sort_quick_optimized
	incl	%r12d
	movl	%r12d, %esi
	cmpl	%r14d, %r12d
	jge	LBB16_11
LBB16_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB16_9 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB16_11
## %bb.3:                               ##   in Loop: Header=BB16_2 Depth=1
	cmpl	$1, %eax
	jne	LBB16_4
## %bb.5:                               ##   in Loop: Header=BB16_2 Depth=1
	movl	(%rbx,%r15,4), %r11d
	movslq	%esi, %rcx
	jmp	LBB16_6
	.p2align	4, 0x90
LBB16_4:                                ##   in Loop: Header=BB16_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %edx
	shrl	$31, %edx
	addl	%eax, %edx
	sarl	%edx
	movslq	%esi, %rcx
	movl	(%rbx,%rcx,4), %r9d
	movslq	%edx, %r8
	movl	(%rbx,%r8,4), %r11d
	movl	(%rbx,%r15,4), %r10d
	cmpl	%r11d, %r9d
	movl	%r11d, %edi
	cmovll	%r9d, %edi
	movl	%r11d, %edx
	cmovgl	%r9d, %edx
	cmpl	%r10d, %edi
	cmovgel	%r10d, %edi
	cmpl	%r10d, %edx
	cmovlel	%r10d, %edx
	addl	%r9d, %r11d
	addl	%r10d, %r11d
	subl	%edi, %r11d
	subl	%edx, %r11d
	movl	%edi, (%rbx,%rcx,4)
	movl	%r11d, (%rbx,%r15,4)
	movl	%edx, (%rbx,%r8,4)
LBB16_6:                                ##   in Loop: Header=BB16_2 Depth=1
	movl	%r14d, %edi
	subl	%ecx, %edi
	movq	%rcx, %r12
	movq	%rcx, %rdx
	testb	$1, %dil
	je	LBB16_8
## %bb.7:                               ##   in Loop: Header=BB16_2 Depth=1
	movl	(%rbx,%rcx,4), %edx
	xorl	%r12d, %r12d
	xorl	%edi, %edi
	cmpl	%edx, %r11d
	setg	%r12b
	setle	%dil
	movl	%edx, (%r13)
	movl	(%rbx,%rcx,4), %edx
	movl	%edx, 4(%r13)
	movl	(%r13,%rdi,4), %edx
	movl	%edx, (%rbx,%rcx,4)
	movl	(%r13,%r12,4), %edx
	movl	%edx, (%rbx,%rcx,4)
	addq	%rcx, %r12
	leaq	1(%rcx), %rdx
LBB16_8:                                ##   in Loop: Header=BB16_2 Depth=1
	notq	%rcx
	cmpq	-48(%rbp), %rcx                 ## 8-byte Folded Reload
	je	LBB16_10
	.p2align	4, 0x90
LBB16_9:                                ##   Parent Loop BB16_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	xorl	%ecx, %ecx
	xorl	%edi, %edi
	cmpl	(%rbx,%rdx,4), %r11d
	setg	%cl
	setle	%dil
	movl	(%rbx,%r12,4), %eax
	movl	%eax, (%r13)
	movl	(%rbx,%rdx,4), %eax
	movl	%eax, 4(%r13)
	movl	(%r13,%rdi,4), %eax
	movl	%eax, (%rbx,%rdx,4)
	movl	(%r13,%rcx,4), %eax
	movl	%eax, (%rbx,%r12,4)
	addq	%rcx, %r12
	xorl	%eax, %eax
	xorl	%ecx, %ecx
	cmpl	4(%rbx,%rdx,4), %r11d
	setg	%al
	setle	%cl
	movl	(%rbx,%r12,4), %edi
	movl	%edi, (%r13)
	movl	4(%rbx,%rdx,4), %edi
	movl	%edi, 4(%r13)
	movl	(%r13,%rcx,4), %ecx
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	(%r13,%rax,4), %ecx
	movl	%ecx, (%rbx,%r12,4)
	addq	%rax, %r12
	addq	$2, %rdx
	cmpq	%rdx, %r15
	jne	LBB16_9
	jmp	LBB16_10
LBB16_11:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_hsum_epi32_avx                 ## -- Begin function hsum_epi32_avx
	.p2align	4, 0x90
_hsum_epi32_avx:                        ## @hsum_epi32_avx
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	vpshufd	$238, %xmm0, %xmm1              ## xmm1 = xmm0[2,3,2,3]
	vpaddd	%xmm0, %xmm1, %xmm0
	vpshufd	$85, %xmm0, %xmm1               ## xmm1 = xmm0[1,1,1,1]
	vpaddd	%xmm0, %xmm1, %xmm0
	vmovd	%xmm0, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_hsum_8x32                      ## -- Begin function hsum_8x32
	.p2align	4, 0x90
_hsum_8x32:                             ## @hsum_8x32
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	vextracti128	$1, %ymm0, %xmm1
	vpaddd	%xmm0, %xmm1, %xmm0
	vpshufd	$238, %xmm0, %xmm1              ## xmm1 = xmm0[2,3,2,3]
	vpaddd	%xmm1, %xmm0, %xmm0
	vpshufd	$85, %xmm0, %xmm1               ## xmm1 = xmm0[1,1,1,1]
	vpaddd	%xmm0, %xmm1, %xmm0
	vmovd	%xmm0, %eax
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_multi          ## -- Begin function partition_quick_multi
	.p2align	4, 0x90
_partition_quick_multi:                 ## @partition_quick_multi
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -32
	.cfi_offset %r14, -24
	cmpq	%rdx, %rsi
	jle	LBB19_1
LBB19_17:
	popq	%rbx
	popq	%r14
	popq	%rbp
	vzeroupper
	retq
LBB19_1:
	vmovdqu	(%rdi,%rsi,4), %ymm0
	vmovd	%xmm0, %eax
	.p2align	4, 0x90
LBB19_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB19_10 Depth 2
	vmovd	%eax, %xmm1
	vpbroadcastd	%xmm1, %ymm1
	vpcmpgtd	%ymm1, %ymm0, %ymm1
	vextracti128	$1, %ymm1, %xmm2
	vpaddd	%xmm1, %xmm2, %xmm1
	vpshufd	$238, %xmm1, %xmm2              ## xmm2 = xmm1[2,3,2,3]
	vpaddd	%xmm2, %xmm1, %xmm1
	vpshufd	$85, %xmm1, %xmm2               ## xmm2 = xmm1[1,1,1,1]
	vpaddd	%xmm1, %xmm2, %xmm1
	vmovd	%xmm1, %r9d
	leal	8(%r9), %r14d
	cmpl	$8, %r14d
	ja	LBB19_15
## %bb.3:                               ##   in Loop: Header=BB19_2 Depth=1
	movq	-8(%rcx,%r14,8), %r10
	movl	$1, %eax
	subl	%r14d, %eax
	testb	$1, %al
	jne	LBB19_5
## %bb.4:                               ##   in Loop: Header=BB19_2 Depth=1
	movq	%r10, %r8
	testl	%r9d, %r9d
	jne	LBB19_9
	jmp	LBB19_15
	.p2align	4, 0x90
LBB19_5:                                ##   in Loop: Header=BB19_2 Depth=1
	movq	(%rcx,%r14,8), %r11
	leaq	1(%r11), %r8
	cmpq	%r8, %r10
	je	LBB19_7
## %bb.6:                               ##   in Loop: Header=BB19_2 Depth=1
	movl	(%rdi,%rsi,4), %r10d
	movl	(%rdi,%r11,4), %eax
	movl	%eax, (%rdi,%rsi,4)
	movl	%r10d, (%rdi,%r11,4)
LBB19_7:                                ##   in Loop: Header=BB19_2 Depth=1
	movq	%r8, (%rcx,%r14,8)
	incq	%r14
	testl	%r9d, %r9d
	je	LBB19_15
LBB19_9:                                ##   in Loop: Header=BB19_2 Depth=1
	incq	%r14
	jmp	LBB19_10
	.p2align	4, 0x90
LBB19_14:                               ##   in Loop: Header=BB19_10 Depth=2
	movq	%r8, (%rcx,%r14,8)
	addq	$2, %r14
	cmpq	$10, %r14
	je	LBB19_15
LBB19_10:                               ##   Parent Loop BB19_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	-8(%rcx,%r14,8), %r9
	leaq	1(%r9), %r10
	cmpq	%r10, %r8
	je	LBB19_12
## %bb.11:                              ##   in Loop: Header=BB19_10 Depth=2
	movl	(%rdi,%rsi,4), %r8d
	movl	(%rdi,%r9,4), %eax
	movl	%eax, (%rdi,%rsi,4)
	movl	%r8d, (%rdi,%r9,4)
LBB19_12:                               ##   in Loop: Header=BB19_10 Depth=2
	movq	%r10, -8(%rcx,%r14,8)
	movq	(%rcx,%r14,8), %rax
	leaq	1(%rax), %r8
	cmpq	%rax, %r9
	je	LBB19_14
## %bb.13:                              ##   in Loop: Header=BB19_10 Depth=2
	movl	(%rdi,%rsi,4), %r9d
	movl	(%rdi,%rax,4), %ebx
	movl	%ebx, (%rdi,%rsi,4)
	movl	%r9d, (%rdi,%rax,4)
	jmp	LBB19_14
	.p2align	4, 0x90
LBB19_15:                               ##   in Loop: Header=BB19_2 Depth=1
	cmpq	%rdx, %rsi
	je	LBB19_17
## %bb.16:                              ##   in Loop: Header=BB19_2 Depth=1
	movl	4(%rdi,%rsi,4), %eax
	incq	%rsi
	jmp	LBB19_2
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_multi_h             ## -- Begin function sort_quick_multi_h
	.p2align	4, 0x90
_sort_quick_multi_h:                    ## @sort_quick_multi_h
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	subq	$80, %rsp
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	movq	%rax, -40(%rbp)
	movq	%rdx, %rax
	subq	%rsi, %rax
	jle	LBB20_21
## %bb.1:
	movq	%rdi, %r12
	cmpq	$201, %rax
	jl	LBB20_18
## %bb.2:
	vmovq	%rsi, %xmm0
	vpbroadcastq	%xmm0, %ymm0
	vmovdqu	%ymm0, -112(%rbp)
	vmovdqu	%ymm0, -80(%rbp)
	movq	%rsi, -48(%rbp)
	vmovdqu	(%r12,%rsi,4), %ymm0
	vmovdqu	(%r12,%rsi,4), %xmm1
	vmovd	%xmm1, %ecx
	movq	%rsi, %r9
	.p2align	4, 0x90
LBB20_3:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB20_11 Depth 2
	vmovd	%ecx, %xmm1
	vpbroadcastd	%xmm1, %ymm1
	vpcmpgtd	%ymm1, %ymm0, %ymm1
	vextracti128	$1, %ymm1, %xmm2
	vpaddd	%xmm1, %xmm2, %xmm1
	vpshufd	$238, %xmm1, %xmm2              ## xmm2 = xmm1[2,3,2,3]
	vpaddd	%xmm2, %xmm1, %xmm1
	vpshufd	$85, %xmm1, %xmm2               ## xmm2 = xmm1[1,1,1,1]
	vpaddd	%xmm1, %xmm2, %xmm1
	vmovd	%xmm1, %r8d
	leal	8(%r8), %ecx
	cmpl	$8, %ecx
	ja	LBB20_16
## %bb.4:                               ##   in Loop: Header=BB20_3 Depth=1
	movq	-120(%rbp,%rcx,8), %rbx
	movl	$1, %eax
	subl	%ecx, %eax
	testb	$1, %al
	jne	LBB20_6
## %bb.5:                               ##   in Loop: Header=BB20_3 Depth=1
	movq	%rbx, %rdi
	testl	%r8d, %r8d
	jne	LBB20_10
	jmp	LBB20_16
	.p2align	4, 0x90
LBB20_6:                                ##   in Loop: Header=BB20_3 Depth=1
	movq	-112(%rbp,%rcx,8), %rax
	leaq	1(%rax), %rdi
	cmpq	%rdi, %rbx
	je	LBB20_8
## %bb.7:                               ##   in Loop: Header=BB20_3 Depth=1
	movl	(%r12,%r9,4), %r10d
	movl	(%r12,%rax,4), %ebx
	movl	%ebx, (%r12,%r9,4)
	movl	%r10d, (%r12,%rax,4)
LBB20_8:                                ##   in Loop: Header=BB20_3 Depth=1
	movq	%rdi, -112(%rbp,%rcx,8)
	incq	%rcx
	testl	%r8d, %r8d
	je	LBB20_16
LBB20_10:                               ##   in Loop: Header=BB20_3 Depth=1
	incq	%rcx
	jmp	LBB20_11
	.p2align	4, 0x90
LBB20_15:                               ##   in Loop: Header=BB20_11 Depth=2
	movq	%rdi, -112(%rbp,%rcx,8)
	addq	$2, %rcx
	cmpq	$10, %rcx
	je	LBB20_16
LBB20_11:                               ##   Parent Loop BB20_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	-120(%rbp,%rcx,8), %rbx
	leaq	1(%rbx), %rax
	cmpq	%rax, %rdi
	je	LBB20_13
## %bb.12:                              ##   in Loop: Header=BB20_11 Depth=2
	movl	(%r12,%r9,4), %r8d
	movl	(%r12,%rbx,4), %edi
	movl	%edi, (%r12,%r9,4)
	movl	%r8d, (%r12,%rbx,4)
LBB20_13:                               ##   in Loop: Header=BB20_11 Depth=2
	movq	%rax, -120(%rbp,%rcx,8)
	movq	-112(%rbp,%rcx,8), %rax
	leaq	1(%rax), %rdi
	cmpq	%rax, %rbx
	je	LBB20_15
## %bb.14:                              ##   in Loop: Header=BB20_11 Depth=2
	movl	(%r12,%r9,4), %r8d
	movl	(%r12,%rax,4), %ebx
	movl	%ebx, (%r12,%r9,4)
	movl	%r8d, (%r12,%rax,4)
	jmp	LBB20_15
	.p2align	4, 0x90
LBB20_16:                               ##   in Loop: Header=BB20_3 Depth=1
	cmpq	%rdx, %r9
	je	LBB20_20
## %bb.17:                              ##   in Loop: Header=BB20_3 Depth=1
	movl	4(%r12,%r9,4), %ecx
	incq	%r9
	jmp	LBB20_3
LBB20_18:
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-40(%rbp), %rax
	jne	LBB20_23
## %bb.19:
	movq	%r12, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
                                        ## kill: def $edx killed $edx killed $rdx
	addq	$80, %rsp
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	jmp	_sort_quick_optimized           ## TAILCALL
LBB20_20:
	movq	-112(%rbp), %r14
	leaq	-1(%r14), %rdx
	movq	%r12, %rdi
	vzeroupper
	callq	_sort_quick_multi_h
	movq	-104(%rbp), %r15
	leaq	-1(%r15), %rdx
	movq	%r12, %rdi
	movq	%r14, %rsi
	callq	_sort_quick_multi_h
	movq	-96(%rbp), %r14
	leaq	-1(%r14), %rdx
	movq	%r12, %rdi
	movq	%r15, %rsi
	callq	_sort_quick_multi_h
	movq	-88(%rbp), %r15
	leaq	-1(%r15), %rdx
	movq	%r12, %rdi
	movq	%r14, %rsi
	callq	_sort_quick_multi_h
	movq	-80(%rbp), %r14
	leaq	-1(%r14), %rdx
	movq	%r12, %rdi
	movq	%r15, %rsi
	callq	_sort_quick_multi_h
	movq	-72(%rbp), %r15
	leaq	-1(%r15), %rdx
	movq	%r12, %rdi
	movq	%r14, %rsi
	callq	_sort_quick_multi_h
	movq	-64(%rbp), %r14
	leaq	-1(%r14), %rdx
	movq	%r12, %rdi
	movq	%r15, %rsi
	callq	_sort_quick_multi_h
	movq	-56(%rbp), %r15
	leaq	-1(%r15), %rdx
	movq	%r12, %rdi
	movq	%r14, %rsi
	callq	_sort_quick_multi_h
	movq	-48(%rbp), %rdx
	decq	%rdx
	movq	%r12, %rdi
	movq	%r15, %rsi
	callq	_sort_quick_multi_h
LBB20_21:
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-40(%rbp), %rax
	jne	LBB20_23
## %bb.22:
	addq	$80, %rsp
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB20_23:
	callq	___stack_chk_fail
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_multi               ## -- Begin function sort_quick_multi
	.p2align	4, 0x90
_sort_quick_multi:                      ## @sort_quick_multi
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movslq	%esi, %rsi
	incl	%edx
	movslq	%edx, %rdx
	popq	%rbp
	jmp	_sort_quick_multi_h             ## TAILCALL
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_simd           ## -- Begin function partition_quick_simd
	.p2align	4, 0x90
_partition_quick_simd:                  ## @partition_quick_simd
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -32
	.cfi_offset %r14, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movslq	%edx, %r8
	subl	%esi, %edx
	cmpl	$2, %edx
	jl	LBB22_2
## %bb.1:
	leal	(%r8,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %r9d
	movslq	%ecx, %r11
	movl	(%rdi,%r11,4), %r10d
	movl	(%rdi,%r8,4), %r14d
	cmpl	%r10d, %r9d
	movl	%r10d, %ebx
	cmovll	%r9d, %ebx
	movl	%r10d, %ecx
	cmovgl	%r9d, %ecx
	cmpl	%r14d, %ebx
	cmovgel	%r14d, %ebx
	cmpl	%r14d, %ecx
	cmovlel	%r14d, %ecx
	addl	%r9d, %r10d
	addl	%r14d, %r10d
	subl	%ebx, %r10d
	subl	%ecx, %r10d
	movl	%ebx, (%rdi,%rax,4)
	movl	%r10d, (%rdi,%r8,4)
	movl	%ecx, (%rdi,%r11,4)
	jmp	LBB22_3
LBB22_2:
	movl	(%rdi,%r8,4), %r10d
	movslq	%esi, %rax
LBB22_3:
	leal	7(%rdx), %ecx
	testl	%edx, %edx
	cmovnsl	%edx, %ecx
	andl	$-8, %ecx
	cmpl	%esi, %ecx
	jle	LBB22_4
## %bb.11:
	vmovd	%r10d, %xmm0
	vpbroadcastd	%xmm0, %ymm0
	movslq	%ecx, %r9
	movq	%rax, %rdx
	.p2align	4, 0x90
LBB22_12:                               ## =>This Inner Loop Header: Depth=1
	vpcmpgtd	(%rdi,%rdx,4), %ymm0, %ymm1
	vpsrld	$31, %ymm1, %ymm1
	vmovdqu	(%rdi,%rdx,4), %xmm2
	vmovdqu	%ymm1, -48(%rbp)
	vmovd	%xmm1, %ecx
	movl	(%rdi,%rax,4), %ebx
	vmovd	%xmm2, %r11d
	testl	%ecx, %ecx
	movl	%r11d, %esi
	cmovel	%ebx, %esi
	movl	%esi, (%rdi,%rax,4)
	cmovel	%r11d, %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	%rax, %rcx
	vpextrd	$1, %xmm1, %eax
	movl	(%rdi,%rcx,4), %esi
	movl	4(%rdi,%rdx,4), %r11d
	testl	%eax, %eax
	movl	%r11d, %ebx
	cmovel	%esi, %ebx
	movl	%ebx, (%rdi,%rcx,4)
	cmovel	%r11d, %esi
	movl	%esi, 4(%rdi,%rdx,4)
	vpextrd	$2, %xmm1, %esi
	addq	%rcx, %rax
	movl	(%rdi,%rax,4), %ecx
	movl	8(%rdi,%rdx,4), %r11d
	testl	%esi, %esi
	movl	%r11d, %ebx
	cmovel	%ecx, %ebx
	movl	%ebx, (%rdi,%rax,4)
	cmovel	%r11d, %ecx
	movl	%ecx, 8(%rdi,%rdx,4)
	addq	%rax, %rsi
	vpextrd	$3, %xmm1, %eax
	movl	(%rdi,%rsi,4), %ecx
	movl	12(%rdi,%rdx,4), %r11d
	testl	%eax, %eax
	movl	%r11d, %ebx
	cmovel	%ecx, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovel	%r11d, %ecx
	movl	%ecx, 12(%rdi,%rdx,4)
	addq	%rsi, %rax
	vextracti128	$1, %ymm1, %xmm1
	vmovd	%xmm1, %ecx
	movl	(%rdi,%rax,4), %esi
	movl	16(%rdi,%rdx,4), %r11d
	testl	%ecx, %ecx
	movl	%r11d, %ebx
	cmovel	%esi, %ebx
	movl	%ebx, (%rdi,%rax,4)
	cmovel	%r11d, %esi
	movl	%esi, 16(%rdi,%rdx,4)
	vpextrd	$1, %xmm1, %esi
	addq	%rax, %rcx
	movl	(%rdi,%rcx,4), %eax
	movl	20(%rdi,%rdx,4), %r11d
	testl	%esi, %esi
	movl	%r11d, %ebx
	cmovel	%eax, %ebx
	movl	%ebx, (%rdi,%rcx,4)
	cmovel	%r11d, %eax
	movl	%eax, 20(%rdi,%rdx,4)
	addq	%rcx, %rsi
	vpextrd	$2, %xmm1, %eax
	movl	(%rdi,%rsi,4), %ecx
	movl	24(%rdi,%rdx,4), %r11d
	testl	%eax, %eax
	movl	%r11d, %ebx
	cmovel	%ecx, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovel	%r11d, %ecx
	movl	%ecx, 24(%rdi,%rdx,4)
	addq	%rsi, %rax
	movslq	-20(%rbp), %r11
	testq	%r11, %r11
	movl	(%rdi,%rax,4), %esi
	movl	28(%rdi,%rdx,4), %ecx
	movl	%ecx, %ebx
	cmovel	%esi, %ebx
	movl	%ebx, (%rdi,%rax,4)
	cmovel	%ecx, %esi
	movl	%esi, 28(%rdi,%rdx,4)
	addq	%r11, %rax
	addq	$8, %rdx
	cmpq	%r9, %rdx
	jl	LBB22_12
## %bb.5:
	cmpq	%r8, %rdx
	jl	LBB22_6
	jmp	LBB22_10
LBB22_4:
	movq	%rax, %rdx
	cmpq	%r8, %rdx
	jge	LBB22_10
LBB22_6:
	movl	%r8d, %r11d
	subl	%edx, %r11d
	movq	%rdx, %r9
	notq	%r9
	addq	%r8, %r9
	andq	$3, %r11
	je	LBB22_8
	.p2align	4, 0x90
LBB22_7:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %ecx
	xorl	%ebx, %ebx
	cmpl	%ecx, %r10d
	setg	%bl
	movl	(%rdi,%rax,4), %r14d
	movl	%r14d, %esi
	cmovgl	%ecx, %esi
	movl	%esi, (%rdi,%rax,4)
	cmovgl	%r14d, %ecx
	movl	%ecx, (%rdi,%rdx,4)
	addq	%rbx, %rax
	incq	%rdx
	decq	%r11
	jne	LBB22_7
LBB22_8:
	cmpq	$3, %r9
	jb	LBB22_10
	.p2align	4, 0x90
LBB22_9:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %ecx
	xorl	%esi, %esi
	cmpl	%ecx, %r10d
	setg	%sil
	movl	(%rdi,%rax,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%ecx, %ebx
	movl	%ebx, (%rdi,%rax,4)
	cmovgl	%r9d, %ecx
	movl	%ecx, (%rdi,%rdx,4)
	addq	%rax, %rsi
	movl	4(%rdi,%rdx,4), %eax
	xorl	%ecx, %ecx
	cmpl	%eax, %r10d
	setg	%cl
	movl	(%rdi,%rsi,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%r9d, %eax
	movl	%eax, 4(%rdi,%rdx,4)
	addq	%rsi, %rcx
	movl	8(%rdi,%rdx,4), %eax
	xorl	%esi, %esi
	cmpl	%eax, %r10d
	setg	%sil
	movl	(%rdi,%rcx,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%rdi,%rcx,4)
	cmovgl	%r9d, %eax
	movl	%eax, 8(%rdi,%rdx,4)
	addq	%rcx, %rsi
	movl	12(%rdi,%rdx,4), %ecx
	xorl	%eax, %eax
	cmpl	%ecx, %r10d
	setg	%al
	movl	(%rdi,%rsi,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%ecx, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%r9d, %ecx
	movl	%ecx, 12(%rdi,%rdx,4)
	addq	%rsi, %rax
	addq	$4, %rdx
	cmpq	%rdx, %r8
	jne	LBB22_9
LBB22_10:
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r8,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r8,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_simd                ## -- Begin function sort_quick_simd
	.p2align	4, 0x90
_sort_quick_simd:                       ## @sort_quick_simd
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	%edx, %esi
	jge	LBB23_3
## %bb.1:
	movl	%edx, %r14d
	movl	%esi, %r12d
	movq	%rdi, %r15
	.p2align	4, 0x90
LBB23_2:                                ## =>This Inner Loop Header: Depth=1
	movq	%r15, %rdi
	movl	%r12d, %esi
	movl	%r14d, %edx
	callq	_partition_quick_simd
	movl	%eax, %ebx
	leal	-1(%rbx), %edx
	movq	%r15, %rdi
	movl	%r12d, %esi
	callq	_sort_quick_simd
	incl	%ebx
	movl	%ebx, %r12d
	cmpl	%r14d, %ebx
	jl	LBB23_2
LBB23_3:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_optimized_swap_arith ## -- Begin function partition_quick_optimized_swap_arith
	.p2align	4, 0x90
_partition_quick_optimized_swap_arith:  ## @partition_quick_optimized_swap_arith
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB24_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %r9d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r15d
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r11d
	cmpl	%r15d, %r9d
	movl	%r15d, %ebx
	cmovll	%r9d, %ebx
	movl	%r15d, %r14d
	cmovgl	%r9d, %r14d
	cmpl	%r11d, %ebx
	cmovgel	%r11d, %ebx
	cmpl	%r11d, %r14d
	cmovlel	%r11d, %r14d
	addl	%r9d, %r15d
	addl	%r11d, %r15d
	subl	%ebx, %r15d
	subl	%r14d, %r15d
	movl	%ebx, (%rdi,%rax,4)
	movl	%r15d, (%rdi,%r8,4)
	movl	%r14d, (%rdi,%r10,4)
	cmpl	%esi, %edx
	jg	LBB24_4
	jmp	LBB24_8
LBB24_2:
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r15d
	movslq	%esi, %rax
	cmpl	%esi, %edx
	jle	LBB24_8
LBB24_4:
	movl	%r8d, %r10d
	subl	%eax, %r10d
	movq	%rax, %r9
	notq	%r9
	addq	%r8, %r9
	movq	%rax, %rdx
	andq	$3, %r10
	je	LBB24_6
	.p2align	4, 0x90
LBB24_5:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %ecx
	xorl	%r11d, %r11d
	cmpl	%ecx, %r15d
	setg	%r11b
	movl	(%rdi,%rax,4), %esi
	movl	%ecx, %ebx
	cmovgl	%esi, %ebx
	cmovgl	%ecx, %esi
	movl	%ebx, (%rdi,%rdx,4)
	movl	%esi, (%rdi,%rax,4)
	addq	%r11, %rax
	incq	%rdx
	decq	%r10
	jne	LBB24_5
LBB24_6:
	cmpq	$3, %r9
	jb	LBB24_8
	.p2align	4, 0x90
LBB24_7:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %r9d
	xorl	%esi, %esi
	cmpl	%r9d, %r15d
	setg	%sil
	movl	(%rdi,%rax,4), %ebx
	movl	%r9d, %ecx
	cmovgl	%ebx, %ecx
	cmovgl	%r9d, %ebx
	movl	%ecx, (%rdi,%rdx,4)
	movl	%ebx, (%rdi,%rax,4)
	addq	%rax, %rsi
	movl	4(%rdi,%rdx,4), %r9d
	xorl	%ecx, %ecx
	cmpl	%r9d, %r15d
	setg	%cl
	movl	(%rdi,%rsi,4), %ebx
	movl	%r9d, %eax
	cmovgl	%ebx, %eax
	cmovgl	%r9d, %ebx
	movl	%eax, 4(%rdi,%rdx,4)
	movl	%ebx, (%rdi,%rsi,4)
	addq	%rsi, %rcx
	movl	8(%rdi,%rdx,4), %r9d
	xorl	%esi, %esi
	cmpl	%r9d, %r15d
	setg	%sil
	movl	(%rdi,%rcx,4), %ebx
	movl	%r9d, %eax
	cmovgl	%ebx, %eax
	cmovgl	%r9d, %ebx
	movl	%eax, 8(%rdi,%rdx,4)
	movl	%ebx, (%rdi,%rcx,4)
	addq	%rcx, %rsi
	movl	12(%rdi,%rdx,4), %r9d
	xorl	%eax, %eax
	cmpl	%r9d, %r15d
	setg	%al
	movl	(%rdi,%rsi,4), %ebx
	movl	%r9d, %ecx
	cmovgl	%ebx, %ecx
	cmovgl	%r9d, %ebx
	movl	%ecx, 12(%rdi,%rdx,4)
	movl	%ebx, (%rdi,%rsi,4)
	addq	%rsi, %rax
	addq	$4, %rdx
	cmpq	%rdx, %r8
	jne	LBB24_7
LBB24_8:
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r8,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r8,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_optimized_swap_arith ## -- Begin function sort_quick_optimized_swap_arith
	.p2align	4, 0x90
_sort_quick_optimized_swap_arith:       ## @sort_quick_optimized_swap_arith
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB25_11
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %r12
	movslq	%edx, %r15
	jmp	LBB25_2
	.p2align	4, 0x90
LBB25_10:                               ##   in Loop: Header=BB25_2 Depth=1
	movl	(%r12,%rbx,4), %eax
	movl	(%r12,%r15,4), %ecx
	movl	%ecx, (%r12,%rbx,4)
	movl	%eax, (%r12,%r15,4)
	leal	-1(%rbx), %edx
	movq	%r12, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	callq	_sort_quick_optimized_swap_arith
	incl	%ebx
	movl	%ebx, %esi
	cmpl	%r14d, %ebx
	jge	LBB25_11
LBB25_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB25_7 Depth 2
                                        ##     Child Loop BB25_9 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB25_11
## %bb.3:                               ##   in Loop: Header=BB25_2 Depth=1
	cmpl	$1, %eax
	jne	LBB25_4
## %bb.5:                               ##   in Loop: Header=BB25_2 Depth=1
	movl	(%r12,%r15,4), %r10d
	movslq	%esi, %rbx
	jmp	LBB25_6
	.p2align	4, 0x90
LBB25_4:                                ##   in Loop: Header=BB25_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rbx
	movl	(%r12,%rbx,4), %r9d
	movslq	%ecx, %r8
	movl	(%r12,%r8,4), %r10d
	movl	(%r12,%r15,4), %edi
	cmpl	%r10d, %r9d
	movl	%r10d, %ecx
	cmovll	%r9d, %ecx
	movl	%r10d, %edx
	cmovgl	%r9d, %edx
	cmpl	%edi, %ecx
	cmovgel	%edi, %ecx
	cmpl	%edi, %edx
	cmovlel	%edi, %edx
	addl	%r9d, %r10d
	addl	%edi, %r10d
	subl	%ecx, %r10d
	subl	%edx, %r10d
	movl	%ecx, (%r12,%rbx,4)
	movl	%r10d, (%r12,%r15,4)
	movl	%edx, (%r12,%r8,4)
LBB25_6:                                ##   in Loop: Header=BB25_2 Depth=1
	movl	%r14d, %r9d
	subl	%ebx, %r9d
	movq	%rbx, %r8
	notq	%r8
	addq	%r15, %r8
	movq	%rbx, %rcx
	andq	$3, %r9
	je	LBB25_8
	.p2align	4, 0x90
LBB25_7:                                ##   Parent Loop BB25_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r12,%rcx,4), %eax
	xorl	%r11d, %r11d
	cmpl	%eax, %r10d
	setg	%r11b
	movl	(%r12,%rbx,4), %edi
	movl	%eax, %edx
	cmovgl	%edi, %edx
	cmovgl	%eax, %edi
	movl	%edx, (%r12,%rcx,4)
	movl	%edi, (%r12,%rbx,4)
	addq	%r11, %rbx
	incq	%rcx
	decq	%r9
	jne	LBB25_7
LBB25_8:                                ##   in Loop: Header=BB25_2 Depth=1
	cmpq	$3, %r8
	jb	LBB25_10
	.p2align	4, 0x90
LBB25_9:                                ##   Parent Loop BB25_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r12,%rcx,4), %r8d
	xorl	%edx, %edx
	cmpl	%r8d, %r10d
	setg	%dl
	movl	(%r12,%rbx,4), %edi
	movl	%r8d, %eax
	cmovgl	%edi, %eax
	cmovgl	%r8d, %edi
	movl	%eax, (%r12,%rcx,4)
	movl	%edi, (%r12,%rbx,4)
	addq	%rbx, %rdx
	movl	4(%r12,%rcx,4), %r8d
	xorl	%edi, %edi
	cmpl	%r8d, %r10d
	setg	%dil
	movl	(%r12,%rdx,4), %ebx
	movl	%r8d, %eax
	cmovgl	%ebx, %eax
	cmovgl	%r8d, %ebx
	movl	%eax, 4(%r12,%rcx,4)
	movl	%ebx, (%r12,%rdx,4)
	addq	%rdx, %rdi
	movl	8(%r12,%rcx,4), %r8d
	xorl	%edx, %edx
	cmpl	%r8d, %r10d
	setg	%dl
	movl	(%r12,%rdi,4), %ebx
	movl	%r8d, %eax
	cmovgl	%ebx, %eax
	cmovgl	%r8d, %ebx
	movl	%eax, 8(%r12,%rcx,4)
	movl	%ebx, (%r12,%rdi,4)
	addq	%rdi, %rdx
	movl	12(%r12,%rcx,4), %r8d
	xorl	%ebx, %ebx
	cmpl	%r8d, %r10d
	setg	%bl
	movl	(%r12,%rdx,4), %edi
	movl	%r8d, %eax
	cmovgl	%edi, %eax
	cmovgl	%r8d, %edi
	movl	%eax, 12(%r12,%rcx,4)
	movl	%edi, (%r12,%rdx,4)
	addq	%rdx, %rbx
	addq	$4, %rcx
	cmpq	%rcx, %r15
	jne	LBB25_9
	jmp	LBB25_10
LBB25_11:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_optimized_swap_array ## -- Begin function partition_quick_optimized_swap_array
	.p2align	4, 0x90
_partition_quick_optimized_swap_array:  ## @partition_quick_optimized_swap_array
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB26_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %r9d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r15d
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r11d
	cmpl	%r15d, %r9d
	movl	%r15d, %ebx
	cmovll	%r9d, %ebx
	movl	%r15d, %r14d
	cmovgl	%r9d, %r14d
	cmpl	%r11d, %ebx
	cmovgel	%r11d, %ebx
	cmpl	%r11d, %r14d
	cmovlel	%r11d, %r14d
	addl	%r9d, %r15d
	addl	%r11d, %r15d
	subl	%ebx, %r15d
	subl	%r14d, %r15d
	movl	%ebx, (%rdi,%rax,4)
	movl	%r15d, (%rdi,%r8,4)
	movl	%r14d, (%rdi,%r10,4)
	cmpl	%esi, %edx
	jg	LBB26_4
	jmp	LBB26_10
LBB26_2:
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r15d
	movslq	%esi, %rax
	cmpl	%esi, %edx
	jle	LBB26_10
LBB26_4:
	movl	%r8d, %edx
	subl	%eax, %edx
	leaq	1(%rax), %r9
	testb	$1, %dl
	jne	LBB26_6
## %bb.5:
	movq	%rax, %rdx
	cmpq	%r9, %r8
	jne	LBB26_8
	jmp	LBB26_10
LBB26_6:
	movl	(%rdi,%rax,4), %edx
	xorl	%ebx, %ebx
	xorl	%esi, %esi
	cmpl	%edx, %r15d
	setg	%bl
	setle	%sil
	movq	_x@GOTPCREL(%rip), %r10
	movl	%edx, (%r10)
	movl	(%rdi,%rax,4), %edx
	movl	%edx, 4(%r10)
	movl	(%r10,%rsi,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	(%r10,%rbx,4), %edx
	movl	%edx, (%rdi,%rax,4)
	addq	%rbx, %rax
	movq	%r9, %rdx
	cmpq	%r9, %r8
	je	LBB26_10
LBB26_8:
	movq	_x@GOTPCREL(%rip), %r9
	.p2align	4, 0x90
LBB26_9:                                ## =>This Inner Loop Header: Depth=1
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	cmpl	(%rdi,%rdx,4), %r15d
	setg	%bl
	setle	%cl
	movl	(%rdi,%rax,4), %esi
	movl	%esi, (%r9)
	movl	(%rdi,%rdx,4), %esi
	movl	%esi, 4(%r9)
	movl	(%r9,%rcx,4), %ecx
	movl	%ecx, (%rdi,%rdx,4)
	movl	(%r9,%rbx,4), %ecx
	movl	%ecx, (%rdi,%rax,4)
	addq	%rbx, %rax
	xorl	%ecx, %ecx
	xorl	%esi, %esi
	cmpl	4(%rdi,%rdx,4), %r15d
	setg	%cl
	setle	%sil
	movl	(%rdi,%rax,4), %ebx
	movl	%ebx, (%r9)
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ebx, 4(%r9)
	movl	(%r9,%rsi,4), %esi
	movl	%esi, 4(%rdi,%rdx,4)
	movl	(%r9,%rcx,4), %esi
	movl	%esi, (%rdi,%rax,4)
	addq	%rcx, %rax
	addq	$2, %rdx
	cmpq	%rdx, %r8
	jne	LBB26_9
LBB26_10:
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r8,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r8,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_optimized_swap_array ## -- Begin function sort_quick_optimized_swap_array
	.p2align	4, 0x90
_sort_quick_optimized_swap_array:       ## @sort_quick_optimized_swap_array
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB27_11
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %rbx
	movslq	%edx, %r15
	movq	%r15, %rax
	negq	%rax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	movq	_x@GOTPCREL(%rip), %r13
	jmp	LBB27_2
	.p2align	4, 0x90
LBB27_10:                               ##   in Loop: Header=BB27_2 Depth=1
	movl	(%rbx,%r12,4), %eax
	movl	(%rbx,%r15,4), %ecx
	movl	%ecx, (%rbx,%r12,4)
	movl	%eax, (%rbx,%r15,4)
	leal	-1(%r12), %edx
	movq	%rbx, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	callq	_sort_quick_optimized_swap_array
	incl	%r12d
	movl	%r12d, %esi
	cmpl	%r14d, %r12d
	jge	LBB27_11
LBB27_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB27_9 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB27_11
## %bb.3:                               ##   in Loop: Header=BB27_2 Depth=1
	cmpl	$1, %eax
	jne	LBB27_4
## %bb.5:                               ##   in Loop: Header=BB27_2 Depth=1
	movl	(%rbx,%r15,4), %r11d
	movslq	%esi, %rcx
	jmp	LBB27_6
	.p2align	4, 0x90
LBB27_4:                                ##   in Loop: Header=BB27_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %edx
	shrl	$31, %edx
	addl	%eax, %edx
	sarl	%edx
	movslq	%esi, %rcx
	movl	(%rbx,%rcx,4), %r9d
	movslq	%edx, %r8
	movl	(%rbx,%r8,4), %r11d
	movl	(%rbx,%r15,4), %r10d
	cmpl	%r11d, %r9d
	movl	%r11d, %edi
	cmovll	%r9d, %edi
	movl	%r11d, %edx
	cmovgl	%r9d, %edx
	cmpl	%r10d, %edi
	cmovgel	%r10d, %edi
	cmpl	%r10d, %edx
	cmovlel	%r10d, %edx
	addl	%r9d, %r11d
	addl	%r10d, %r11d
	subl	%edi, %r11d
	subl	%edx, %r11d
	movl	%edi, (%rbx,%rcx,4)
	movl	%r11d, (%rbx,%r15,4)
	movl	%edx, (%rbx,%r8,4)
LBB27_6:                                ##   in Loop: Header=BB27_2 Depth=1
	movl	%r14d, %edi
	subl	%ecx, %edi
	movq	%rcx, %r12
	movq	%rcx, %rdx
	testb	$1, %dil
	je	LBB27_8
## %bb.7:                               ##   in Loop: Header=BB27_2 Depth=1
	movl	(%rbx,%rcx,4), %edx
	xorl	%r12d, %r12d
	xorl	%edi, %edi
	cmpl	%edx, %r11d
	setg	%r12b
	setle	%dil
	movl	%edx, (%r13)
	movl	(%rbx,%rcx,4), %edx
	movl	%edx, 4(%r13)
	movl	(%r13,%rdi,4), %edx
	movl	%edx, (%rbx,%rcx,4)
	movl	(%r13,%r12,4), %edx
	movl	%edx, (%rbx,%rcx,4)
	addq	%rcx, %r12
	leaq	1(%rcx), %rdx
LBB27_8:                                ##   in Loop: Header=BB27_2 Depth=1
	notq	%rcx
	cmpq	-48(%rbp), %rcx                 ## 8-byte Folded Reload
	je	LBB27_10
	.p2align	4, 0x90
LBB27_9:                                ##   Parent Loop BB27_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	xorl	%ecx, %ecx
	xorl	%edi, %edi
	cmpl	(%rbx,%rdx,4), %r11d
	setg	%cl
	setle	%dil
	movl	(%rbx,%r12,4), %eax
	movl	%eax, (%r13)
	movl	(%rbx,%rdx,4), %eax
	movl	%eax, 4(%r13)
	movl	(%r13,%rdi,4), %eax
	movl	%eax, (%rbx,%rdx,4)
	movl	(%r13,%rcx,4), %eax
	movl	%eax, (%rbx,%r12,4)
	addq	%rcx, %r12
	xorl	%eax, %eax
	xorl	%ecx, %ecx
	cmpl	4(%rbx,%rdx,4), %r11d
	setg	%al
	setle	%cl
	movl	(%rbx,%r12,4), %edi
	movl	%edi, (%r13)
	movl	4(%rbx,%rdx,4), %edi
	movl	%edi, 4(%r13)
	movl	(%r13,%rcx,4), %ecx
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	(%r13,%rax,4), %ecx
	movl	%ecx, (%rbx,%r12,4)
	addq	%rax, %r12
	addq	$2, %rdx
	cmpq	%rdx, %r15
	jne	LBB27_9
	jmp	LBB27_10
LBB27_11:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_optimized_swap_asm ## -- Begin function partition_quick_optimized_swap_asm
	.p2align	4, 0x90
_partition_quick_optimized_swap_asm:    ## @partition_quick_optimized_swap_asm
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r12, -32
	.cfi_offset %r14, -24
	movq	%rsi, %rax
	movq	%rdx, %rcx
	subq	%rsi, %rcx
	cmpq	$2, %rcx
	jl	LBB28_2
## %bb.1:
	leal	(%rdx,%rax), %ecx
	movl	%ecx, %esi
	shrl	$31, %esi
	addl	%ecx, %esi
	sarl	%esi
	movslq	%eax, %r8
	movl	(%rdi,%r8,4), %r9d
	movslq	%esi, %r10
	movl	(%rdi,%r10,4), %ecx
	movslq	%edx, %r11
	movl	(%rdi,%r11,4), %r14d
	cmpl	%ecx, %r9d
	movl	%ecx, %ebx
	cmovll	%r9d, %ebx
	movl	%ecx, %esi
	cmovgl	%r9d, %esi
	cmpl	%r14d, %ebx
	cmovgel	%r14d, %ebx
	cmpl	%r14d, %esi
	cmovlel	%r14d, %esi
	addl	%r9d, %ecx
	addl	%r14d, %ecx
	subl	%ebx, %ecx
	subl	%esi, %ecx
	movl	%ebx, (%rdi,%r8,4)
	movl	%ecx, (%rdi,%r11,4)
	movl	%esi, (%rdi,%r10,4)
	jmp	LBB28_3
LBB28_2:
	movl	(%rdi,%rdx,4), %ecx
LBB28_3:
	## InlineAsm Start
	movq	%rax, %r12
Ltmp0:

	movl	(%rdi,%r12,4), %r8d
	movl	(%rdi,%rax,4), %r9d
	xorq	%r10, %r10
	cmpl	%ecx, %r8d
	setl	%r10b
	movl	%r8d, %r11d
	cmovll	%r9d, %r11d
	movl	%r11d, (%rdi,%r12,4)
	cmovll	%r8d, %r9d
	movl	%r9d, (%rdi,%rax,4)
	addq	%r10, %rax

	incq	%r12
	cmpq	%r12, %rdx
	jne	Ltmp0

	movl	(%rdi,%rax,4), %r9d
	movl	(%rdi,%rdx,4), %r8d
	movl	%r9d, (%rdi,%rdx,4)
	movl	%r8d, (%rdi,%rax,4)

	## InlineAsm End
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_optimized_swap_asm  ## -- Begin function sort_quick_optimized_swap_asm
	.p2align	4, 0x90
_sort_quick_optimized_swap_asm:         ## @sort_quick_optimized_swap_asm
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$24, %rsp
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpq	%rsi, %rdx
	jle	LBB29_25
## %bb.1:
	movq	%rdx, %r14
	movq	%rdi, %r13
	movabsq	$-4294967296, %r15              ## imm = 0xFFFFFFFF00000000
	movabsq	$4294967296, %rax               ## imm = 0x100000000
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	movslq	%r14d, %rax
	movq	%rax, -56(%rbp)                 ## 8-byte Spill
	jmp	LBB29_2
	.p2align	4, 0x90
LBB29_5:                                ##   in Loop: Header=BB29_2 Depth=1
	movl	(%r13,%r14,4), %eax
LBB29_6:                                ##   in Loop: Header=BB29_2 Depth=1
	movq	%rsi, %rbx
	## InlineAsm Start
	movq	%rbx, %r12
Ltmp1:

	movl	(%r13,%r12,4), %r8d
	movl	(%r13,%rbx,4), %r9d
	xorq	%r10, %r10
	cmpl	%eax, %r8d
	setl	%r10b
	movl	%r8d, %r11d
	cmovll	%r9d, %r11d
	movl	%r11d, (%r13,%r12,4)
	cmovll	%r8d, %r9d
	movl	%r9d, (%r13,%rbx,4)
	addq	%r10, %rbx

	incq	%r12
	cmpq	%r12, %r14
	jne	Ltmp1

	movl	(%r13,%rbx,4), %r9d
	movl	(%r13,%r14,4), %r8d
	movl	%r9d, (%r13,%r14,4)
	movl	%r8d, (%r13,%rbx,4)

	## InlineAsm End
	shlq	$32, %rbx
	leaq	(%rbx,%r15), %rdx
	sarq	$32, %rdx
	movq	%r13, %rdi
	callq	_sort_quick_optimized_swap_asm
	movabsq	$4294967296, %rax               ## imm = 0x100000000
	addq	%rax, %rbx
	sarq	$32, %rbx
	movq	%rbx, %rsi
	cmpq	%r14, %rbx
	jge	LBB29_25
LBB29_2:                                ## =>This Inner Loop Header: Depth=1
	movq	%r14, %rdx
	subq	%rsi, %rdx
	jle	LBB29_7
## %bb.3:                               ##   in Loop: Header=BB29_2 Depth=1
	cmpq	$1, %rdx
	je	LBB29_5
## %bb.4:                               ##   in Loop: Header=BB29_2 Depth=1
	movq	-56(%rbp), %r10                 ## 8-byte Reload
	leal	(%r10,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r9
	movl	(%r13,%r9,4), %edi
	movslq	%ecx, %r8
	movl	(%r13,%r8,4), %eax
	movl	(%r13,%r10,4), %ecx
	cmpl	%eax, %edi
	movl	%eax, %edx
	cmovll	%edi, %edx
	movl	%eax, %ebx
	cmovgl	%edi, %ebx
	cmpl	%ecx, %edx
	cmovgel	%ecx, %edx
	cmpl	%ecx, %ebx
	cmovlel	%ecx, %ebx
	addl	%edi, %eax
	addl	%ecx, %eax
	subl	%edx, %eax
	subl	%ebx, %eax
	movl	%edx, (%r13,%r9,4)
	movl	%eax, (%r13,%r10,4)
	movl	%ebx, (%r13,%r8,4)
	jmp	LBB29_6
LBB29_7:
	incl	%edx
	cmpl	$2, %edx
	jl	LBB29_25
## %bb.8:
	leaq	(,%rsi,4), %rax
	addq	%r13, %rax
	movl	%edx, %r8d
	decq	%r8
	movl	$1, %ecx
	cmpl	$2, %edx
	jne	LBB29_9
LBB29_19:
	testb	$1, %r8b
	je	LBB29_25
## %bb.20:
	movl	(%rax,%rcx,4), %edx
	movq	%rcx, %rsi
	shlq	$32, %rsi
	addq	%r15, %rsi
	.p2align	4, 0x90
LBB29_21:                               ## =>This Inner Loop Header: Depth=1
	movq	%rsi, %rdi
	sarq	$30, %rdi
	movl	(%rax,%rdi), %edi
	cmpl	%edx, %edi
	jle	LBB29_24
## %bb.22:                              ##   in Loop: Header=BB29_21 Depth=1
	movl	%edi, (%rax,%rcx,4)
	leaq	-1(%rcx), %rdi
	addq	%r15, %rsi
	cmpq	$1, %rcx
	movq	%rdi, %rcx
	jg	LBB29_21
## %bb.23:
	xorl	%ecx, %ecx
LBB29_24:
	movslq	%ecx, %rcx
	movl	%edx, (%rax,%rcx,4)
LBB29_25:
	addq	$24, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB29_9:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movq	%r8, %r10
	andq	$-2, %r10
	movl	$1, %ecx
	xorl	%r11d, %r11d
	jmp	LBB29_10
	.p2align	4, 0x90
LBB29_18:                               ##   in Loop: Header=BB29_10 Depth=1
	movslq	%esi, %rsi
	movl	%edx, (%rax,%rsi,4)
	addq	$2, %rcx
	addq	%r9, %r11
	addq	%r9, -48(%rbp)                  ## 8-byte Folded Spill
	addq	$-2, %r10
	je	LBB29_19
LBB29_10:                               ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB29_11 Depth 2
                                        ##     Child Loop BB29_15 Depth 2
	movl	(%rax,%rcx,4), %edx
	movq	%r11, %rdi
	movq	%rcx, %rsi
	.p2align	4, 0x90
LBB29_11:                               ##   Parent Loop BB29_10 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdi, %rbx
	sarq	$30, %rbx
	movl	(%rax,%rbx), %ebx
	cmpl	%edx, %ebx
	jle	LBB29_14
## %bb.12:                              ##   in Loop: Header=BB29_11 Depth=2
	movl	%ebx, (%rax,%rsi,4)
	leaq	-1(%rsi), %rbx
	addq	%r15, %rdi
	cmpq	$1, %rsi
	movq	%rbx, %rsi
	jg	LBB29_11
## %bb.13:                              ##   in Loop: Header=BB29_10 Depth=1
	xorl	%esi, %esi
LBB29_14:                               ##   in Loop: Header=BB29_10 Depth=1
	movslq	%esi, %rsi
	movl	%edx, (%rax,%rsi,4)
	leaq	1(%rcx), %rsi
	movl	4(%rax,%rcx,4), %edx
	movq	-48(%rbp), %rdi                 ## 8-byte Reload
	.p2align	4, 0x90
LBB29_15:                               ##   Parent Loop BB29_10 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdi, %rbx
	sarq	$30, %rbx
	movl	(%rax,%rbx), %ebx
	cmpl	%edx, %ebx
	jle	LBB29_18
## %bb.16:                              ##   in Loop: Header=BB29_15 Depth=2
	movl	%ebx, (%rax,%rsi,4)
	leaq	-1(%rsi), %rbx
	addq	%r15, %rdi
	cmpq	$1, %rsi
	movq	%rbx, %rsi
	jg	LBB29_15
## %bb.17:                              ##   in Loop: Header=BB29_10 Depth=1
	xorl	%esi, %esi
	jmp	LBB29_18
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_optimized_swap_cmov ## -- Begin function partition_quick_optimized_swap_cmov
	.p2align	4, 0x90
_partition_quick_optimized_swap_cmov:   ## @partition_quick_optimized_swap_cmov
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB30_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %r9d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r15d
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r11d
	cmpl	%r15d, %r9d
	movl	%r15d, %ebx
	cmovll	%r9d, %ebx
	movl	%r15d, %r14d
	cmovgl	%r9d, %r14d
	cmpl	%r11d, %ebx
	cmovgel	%r11d, %ebx
	cmpl	%r11d, %r14d
	cmovlel	%r11d, %r14d
	addl	%r9d, %r15d
	addl	%r11d, %r15d
	subl	%ebx, %r15d
	subl	%r14d, %r15d
	movl	%ebx, (%rdi,%rax,4)
	movl	%r15d, (%rdi,%r8,4)
	movl	%r14d, (%rdi,%r10,4)
	cmpl	%esi, %edx
	jg	LBB30_4
	jmp	LBB30_8
LBB30_2:
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r15d
	movslq	%esi, %rax
	cmpl	%esi, %edx
	jle	LBB30_8
LBB30_4:
	movl	%r8d, %r10d
	subl	%eax, %r10d
	movq	%rax, %r9
	notq	%r9
	addq	%r8, %r9
	movq	%rax, %rdx
	andq	$3, %r10
	je	LBB30_6
	.p2align	4, 0x90
LBB30_5:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %ebx
	xorl	%ecx, %ecx
	cmpl	%ebx, %r15d
	setg	%cl
	movl	(%rdi,%rax,4), %r11d
	movl	%r11d, %esi
	cmovgl	%ebx, %esi
	movl	%esi, (%rdi,%rax,4)
	cmovgl	%r11d, %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	%rcx, %rax
	incq	%rdx
	decq	%r10
	jne	LBB30_5
LBB30_6:
	cmpq	$3, %r9
	jb	LBB30_8
	.p2align	4, 0x90
LBB30_7:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %ecx
	xorl	%esi, %esi
	cmpl	%ecx, %r15d
	setg	%sil
	movl	(%rdi,%rax,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%ecx, %ebx
	movl	%ebx, (%rdi,%rax,4)
	cmovgl	%r9d, %ecx
	movl	%ecx, (%rdi,%rdx,4)
	addq	%rax, %rsi
	movl	4(%rdi,%rdx,4), %eax
	xorl	%ecx, %ecx
	cmpl	%eax, %r15d
	setg	%cl
	movl	(%rdi,%rsi,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%r9d, %eax
	movl	%eax, 4(%rdi,%rdx,4)
	addq	%rsi, %rcx
	movl	8(%rdi,%rdx,4), %eax
	xorl	%esi, %esi
	cmpl	%eax, %r15d
	setg	%sil
	movl	(%rdi,%rcx,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%rdi,%rcx,4)
	cmovgl	%r9d, %eax
	movl	%eax, 8(%rdi,%rdx,4)
	addq	%rcx, %rsi
	movl	12(%rdi,%rdx,4), %ecx
	xorl	%eax, %eax
	cmpl	%ecx, %r15d
	setg	%al
	movl	(%rdi,%rsi,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%ecx, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%r9d, %ecx
	movl	%ecx, 12(%rdi,%rdx,4)
	addq	%rsi, %rax
	addq	$4, %rdx
	cmpq	%rdx, %r8
	jne	LBB30_7
LBB30_8:
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r8,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r8,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_optimized_swap_cmov ## -- Begin function sort_quick_optimized_swap_cmov
	.p2align	4, 0x90
_sort_quick_optimized_swap_cmov:        ## @sort_quick_optimized_swap_cmov
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB31_11
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %r12
	movslq	%edx, %r15
	jmp	LBB31_2
	.p2align	4, 0x90
LBB31_10:                               ##   in Loop: Header=BB31_2 Depth=1
	movl	(%r12,%rbx,4), %eax
	movl	(%r12,%r15,4), %ecx
	movl	%ecx, (%r12,%rbx,4)
	movl	%eax, (%r12,%r15,4)
	leal	-1(%rbx), %edx
	movq	%r12, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	callq	_sort_quick_optimized_swap_cmov
	incl	%ebx
	movl	%ebx, %esi
	cmpl	%r14d, %ebx
	jge	LBB31_11
LBB31_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB31_7 Depth 2
                                        ##     Child Loop BB31_9 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB31_11
## %bb.3:                               ##   in Loop: Header=BB31_2 Depth=1
	cmpl	$1, %eax
	jne	LBB31_4
## %bb.5:                               ##   in Loop: Header=BB31_2 Depth=1
	movl	(%r12,%r15,4), %r10d
	movslq	%esi, %rbx
	jmp	LBB31_6
	.p2align	4, 0x90
LBB31_4:                                ##   in Loop: Header=BB31_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rbx
	movl	(%r12,%rbx,4), %r9d
	movslq	%ecx, %r8
	movl	(%r12,%r8,4), %r10d
	movl	(%r12,%r15,4), %edi
	cmpl	%r10d, %r9d
	movl	%r10d, %ecx
	cmovll	%r9d, %ecx
	movl	%r10d, %edx
	cmovgl	%r9d, %edx
	cmpl	%edi, %ecx
	cmovgel	%edi, %ecx
	cmpl	%edi, %edx
	cmovlel	%edi, %edx
	addl	%r9d, %r10d
	addl	%edi, %r10d
	subl	%ecx, %r10d
	subl	%edx, %r10d
	movl	%ecx, (%r12,%rbx,4)
	movl	%r10d, (%r12,%r15,4)
	movl	%edx, (%r12,%r8,4)
LBB31_6:                                ##   in Loop: Header=BB31_2 Depth=1
	movl	%r14d, %r9d
	subl	%ebx, %r9d
	movq	%rbx, %r8
	notq	%r8
	addq	%r15, %r8
	movq	%rbx, %rcx
	andq	$3, %r9
	je	LBB31_8
	.p2align	4, 0x90
LBB31_7:                                ##   Parent Loop BB31_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r12,%rcx,4), %edx
	xorl	%eax, %eax
	cmpl	%edx, %r10d
	setg	%al
	movl	(%r12,%rbx,4), %r11d
	movl	%r11d, %edi
	cmovgl	%edx, %edi
	movl	%edi, (%r12,%rbx,4)
	cmovgl	%r11d, %edx
	movl	%edx, (%r12,%rcx,4)
	addq	%rax, %rbx
	incq	%rcx
	decq	%r9
	jne	LBB31_7
LBB31_8:                                ##   in Loop: Header=BB31_2 Depth=1
	cmpq	$3, %r8
	jb	LBB31_10
	.p2align	4, 0x90
LBB31_9:                                ##   Parent Loop BB31_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r12,%rcx,4), %eax
	xorl	%edx, %edx
	cmpl	%eax, %r10d
	setg	%dl
	movl	(%r12,%rbx,4), %r8d
	movl	%r8d, %edi
	cmovgl	%eax, %edi
	movl	%edi, (%r12,%rbx,4)
	cmovgl	%r8d, %eax
	movl	%eax, (%r12,%rcx,4)
	addq	%rbx, %rdx
	movl	4(%r12,%rcx,4), %eax
	xorl	%edi, %edi
	cmpl	%eax, %r10d
	setg	%dil
	movl	(%r12,%rdx,4), %r8d
	movl	%r8d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%r12,%rdx,4)
	cmovgl	%r8d, %eax
	movl	%eax, 4(%r12,%rcx,4)
	addq	%rdx, %rdi
	movl	8(%r12,%rcx,4), %eax
	xorl	%edx, %edx
	cmpl	%eax, %r10d
	setg	%dl
	movl	(%r12,%rdi,4), %r8d
	movl	%r8d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%r12,%rdi,4)
	cmovgl	%r8d, %eax
	movl	%eax, 8(%r12,%rcx,4)
	addq	%rdi, %rdx
	movl	12(%r12,%rcx,4), %eax
	xorl	%ebx, %ebx
	cmpl	%eax, %r10d
	setg	%bl
	movl	(%r12,%rdx,4), %r8d
	movl	%r8d, %edi
	cmovgl	%eax, %edi
	movl	%edi, (%r12,%rdx,4)
	cmovgl	%r8d, %eax
	movl	%eax, 12(%r12,%rcx,4)
	addq	%rdx, %rbx
	addq	$4, %rcx
	cmpq	%rcx, %r15
	jne	LBB31_9
	jmp	LBB31_10
LBB31_11:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_standard       ## -- Begin function partition_quick_standard
	.p2align	4, 0x90
_partition_quick_standard:              ## @partition_quick_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -32
	.cfi_offset %r14, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB32_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%rdi,%r8,4), %r14d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r9d
	movslq	%edx, %r11
	movl	(%rdi,%r11,4), %ecx
	cmpl	%r9d, %r14d
	movl	%r9d, %ebx
	cmovll	%r14d, %ebx
	movl	%r9d, %eax
	cmovgl	%r14d, %eax
	cmpl	%ecx, %ebx
	cmovgel	%ecx, %ebx
	cmpl	%ecx, %eax
	cmovlel	%ecx, %eax
	addl	%r14d, %r9d
	addl	%ecx, %r9d
	subl	%ebx, %r9d
	subl	%eax, %r9d
	movl	%ebx, (%rdi,%r8,4)
	movl	%r9d, (%rdi,%r11,4)
	movl	%eax, (%rdi,%r10,4)
	leal	-1(%rsi), %eax
	movl	%edx, %ecx
	subl	%esi, %ecx
	jg	LBB32_5
LBB32_4:
	movslq	%edx, %r10
	jmp	LBB32_19
LBB32_2:
	movslq	%edx, %rax
	movl	(%rdi,%rax,4), %r9d
	leal	-1(%rsi), %eax
	movl	%edx, %ecx
	subl	%esi, %ecx
	jle	LBB32_4
LBB32_5:
	movslq	%esi, %rsi
	movslq	%edx, %r10
	movq	%rsi, %r8
	notq	%r8
	addq	%r10, %r8
	andq	$3, %rcx
	jne	LBB32_6
LBB32_9:
	cmpq	$3, %r8
	jae	LBB32_10
LBB32_19:
	movslq	%eax, %rcx
	incl	%eax
	movl	4(%rdi,%rcx,4), %edx
	movl	(%rdi,%r10,4), %esi
	movl	%esi, 4(%rdi,%rcx,4)
	movl	%edx, (%rdi,%r10,4)
	popq	%rbx
	popq	%r14
	popq	%rbp
	retq
	.p2align	4, 0x90
LBB32_8:                                ##   in Loop: Header=BB32_6 Depth=1
	incq	%rsi
	decq	%rcx
	je	LBB32_9
LBB32_6:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rsi,4), %edx
	cmpl	%r9d, %edx
	jg	LBB32_8
## %bb.7:                               ##   in Loop: Header=BB32_6 Depth=1
	movslq	%eax, %rbx
	incl	%eax
	movl	4(%rdi,%rbx,4), %r11d
	movl	%edx, 4(%rdi,%rbx,4)
	movl	%r11d, (%rdi,%rsi,4)
	jmp	LBB32_8
	.p2align	4, 0x90
LBB32_18:                               ##   in Loop: Header=BB32_10 Depth=1
	addq	$4, %rsi
	cmpq	%rsi, %r10
	je	LBB32_19
LBB32_10:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB32_11
## %bb.12:                              ##   in Loop: Header=BB32_10 Depth=1
	movl	4(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB32_13
LBB32_14:                               ##   in Loop: Header=BB32_10 Depth=1
	movl	8(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB32_15
LBB32_16:                               ##   in Loop: Header=BB32_10 Depth=1
	movl	12(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB32_18
	jmp	LBB32_17
	.p2align	4, 0x90
LBB32_11:                               ##   in Loop: Header=BB32_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, (%rdi,%rsi,4)
	movl	4(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB32_14
LBB32_13:                               ##   in Loop: Header=BB32_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, 4(%rdi,%rsi,4)
	movl	8(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB32_16
LBB32_15:                               ##   in Loop: Header=BB32_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, 8(%rdi,%rsi,4)
	movl	12(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB32_18
LBB32_17:                               ##   in Loop: Header=BB32_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, 12(%rdi,%rsi,4)
	jmp	LBB32_18
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_standard            ## -- Begin function sort_quick_standard
	.p2align	4, 0x90
_sort_quick_standard:                   ## @sort_quick_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB33_21
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %rbx
	movslq	%edx, %r12
	jmp	LBB33_2
	.p2align	4, 0x90
LBB33_20:                               ##   in Loop: Header=BB33_2 Depth=1
	movslq	%r10d, %r15
	movl	4(%rbx,%r15,4), %eax
	movl	(%rbx,%r12,4), %ecx
	movl	%ecx, 4(%rbx,%r15,4)
	movl	%eax, (%rbx,%r12,4)
	movq	%rbx, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	movl	%r15d, %edx
	callq	_sort_quick_standard
	addl	$2, %r15d
	movl	%r15d, %esi
	cmpl	%r14d, %r15d
	jge	LBB33_21
LBB33_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB33_7 Depth 2
                                        ##     Child Loop BB33_11 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB33_21
## %bb.3:                               ##   in Loop: Header=BB33_2 Depth=1
	cmpl	$1, %eax
	jne	LBB33_4
## %bb.5:                               ##   in Loop: Header=BB33_2 Depth=1
	movl	(%rbx,%r12,4), %r9d
	movslq	%esi, %rax
	jmp	LBB33_6
	.p2align	4, 0x90
LBB33_4:                                ##   in Loop: Header=BB33_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rbx,%rax,4), %r10d
	movslq	%ecx, %r8
	movl	(%rbx,%r8,4), %r9d
	movl	(%rbx,%r12,4), %edi
	cmpl	%r9d, %r10d
	movl	%r9d, %ecx
	cmovll	%r10d, %ecx
	movl	%r9d, %edx
	cmovgl	%r10d, %edx
	cmpl	%edi, %ecx
	cmovgel	%edi, %ecx
	cmpl	%edi, %edx
	cmovlel	%edi, %edx
	addl	%r10d, %r9d
	addl	%edi, %r9d
	subl	%ecx, %r9d
	subl	%edx, %r9d
	movl	%ecx, (%rbx,%rax,4)
	movl	%r9d, (%rbx,%r12,4)
	movl	%edx, (%rbx,%r8,4)
LBB33_6:                                ##   in Loop: Header=BB33_2 Depth=1
	leal	-1(%rsi), %r10d
	movl	%r14d, %edi
	subl	%eax, %edi
	movq	%rax, %r8
	notq	%r8
	addq	%r12, %r8
	andq	$3, %rdi
	jne	LBB33_7
LBB33_10:                               ##   in Loop: Header=BB33_2 Depth=1
	cmpq	$3, %r8
	jae	LBB33_11
	jmp	LBB33_20
	.p2align	4, 0x90
LBB33_9:                                ##   in Loop: Header=BB33_7 Depth=2
	incq	%rax
	decq	%rdi
	je	LBB33_10
LBB33_7:                                ##   Parent Loop BB33_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB33_9
## %bb.8:                               ##   in Loop: Header=BB33_7 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %r11d
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%r11d, (%rbx,%rax,4)
	jmp	LBB33_9
	.p2align	4, 0x90
LBB33_19:                               ##   in Loop: Header=BB33_11 Depth=2
	addq	$4, %rax
	cmpq	%rax, %r12
	je	LBB33_20
LBB33_11:                               ##   Parent Loop BB33_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB33_12
## %bb.13:                              ##   in Loop: Header=BB33_11 Depth=2
	movl	4(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB33_14
LBB33_15:                               ##   in Loop: Header=BB33_11 Depth=2
	movl	8(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB33_16
LBB33_17:                               ##   in Loop: Header=BB33_11 Depth=2
	movl	12(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB33_19
	jmp	LBB33_18
	.p2align	4, 0x90
LBB33_12:                               ##   in Loop: Header=BB33_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, (%rbx,%rax,4)
	movl	4(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB33_15
LBB33_14:                               ##   in Loop: Header=BB33_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, 4(%rbx,%rax,4)
	movl	8(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB33_17
LBB33_16:                               ##   in Loop: Header=BB33_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, 8(%rbx,%rax,4)
	movl	12(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB33_19
LBB33_18:                               ##   in Loop: Header=BB33_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, 12(%rbx,%rax,4)
	jmp	LBB33_19
LBB33_21:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_shuffle_data                   ## -- Begin function shuffle_data
	.p2align	4, 0x90
_shuffle_data:                          ## @shuffle_data
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movl	%esi, %eax
	decl	%eax
	je	LBB34_6
## %bb.1:
	movl	%esi, %r14d
	movq	%rdi, %r13
	movslq	%eax, %r15
	movslq	%esi, %r12
	xorl	%ebx, %ebx
	jmp	LBB34_2
	.p2align	4, 0x90
LBB34_4:                                ##   in Loop: Header=BB34_2 Depth=1
	xorl	%edx, %edx
	divq	%r12
LBB34_5:                                ##   in Loop: Header=BB34_2 Depth=1
	movl	(%r13,%rdx,4), %eax
	movl	(%r13,%rbx,4), %ecx
	movl	%ecx, (%r13,%rdx,4)
	movl	%eax, (%r13,%rbx,4)
	incq	%rbx
	cmpq	%r15, %rbx
	jae	LBB34_6
LBB34_2:                                ## =>This Inner Loop Header: Depth=1
	callq	_rand
	cltq
	addq	%rbx, %rax
	movq	%rax, %rcx
	orq	%r12, %rcx
	shrq	$32, %rcx
	jne	LBB34_4
## %bb.3:                               ##   in Loop: Header=BB34_2 Depth=1
                                        ## kill: def $eax killed $eax killed $rax
	xorl	%edx, %edx
	divl	%r14d
                                        ## kill: def $edx killed $edx def $rdx
	jmp	LBB34_5
LBB34_6:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.section	__TEXT,__literal4,4byte_literals
	.p2align	2                               ## -- Begin function bench
LCPI35_0:
	.long	0x49742400                      ## float 1.0E+6
LCPI35_1:
	.long	0x447a0000                      ## float 1000
	.section	__TEXT,__text,regular,pure_instructions
	.globl	_bench
	.p2align	4, 0x90
_bench:                                 ## @bench
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$56, %rsp
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movq	%rsi, -80(%rbp)                 ## 8-byte Spill
	movq	%rdi, %rsi
	cmpl	$10, %edx
	jne	LBB35_1
## %bb.8:
	leaq	L_.str(%rip), %rdi
	xorl	%eax, %eax
	addq	$56, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	jmp	_printf                         ## TAILCALL
LBB35_1:
	movq	%rcx, %r12
	movl	%edx, %r15d
	movl	%edx, %ecx
	decl	%ecx
	je	LBB35_2
## %bb.9:
	movq	%rsi, -88(%rbp)                 ## 8-byte Spill
	movslq	%ecx, %r14
	movslq	%r15d, %r13
	movl	%ecx, %eax
	sarl	$31, %eax
	movl	%ecx, -60(%rbp)                 ## 4-byte Spill
	andnl	%ecx, %eax, %esi
	xorl	%edx, %edx
	xorl	%eax, %eax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	movq	%rsi, -72(%rbp)                 ## 8-byte Spill
	.p2align	4, 0x90
LBB35_10:                               ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB35_11 Depth 2
                                        ##     Child Loop BB35_20 Depth 2
	movq	%rdx, -56(%rbp)                 ## 8-byte Spill
	xorl	%ebx, %ebx
	jmp	LBB35_11
	.p2align	4, 0x90
LBB35_13:                               ##   in Loop: Header=BB35_11 Depth=2
	xorl	%edx, %edx
	divq	%r13
LBB35_14:                               ##   in Loop: Header=BB35_11 Depth=2
	movl	(%r12,%rdx,4), %eax
	movl	(%r12,%rbx,4), %ecx
	movl	%ecx, (%r12,%rdx,4)
	movl	%eax, (%r12,%rbx,4)
	incq	%rbx
	cmpq	%r14, %rbx
	jae	LBB35_15
LBB35_11:                               ##   Parent Loop BB35_10 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	callq	_rand
	cltq
	addq	%rbx, %rax
	movq	%rax, %rcx
	orq	%r13, %rcx
	shrq	$32, %rcx
	jne	LBB35_13
## %bb.12:                              ##   in Loop: Header=BB35_11 Depth=2
                                        ## kill: def $eax killed $eax killed $rax
	xorl	%edx, %edx
	divl	%r15d
                                        ## kill: def $edx killed $edx def $rdx
	jmp	LBB35_14
	.p2align	4, 0x90
LBB35_15:                               ##   in Loop: Header=BB35_10 Depth=1
	movl	%r15d, %ebx
	movl	$12, %edi
	callq	_clock_gettime_nsec_np
	movq	%rax, %r15
	movq	%r12, %rdi
	xorl	%esi, %esi
	movl	-60(%rbp), %edx                 ## 4-byte Reload
	callq	*-80(%rbp)                      ## 8-byte Folded Reload
	movl	$12, %edi
	callq	_clock_gettime_nsec_np
	subq	%r15, %rax
	js	LBB35_16
## %bb.17:                              ##   in Loop: Header=BB35_10 Depth=1
	vcvtsi2ss	%rax, %xmm1, %xmm0
	jmp	LBB35_18
	.p2align	4, 0x90
LBB35_16:                               ##   in Loop: Header=BB35_10 Depth=1
	movq	%rax, %rcx
	shrq	%rcx
	movl	%eax, %edx
	andl	$1, %edx
	orq	%rcx, %rdx
	vcvtsi2ss	%rdx, %xmm1, %xmm0
	vaddss	%xmm0, %xmm0, %xmm0
LBB35_18:                               ##   in Loop: Header=BB35_10 Depth=1
	movq	-72(%rbp), %rsi                 ## 8-byte Reload
	movq	-56(%rbp), %rdi                 ## 8-byte Reload
	vdivss	LCPI35_0(%rip), %xmm0, %xmm0
	vmulss	LCPI35_1(%rip), %xmm0, %xmm0
	movq	_individual_times@GOTPCREL(%rip), %rcx
	vmovss	%xmm0, (%rcx,%rdi,4)
	testq	%rdi, %rdi
	je	LBB35_19
LBB35_26:                               ##   in Loop: Header=BB35_10 Depth=1
	leaq	1(%rdi), %rcx
	movq	-48(%rbp), %rdx                 ## 8-byte Reload
	addq	%rax, %rdx
	movq	%rdx, %rax
	movq	%rdx, -48(%rbp)                 ## 8-byte Spill
	cmpq	$400000000, %rdx                ## imm = 0x17D78400
	setb	%al
	cmpq	$9, %rdi
	setb	%dl
	cmpq	$998, %rdi                      ## imm = 0x3E6
	ja	LBB35_28
## %bb.27:                              ##   in Loop: Header=BB35_10 Depth=1
	orb	%al, %dl
	movq	%rcx, %rdx
	movl	%ebx, %r15d
	jne	LBB35_10
	jmp	LBB35_28
	.p2align	4, 0x90
LBB35_19:                               ##   in Loop: Header=BB35_10 Depth=1
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB35_20:                               ##   Parent Loop BB35_10 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	cmpq	%rcx, %rsi
	je	LBB35_26
## %bb.21:                              ##   in Loop: Header=BB35_20 Depth=2
	movl	(%r12,%rcx,4), %edx
	leaq	1(%rcx), %r15
	cmpl	4(%r12,%rcx,4), %edx
	movq	%r15, %rcx
	jle	LBB35_20
## %bb.22:
	leaq	L_.str.3(%rip), %rdi
	xorl	%eax, %eax
	callq	_printf
	testl	%ebx, %ebx
	js	LBB35_25
## %bb.23:
	incq	%r13
	leaq	L_.str.2(%rip), %r14
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB35_24:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r12,%rbx,4), %esi
	movq	%r14, %rdi
	xorl	%eax, %eax
	callq	_printf
	incq	%rbx
	cmpq	%rbx, %r13
	jne	LBB35_24
LBB35_25:
	leaq	L_.str.4(%rip), %rdi
	movq	-88(%rbp), %rsi                 ## 8-byte Reload
	movl	%r15d, %edx
	xorl	%eax, %eax
	callq	_printf
	movl	$1, %edi
	callq	_exit
LBB35_2:
	xorl	%ebx, %ebx
	movq	_individual_times@GOTPCREL(%rip), %r14
	xorl	%eax, %eax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	.p2align	4, 0x90
LBB35_3:                                ## =>This Inner Loop Header: Depth=1
	movl	$12, %edi
	callq	_clock_gettime_nsec_np
	movq	%rax, %r15
	movq	%r12, %rdi
	xorl	%esi, %esi
	xorl	%edx, %edx
	callq	*-80(%rbp)                      ## 8-byte Folded Reload
	movl	$12, %edi
	callq	_clock_gettime_nsec_np
	subq	%r15, %rax
	movq	-48(%rbp), %rdx                 ## 8-byte Reload
	addq	%rax, %rdx
	testq	%rax, %rax
	js	LBB35_4
## %bb.5:                               ##   in Loop: Header=BB35_3 Depth=1
	vcvtsi2ss	%rax, %xmm1, %xmm0
	jmp	LBB35_6
	.p2align	4, 0x90
LBB35_4:                                ##   in Loop: Header=BB35_3 Depth=1
	movq	%rax, %rcx
	shrq	%rcx
	andl	$1, %eax
	orq	%rcx, %rax
	vcvtsi2ss	%rax, %xmm1, %xmm0
	vaddss	%xmm0, %xmm0, %xmm0
LBB35_6:                                ##   in Loop: Header=BB35_3 Depth=1
	vdivss	LCPI35_0(%rip), %xmm0, %xmm0
	vmulss	LCPI35_1(%rip), %xmm0, %xmm0
	vmovss	%xmm0, (%r14,%rbx,4)
	leaq	1(%rbx), %rcx
	movq	%rdx, %rax
	movq	%rdx, -48(%rbp)                 ## 8-byte Spill
	cmpq	$400000000, %rdx                ## imm = 0x17D78400
	setb	%al
	cmpq	$9, %rbx
	setb	%dl
	cmpq	$998, %rbx                      ## imm = 0x3E6
	ja	LBB35_28
## %bb.7:                               ##   in Loop: Header=BB35_3 Depth=1
	orb	%al, %dl
	movq	%rcx, %rbx
	jne	LBB35_3
LBB35_28:
	movq	-48(%rbp), %rdx                 ## 8-byte Reload
	testq	%rdx, %rdx
	js	LBB35_29
## %bb.30:
	vcvtsi2ss	%rdx, %xmm1, %xmm0
	jmp	LBB35_31
LBB35_29:
	movq	%rdx, %rax
	shrq	%rax
	andl	$1, %edx
	orq	%rax, %rdx
	vcvtsi2ss	%rdx, %xmm1, %xmm0
	vaddss	%xmm0, %xmm0, %xmm0
LBB35_31:
	vmulss	LCPI35_1(%rip), %xmm0, %xmm0
	vdivss	LCPI35_0(%rip), %xmm0, %xmm1
	vcvtsi2ss	%ecx, %xmm2, %xmm0
	vdivss	%xmm0, %xmm1, %xmm3
	leaq	-1(%rcx), %rdx
	movl	%ecx, %eax
	andl	$7, %eax
	cmpq	$7, %rdx
	jae	LBB35_75
## %bb.32:
	vxorps	%xmm1, %xmm1, %xmm1
	xorl	%edx, %edx
	jmp	LBB35_33
LBB35_75:
	andq	$-8, %rcx
	vxorps	%xmm1, %xmm1, %xmm1
	xorl	%edx, %edx
	movq	_individual_times@GOTPCREL(%rip), %rsi
	.p2align	4, 0x90
LBB35_76:                               ## =>This Inner Loop Header: Depth=1
	vsubss	(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	4(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	8(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	12(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	16(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	20(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	24(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	vsubss	28(%rsi,%rdx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB35_76
LBB35_33:
	testq	%rax, %rax
	je	LBB35_36
## %bb.34:
	shlq	$2, %rdx
	addq	_individual_times@GOTPCREL(%rip), %rdx
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB35_35:                               ## =>This Inner Loop Header: Depth=1
	vsubss	(%rdx,%rcx,4), %xmm3, %xmm2
	vmulss	%xmm2, %xmm2, %xmm2
	vaddss	%xmm2, %xmm1, %xmm1
	incq	%rcx
	cmpq	%rcx, %rax
	jne	LBB35_35
LBB35_36:
	vdivss	%xmm0, %xmm1, %xmm0
	vsqrtss	%xmm0, %xmm0, %xmm0
	vmovss	%xmm0, -48(%rbp)                ## 4-byte Spill
	movl	$20, %edi
	vmovss	%xmm3, -56(%rbp)                ## 4-byte Spill
	callq	_malloc
	movq	%rax, %rbx
	vmovss	-56(%rbp), %xmm0                ## 4-byte Reload
                                        ## xmm0 = mem[0],zero,zero,zero
	vcvtss2sd	%xmm0, %xmm0, %xmm0
	vmovss	-48(%rbp), %xmm1                ## 4-byte Reload
                                        ## xmm1 = mem[0],zero,zero,zero
	vcvtss2sd	%xmm1, %xmm1, %xmm1
	leaq	L_.str.5(%rip), %rcx
	movl	$20, %edx
	movq	%rax, %rdi
	xorl	%esi, %esi
	movb	$2, %al
	callq	___sprintf_chk
	cmpb	$0, (%rbx)
	je	LBB35_37
## %bb.38:
	cmpb	$0, 1(%rbx)
	je	LBB35_39
LBB35_40:
	cmpb	$0, 2(%rbx)
	je	LBB35_41
LBB35_42:
	cmpb	$0, 3(%rbx)
	je	LBB35_43
LBB35_44:
	cmpb	$0, 4(%rbx)
	je	LBB35_45
LBB35_46:
	cmpb	$0, 5(%rbx)
	je	LBB35_47
LBB35_48:
	cmpb	$0, 6(%rbx)
	je	LBB35_49
LBB35_50:
	cmpb	$0, 7(%rbx)
	je	LBB35_51
LBB35_52:
	cmpb	$0, 8(%rbx)
	je	LBB35_53
LBB35_54:
	cmpb	$0, 9(%rbx)
	je	LBB35_55
LBB35_56:
	cmpb	$0, 10(%rbx)
	je	LBB35_57
LBB35_58:
	cmpb	$0, 11(%rbx)
	je	LBB35_59
LBB35_60:
	cmpb	$0, 12(%rbx)
	je	LBB35_61
LBB35_62:
	cmpb	$0, 13(%rbx)
	je	LBB35_63
LBB35_64:
	cmpb	$0, 14(%rbx)
	je	LBB35_65
LBB35_66:
	cmpb	$0, 15(%rbx)
	je	LBB35_67
LBB35_68:
	cmpb	$0, 16(%rbx)
	je	LBB35_69
LBB35_70:
	cmpb	$0, 17(%rbx)
	je	LBB35_71
LBB35_72:
	cmpb	$0, 18(%rbx)
	je	LBB35_73
LBB35_74:
	leaq	L_.str(%rip), %rdi
	movq	%rbx, %rsi
	xorl	%eax, %eax
	callq	_printf
	movq	%rbx, %rdi
	addq	$56, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	jmp	_free                           ## TAILCALL
LBB35_37:
	movb	$32, (%rbx)
	cmpb	$0, 1(%rbx)
	jne	LBB35_40
LBB35_39:
	movb	$32, 1(%rbx)
	cmpb	$0, 2(%rbx)
	jne	LBB35_42
LBB35_41:
	movb	$32, 2(%rbx)
	cmpb	$0, 3(%rbx)
	jne	LBB35_44
LBB35_43:
	movb	$32, 3(%rbx)
	cmpb	$0, 4(%rbx)
	jne	LBB35_46
LBB35_45:
	movb	$32, 4(%rbx)
	cmpb	$0, 5(%rbx)
	jne	LBB35_48
LBB35_47:
	movb	$32, 5(%rbx)
	cmpb	$0, 6(%rbx)
	jne	LBB35_50
LBB35_49:
	movb	$32, 6(%rbx)
	cmpb	$0, 7(%rbx)
	jne	LBB35_52
LBB35_51:
	movb	$32, 7(%rbx)
	cmpb	$0, 8(%rbx)
	jne	LBB35_54
LBB35_53:
	movb	$32, 8(%rbx)
	cmpb	$0, 9(%rbx)
	jne	LBB35_56
LBB35_55:
	movb	$32, 9(%rbx)
	cmpb	$0, 10(%rbx)
	jne	LBB35_58
LBB35_57:
	movb	$32, 10(%rbx)
	cmpb	$0, 11(%rbx)
	jne	LBB35_60
LBB35_59:
	movb	$32, 11(%rbx)
	cmpb	$0, 12(%rbx)
	jne	LBB35_62
LBB35_61:
	movb	$32, 12(%rbx)
	cmpb	$0, 13(%rbx)
	jne	LBB35_64
LBB35_63:
	movb	$32, 13(%rbx)
	cmpb	$0, 14(%rbx)
	jne	LBB35_66
LBB35_65:
	movb	$32, 14(%rbx)
	cmpb	$0, 15(%rbx)
	jne	LBB35_68
LBB35_67:
	movb	$32, 15(%rbx)
	cmpb	$0, 16(%rbx)
	jne	LBB35_70
LBB35_69:
	movb	$32, 16(%rbx)
	cmpb	$0, 17(%rbx)
	jne	LBB35_72
LBB35_71:
	movb	$32, 17(%rbx)
	cmpb	$0, 18(%rbx)
	jne	LBB35_74
LBB35_73:
	movb	$32, 18(%rbx)
	jmp	LBB35_74
	.cfi_endproc
                                        ## -- End function
	.section	__TEXT,__const
	.p2align	5                               ## -- Begin function main
LCPI36_0:
	.quad	4                               ## 0x4
	.quad	5                               ## 0x5
	.quad	6                               ## 0x6
	.quad	7                               ## 0x7
LCPI36_1:
	.quad	0                               ## 0x0
	.quad	1                               ## 0x1
	.quad	2                               ## 0x2
	.quad	3                               ## 0x3
LCPI36_2:
	.long	0                               ## 0x0
	.long	2                               ## 0x2
	.long	4                               ## 0x4
	.long	6                               ## 0x6
	.long	4                               ## 0x4
	.long	6                               ## 0x6
	.long	6                               ## 0x6
	.long	7                               ## 0x7
	.section	__TEXT,__literal4,4byte_literals
	.p2align	2
LCPI36_3:
	.long	9                               ## 0x9
LCPI36_4:
	.long	17                              ## 0x11
LCPI36_5:
	.long	25                              ## 0x19
LCPI36_6:
	.long	33                              ## 0x21
LCPI36_7:
	.long	41                              ## 0x29
LCPI36_8:
	.long	49                              ## 0x31
LCPI36_9:
	.long	57                              ## 0x39
	.section	__TEXT,__literal8,8byte_literals
	.p2align	3
LCPI36_10:
	.quad	64                              ## 0x40
	.section	__TEXT,__text,regular,pure_instructions
	.globl	_main
	.p2align	4, 0x90
_main:                                  ## @main
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	movl	$8000008, %eax                  ## imm = 0x7A1208
	callq	____chkstk_darwin
	subq	%rax, %rsp
	popq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	movq	%rax, -48(%rbp)
	leaq	L_str(%rip), %rdi
	callq	_puts
	leaq	L_str.18(%rip), %rdi
	callq	_puts
	callq	_clock
	movl	%eax, %edi
	callq	_srand
	vmovdqa	LCPI36_0(%rip), %ymm0           ## ymm0 = [4,5,6,7]
	vmovdqa	LCPI36_1(%rip), %ymm1           ## ymm1 = [0,1,2,3]
	movl	$56, %eax
	vmovdqa	LCPI36_2(%rip), %ymm2           ## ymm2 = [0,2,4,6,4,6,6,7]
	vpcmpeqd	%ymm3, %ymm3, %ymm3
	vpbroadcastd	LCPI36_3(%rip), %ymm4   ## ymm4 = [9,9,9,9,9,9,9,9]
	vpbroadcastd	LCPI36_4(%rip), %ymm5   ## ymm5 = [17,17,17,17,17,17,17,17]
	vpbroadcastd	LCPI36_5(%rip), %ymm6   ## ymm6 = [25,25,25,25,25,25,25,25]
	vpbroadcastd	LCPI36_6(%rip), %ymm7   ## ymm7 = [33,33,33,33,33,33,33,33]
	vpbroadcastd	LCPI36_7(%rip), %ymm8   ## ymm8 = [41,41,41,41,41,41,41,41]
	vpbroadcastd	LCPI36_8(%rip), %ymm9   ## ymm9 = [49,49,49,49,49,49,49,49]
	vpbroadcastd	LCPI36_9(%rip), %ymm10  ## ymm10 = [57,57,57,57,57,57,57,57]
	vpbroadcastq	LCPI36_10(%rip), %ymm11 ## ymm11 = [64,64,64,64]
	.p2align	4, 0x90
LBB36_1:                                ## =>This Inner Loop Header: Depth=1
	vpermd	%ymm1, %ymm2, %ymm12
	vpermd	%ymm0, %ymm2, %ymm13
	vinserti128	$1, %xmm13, %ymm12, %ymm12
	vpsubd	%ymm3, %ymm12, %ymm13
	vmovdqu	%ymm13, -8000272(%rbp,%rax,4)
	vpaddd	%ymm4, %ymm12, %ymm13
	vmovdqu	%ymm13, -8000240(%rbp,%rax,4)
	vpaddd	%ymm5, %ymm12, %ymm13
	vmovdqu	%ymm13, -8000208(%rbp,%rax,4)
	vpaddd	%ymm6, %ymm12, %ymm13
	vmovdqu	%ymm13, -8000176(%rbp,%rax,4)
	vpaddd	%ymm7, %ymm12, %ymm13
	vmovdqu	%ymm13, -8000144(%rbp,%rax,4)
	vpaddd	%ymm8, %ymm12, %ymm13
	vmovdqu	%ymm13, -8000112(%rbp,%rax,4)
	vpaddd	%ymm9, %ymm12, %ymm13
	vmovdqu	%ymm13, -8000080(%rbp,%rax,4)
	vpaddd	%ymm10, %ymm12, %ymm12
	vmovdqu	%ymm12, -8000048(%rbp,%rax,4)
	vpaddq	%ymm1, %ymm11, %ymm1
	vpaddq	%ymm0, %ymm11, %ymm0
	addq	$64, %rax
	cmpq	$2000056, %rax                  ## imm = 0x1E84B8
	jne	LBB36_1
## %bb.2:
	xorl	%r15d, %r15d
	leaq	-8000048(%rbp), %rbx
	leaq	L_.str.17(%rip), %r12
	leaq	_sort_merge_optimized(%rip), %r13
	.p2align	4, 0x90
LBB36_3:                                ## =>This Inner Loop Header: Depth=1
	leaq	l___const.main.array_sizes(%rip), %rax
	movl	(%r15,%rax), %r14d
	leaq	L_.str.8(%rip), %rdi
	leaq	_sort_quick_standard(%rip), %rsi
	movl	%r14d, %edx
	movq	%rbx, %rcx
	vzeroupper
	callq	_bench
	leaq	L_.str.9(%rip), %rdi
	leaq	_sort_quick_simd(%rip), %rsi
	movl	%r14d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.10(%rip), %rdi
	leaq	_sort_quick_optimized_swap_arith(%rip), %rsi
	movl	%r14d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.11(%rip), %rdi
	leaq	_sort_quick_optimized_swap_cmov(%rip), %rsi
	movl	%r14d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.12(%rip), %rdi
	leaq	_sort_quick_optimized_swap_array(%rip), %rsi
	movl	%r14d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.13(%rip), %rdi
	leaq	_sort_quick_optimized_swap_asm(%rip), %rsi
	movl	%r14d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.14(%rip), %rdi
	leaq	_sort_quick_multi(%rip), %rsi
	movl	%r14d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.15(%rip), %rdi
	leaq	_sort_quick_block(%rip), %rsi
	movl	%r14d, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.16(%rip), %rdi
	leaq	_sort_merge_standard(%rip), %rsi
	movl	%r14d, %edx
	movq	%rbx, %rcx
	callq	_bench
	movq	%r12, %rdi
	movq	%r13, %rsi
	movl	%r14d, %edx
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	addq	$4, %r15
	cmpq	$24, %r15
	jne	LBB36_3
## %bb.4:
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB36_6
## %bb.5:
	xorl	%eax, %eax
	addq	$8000008, %rsp                  ## imm = 0x7A1208
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB36_6:
	callq	___stack_chk_fail
	.cfi_endproc
                                        ## -- End function
	.section	__TEXT,__const
	.globl	_INSERTION_SORT_THRESH_BLOCK    ## @INSERTION_SORT_THRESH_BLOCK
	.p2align	2
_INSERTION_SORT_THRESH_BLOCK:
	.long	20                              ## 0x14

	.globl	_blocksize                      ## @blocksize
	.p2align	2
_blocksize:
	.long	128                             ## 0x80

	.comm	_b,4000000,4                    ## @b
	.comm	_x,8,2                          ## @x
	.globl	_DATA_AMOUNT                    ## @DATA_AMOUNT
	.p2align	2
_DATA_AMOUNT:
	.long	2000000                         ## 0x1e8480

	.globl	_MIN_RUNS_PER_BENCH             ## @MIN_RUNS_PER_BENCH
	.p2align	2
_MIN_RUNS_PER_BENCH:
	.long	10                              ## 0xa

	.globl	_MAX_RUNS_PER_BENCH             ## @MAX_RUNS_PER_BENCH
	.p2align	2
_MAX_RUNS_PER_BENCH:
	.long	1000                            ## 0x3e8

	.section	__TEXT,__cstring,cstring_literals
L_.str:                                 ## @.str
	.asciz	"%s"

	.comm	_individual_times,4000,4        ## @individual_times
L_.str.2:                               ## @.str.2
	.asciz	"%d "

L_.str.3:                               ## @.str.3
	.asciz	"\nArray "

L_.str.4:                               ## @.str.4
	.asciz	"Integrity check failed for %s at index %d\n"

L_.str.5:                               ## @.str.5
	.asciz	"%.2f\302\261%.2f"

	.section	__TEXT,__const
	.p2align	4                               ## @__const.main.array_sizes
l___const.main.array_sizes:
	.long	10                              ## 0xa
	.long	100                             ## 0x64
	.long	1000                            ## 0x3e8
	.long	10000                           ## 0x2710
	.long	100000                          ## 0x186a0
	.long	1000000                         ## 0xf4240

	.section	__TEXT,__cstring,cstring_literals
L_.str.8:                               ## @.str.8
	.asciz	"QStd              "

L_.str.9:                               ## @.str.9
	.asciz	"QSIMD             "

L_.str.10:                              ## @.str.10
	.asciz	"QArith            "

L_.str.11:                              ## @.str.11
	.asciz	"QCMov             "

L_.str.12:                              ## @.str.12
	.asciz	"QArray            "

L_.str.13:                              ## @.str.13
	.asciz	"QAsm              "

L_.str.14:                              ## @.str.14
	.asciz	"QMult             "

L_.str.15:                              ## @.str.15
	.asciz	"QBlock            "

L_.str.16:                              ## @.str.16
	.asciz	"MSStd             "

L_.str.17:                              ## @.str.17
	.asciz	"MSOpt             "

L_str:                                  ## @str
	.asciz	"Starting"

L_str.18:                               ## @str.18
	.asciz	"Generating random data"

.subsections_via_symbols
