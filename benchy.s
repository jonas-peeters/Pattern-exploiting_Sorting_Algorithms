	.file	"benchy.c"
# GNU C17 (Ubuntu 10.3.0-1ubuntu1~20.04) version 10.3.0 (x86_64-linux-gnu)
#	compiled by GNU C version 10.3.0, GMP version 6.2.0, MPFR version 4.0.2, MPC version 1.1.0, isl version isl-0.22.1-GMP

# GGC heuristics: --param ggc-min-expand=100 --param ggc-min-heapsize=131072
# options passed:  -imultiarch x86_64-linux-gnu benchy.c -march=skylake
# -mmmx -mno-3dnow -msse -msse2 -msse3 -mssse3 -mno-sse4a -mcx16 -msahf
# -mmovbe -maes -mno-sha -mpclmul -mpopcnt -mabm -mno-lwp -mfma -mno-fma4
# -mno-xop -mbmi -msgx -mbmi2 -mno-pconfig -mno-wbnoinvd -mno-tbm -mavx
# -mavx2 -msse4.2 -msse4.1 -mlzcnt -mrtm -mhle -mrdrnd -mf16c -mfsgsbase
# -mrdseed -mprfchw -madx -mfxsr -mxsave -mxsaveopt -mno-avx512f
# -mno-avx512er -mno-avx512cd -mno-avx512pf -mno-prefetchwt1 -mclflushopt
# -mxsavec -mxsaves -mno-avx512dq -mno-avx512bw -mno-avx512vl
# -mno-avx512ifma -mno-avx512vbmi -mno-avx5124fmaps -mno-avx5124vnniw
# -mno-clwb -mno-mwaitx -mno-clzero -mno-pku -mno-rdpid -mno-gfni
# -mno-shstk -mno-avx512vbmi2 -mno-avx512vnni -mno-vaes -mno-vpclmulqdq
# -mno-avx512bitalg -mno-avx512vpopcntdq -mno-movdiri -mno-movdir64b
# -mno-waitpkg -mno-cldemote -mno-ptwrite -mno-avx512bf16 -mno-enqcmd
# -mno-avx512vp2intersect --param=l1-cache-size=32
# --param=l1-cache-line-size=64 --param=l2-cache-size=8192 -mtune=skylake
# -O3 -fverbose-asm -fasynchronous-unwind-tables -fstack-protector-strong
# -Wformat -Wformat-security -fstack-clash-protection -fcf-protection
# options enabled:  -fPIC -fPIE -faggressive-loop-optimizations
# -falign-functions -falign-jumps -falign-labels -falign-loops
# -fallocation-dce -fasynchronous-unwind-tables -fauto-inc-dec
# -fbranch-count-reg -fcaller-saves -fcode-hoisting
# -fcombine-stack-adjustments -fcompare-elim -fcprop-registers
# -fcrossjumping -fcse-follow-jumps -fdefer-pop
# -fdelete-null-pointer-checks -fdevirtualize -fdevirtualize-speculatively
# -fdwarf2-cfi-asm -fearly-inlining -feliminate-unused-debug-symbols
# -feliminate-unused-debug-types -fexpensive-optimizations
# -fforward-propagate -ffp-int-builtin-inexact -ffunction-cse -fgcse
# -fgcse-after-reload -fgcse-lm -fgnu-unique -fguess-branch-probability
# -fhoist-adjacent-loads -fident -fif-conversion -fif-conversion2
# -findirect-inlining -finline -finline-atomics -finline-functions
# -finline-functions-called-once -finline-small-functions -fipa-bit-cp
# -fipa-cp -fipa-cp-clone -fipa-icf -fipa-icf-functions -fipa-icf-variables
# -fipa-profile -fipa-pure-const -fipa-ra -fipa-reference
# -fipa-reference-addressable -fipa-sra -fipa-stack-alignment -fipa-vrp
# -fira-hoist-pressure -fira-share-save-slots -fira-share-spill-slots
# -fisolate-erroneous-paths-dereference -fivopts -fkeep-static-consts
# -fleading-underscore -flifetime-dse -floop-interchange
# -floop-unroll-and-jam -flra-remat -fmath-errno -fmerge-constants
# -fmerge-debug-strings -fmove-loop-invariants -fomit-frame-pointer
# -foptimize-sibling-calls -foptimize-strlen -fpartial-inlining
# -fpeel-loops -fpeephole -fpeephole2 -fplt -fpredictive-commoning
# -fprefetch-loop-arrays -free -freg-struct-return -freorder-blocks
# -freorder-blocks-and-partition -freorder-functions -frerun-cse-after-loop
# -fsched-critical-path-heuristic -fsched-dep-count-heuristic
# -fsched-group-heuristic -fsched-interblock -fsched-last-insn-heuristic
# -fsched-rank-heuristic -fsched-spec -fsched-spec-insn-heuristic
# -fsched-stalled-insns-dep -fschedule-fusion -fschedule-insns2
# -fsemantic-interposition -fshow-column -fshrink-wrap
# -fshrink-wrap-separate -fsigned-zeros -fsplit-ivs-in-unroller
# -fsplit-loops -fsplit-paths -fsplit-wide-types -fssa-backprop
# -fssa-phiopt -fstack-clash-protection -fstack-protector-strong
# -fstdarg-opt -fstore-merging -fstrict-aliasing
# -fstrict-volatile-bitfields -fsync-libcalls -fthread-jumps
# -ftoplevel-reorder -ftrapping-math -ftree-bit-ccp -ftree-builtin-call-dce
# -ftree-ccp -ftree-ch -ftree-coalesce-vars -ftree-copy-prop -ftree-cselim
# -ftree-dce -ftree-dominator-opts -ftree-dse -ftree-forwprop -ftree-fre
# -ftree-loop-distribute-patterns -ftree-loop-distribution
# -ftree-loop-if-convert -ftree-loop-im -ftree-loop-ivcanon
# -ftree-loop-optimize -ftree-loop-vectorize -ftree-parallelize-loops=
# -ftree-partial-pre -ftree-phiprop -ftree-pre -ftree-pta -ftree-reassoc
# -ftree-scev-cprop -ftree-sink -ftree-slp-vectorize -ftree-slsr -ftree-sra
# -ftree-switch-conversion -ftree-tail-merge -ftree-ter -ftree-vrp
# -funit-at-a-time -funswitch-loops -funwind-tables -fverbose-asm
# -fversion-loops-for-strides -fzero-initialized-in-bss
# -m128bit-long-double -m64 -m80387 -mabm -madx -maes -malign-stringops
# -mavx -mavx2 -mbmi -mbmi2 -mclflushopt -mcx16 -mf16c -mfancy-math-387
# -mfma -mfp-ret-in-387 -mfsgsbase -mfxsr -mglibc -mhle -mieee-fp
# -mlong-double-80 -mlzcnt -mmmx -mmovbe -mpclmul -mpopcnt -mprfchw
# -mpush-args -mrdrnd -mrdseed -mred-zone -mrtm -msahf -msgx -msse -msse2
# -msse3 -msse4 -msse4.1 -msse4.2 -mssse3 -mstv -mtls-direct-seg-refs
# -mvzeroupper -mxsave -mxsavec -mxsaveopt -mxsaves

	.text
	.p2align 4
	.globl	compare_ints
	.type	compare_ints, @function
compare_ints:
.LFB5706:
	.cfi_startproc
	endbr64	
# benchy.c:69:   return (*da > *db) - (*da < *db);
	movl	(%rsi), %eax	# MEM[(const int *)b_8(D)], tmp98
	cmpl	%eax, (%rdi)	# tmp98, MEM[(const int *)a_7(D)]
	setg	%al	#, tmp92
# benchy.c:69:   return (*da > *db) - (*da < *db);
	setl	%dl	#, tmp94
	movzbl	%dl, %edx	# tmp94, tmp94
# benchy.c:69:   return (*da > *db) - (*da < *db);
	movzbl	%al, %eax	# tmp92, tmp92
# benchy.c:69:   return (*da > *db) - (*da < *db);
	subl	%edx, %eax	# tmp94, tmp91
# benchy.c:70: }
	ret	
	.cfi_endproc
.LFE5706:
	.size	compare_ints, .-compare_ints
	.p2align 4
	.globl	qsort_h
	.type	qsort_h, @function
qsort_h:
.LFB5707:
	.cfi_startproc
	endbr64	
# benchy.c:72: void qsort_h(int* array, int low, int high) {
	movslq	%esi, %rax	# tmp98,
# benchy.c:73:   qsort(&array[low], high - low + 1, sizeof (int), compare_ints);
	subl	%eax, %edx	# low, tmp99
	movl	%edx, %esi	# tmp99, tmp91
# benchy.c:73:   qsort(&array[low], high - low + 1, sizeof (int), compare_ints);
	incl	%esi	# tmp92
# benchy.c:73:   qsort(&array[low], high - low + 1, sizeof (int), compare_ints);
	movslq	%esi, %rsi	# tmp92, tmp93
# benchy.c:73:   qsort(&array[low], high - low + 1, sizeof (int), compare_ints);
	leaq	(%rdi,%rax,4), %rdi	#, tmp96
# benchy.c:73:   qsort(&array[low], high - low + 1, sizeof (int), compare_ints);
	leaq	compare_ints(%rip), %rcx	#,
	movl	$4, %edx	#,
	jmp	qsort@PLT	#
	.cfi_endproc
.LFE5707:
	.size	qsort_h, .-qsort_h
	.section	.rodata.str1.1,"aMS",@progbits,1
.LC2:
	.string	"PAPI error %d: %s\n"
	.text
	.p2align 4
	.type	handle_error.part.0, @function
handle_error.part.0:
.LFB5717:
	.cfi_startproc
	pushq	%r12	#
	.cfi_def_cfa_offset 16
	.cfi_offset 12, -16
# benchy.c:76: void handle_error(int retval) {
	movl	%edi, %r12d	# tmp84, retval
# benchy.c:78:     printf("PAPI error %d: %s\n", retval, PAPI_strerror(retval));
	call	PAPI_strerror@PLT	#
	movq	%rax, %rcx	# tmp85, _2
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	movl	$1, %edi	#,
	movl	%r12d, %edx	# retval,
	leaq	.LC2(%rip), %rsi	#,
	xorl	%eax, %eax	#
	call	__printf_chk@PLT	#
# benchy.c:79:     exit(1);
	movl	$1, %edi	#,
	call	exit@PLT	#
	.cfi_endproc
.LFE5717:
	.size	handle_error.part.0, .-handle_error.part.0
	.p2align 4
	.globl	random_data
	.type	random_data, @function
random_data:
.LFB41:
	.cfi_startproc
	endbr64	
	pushq	%rbp	#
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rdi, %rbp	# tmp109, array
	pushq	%rbx	#
	.cfi_def_cfa_offset 24
	.cfi_offset 3, -24
	movl	%esi, %ebx	# tmp110, amount
	subq	$8, %rsp	#,
	.cfi_def_cfa_offset 32
# data-random.h:5:   srand(clock());
	call	clock@PLT	#
	movq	%rax, %rdi	# tmp111, _1
# data-random.h:5:   srand(clock());
	call	srand@PLT	#
# data-random.h:6:   for (int i = 0; i < amount; i++) {
	testl	%ebx, %ebx	# amount
	jle	.L10	#,
	leal	-1(%rbx), %eax	#, tmp97
	leaq	4(%rbp,%rax,4), %rbx	#, _29
	.p2align 4,,10
	.p2align 3
.L8:
# data-random.h:7:     array[i] = rand() % 100000; //i / 3;//i / 2; // 
	call	rand@PLT	#
	movl	%eax, %edx	# tmp112, _3
# data-random.h:7:     array[i] = rand() % 100000; //i / 3;//i / 2; // 
	cltq
	imulq	$351843721, %rax, %rax	#, _3, tmp101
	movl	%edx, %ecx	# _3, tmp104
	sarl	$31, %ecx	#, tmp104
	sarq	$45, %rax	#, tmp103
	subl	%ecx, %eax	# tmp104, tmp105
	imull	$100000, %eax, %eax	#, tmp105, tmp106
# data-random.h:6:   for (int i = 0; i < amount; i++) {
	addq	$4, %rbp	#, ivtmp.180
# data-random.h:7:     array[i] = rand() % 100000; //i / 3;//i / 2; // 
	subl	%eax, %edx	# tmp106, tmp108
	movl	%edx, -4(%rbp)	# tmp108, MEM[base: _8, offset: 0B]
# data-random.h:6:   for (int i = 0; i < amount; i++) {
	cmpq	%rbx, %rbp	# _29, ivtmp.180
	jne	.L8	#,
.L10:
# data-random.h:9: }
	addq	$8, %rsp	#,
	.cfi_def_cfa_offset 24
	popq	%rbx	#
	.cfi_def_cfa_offset 16
	popq	%rbp	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE41:
	.size	random_data, .-random_data
	.p2align 4
	.globl	fill_random
	.type	fill_random, @function
fill_random:
.LFB42:
	.cfi_startproc
	endbr64	
	pushq	%rbp	#
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movl	%esi, %ebp	# tmp100, amount
	pushq	%rbx	#
	.cfi_def_cfa_offset 24
	.cfi_offset 3, -24
	movq	%rdi, %rbx	# tmp99, array
	movl	%edx, %edi	# tmp101, seed
	subq	$8, %rsp	#,
	.cfi_def_cfa_offset 32
# data-random.h:12:   srand(seed);
	call	srand@PLT	#
# data-random.h:13:   for (int i = 0; i < amount; i++) {
	testl	%ebp, %ebp	# amount
	jle	.L16	#,
	leal	-1(%rbp), %eax	#, tmp96
	leaq	4(%rbx,%rax,4), %rbp	#, _27
	.p2align 4,,10
	.p2align 3
.L14:
# data-random.h:14:     array[i] = rand();
	call	rand@PLT	#
# data-random.h:14:     array[i] = rand();
	movl	%eax, (%rbx)	# tmp102, MEM[base: _6, offset: 0B]
# data-random.h:13:   for (int i = 0; i < amount; i++) {
	addq	$4, %rbx	#, ivtmp.190
	cmpq	%rbp, %rbx	# _27, ivtmp.190
	jne	.L14	#,
.L16:
# data-random.h:16: }
	addq	$8, %rsp	#,
	.cfi_def_cfa_offset 24
	popq	%rbx	#
	.cfi_def_cfa_offset 16
	popq	%rbp	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE42:
	.size	fill_random, .-fill_random
	.p2align 4
	.globl	randomise
	.type	randomise, @function
randomise:
.LFB43:
	.cfi_startproc
	endbr64	
	pushq	%r13	#
	.cfi_def_cfa_offset 16
	.cfi_offset 13, -16
	movq	%rdi, %r13	# tmp120, array
# data-random.h:19:   srand(seed + 100);
	leal	100(%rcx), %edi	#, tmp108
# data-random.h:18: void randomise(int *array, int low, int high, float percentage, int seed) {
	pushq	%r12	#
	.cfi_def_cfa_offset 24
	.cfi_offset 12, -24
	movl	%esi, %r12d	# tmp121, low
	pushq	%rbp	#
	.cfi_def_cfa_offset 32
	.cfi_offset 6, -32
	movl	%edx, %ebp	# tmp122, high
	pushq	%rbx	#
	.cfi_def_cfa_offset 40
	.cfi_offset 3, -40
	subq	$24, %rsp	#,
	.cfi_def_cfa_offset 64
# data-random.h:18: void randomise(int *array, int low, int high, float percentage, int seed) {
	vmovss	%xmm0, 12(%rsp)	# tmp123, %sfp
# data-random.h:19:   srand(seed + 100);
	call	srand@PLT	#
# data-random.h:20:   for (int i = low; i < high; i++) {
	cmpl	%ebp, %r12d	# high, low
	jge	.L25	#,
	decl	%ebp	# tmp110
	movslq	%r12d, %rax	# low, _24
	subl	%r12d, %ebp	# low, tmp112
	addq	%rax, %rbp	# _24, tmp113
	leaq	0(%r13,%rax,4), %rbx	#, ivtmp.202
	leaq	4(%r13,%rbp,4), %rbp	#, _41
	jmp	.L22	#
	.p2align 4,,10
	.p2align 3
.L20:
# data-random.h:20:   for (int i = low; i < high; i++) {
	addq	$4, %rbx	#, ivtmp.202
	cmpq	%rbp, %rbx	# _41, ivtmp.202
	je	.L25	#,
.L22:
# data-random.h:21:     int should_regenerate = rand();
	call	rand@PLT	#
# data-random.h:22:     if (should_regenerate < (float)RAND_MAX * percentage) {
	vmovss	.LC3(%rip), %xmm3	#, tmp130
# data-random.h:22:     if (should_regenerate < (float)RAND_MAX * percentage) {
	vxorps	%xmm2, %xmm2, %xmm2	# tmp129
# data-random.h:22:     if (should_regenerate < (float)RAND_MAX * percentage) {
	vmulss	12(%rsp), %xmm3, %xmm1	# %sfp, tmp130, tmp117
# data-random.h:22:     if (should_regenerate < (float)RAND_MAX * percentage) {
	vcvtsi2ssl	%eax, %xmm2, %xmm0	# tmp125, tmp129, tmp128
# data-random.h:22:     if (should_regenerate < (float)RAND_MAX * percentage) {
	vcomiss	%xmm0, %xmm1	# tmp116, tmp117
	jbe	.L20	#,
# data-random.h:23:       array[i] = rand();
	call	rand@PLT	#
# data-random.h:23:       array[i] = rand();
	movl	%eax, (%rbx)	# tmp126, MEM[base: _42, offset: 0B]
# data-random.h:20:   for (int i = low; i < high; i++) {
	addq	$4, %rbx	#, ivtmp.202
	cmpq	%rbp, %rbx	# _41, ivtmp.202
	jne	.L22	#,
.L25:
# data-random.h:26: }
	addq	$24, %rsp	#,
	.cfi_def_cfa_offset 40
	popq	%rbx	#
	.cfi_def_cfa_offset 32
	popq	%rbp	#
	.cfi_def_cfa_offset 24
	popq	%r12	#
	.cfi_def_cfa_offset 16
	popq	%r13	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE43:
	.size	randomise, .-randomise
	.p2align 4
	.globl	insertionSort
	.type	insertionSort, @function
insertionSort:
.LFB44:
	.cfi_startproc
	endbr64	
# insertionssort.h:3: void insertionSort(int array[], int n) {
	movq	%rdi, %r11	# tmp102, array
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	cmpl	$1, %esi	#, n
	jle	.L36	#,
	leaq	4(%rdi), %r8	#, ivtmp.223
	leal	-1(%rsi), %r10d	#, _59
	xorl	%r9d, %r9d	# ivtmp.220
	.p2align 4,,10
	.p2align 3
.L32:
	leaq	0(,%r9,4), %rax	#, tmp100
	leaq	-4(%r8), %rsi	#, tmp99
# insertionssort.h:6:     element = array[i];
	movl	(%r8), %edi	# MEM[base: _16, offset: 0B], element
	subq	%rax, %rsi	# tmp100, _41
	movq	%r8, %rax	# ivtmp.223, ivtmp.212
	.p2align 4,,10
	.p2align 3
.L29:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %edx	# MEM[base: _51, offset: -4B], _11
	movq	%rax, %rcx	# ivtmp.212, _51
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edi, %edx	# element, _11
	jle	.L30	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, (%rax)	# _11, MEM[base: _51, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rcx), %rax	#, ivtmp.212
	cmpq	%rsi, %rax	# _41, ivtmp.212
	jne	.L29	#,
	movq	%r11, %rcx	# array, _51
.L30:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%r9	# ivtmp.220
# insertionssort.h:13:     array[j + 1] = element;
	movl	%edi, (%rcx)	# element, *prephitmp_75
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %r8	#, ivtmp.223
	cmpq	%r10, %r9	# _59, ivtmp.220
	jne	.L32	#,
.L36:
# insertionssort.h:15: }
	ret	
	.cfi_endproc
.LFE44:
	.size	insertionSort, .-insertionSort
	.p2align 4
	.globl	insertionSortOptimized
	.type	insertionSortOptimized, @function
insertionSortOptimized:
.LFB5719:
	.cfi_startproc
	endbr64	
	movq	%rdi, %r11	# tmp102, array
	cmpl	$1, %esi	#, n
	jle	.L46	#,
	leaq	4(%rdi), %r8	#, ivtmp.249
	leal	-1(%rsi), %r10d	#, _59
	xorl	%r9d, %r9d	# ivtmp.246
	.p2align 4,,10
	.p2align 3
.L42:
	leaq	0(,%r9,4), %rax	#, tmp100
	leaq	-4(%r8), %rsi	#, tmp99
	movl	(%r8), %edi	# MEM[base: _5, offset: 0B], element
	subq	%rax, %rsi	# tmp100, _41
	movq	%r8, %rax	# ivtmp.249, ivtmp.238
	.p2align 4,,10
	.p2align 3
.L39:
	movl	-4(%rax), %edx	# MEM[base: _51, offset: -4B], _15
	movq	%rax, %rcx	# ivtmp.238, _51
	cmpl	%edx, %edi	# _15, element
	jge	.L40	#,
	movl	%edx, (%rax)	# _15, MEM[base: _51, offset: 0B]
	leaq	-4(%rcx), %rax	#, ivtmp.238
	cmpq	%rsi, %rax	# _41, ivtmp.238
	jne	.L39	#,
	movq	%r11, %rcx	# array, _51
.L40:
	incq	%r9	# ivtmp.246
	movl	%edi, (%rcx)	# element, *prephitmp_75
	addq	$4, %r8	#, ivtmp.249
	cmpq	%r10, %r9	# _59, ivtmp.246
	jne	.L42	#,
.L46:
	ret	
	.cfi_endproc
.LFE5719:
	.size	insertionSortOptimized, .-insertionSortOptimized
	.p2align 4
	.globl	insertionSortStd
	.type	insertionSortStd, @function
insertionSortStd:
.LFB46:
	.cfi_startproc
	endbr64	
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	leal	1(%rsi), %eax	#, i
	movslq	%eax, %r8	# i, i
# insertionssort.h:31: void insertionSortStd(int array[], int low, int high) {
	movl	%edx, %r9d	# tmp105, high
	decq	%r8	# ivtmp.277
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	cmpl	%edx, %eax	# high, i
	jg	.L59	#,
	.p2align 4,,10
	.p2align 3
.L53:
# insertionssort.h:35:     element = array[i];
	movl	4(%rdi,%r8,4), %ecx	# MEM[base: array_24(D), index: ivtmp.277_54, step: 4, offset: 4B], element
	movslq	%esi, %rax	# ivtmp.276, ivtmp.265
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	testl	%esi, %esi	# ivtmp.276
	jns	.L51	#,
	jmp	.L60	#
	.p2align 4,,10
	.p2align 3
.L52:
# insertionssort.h:39:       array[j + 1] = array[j];
	movl	%edx, 4(%rdi,%rax,4)	# _11, MEM[base: array_24(D), index: ivtmp.265_40, step: 4, offset: 4B]
	leal	-1(%rax), %edx	#, _60
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	decq	%rax	# ivtmp.265
	cmpl	$-1, %eax	#, ivtmp.265
	je	.L61	#,
.L51:
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	movl	(%rdi,%rax,4), %edx	# MEM[base: array_24(D), index: ivtmp.265_40, step: 4, offset: 0B], _11
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	cmpl	%ecx, %edx	# element, _11
	jg	.L52	#,
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incl	%esi	# ivtmp.276
# insertionssort.h:42:     array[j + 1] = element;
	movl	%ecx, 4(%rdi,%rax,4)	# element, *_15
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incq	%r8	# ivtmp.277
	cmpl	%esi, %r9d	# ivtmp.276, high
	jne	.L53	#,
.L59:
# insertionssort.h:44: }
	ret	
	.p2align 4,,10
	.p2align 3
.L61:
# insertionssort.h:42:     array[j + 1] = element;
	movslq	%edx, %rax	# _60, ivtmp.265
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incl	%esi	# ivtmp.276
# insertionssort.h:42:     array[j + 1] = element;
	movl	%ecx, 4(%rdi,%rax,4)	# element, *_15
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incq	%r8	# ivtmp.277
	cmpl	%esi, %r9d	# ivtmp.276, high
	jne	.L53	#,
	jmp	.L59	#
.L60:
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	movq	%r8, %rax	# ivtmp.277, ivtmp.265
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incl	%esi	# ivtmp.276
# insertionssort.h:42:     array[j + 1] = element;
	movl	%ecx, 4(%rdi,%rax,4)	# element, *_15
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incq	%r8	# ivtmp.277
	cmpl	%esi, %r9d	# ivtmp.276, high
	jne	.L53	#,
	jmp	.L59	#
	.cfi_endproc
.LFE46:
	.size	insertionSortStd, .-insertionSortStd
	.p2align 4
	.globl	insertionSortStdOpt
	.type	insertionSortStdOpt, @function
insertionSortStdOpt:
.LFB47:
	.cfi_startproc
	endbr64	
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	leal	1(%rsi), %eax	#, i
	movslq	%eax, %r8	# i, i
# insertionssort.h:46: void insertionSortStdOpt(int array[], int low, int high) {
	movl	%edx, %r9d	# tmp105, high
	decq	%r8	# ivtmp.301
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	cmpl	%eax, %edx	# i, high
	jl	.L74	#,
	.p2align 4,,10
	.p2align 3
.L68:
# insertionssort.h:35:     element = array[i];
	movl	4(%rdi,%r8,4), %ecx	# MEM[base: array_2(D), index: ivtmp.301_54, step: 4, offset: 4B], element
	movslq	%esi, %rax	# ivtmp.300, ivtmp.286
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	testl	%esi, %esi	# ivtmp.300
	jns	.L66	#,
	jmp	.L75	#
	.p2align 4,,10
	.p2align 3
.L67:
# insertionssort.h:39:       array[j + 1] = array[j];
	movl	%edx, 4(%rdi,%rax,4)	# _17, MEM[base: array_2(D), index: ivtmp.286_40, step: 4, offset: 4B]
	leal	-1(%rax), %edx	#, _60
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	decq	%rax	# ivtmp.286
	cmpl	$-1, %eax	#, ivtmp.286
	je	.L76	#,
.L66:
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	movl	(%rdi,%rax,4), %edx	# MEM[base: array_2(D), index: ivtmp.286_40, step: 4, offset: 0B], _17
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %ecx	# _17, element
	jl	.L67	#,
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incl	%esi	# ivtmp.300
# insertionssort.h:42:     array[j + 1] = element;
	movl	%ecx, 4(%rdi,%rax,4)	# element, *_26
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incq	%r8	# ivtmp.301
	cmpl	%esi, %r9d	# ivtmp.300, high
	jne	.L68	#,
.L74:
# insertionssort.h:178: }
	ret	
	.p2align 4,,10
	.p2align 3
.L76:
# insertionssort.h:42:     array[j + 1] = element;
	movslq	%edx, %rax	# _60, ivtmp.286
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incl	%esi	# ivtmp.300
# insertionssort.h:42:     array[j + 1] = element;
	movl	%ecx, 4(%rdi,%rax,4)	# element, *_26
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incq	%r8	# ivtmp.301
	cmpl	%esi, %r9d	# ivtmp.300, high
	jne	.L68	#,
	jmp	.L74	#
.L75:
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	movq	%r8, %rax	# ivtmp.301, ivtmp.286
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incl	%esi	# ivtmp.300
# insertionssort.h:42:     array[j + 1] = element;
	movl	%ecx, 4(%rdi,%rax,4)	# element, *_26
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incq	%r8	# ivtmp.301
	cmpl	%esi, %r9d	# ivtmp.300, high
	jne	.L68	#,
	jmp	.L74	#
	.cfi_endproc
.LFE47:
	.size	insertionSortStdOpt, .-insertionSortStdOpt
	.p2align 4
	.globl	heapify
	.type	heapify, @function
heapify:
.LFB48:
	.cfi_startproc
	endbr64	
# heapsort.h:3: void heapify(int arr[], int n, int i) {
	movl	%esi, %r9d	# tmp117, n
	jmp	.L81	#
	.p2align 4,,10
	.p2align 3
.L86:
# heapsort.h:9:     if (l < n && arr[l] > arr[largest])
	movslq	%ecx, %r10	# l, l
	leaq	(%rdi,%r10,4), %rsi	#, _5
	movl	(%rsi), %r8d	# *_5, _6
# heapsort.h:9:     if (l < n && arr[l] > arr[largest])
	movslq	%edx, %r11	# i, i
# heapsort.h:9:     if (l < n && arr[l] > arr[largest])
	cmpl	(%rdi,%r11,4), %r8d	# *_9, _6
	jle	.L78	#,
# heapsort.h:13:     if (r < n && arr[r] > arr[largest])
	cmpl	%r9d, %eax	# n, r
	jl	.L82	#,
.L79:
# heapsort.h:17:     if (largest != i) {
	cmpl	%edx, %ecx	# i, l
	je	.L85	#,
# heapsort.h:18:         swap(&arr[i], &arr[largest]);
	movslq	%edx, %rdx	# i, i
# heapsort.h:18:         swap(&arr[i], &arr[largest]);
	leaq	(%rdi,%rdx,4), %rax	#, _24
# swap.h:2:   int t = *a;
	movl	(%rax), %edx	# *_24, t
# swap.h:3:   *a = *b;
	movl	%r8d, (%rax)	# _6, *_24
# swap.h:4:   *b = t;
	movl	%edx, (%rsi)	# t, *prephitmp_58
	movl	%ecx, %edx	# l, i
.L81:
# heapsort.h:5:     int l = 2 * i + 1; // left = 2*i + 1
	leal	(%rdx,%rdx), %eax	#, _1
# heapsort.h:5:     int l = 2 * i + 1; // left = 2*i + 1
	leal	1(%rax), %ecx	#, l
# heapsort.h:6:     int r = 2 * i + 2; // right = 2*i + 2
	addl	$2, %eax	#, r
# heapsort.h:9:     if (l < n && arr[l] > arr[largest])
	cmpl	%r9d, %ecx	# n, l
	jl	.L86	#,
.L78:
# heapsort.h:13:     if (r < n && arr[r] > arr[largest])
	cmpl	%r9d, %eax	# n, r
	jge	.L85	#,
	movl	%edx, %ecx	# i, l
	movslq	%edx, %r10	# i, l
.L82:
# heapsort.h:13:     if (r < n && arr[r] > arr[largest])
	movslq	%eax, %rsi	# r, r
	leaq	(%rdi,%rsi,4), %rsi	#, _5
# heapsort.h:13:     if (r < n && arr[r] > arr[largest])
	leaq	(%rdi,%r10,4), %r10	#, _17
# heapsort.h:13:     if (r < n && arr[r] > arr[largest])
	movl	(%rsi), %r8d	# *_13, _6
# heapsort.h:13:     if (r < n && arr[r] > arr[largest])
	movl	(%r10), %r11d	# *_17, _18
# heapsort.h:13:     if (r < n && arr[r] > arr[largest])
	cmpl	%r11d, %r8d	# _18, _6
	jg	.L83	#,
# heapsort.h:13:     if (r < n && arr[r] > arr[largest])
	movl	%r11d, %r8d	# _18, _6
	movq	%r10, %rsi	# _17, _5
	jmp	.L79	#
	.p2align 4,,10
	.p2align 3
.L83:
	movl	%eax, %ecx	# r, l
	jmp	.L79	#
	.p2align 4,,10
	.p2align 3
.L85:
# heapsort.h:23: }
	ret	
	.cfi_endproc
.LFE48:
	.size	heapify, .-heapify
	.p2align 4
	.globl	heapsort_h
	.type	heapsort_h, @function
heapsort_h:
.LFB49:
	.cfi_startproc
	endbr64	
	pushq	%rbp	#
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
# heapsort.h:27:     for (int i = n / 2 - 1; i >= 0; i--)
	movl	%esi, %ebp	# n, tmp93
	shrl	$31, %ebp	#, tmp93
	addl	%esi, %ebp	# n, tmp94
	sarl	%ebp	# tmp95
# heapsort.h:25: void heapsort_h(int array[], int n) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 24
	.cfi_offset 3, -24
# heapsort.h:25: void heapsort_h(int array[], int n) {
	movl	%esi, %ebx	# tmp97, n
# heapsort.h:27:     for (int i = n / 2 - 1; i >= 0; i--)
	decl	%ebp	# i
	js	.L88	#,
	.p2align 4,,10
	.p2align 3
.L89:
# heapsort.h:28:         heapify(array, n, i);
	movl	%ebp, %edx	# i,
	movl	%ebx, %esi	# n,
	call	heapify	#
# heapsort.h:27:     for (int i = n / 2 - 1; i >= 0; i--)
	subl	$1, %ebp	#, i
	jnb	.L89	#,
.L88:
# heapsort.h:31:     for (int i = n - 1; i >= 0; i--) {
	decl	%ebx	# i
	js	.L94	#,
	movslq	%ebx, %rbx	# i, ivtmp.315
	.p2align 4,,10
	.p2align 3
.L91:
# swap.h:3:   *a = *b;
	movl	(%rdi,%rbx,4), %edx	# MEM[base: array_13(D), index: ivtmp.315_31, step: 4, offset: 0B], _19
# swap.h:2:   int t = *a;
	movl	(%rdi), %eax	# *array_13(D), t
# swap.h:3:   *a = *b;
	movl	%edx, (%rdi)	# _19, *array_13(D)
# swap.h:4:   *b = t;
	movl	%eax, (%rdi,%rbx,4)	# t, MEM[base: array_13(D), index: ivtmp.315_31, step: 4, offset: 0B]
# heapsort.h:36:         heapify(array, i, 0);
	movl	%ebx, %esi	# ivtmp.315,
	xorl	%edx, %edx	#
# heapsort.h:31:     for (int i = n - 1; i >= 0; i--) {
	decq	%rbx	# ivtmp.315
# heapsort.h:36:         heapify(array, i, 0);
	call	heapify	#
# heapsort.h:31:     for (int i = n - 1; i >= 0; i--) {
	testl	%ebx, %ebx	# ivtmp.315
	jns	.L91	#,
.L94:
# heapsort.h:38: }
	popq	%rbx	#
	.cfi_def_cfa_offset 16
	popq	%rbp	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE49:
	.size	heapsort_h, .-heapsort_h
	.p2align 4
	.globl	heapsort
	.type	heapsort, @function
heapsort:
.LFB50:
	.cfi_startproc
	endbr64	
	pushq	%r12	#
	.cfi_def_cfa_offset 16
	.cfi_offset 12, -16
# heapsort.h:41:     heapsort_h(&array[low], high - low + 1);
	subl	%esi, %edx	# low, tmp105
# heapsort.h:41:     heapsort_h(&array[low], high - low + 1);
	movslq	%esi, %rsi	# low, low
# heapsort.h:40: void heapsort(int array[], int low, int high) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 24
	.cfi_offset 6, -24
# heapsort.h:41:     heapsort_h(&array[low], high - low + 1);
	leaq	(%rdi,%rsi,4), %rdi	#, _5
# heapsort.h:40: void heapsort(int array[], int low, int high) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 32
	.cfi_offset 3, -32
# heapsort.h:41:     heapsort_h(&array[low], high - low + 1);
	movslq	%edx, %rbx	# tmp105,
# heapsort.h:41:     heapsort_h(&array[low], high - low + 1);
	leal	1(%rbx), %r12d	#, _2
# heapsort.h:27:     for (int i = n / 2 - 1; i >= 0; i--)
	movl	%r12d, %ebp	# _2, tmp100
	shrl	$31, %ebp	#, tmp100
	addl	%r12d, %ebp	# _2, tmp101
	sarl	%ebp	# tmp102
# heapsort.h:27:     for (int i = n / 2 - 1; i >= 0; i--)
	decl	%ebp	# i
	js	.L105	#,
	.p2align 4,,10
	.p2align 3
.L98:
# heapsort.h:28:         heapify(array, n, i);
	movl	%ebp, %edx	# i,
	movl	%r12d, %esi	# _2,
	call	heapify	#
# heapsort.h:27:     for (int i = n / 2 - 1; i >= 0; i--)
	subl	$1, %ebp	#, i
	jnb	.L98	#,
# heapsort.h:31:     for (int i = n - 1; i >= 0; i--) {
	testl	%ebx, %ebx	# ivtmp.335
	js	.L106	#,
	.p2align 4,,10
	.p2align 3
.L100:
# swap.h:3:   *a = *b;
	movl	(%rdi,%rbx,4), %edx	# MEM[base: _5, index: ivtmp.335_36, step: 4, offset: 0B], _21
# swap.h:2:   int t = *a;
	movl	(%rdi), %eax	# *_5, t
# swap.h:3:   *a = *b;
	movl	%edx, (%rdi)	# _21, *_5
# swap.h:4:   *b = t;
	movl	%eax, (%rdi,%rbx,4)	# t, MEM[base: _5, index: ivtmp.335_36, step: 4, offset: 0B]
# heapsort.h:36:         heapify(array, i, 0);
	movl	%ebx, %esi	# ivtmp.335,
	xorl	%edx, %edx	#
	call	heapify	#
# heapsort.h:31:     for (int i = n - 1; i >= 0; i--) {
	decq	%rbx	# ivtmp.335
.L105:
	testl	%ebx, %ebx	# ivtmp.335
	jns	.L100	#,
.L106:
# heapsort.h:42: }
	popq	%rbx	#
	.cfi_def_cfa_offset 24
	popq	%rbp	#
	.cfi_def_cfa_offset 16
	popq	%r12	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE50:
	.size	heapsort, .-heapsort
	.p2align 4
	.globl	heapifyo
	.type	heapifyo, @function
heapifyo:
.LFB51:
	.cfi_startproc
	endbr64	
# heapsorto.h:3: void heapifyo(int arr[], int n, int i) {
	movl	%esi, %r9d	# tmp117, n
	jmp	.L111	#
	.p2align 4,,10
	.p2align 3
.L116:
# heapsorto.h:9:     int c = l < n && arr[l] > arr[largest];
	movslq	%ecx, %r10	# l, l
	leaq	(%rdi,%r10,4), %rsi	#, _5
	movl	(%rsi), %r8d	# *_5, _6
# heapsorto.h:9:     int c = l < n && arr[l] > arr[largest];
	movslq	%edx, %r11	# i, i
# heapsorto.h:9:     int c = l < n && arr[l] > arr[largest];
	cmpl	(%rdi,%r11,4), %r8d	# *_9, _6
	jle	.L108	#,
# heapsorto.h:13:     c = r < n && arr[r] > arr[largest];
	cmpl	%r9d, %eax	# n, r
	jl	.L112	#,
.L109:
# heapsorto.h:17:     if (largest != i) {
	cmpl	%edx, %ecx	# i, l
	je	.L115	#,
# heapsorto.h:18:         swap(&arr[i], &arr[largest]);
	movslq	%edx, %rdx	# i, i
# heapsorto.h:18:         swap(&arr[i], &arr[largest]);
	leaq	(%rdi,%rdx,4), %rax	#, _24
# swap.h:2:   int t = *a;
	movl	(%rax), %edx	# *_24, t
# swap.h:3:   *a = *b;
	movl	%r8d, (%rax)	# _6, *_24
# swap.h:4:   *b = t;
	movl	%edx, (%rsi)	# t, *prephitmp_58
	movl	%ecx, %edx	# l, i
.L111:
# heapsorto.h:5:     int l = 2 * i + 1; // left = 2*i + 1
	leal	(%rdx,%rdx), %eax	#, _1
# heapsorto.h:5:     int l = 2 * i + 1; // left = 2*i + 1
	leal	1(%rax), %ecx	#, l
# heapsorto.h:6:     int r = 2 * i + 2; // right = 2*i + 2
	addl	$2, %eax	#, r
# heapsorto.h:9:     int c = l < n && arr[l] > arr[largest];
	cmpl	%r9d, %ecx	# n, l
	jl	.L116	#,
.L108:
# heapsorto.h:13:     c = r < n && arr[r] > arr[largest];
	cmpl	%r9d, %eax	# n, r
	jge	.L115	#,
	movl	%edx, %ecx	# i, l
	movslq	%edx, %r10	# i, l
.L112:
# heapsorto.h:13:     c = r < n && arr[r] > arr[largest];
	movslq	%eax, %rsi	# r, r
	leaq	(%rdi,%rsi,4), %rsi	#, _5
# heapsorto.h:13:     c = r < n && arr[r] > arr[largest];
	leaq	(%rdi,%r10,4), %r10	#, _17
# heapsorto.h:13:     c = r < n && arr[r] > arr[largest];
	movl	(%rsi), %r8d	# *_13, _6
# heapsorto.h:13:     c = r < n && arr[r] > arr[largest];
	movl	(%r10), %r11d	# *_17, _18
# heapsorto.h:13:     c = r < n && arr[r] > arr[largest];
	cmpl	%r11d, %r8d	# _18, _6
	jg	.L113	#,
# heapsorto.h:13:     c = r < n && arr[r] > arr[largest];
	movl	%r11d, %r8d	# _18, _6
	movq	%r10, %rsi	# _17, _5
	jmp	.L109	#
	.p2align 4,,10
	.p2align 3
.L113:
	movl	%eax, %ecx	# r, l
	jmp	.L109	#
	.p2align 4,,10
	.p2align 3
.L115:
# heapsorto.h:23: }
	ret	
	.cfi_endproc
.LFE51:
	.size	heapifyo, .-heapifyo
	.p2align 4
	.globl	heapsorto_h
	.type	heapsorto_h, @function
heapsorto_h:
.LFB52:
	.cfi_startproc
	endbr64	
	pushq	%rbp	#
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
# heapsorto.h:29:     for (int i = n / 2 - 1; i >= 0; i--)
	movl	%esi, %ebp	# n, tmp95
	shrl	$31, %ebp	#, tmp95
	addl	%esi, %ebp	# n, tmp96
	sarl	%ebp	# tmp97
# heapsorto.h:27: void heapsorto_h(int array[], int n) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 24
	.cfi_offset 3, -24
# heapsorto.h:27: void heapsorto_h(int array[], int n) {
	movl	%esi, %ebx	# tmp99, n
# heapsorto.h:29:     for (int i = n / 2 - 1; i >= 0; i--)
	decl	%ebp	# i
	js	.L118	#,
	.p2align 4,,10
	.p2align 3
.L119:
# heapsorto.h:30:         heapifyo(array, n, i);
	movl	%ebp, %edx	# i,
	movl	%ebx, %esi	# n,
	call	heapifyo	#
# heapsorto.h:29:     for (int i = n / 2 - 1; i >= 0; i--)
	subl	$1, %ebp	#, i
	jnb	.L119	#,
.L118:
# heapsorto.h:33:     count++;
	incl	count(%rip)	# count
# heapsorto.h:34:     for (int i = n - 1; i >= 0; i--) {
	decl	%ebx	# i
	js	.L124	#,
	movslq	%ebx, %rbx	# i, ivtmp.357
	.p2align 4,,10
	.p2align 3
.L121:
# swap.h:3:   *a = *b;
	movl	(%rdi,%rbx,4), %edx	# MEM[base: array_16(D), index: ivtmp.357_34, step: 4, offset: 0B], _22
# swap.h:2:   int t = *a;
	movl	(%rdi), %eax	# *array_16(D), t
# swap.h:3:   *a = *b;
	movl	%edx, (%rdi)	# _22, *array_16(D)
# swap.h:4:   *b = t;
	movl	%eax, (%rdi,%rbx,4)	# t, MEM[base: array_16(D), index: ivtmp.357_34, step: 4, offset: 0B]
# heapsorto.h:39:         heapifyo(array, i, 0);
	movl	%ebx, %esi	# ivtmp.357,
	xorl	%edx, %edx	#
# heapsorto.h:34:     for (int i = n - 1; i >= 0; i--) {
	decq	%rbx	# ivtmp.357
# heapsorto.h:39:         heapifyo(array, i, 0);
	call	heapifyo	#
# heapsorto.h:34:     for (int i = n - 1; i >= 0; i--) {
	testl	%ebx, %ebx	# ivtmp.357
	jns	.L121	#,
.L124:
# heapsorto.h:41: }
	popq	%rbx	#
	.cfi_def_cfa_offset 16
	popq	%rbp	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE52:
	.size	heapsorto_h, .-heapsorto_h
	.p2align 4
	.globl	heapsorto
	.type	heapsorto, @function
heapsorto:
.LFB53:
	.cfi_startproc
	endbr64	
	pushq	%r12	#
	.cfi_def_cfa_offset 16
	.cfi_offset 12, -16
# heapsorto.h:44:     heapsorto_h(&array[low], high - low + 1);
	subl	%esi, %edx	# low, tmp107
# heapsorto.h:44:     heapsorto_h(&array[low], high - low + 1);
	movslq	%esi, %rsi	# low, low
# heapsorto.h:43: void heapsorto(int array[], int low, int high) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 24
	.cfi_offset 6, -24
# heapsorto.h:44:     heapsorto_h(&array[low], high - low + 1);
	leaq	(%rdi,%rsi,4), %rdi	#, _5
# heapsorto.h:43: void heapsorto(int array[], int low, int high) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 32
	.cfi_offset 3, -32
# heapsorto.h:44:     heapsorto_h(&array[low], high - low + 1);
	movslq	%edx, %rbx	# tmp107,
# heapsorto.h:44:     heapsorto_h(&array[low], high - low + 1);
	leal	1(%rbx), %r12d	#, _2
# heapsorto.h:29:     for (int i = n / 2 - 1; i >= 0; i--)
	movl	%r12d, %ebp	# _2, tmp102
	shrl	$31, %ebp	#, tmp102
	addl	%r12d, %ebp	# _2, tmp103
	sarl	%ebp	# tmp104
# heapsorto.h:29:     for (int i = n / 2 - 1; i >= 0; i--)
	decl	%ebp	# i
	js	.L127	#,
	.p2align 4,,10
	.p2align 3
.L128:
# heapsorto.h:30:         heapifyo(array, n, i);
	movl	%ebp, %edx	# i,
	movl	%r12d, %esi	# _2,
	call	heapifyo	#
# heapsorto.h:29:     for (int i = n / 2 - 1; i >= 0; i--)
	subl	$1, %ebp	#, i
	jnb	.L128	#,
.L127:
# heapsorto.h:33:     count++;
	incl	count(%rip)	# count
# heapsorto.h:34:     for (int i = n - 1; i >= 0; i--) {
	testl	%ebx, %ebx	# _1
	js	.L133	#,
	.p2align 4,,10
	.p2align 3
.L130:
# swap.h:3:   *a = *b;
	movl	(%rdi,%rbx,4), %edx	# MEM[base: _5, index: ivtmp.377_39, step: 4, offset: 0B], _23
# swap.h:2:   int t = *a;
	movl	(%rdi), %eax	# *_5, t
# swap.h:3:   *a = *b;
	movl	%edx, (%rdi)	# _23, *_5
# swap.h:4:   *b = t;
	movl	%eax, (%rdi,%rbx,4)	# t, MEM[base: _5, index: ivtmp.377_39, step: 4, offset: 0B]
# heapsorto.h:39:         heapifyo(array, i, 0);
	movl	%ebx, %esi	# ivtmp.377,
	xorl	%edx, %edx	#
# heapsorto.h:34:     for (int i = n - 1; i >= 0; i--) {
	decq	%rbx	# ivtmp.377
# heapsorto.h:39:         heapifyo(array, i, 0);
	call	heapifyo	#
# heapsorto.h:34:     for (int i = n - 1; i >= 0; i--) {
	testl	%ebx, %ebx	# ivtmp.377
	jns	.L130	#,
.L133:
# heapsorto.h:45: }
	popq	%rbx	#
	.cfi_def_cfa_offset 24
	popq	%rbp	#
	.cfi_def_cfa_offset 16
	popq	%r12	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE53:
	.size	heapsorto, .-heapsorto
	.p2align 4
	.globl	sort_indexes
	.type	sort_indexes, @function
sort_indexes:
.LFB54:
	.cfi_startproc
	endbr64	
# median.h:6:   int y = *i2;
	movslq	(%rdx), %r8	# *i2_14(D),
# median.h:5:   int x = *i1;
	movslq	(%rsi), %r9	# *i1_12(D),
# median.h:8:   *i1 = c ? x : y;
	movl	(%rdi,%r8,4), %r10d	# *_7, tmp108
# median.h:5:   int x = *i1;
	movq	%r9, %rcx	#,
# median.h:6:   int y = *i2;
	movq	%r8, %rax	#,
# median.h:8:   *i1 = c ? x : y;
	cmpl	%r10d, (%rdi,%r9,4)	# tmp108, *_3
	jle	.L136	#,
# median.h:9:   *i2 = c ? y : x;
	movl	%r9d, %eax	# x, y
# median.h:8:   *i1 = c ? x : y;
	movl	%r8d, %ecx	# y, x
.L136:
	movl	%ecx, (%rsi)	# x, *i1_12(D)
# median.h:9:   *i2 = c ? y : x;
	movl	%eax, (%rdx)	# y, *i2_14(D)
# median.h:10: }
	ret	
	.cfi_endproc
.LFE54:
	.size	sort_indexes, .-sort_indexes
	.p2align 4
	.globl	median_of_three
	.type	median_of_three, @function
median_of_three:
.LFB55:
	.cfi_startproc
	endbr64	
# median.h:14:     return array[high];
	movslq	%edx, %rax	# high, high
	leaq	(%rdi,%rax,4), %r9	#, _32
	movl	(%r9), %ecx	# *_32, pretmp_31
# median.h:13:   if (high - low < 2) {
	movl	%edx, %r8d	# high, tmp104
	subl	%esi, %r8d	# low, tmp104
# median.h:14:     return array[high];
	movl	%ecx, %eax	# pretmp_31, <retval>
# median.h:13:   if (high - low < 2) {
	cmpl	$1, %r8d	#, tmp104
	jle	.L137	#,
# median.h:18:   int m = (low + high) / 2;
	addl	%esi, %edx	# low, tmp107
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%esi, %rax	# low, low
# median.h:18:   int m = (low + high) / 2;
	movl	%edx, %esi	# tmp107, tmp109
	shrl	$31, %esi	#, tmp109
	addl	%esi, %edx	# tmp109, tmp110
	sarl	%edx	# tmp111
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%edx, %rdx	# tmp111, tmp112
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rax,4), %r8	#, prephitmp_54
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rdx,4), %rsi	#, _42
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%r8), %eax	# *_38, <retval>
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%rsi), %edx	# *_42, _43
# median.h:8:   *i1 = c ? x : y;
	cmpl	%edx, %eax	# _43, <retval>
	jg	.L145	#,
	cmpl	%edx, %ecx	# _43, pretmp_31
	jge	.L143	#,
.L147:
# median.h:9:   *i2 = c ? y : x;
	cmpl	%eax, %ecx	# <retval>, pretmp_31
	jge	.L146	#,
.L140:
# swap.h:3:   *a = *b;
	movl	%ecx, (%r8)	# pretmp_31, *prephitmp_58
# swap.h:4:   *b = t;
	movl	%eax, (%r9)	# <retval>, *_32
# median.h:27:   return array[high];
	ret	
	.p2align 4,,10
	.p2align 3
.L137:
# median.h:28: }
	ret	
	.p2align 4,,10
	.p2align 3
.L143:
# median.h:8:   *i1 = c ? x : y;
	movl	%edx, %eax	# _43, <retval>
	movq	%rsi, %r8	# _42, prephitmp_54
# swap.h:3:   *a = *b;
	movl	%ecx, (%r8)	# pretmp_31, *prephitmp_58
# swap.h:4:   *b = t;
	movl	%eax, (%r9)	# <retval>, *_32
# median.h:27:   return array[high];
	ret	
	.p2align 4,,10
	.p2align 3
.L145:
# median.h:8:   *i1 = c ? x : y;
	movl	%edx, %edi	# _43, _43
	movl	%eax, %edx	# <retval>, _43
	movl	%edi, %eax	# _43, <retval>
	movq	%rsi, %rdi	# _42, _42
	movq	%r8, %rsi	# prephitmp_54, _42
	movq	%rdi, %r8	# _42, prephitmp_54
	cmpl	%edx, %ecx	# _43, pretmp_31
	jge	.L143	#,
	jmp	.L147	#
.L146:
# median.h:9:   *i2 = c ? y : x;
	movl	%ecx, %eax	# pretmp_31, <retval>
	movq	%r9, %r8	# _32, prephitmp_54
	jmp	.L140	#
	.cfi_endproc
.LFE55:
	.size	median_of_three, .-median_of_three
	.p2align 4
	.globl	sort_pair
	.type	sort_pair, @function
sort_pair:
.LFB56:
	.cfi_startproc
	endbr64	
# median.h:31:   int x = *i1;
	vmovd	(%rdi), %xmm0	# *i1_3(D), tmp92
# median.h:32:   int y = *i2;
	vmovd	(%rsi), %xmm1	# *i2_5(D), tmp93
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, x, tmp88
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, x, tmp89
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rdi)	# tmp88, *i1_3(D)
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rsi)	# tmp89, *i2_5(D)
# median.h:36: }
	ret	
	.cfi_endproc
.LFE56:
	.size	sort_pair, .-sort_pair
	.p2align 4
	.globl	median_of_three_auto_finish
	.type	median_of_three_auto_finish, @function
median_of_three_auto_finish:
.LFB57:
	.cfi_startproc
	endbr64	
# median.h:41:     sort_pair(&array[low], &array[high]);
	movslq	%esi, %rax	# low, low
# median.h:39:   if (high - low == 1) {
	movl	%edx, %r9d	# high, _1
# median.h:38: int median_of_three_auto_finish(int array[], int low, int high, int *done) {
	movq	%rcx, %r8	# tmp126, done
# median.h:39:   if (high - low == 1) {
	subl	%esi, %r9d	# low, _1
# median.h:41:     sort_pair(&array[low], &array[high]);
	leaq	(%rdi,%rax,4), %rcx	#, _15
# median.h:41:     sort_pair(&array[low], &array[high]);
	movslq	%edx, %rax	# high, high
# median.h:41:     sort_pair(&array[low], &array[high]);
	leaq	(%rdi,%rax,4), %rax	#, _54
# median.h:39:   if (high - low == 1) {
	cmpl	$1, %r9d	#, _1
	je	.L153	#,
# median.h:45:   int mid = (low + high) / 2;
	addl	%esi, %edx	# low, tmp115
# median.h:45:   int mid = (low + high) / 2;
	movl	%edx, %esi	# tmp115, tmp117
	shrl	$31, %esi	#, tmp117
	addl	%esi, %edx	# tmp117, tmp118
	sarl	%edx	# mid
# median.h:47:   int y = array[mid];
	movslq	%edx, %rdx	# mid, mid
# median.h:46:   int x = array[low];
	vmovd	(%rcx), %xmm0	# *_15, tmp131
# median.h:47:   int y = array[mid];
	leaq	(%rdi,%rdx,4), %rdx	#, _9
# median.h:46:   int x = array[low];
	vmovdqa	%xmm0, %xmm1	# tmp131, _6
# median.h:47:   int y = array[mid];
	vmovd	(%rdx), %xmm0	# *_9, tmp132
	vpminsd	%xmm0, %xmm1, %xmm3	# _10, _6, iftmp.16_36
# median.h:48:   int z = array[high];
	vmovd	(%rax), %xmm2	# *_54, tmp133
	vpmaxsd	%xmm0, %xmm1, %xmm0	# _10, _6, iftmp.17_37
	vpminsd	%xmm0, %xmm2, %xmm1	# iftmp.17_37, _14, iftmp.16_34
	vpmaxsd	%xmm0, %xmm2, %xmm0	# iftmp.17_37, _14, iftmp.17_35
	vpminsd	%xmm3, %xmm1, %xmm2	# iftmp.16_36, iftmp.16_34, iftmp.16_32
	vpmaxsd	%xmm3, %xmm1, %xmm1	# iftmp.16_36, iftmp.16_34, tmp130
	vmovd	%xmm1, %r10d	# tmp130, <retval>
# median.h:54:   if (high - low == 2) {
	cmpl	$2, %r9d	#, _1
	je	.L154	#,
# median.h:62:   array[low] = x;
	vmovd	%xmm2, (%rcx)	# iftmp.16_32, *_15
# median.h:63:   array[high] = y;
	vmovd	%xmm1, (%rax)	# tmp130, *_54
# median.h:64:   array[mid] = z;
	vmovd	%xmm0, (%rdx)	# iftmp.17_35, *_9
# median.h:67: }
	movl	%r10d, %eax	# <retval>,
	ret	
	.p2align 4,,10
	.p2align 3
.L153:
# median.h:40:     *done = true;
	movl	$1, (%r8)	#, *done_27(D)
# median.h:31:   int x = *i1;
	vmovd	(%rcx), %xmm0	# *_15, tmp128
	vmovdqa	%xmm0, %xmm1	# tmp128, x
# median.h:32:   int y = *i2;
	vmovd	(%rax), %xmm0	# *_54, tmp129
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm0, %xmm1, %xmm2	# y, x, tmp114
	vpmaxsd	%xmm0, %xmm1, %xmm0	# y, x, tmp127
	vmovd	%xmm0, %r10d	# tmp127, <retval>
	vmovd	%xmm2, (%rcx)	# tmp114, *_15
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rax)	# tmp127, *_54
# median.h:67: }
	movl	%r10d, %eax	# <retval>,
	ret	
	.p2align 4,,10
	.p2align 3
.L154:
# median.h:55:     *done = true;
	movl	$1, (%r8)	#, *done_27(D)
# median.h:56:     array[low] = x;
	vmovd	%xmm2, (%rcx)	# iftmp.16_32, *_15
# median.h:57:     array[mid] = y;
	vmovd	%xmm1, (%rdx)	# tmp130, *_9
# median.h:58:     array[high] = z;
	vmovd	%xmm0, (%rax)	# iftmp.17_35, *_54
# median.h:67: }
	movl	%r10d, %eax	# <retval>,
	ret	
	.cfi_endproc
.LFE57:
	.size	median_of_three_auto_finish, .-median_of_three_auto_finish
	.p2align 4
	.globl	median_of_three_stable
	.type	median_of_three_stable, @function
median_of_three_stable:
.LFB58:
	.cfi_startproc
	endbr64	
# median.h:70:   if (high - low > 2) {
	movl	%edx, %ecx	# high, _1
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%edx, %rax	# high, high
# median.h:70:   if (high - low > 2) {
	subl	%esi, %ecx	# low, _1
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rax,4), %r8	#, _105
# median.h:70:   if (high - low > 2) {
	cmpl	$2, %ecx	#, _1
	jg	.L162	#,
# median.h:88:   } if (high - low == 2) {
	je	.L163	#,
# median.h:7:   int c = array[*i1] <= array[*i2];
	vmovd	(%r8), %xmm0	# *_105, tmp160
	vmovd	%xmm0, %eax	# tmp159, <retval>
# median.h:94:   } else if (high - low == 1) {
	cmpl	$1, %ecx	#, _1
	je	.L164	#,
# median.h:100: }
	ret	
	.p2align 4,,10
	.p2align 3
.L162:
# median.h:82:     int mid = (low + high) / 2;
	addl	%esi, %edx	# low, tmp125
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%esi, %rax	# low, low
# median.h:82:     int mid = (low + high) / 2;
	movl	%edx, %esi	# tmp125, tmp127
	shrl	$31, %esi	#, tmp127
	addl	%esi, %edx	# tmp127, tmp128
	sarl	%edx	# tmp129
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%edx, %rdx	# tmp129, tmp130
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%rdi,%rax,4), %ecx	# *_44, _45
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%rdi,%rdx,4), %eax	# *_48, <retval>
# median.h:8:   *i1 = c ? x : y;
	cmpl	%eax, %ecx	# <retval>, _45
	jg	.L165	#,
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%r8), %edx	# *_105, _103
	cmpl	%edx, %ecx	# _103, _45
	cmovl	%edx, %ecx	# _45,, _103, tmp145
	cmpl	%edx, %eax	# _103, <retval>
	cmovg	%ecx, %eax	# tmp145,, <retval>
.L166:
# median.h:100: }
	ret	
	.p2align 4,,10
	.p2align 3
.L164:
# median.h:95:     sort_pair(&array[low], &array[high]);
	movslq	%esi, %rdx	# low, low
# median.h:95:     sort_pair(&array[low], &array[high]);
	leaq	(%rdi,%rdx,4), %rax	#, _13
# median.h:31:   int x = *i1;
	vmovd	(%rax), %xmm1	# *_13, tmp161
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# x, tmp159, tmp140
	vpmaxsd	%xmm1, %xmm0, %xmm0	# x, tmp159, tmp159
	vmovd	%xmm2, (%rax)	# tmp140, *_13
	vmovd	%xmm0, %eax	# tmp159, <retval>
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%r8)	# tmp159, *_105
# median.h:96:     return array[high];
	ret	
	.p2align 4,,10
	.p2align 3
.L165:
# median.h:8:   *i1 = c ? x : y;
	movl	%eax, %edx	# <retval>, <retval>
	movl	%ecx, %eax	# _45, <retval>
	movl	%edx, %ecx	# <retval>, _45
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%r8), %edx	# *_105, _103
	cmpl	%edx, %ecx	# _103, _45
	cmovl	%edx, %ecx	# _45,, _103, tmp145
	cmpl	%edx, %eax	# _103, <retval>
	cmovg	%ecx, %eax	# tmp145,, <retval>
	jmp	.L166	#
	.p2align 4,,10
	.p2align 3
.L163:
# median.h:89:     int mid = low + 1;
	leal	1(%rsi), %edx	#, mid
# median.h:90:     sort_pair(&array[low], &array[mid]);
	movslq	%edx, %rdx	# mid, mid
	salq	$2, %rdx	#, _62
# median.h:90:     sort_pair(&array[low], &array[mid]);
	leaq	-4(%rdi,%rdx), %rax	#, _66
# median.h:31:   int x = *i1;
	vmovd	(%rax), %xmm0	# *_66, tmp153
# median.h:90:     sort_pair(&array[low], &array[mid]);
	leaq	(%rdi,%rdx), %rcx	#, _63
# median.h:31:   int x = *i1;
	vmovdqa	%xmm0, %xmm1	# tmp153, x
# median.h:32:   int y = *i2;
	vmovd	(%rcx), %xmm0	# *_63, tmp154
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm0, %xmm1, %xmm2	# y, x, tmp134
	vpmaxsd	%xmm0, %xmm1, %xmm0	# y, x, iftmp.17_70
	vmovd	%xmm2, (%rax)	# tmp134, *_66
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rcx)	# iftmp.17_70, *_63
# median.h:32:   int y = *i2;
	vmovd	(%r8), %xmm1	# *_105, tmp155
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, iftmp.17_70, tmp135
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, iftmp.17_70, tmp136
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rcx)	# tmp135, *_63
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%r8)	# tmp136, *_105
# median.h:31:   int x = *i1;
	vmovd	(%rax), %xmm0	# *_66, tmp157
	vmovdqa	%xmm0, %xmm1	# tmp157, x
# median.h:32:   int y = *i2;
	vmovd	(%rcx), %xmm0	# *_63, tmp158
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm0, %xmm1, %xmm2	# y, x, tmp137
	vpmaxsd	%xmm0, %xmm1, %xmm0	# y, x, tmp156
	vmovd	%xmm2, (%rax)	# tmp137, *_66
	vmovd	%xmm0, %eax	# tmp156, <retval>
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rcx)	# tmp156, *_63
	ret	
	.cfi_endproc
.LFE58:
	.size	median_of_three_stable, .-median_of_three_stable
	.p2align 4
	.globl	median_of_three_of_median_of_three
	.type	median_of_three_of_median_of_three, @function
median_of_three_of_median_of_three:
.LFB59:
	.cfi_startproc
	endbr64	
	movslq	%edx, %r9	# tmp189,
# median.h:103:   if (high - low < 100) {
	movl	%r9d, %eax	# high, _1
	subl	%esi, %eax	# low, _1
# median.h:103:   if (high - low < 100) {
	cmpl	$99, %eax	#, _1
	jle	.L198	#,
# median.h:102: int median_of_three_of_median_of_three(int array[], int low, int high) {
	pushq	%r12	#
	.cfi_def_cfa_offset 16
	.cfi_offset 12, -16
# median.h:106:     int offset = (high - low) / 8;
	sarl	$3, %eax	#, offset
# median.h:109:     int b = low + offset;
	leal	(%rsi,%rax), %ecx	#, _2
# median.h:102: int median_of_three_of_median_of_three(int array[], int low, int high) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 24
	.cfi_offset 6, -24
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%esi, %rsi	# low, low
# median.h:110:     int c = low + offset * 2;
	leal	(%rcx,%rax), %edx	#, _4
# median.h:102: int median_of_three_of_median_of_three(int array[], int low, int high) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 32
	.cfi_offset 3, -32
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%ecx, %rcx	# _2, _2
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rsi,4), %r10	#, prephitmp_169
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rcx,4), %rsi	#, _136
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%r10), %r8d	# *_132, <retval>
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%rsi), %ecx	# *_136, _137
# median.h:8:   *i1 = c ? x : y;
	cmpl	%ecx, %r8d	# _137, <retval>
	jg	.L199	#,
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%edx, %r11	# _4, _4
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%r11,4), %rbx	#, _216
	movl	(%rbx), %r11d	# *_216, _217
# median.h:8:   *i1 = c ? x : y;
	cmpl	%r11d, %ecx	# _217, _137
	jle	.L188	#,
.L204:
# median.h:9:   *i2 = c ? y : x;
	cmpl	%r11d, %r8d	# _217, <retval>
	jle	.L200	#,
.L171:
# median.h:115:     int d = low + offset * 3;
	leal	(%rdx,%rax), %esi	#, _6
# median.h:116:     int e = low + offset * 4;
	leal	(%rsi,%rax), %ecx	#, _8
# median.h:117:     int f = low + offset * 5;
	leal	(%rcx,%rax), %edx	#, _10
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%esi, %rsi	# _6, _6
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%ecx, %rcx	# _8, _8
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rsi,4), %rsi	#, prephitmp_128
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rcx,4), %rbx	#, _108
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%rsi), %r11d	# *_104, _105
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%rbx), %ecx	# *_108, _109
# median.h:8:   *i1 = c ? x : y;
	cmpl	%ecx, %r11d	# _109, _105
	jle	.L172	#,
	movl	%ecx, %ebp	# _109, _109
	movl	%r11d, %ecx	# _105, _109
	movl	%ebp, %r11d	# _109, _105
	movq	%rbx, %rbp	# _108, _108
	movq	%rsi, %rbx	# prephitmp_128, _108
	movq	%rbp, %rsi	# _108, prephitmp_128
.L172:
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%edx, %rbp	# _10, _10
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rbp,4), %r12	#, _197
	movl	(%r12), %ebp	# *_197, _198
# median.h:8:   *i1 = c ? x : y;
	cmpl	%ebp, %ecx	# _198, _109
	jg	.L201	#,
	movl	%ecx, %r11d	# _109, _105
	movq	%rbx, %rsi	# _108, prephitmp_128
.L174:
# median.h:122:     int g = low + offset * 6;
	addl	%eax, %edx	# offset, _12
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%edx, %rcx	# _12, _12
# median.h:123:     int h = low + offset * 7;
	addl	%eax, %edx	# offset, tmp147
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%edx, %rdx	# tmp147, tmp148
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rcx,4), %rbp	#, _76
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rdx,4), %rbx	#, _80
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	0(%rbp), %ecx	# *_76, _77
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%rbx), %eax	# *_80, _81
# median.h:8:   *i1 = c ? x : y;
	cmpl	%eax, %ecx	# _81, _77
	jg	.L176	#,
	movl	%ecx, %edx	# _77, _77
	movl	%eax, %ecx	# _81, _77
	movl	%edx, %eax	# _77, _81
	movq	%rbp, %rdx	# _76, _76
	movq	%rbx, %rbp	# _80, _76
	movq	%rdx, %rbx	# _76, _80
.L176:
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%r9,4), %rdi	#, _178
	movl	(%rdi), %edx	# *_178, _179
# median.h:8:   *i1 = c ? x : y;
	cmpl	%edx, %ecx	# _179, _77
	jg	.L202	#,
	movl	%ecx, %eax	# _77, _81
	movq	%rbp, %rbx	# _76, _80
.L177:
	cmpl	%r8d, %r11d	# <retval>, _105
	jl	.L179	#,
	movq	%r10, %rcx	# prephitmp_169, prephitmp_169
	movl	%r11d, %r8d	# _105, <retval>
	movq	%rsi, %r10	# prephitmp_128, prephitmp_169
	movq	%rcx, %rsi	# prephitmp_169, prephitmp_128
.L179:
	cmpl	%eax, %r8d	# _81, <retval>
	jg	.L203	#,
	movq	%r10, %rsi	# prephitmp_169, prephitmp_128
.L180:
# swap.h:3:   *a = *b;
	movl	%edx, (%rsi)	# _179, *prephitmp_128
# swap.h:4:   *b = t;
	movl	%r8d, (%rdi)	# <retval>, *_178
# median.h:137: }
	movl	%r8d, %eax	# <retval>,
	popq	%rbx	#
	.cfi_remember_state
	.cfi_def_cfa_offset 24
	popq	%rbp	#
	.cfi_def_cfa_offset 16
	popq	%r12	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L188:
	.cfi_restore_state
# median.h:8:   *i1 = c ? x : y;
	movl	%ecx, %r8d	# _137, <retval>
	movq	%rsi, %r10	# _136, prephitmp_169
	jmp	.L171	#
	.p2align 4,,10
	.p2align 3
.L199:
	movl	%ecx, %r11d	# _137, _137
	movl	%r8d, %ecx	# <retval>, _137
	movl	%r11d, %r8d	# _137, <retval>
	movq	%rsi, %r11	# _136, _136
	movq	%r10, %rsi	# prephitmp_169, _136
	movq	%r11, %r10	# _136, prephitmp_169
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%edx, %r11	# _4, _4
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%r11,4), %rbx	#, _216
	movl	(%rbx), %r11d	# *_216, _217
# median.h:8:   *i1 = c ? x : y;
	cmpl	%r11d, %ecx	# _217, _137
	jle	.L188	#,
	jmp	.L204	#
	.p2align 4,,10
	.p2align 3
.L202:
# median.h:9:   *i2 = c ? y : x;
	cmpl	%edx, %eax	# _179, _81
	jg	.L177	#,
	movl	%edx, %eax	# _179, _81
	movq	%rdi, %rbx	# _178, _80
	jmp	.L177	#
	.p2align 4,,10
	.p2align 3
.L201:
	cmpl	%ebp, %r11d	# _198, _105
	jg	.L174	#,
	movl	%ebp, %r11d	# _198, _105
	movq	%r12, %rsi	# _197, prephitmp_128
	jmp	.L174	#
	.p2align 4,,10
	.p2align 3
.L203:
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%rsi), %r8d	# *prephitmp_172, <retval>
# median.h:9:   *i2 = c ? y : x;
	cmpl	%eax, %r8d	# _81, <retval>
	jg	.L180	#,
	movl	%eax, %r8d	# _81, <retval>
	movq	%rbx, %rsi	# _80, prephitmp_128
	jmp	.L180	#
	.p2align 4,,10
	.p2align 3
.L198:
	.cfi_def_cfa_offset 8
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
# median.h:104:     return median_of_three(array, low, high);
	movl	%r9d, %edx	# high,
	jmp	median_of_three	#
.L200:
	.cfi_def_cfa_offset 32
	.cfi_offset 3, -32
	.cfi_offset 6, -24
	.cfi_offset 12, -16
# median.h:9:   *i2 = c ? y : x;
	movl	%r11d, %r8d	# _217, <retval>
	movq	%rbx, %r10	# _216, prephitmp_169
	jmp	.L171	#
	.cfi_endproc
.LFE59:
	.size	median_of_three_of_median_of_three, .-median_of_three_of_median_of_three
	.p2align 4
	.globl	partition_quick_block
	.type	partition_quick_block, @function
partition_quick_block:
.LFB39:
	.cfi_startproc
	endbr64	
	pushq	%rbp	#
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movq	%rsp, %rbp	#,
	.cfi_def_cfa_register 6
	pushq	%r15	#
	pushq	%r14	#
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	movl	%edx, %r14d	# tmp454, high
	pushq	%r13	#
	pushq	%r12	#
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	movl	%esi, %r12d	# tmp453, low
	pushq	%rbx	#
	.cfi_offset 3, -56
	movq	%rdi, %rbx	# tmp452, array
	subq	$72, %rsp	#,
# blockquick.h:18: int partition_quick_block(int array[], int low, int high) {
	movl	%edx, -92(%rbp)	# high, %sfp
	movq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], tmp582
	movq	%rax, -56(%rbp)	# tmp582, D.39399
	xorl	%eax, %eax	# tmp582
# blockquick.h:19:   int pivot = median_of_three_of_median_of_three(array, low, high);
	call	median_of_three_of_median_of_three	#
# blockquick.h:23:   int offsetsL[blocksize], offsetsR[blocksize];
	movq	%rsp, %rdx	#, tmp309
# blockquick.h:21:   high--;
	leal	-1(%r14), %r10d	#, high
# blockquick.h:23:   int offsetsL[blocksize], offsetsR[blocksize];
	cmpq	%rdx, %rsp	# tmp309,
	je	.L207	#,
.L277:
	subq	$4096, %rsp	#,
	orq	$0, 4088(%rsp)	#,
	cmpq	%rdx, %rsp	# tmp309,
	jne	.L277	#,
.L207:
	subq	$512, %rsp	#,
	orq	$0, 504(%rsp)	#,
# blockquick.h:23:   int offsetsL[blocksize], offsetsR[blocksize];
	movq	%rsp, %rdx	#, tmp326
# blockquick.h:23:   int offsetsL[blocksize], offsetsR[blocksize];
	movq	%rsp, %rcx	#, tmp317
# blockquick.h:23:   int offsetsL[blocksize], offsetsR[blocksize];
	cmpq	%rdx, %rsp	# tmp326,
	je	.L210	#,
.L278:
	subq	$4096, %rsp	#,
	orq	$0, 4088(%rsp)	#,
	cmpq	%rdx, %rsp	# tmp326,
	jne	.L278	#,
.L210:
	subq	$512, %rsp	#,
	orq	$0, 504(%rsp)	#,
# blockquick.h:26:   while (high - low + 1 > 2 * blocksize) {
	movl	%r10d, %edx	# high, _27
	subl	%r12d, %edx	# low, _27
# blockquick.h:23:   int offsetsL[blocksize], offsetsR[blocksize];
	movq	%rsp, %rsi	#, tmp334
# blockquick.h:26:   while (high - low + 1 > 2 * blocksize) {
	cmpl	$255, %edx	#, _27
	jle	.L212	#,
# blockquick.h:24:   int startL = 0, startR = 0, numL = 0, numR = 0;
	movl	$0, -68(%rbp)	#, %sfp
# blockquick.h:24:   int startL = 0, startR = 0, numL = 0, numR = 0;
	movl	$0, -72(%rbp)	#, %sfp
# blockquick.h:24:   int startL = 0, startR = 0, numL = 0, numR = 0;
	movl	$0, -80(%rbp)	#, %sfp
# blockquick.h:24:   int startL = 0, startR = 0, numL = 0, numR = 0;
	movl	$0, -76(%rbp)	#, %sfp
	.p2align 4,,10
	.p2align 3
.L223:
# blockquick.h:27:     if (numL == 0) {
	movl	-72(%rbp), %r11d	# %sfp,
	testl	%r11d, %r11d	#
	je	.L279	#,
.L213:
# blockquick.h:34:     if (numR == 0) {
	movl	-68(%rbp), %r9d	# %sfp,
	testl	%r9d, %r9d	#
	je	.L280	#,
.L215:
# minmax.h:3: inline int min(int x, int y) { return (x < y) ? x : y; }
	movl	-72(%rbp), %edi	# %sfp, numL
	movl	-68(%rbp), %r15d	# %sfp, numR
	cmpl	%r15d, %edi	# numR, numL
	cmovle	%edi, %r15d	# numL,, _223
# blockquick.h:42:     for (int j = 0; j < num; j++) {
	testl	%r15d, %r15d	# _223
	jle	.L221	#,
	movslq	-80(%rbp), %rdx	# %sfp, startR
	movl	%eax, -84(%rbp)	# pivot, %sfp
	leaq	(%rsi,%rdx,4), %r13	#, _549
	movslq	-76(%rbp), %rdx	# %sfp, startL
	movslq	%r15d, %r14	# _223, _542
	leaq	(%rcx,%rdx,4), %r11	#, _546
	xorl	%edx, %edx	# ivtmp.489
	.p2align 4,,10
	.p2align 3
.L220:
# blockquick.h:43:       swap(&array[low + offsetsL[startL + j]],
	movl	(%r11,%rdx,4), %r8d	# MEM[base: _546, index: ivtmp.489_553, step: 4, offset: 0B], tmp352
# blockquick.h:44:            &array[high - offsetsR[startR + j]]);
	movl	%r10d, %edi	# high, tmp349
	subl	0(%r13,%rdx,4), %edi	# MEM[base: _549, index: ivtmp.489_553, step: 4, offset: 0B], tmp349
# blockquick.h:43:       swap(&array[low + offsetsL[startL + j]],
	addl	%r12d, %r8d	# low, tmp352
# blockquick.h:44:            &array[high - offsetsR[startR + j]]);
	movslq	%edi, %rdi	# tmp349, tmp350
# blockquick.h:43:       swap(&array[low + offsetsL[startL + j]],
	movslq	%r8d, %r8	# tmp352, tmp354
# blockquick.h:43:       swap(&array[low + offsetsL[startL + j]],
	leaq	(%rbx,%rdi,4), %rdi	#, _20
	leaq	(%rbx,%r8,4), %r8	#, _26
# swap.h:2:   int t = *a;
	movl	(%r8), %r9d	# *_26, t
# swap.h:3:   *a = *b;
	movl	(%rdi), %eax	# *_20, tmp602
# blockquick.h:42:     for (int j = 0; j < num; j++) {
	incq	%rdx	# ivtmp.489
# swap.h:3:   *a = *b;
	movl	%eax, (%r8)	# tmp602, *_26
# swap.h:4:   *b = t;
	movl	%r9d, (%rdi)	# t, *_20
# blockquick.h:42:     for (int j = 0; j < num; j++) {
	cmpq	%rdx, %r14	# ivtmp.489, _542
	jne	.L220	#,
	movl	-84(%rbp), %eax	# %sfp, pivot
.L221:
# blockquick.h:48:     startL += num;
	addl	%r15d, -76(%rbp)	# _223, %sfp
# blockquick.h:49:     startR += num;
	addl	%r15d, -80(%rbp)	# _223, %sfp
# blockquick.h:51:       low += blocksize;
	subl	%r15d, -72(%rbp)	# _223, %sfp
	leal	128(%r12), %edx	#, tmp446
	cmove	%edx, %r12d	# tmp446,, low
# blockquick.h:54:       high -= blocksize;
	subl	%r15d, -68(%rbp)	# _223, %sfp
	leal	-128(%r10), %edx	#, tmp448
	cmove	%edx, %r10d	# tmp448,, high
# blockquick.h:26:   while (high - low + 1 > 2 * blocksize) {
	movl	%r10d, %edx	# high, _27
	subl	%r12d, %edx	# low, _27
# blockquick.h:26:   while (high - low + 1 > 2 * blocksize) {
	cmpl	$255, %edx	#, _27
	jg	.L223	#,
# blockquick.h:60:   if (numR == 0 && numL == 0) {
	movl	-72(%rbp), %edi	# %sfp, tmp583
	orl	-68(%rbp), %edi	# %sfp, tmp583
	je	.L212	#,
# blockquick.h:75:   } else if (numR != 0) {
	movl	-68(%rbp), %r8d	# %sfp,
# blockquick.h:76:     shiftL = high - low - blocksize + 1;
	leal	-127(%rdx), %edi	#, shiftL
	movl	%edi, -84(%rbp)	# shiftL, %sfp
# blockquick.h:75:   } else if (numR != 0) {
	testl	%r8d, %r8d	#
	je	.L228	#,
# blockquick.h:79:     for (int j = 0; j < shiftL; j++) {
	testl	%edi, %edi	# shiftL
	jle	.L255	#,
	leal	-128(%rdx), %r9d	#, _567
	movl	-72(%rbp), %edi	# %sfp, numL
	movslq	%r12d, %rdx	# low, low
	leaq	(%rbx,%rdx,4), %r8	#, _573
	xorl	%edx, %edx	# ivtmp.479
.L229:
# blockquick.h:80:       offsetsL[numL] = j;
	movslq	%edi, %r11	# numL, numL
	movl	%edx, (%rcx,%r11,4)	# ivtmp.479, (*offsetsL.0_202)[numL_310]
# blockquick.h:81:       numL += pivot <= array[low + j];
	xorl	%r11d, %r11d	# tmp381
	cmpl	%eax, (%r8,%rdx,4)	# pivot, MEM[base: _573, index: ivtmp.479_578, step: 4, offset: 0B]
	setge	%r11b	#, tmp381
# blockquick.h:81:       numL += pivot <= array[low + j];
	addl	%r11d, %edi	# tmp381, numL
	movq	%rdx, %r11	# ivtmp.479, ivtmp.479
# blockquick.h:79:     for (int j = 0; j < shiftL; j++) {
	incq	%rdx	# ivtmp.479
	cmpq	%r11, %r9	# ivtmp.479, _567
	jne	.L229	#,
# blockquick.h:77:     shiftR = blocksize;
	movl	%edi, -72(%rbp)	# numL, %sfp
	movl	$128, -88(%rbp)	#, %sfp
# blockquick.h:78:     startL = 0;
	movl	$0, -76(%rbp)	#, %sfp
.L227:
# minmax.h:3: inline int min(int x, int y) { return (x < y) ? x : y; }
	movl	-72(%rbp), %eax	# %sfp, numL
	movl	-68(%rbp), %r14d	# %sfp, numR
	cmpl	%r14d, %eax	# numR, numL
	cmovle	%eax, %r14d	# numL,, _56
# blockquick.h:103:   startR += num;
	movslq	-80(%rbp), %rax	# %sfp,
	leal	(%rax,%r14), %r15d	#, prephitmp_665
# blockquick.h:95:   for (int j = 0; j < num; j++) {
	testl	%r14d, %r14d	# _56
	jle	.L232	#,
	leaq	(%rsi,%rax,4), %r11	#, _602
	movq	%rcx, -104(%rbp)	# tmp317, %sfp
	movslq	-76(%rbp), %rax	# %sfp, startL
	movslq	%r14d, %r13	# _56, _593
	leaq	(%rcx,%rax,4), %r9	#, _597
	xorl	%eax, %eax	# ivtmp.466
	.p2align 4,,10
	.p2align 3
.L233:
# blockquick.h:96:     swap(&array[low + offsetsL[startL + j]],
	movl	(%r9,%rax,4), %edi	# MEM[base: _597, index: ivtmp.466_606, step: 4, offset: 0B], tmp395
# blockquick.h:97:          &array[high - offsetsR[startR + j]]);
	movl	%r10d, %edx	# high, tmp392
	subl	(%r11,%rax,4), %edx	# MEM[base: _602, index: ivtmp.466_606, step: 4, offset: 0B], tmp392
# blockquick.h:96:     swap(&array[low + offsetsL[startL + j]],
	addl	%r12d, %edi	# low, tmp395
# blockquick.h:97:          &array[high - offsetsR[startR + j]]);
	movslq	%edx, %rdx	# tmp392, tmp393
# blockquick.h:96:     swap(&array[low + offsetsL[startL + j]],
	movslq	%edi, %rdi	# tmp395, tmp397
# blockquick.h:96:     swap(&array[low + offsetsL[startL + j]],
	leaq	(%rbx,%rdx,4), %rdx	#, _76
	leaq	(%rbx,%rdi,4), %rdi	#, _82
# swap.h:2:   int t = *a;
	movl	(%rdi), %r8d	# *_82, t
# swap.h:3:   *a = *b;
	movl	(%rdx), %ecx	# *_76, tmp626
# blockquick.h:95:   for (int j = 0; j < num; j++) {
	incq	%rax	# ivtmp.466
# swap.h:3:   *a = *b;
	movl	%ecx, (%rdi)	# tmp626, *_82
# swap.h:4:   *b = t;
	movl	%r8d, (%rdx)	# t, *_76
# blockquick.h:95:   for (int j = 0; j < num; j++) {
	cmpq	%rax, %r13	# ivtmp.466, _593
	jne	.L233	#,
	movq	-104(%rbp), %rcx	# %sfp, tmp317
.L232:
# blockquick.h:101:   numR -= num;
	movl	-68(%rbp), %edx	# %sfp, numR
# blockquick.h:136:     swap(&array[pivot_position], &array[low]);
	movslq	-92(%rbp), %rax	# %sfp, high
# blockquick.h:101:   numR -= num;
	subl	%r14d, %edx	# _56, numR
# blockquick.h:136:     swap(&array[pivot_position], &array[low]);
	leaq	(%rbx,%rax,4), %rax	#, _735
# blockquick.h:104:   if (numL == 0) {
	cmpl	-72(%rbp), %r14d	# %sfp, _56
	jne	.L234	#,
# blockquick.h:105:     low += shiftL;
	addl	-84(%rbp), %r12d	# %sfp, <retval>
# blockquick.h:107:   if (numR == 0) {
	testl	%edx, %edx	# numR
	jne	.L281	#,
.L235:
# blockquick.h:136:     swap(&array[pivot_position], &array[low]);
	movslq	%r12d, %rdx	# <retval>, <retval>
# blockquick.h:136:     swap(&array[pivot_position], &array[low]);
	leaq	(%rbx,%rdx,4), %rdx	#, _127
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# *_735, t
# swap.h:3:   *a = *b;
	movl	(%rdx), %esi	#* _127, _277
# swap.h:3:   *a = *b;
	movl	%esi, (%rax)	# _277, *_735
# swap.h:4:   *b = t;
	movl	%ecx, (%rdx)	# t,* _127
.L205:
# blockquick.h:139: }
	movq	-56(%rbp), %rax	# D.39399, tmp584
	subq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], tmp584
	jne	.L282	#,
	leaq	-40(%rbp), %rsp	#,
	popq	%rbx	#
	movl	%r12d, %eax	# <retval>,
	popq	%r12	#
	popq	%r13	#
	popq	%r14	#
	popq	%r15	#
	popq	%rbp	#
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret	
.L280:
	.cfi_restore_state
	movslq	%r10d, %rdx	# high, high
	leaq	(%rbx,%rdx,4), %r8	#, ivtmp.501
# blockquick.h:34:     if (numR == 0) {
	xorl	%edi, %edi	# numR
# blockquick.h:36:       for (int i = 0; i < blocksize; i++) {
	xorl	%edx, %edx	# i
	.p2align 4,,10
	.p2align 3
.L216:
# blockquick.h:37:         offsetsR[numR] = i;
	movslq	%edi, %r9	# numR, numR
	movl	%edx, (%rsi,%r9,4)	# i, (*offsetsR.1_205)[numR_381]
# blockquick.h:38:         numR += pivot >= array[high - i];
	xorl	%r9d, %r9d	# tmp343
	cmpl	%eax, (%r8)	# pivot, MEM[base: _533, offset: 0B]
	setle	%r9b	#, tmp343
# blockquick.h:36:       for (int i = 0; i < blocksize; i++) {
	incl	%edx	# i
# blockquick.h:38:         numR += pivot >= array[high - i];
	addl	%r9d, %edi	# tmp343, numR
# blockquick.h:36:       for (int i = 0; i < blocksize; i++) {
	subq	$4, %r8	#, ivtmp.501
	cmpl	$128, %edx	#, i
	jne	.L216	#,
# blockquick.h:35:       startR = 0;
	movl	$0, -80(%rbp)	#, %sfp
# blockquick.h:38:         numR += pivot >= array[high - i];
	movl	%edi, -68(%rbp)	# numR, %sfp
	jmp	.L215	#
.L279:
	movslq	%r12d, %rdx	# low, low
	leaq	(%rbx,%rdx,4), %r9	#, _527
# blockquick.h:27:     if (numL == 0) {
	xorl	%edi, %edi	# numL
	xorl	%edx, %edx	# ivtmp.503
	.p2align 4,,10
	.p2align 3
.L214:
# blockquick.h:30:         offsetsL[numL] = i;
	movslq	%edi, %r8	# numL, numL
	movl	%edx, (%rcx,%r8,4)	# ivtmp.503, (*offsetsL.0_202)[numL_380]
# blockquick.h:31:         numL += pivot <= array[low + i];
	xorl	%r8d, %r8d	# tmp338
	cmpl	%eax, (%r9,%rdx,4)	# pivot, MEM[base: _527, index: ivtmp.503_532, step: 4, offset: 0B]
	setge	%r8b	#, tmp338
# blockquick.h:29:       for (int i = 0; i < blocksize; i++) {
	incq	%rdx	# ivtmp.503
# blockquick.h:31:         numL += pivot <= array[low + i];
	addl	%r8d, %edi	# tmp338, numL
# blockquick.h:29:       for (int i = 0; i < blocksize; i++) {
	cmpq	$128, %rdx	#, ivtmp.503
	jne	.L214	#,
# blockquick.h:28:       startL = 0;
	movl	$0, -76(%rbp)	#, %sfp
# blockquick.h:31:         numL += pivot <= array[low + i];
	movl	%edi, -72(%rbp)	# numL, %sfp
	jmp	.L213	#
.L212:
# blockquick.h:61:     shiftL = (high - low + 1) / 2;
	incl	%edx	# _30
# blockquick.h:61:     shiftL = (high - low + 1) / 2;
	movl	%edx, %r9d	# _30, tmp357
	shrl	$31, %r9d	#, tmp357
	addl	%edx, %r9d	# _30, tmp358
	sarl	%r9d	# tmp359
# blockquick.h:62:     shiftR = high - low + 1 - shiftL;
	movl	%edx, %edi	# _30, shiftR
	subl	%r9d, %edi	# tmp359, shiftR
# blockquick.h:61:     shiftL = (high - low + 1) / 2;
	movl	%r9d, -84(%rbp)	# tmp359, %sfp
# blockquick.h:62:     shiftR = high - low + 1 - shiftL;
	movl	%edi, -88(%rbp)	# shiftR, %sfp
# blockquick.h:65:     for (int j = 0; j < shiftL; j++) {
	cmpl	$1, %edx	#, _30
	jle	.L253	#,
	movslq	%r10d, %rdx	# high, high
	leaq	(%rbx,%rdx,4), %rdi	#, ivtmp.476
	movslq	%r12d, %rdx	# low, low
	leaq	(%rbx,%rdx,4), %r11	#, _581
	xorl	%r13d, %r13d	# numR
	xorl	%edx, %edx	# ivtmp.473
	xorl	%r8d, %r8d	# numL
	.p2align 4,,10
	.p2align 3
.L226:
# blockquick.h:66:       offsetsL[numL] = j;
	movslq	%r8d, %r14	# numL, numL
	movl	%edx, (%rcx,%r14,4)	# ivtmp.473, (*offsetsL.0_202)[numL_312]
# blockquick.h:67:       numL += pivot <= array[low + j];
	xorl	%r14d, %r14d	# tmp365
	cmpl	%eax, (%r11,%rdx,4)	# pivot, MEM[base: _581, index: ivtmp.473_592, step: 4, offset: 0B]
	setge	%r14b	#, tmp365
# blockquick.h:67:       numL += pivot <= array[low + j];
	addl	%r14d, %r8d	# tmp365, numL
# blockquick.h:68:       offsetsR[numR] = j;
	movslq	%r13d, %r14	# numR, numR
	movl	%edx, (%rsi,%r14,4)	# ivtmp.473, (*offsetsR.1_205)[numR_331]
# blockquick.h:69:       numR += pivot >= array[high - j];
	xorl	%r14d, %r14d	# tmp368
	cmpl	%eax, (%rdi)	# pivot, MEM[base: _580, offset: 0B]
	setle	%r14b	#, tmp368
# blockquick.h:65:     for (int j = 0; j < shiftL; j++) {
	incq	%rdx	# ivtmp.473
# blockquick.h:69:       numR += pivot >= array[high - j];
	addl	%r14d, %r13d	# tmp368, numR
# blockquick.h:65:     for (int j = 0; j < shiftL; j++) {
	subq	$4, %rdi	#, ivtmp.476
	cmpl	%edx, %r9d	# ivtmp.473, tmp359
	jg	.L226	#,
	movl	%r8d, -72(%rbp)	# numL, %sfp
	movl	%r13d, -68(%rbp)	# numR, %sfp
.L225:
# blockquick.h:71:     if (shiftL < shiftR) {
	movl	-88(%rbp), %r11d	# %sfp, shiftR
	cmpl	%r11d, %r9d	# shiftR, tmp359
	jge	.L254	#,
# blockquick.h:72:       offsetsR[numR] = shiftR - 1;
	movslq	-68(%rbp), %rdx	# %sfp,
# blockquick.h:72:       offsetsR[numR] = shiftR - 1;
	leal	-1(%r11), %edi	#, tmp371
# blockquick.h:72:       offsetsR[numR] = shiftR - 1;
	movq	%rdx, %r14	#,
# blockquick.h:72:       offsetsR[numR] = shiftR - 1;
	movl	%edi, (%rsi,%rdx,4)	# tmp371, (*offsetsR.1_205)[numR_333]
# blockquick.h:73:       numR += pivot >= array[high - shiftR + 1];
	movl	%r10d, %edx	# high, tmp372
	subl	%r11d, %edx	# shiftR, tmp372
# blockquick.h:73:       numR += pivot >= array[high - shiftR + 1];
	movslq	%edx, %rdx	# tmp372, tmp373
# blockquick.h:73:       numR += pivot >= array[high - shiftR + 1];
	cmpl	%eax, 4(%rbx,%rdx,4)	# pivot, *_52
	setle	%al	#, tmp375
	movzbl	%al, %eax	# tmp375, tmp375
# blockquick.h:73:       numR += pivot >= array[high - shiftR + 1];
	addl	%eax, %r14d	# tmp375, numR
	movl	%r14d, -68(%rbp)	# numR, %sfp
# blockquick.h:64:     startR = 0;
	movl	$0, -80(%rbp)	#, %sfp
# blockquick.h:63:     startL = 0;
	movl	$0, -76(%rbp)	#, %sfp
	jmp	.L227	#
.L234:
# blockquick.h:108:     high -= shiftR;
	movl	%r10d, %esi	# high, tmp450
	subl	-88(%rbp), %esi	# %sfp, tmp450
	testl	%edx, %edx	# numR
	cmove	%esi, %r10d	# tmp450,, high
# blockquick.h:112:     int lower = startL + numL - 1;
	movl	-72(%rbp), %edi	# %sfp, numL
# blockquick.h:102:   startL += num;
	movl	-76(%rbp), %esi	# %sfp, startL
	addl	%esi, %r14d	# startL, startL
# blockquick.h:112:     int lower = startL + numL - 1;
	leal	-1(%rdi,%rsi), %esi	#, lower
# blockquick.h:113:     int upper = high - low;
	movl	%r10d, %edi	# high, upper
	subl	%r12d, %edi	# low, upper
	movslq	%esi, %rdx	# lower, ivtmp.436
# blockquick.h:114:     while (lower >= startL && offsetsL[lower] == upper) {
	cmpl	%esi, %r14d	# lower, startL
	jle	.L239	#,
	jmp	.L238	#
	.p2align 4,,10
	.p2align 3
.L240:
	decq	%rdx	# ivtmp.436
# blockquick.h:115:       upper--;
	decl	%edi	# upper
# blockquick.h:114:     while (lower >= startL && offsetsL[lower] == upper) {
	cmpl	%edx, %r14d	# ivtmp.436, startL
	jg	.L275	#,
.L239:
	movl	%edx, %r10d	# ivtmp.436, _648
# blockquick.h:114:     while (lower >= startL && offsetsL[lower] == upper) {
	cmpl	%edi, (%rcx,%rdx,4)	# upper, MEM[base: offsetsL.0_202, index: ivtmp.436_672, step: 4, offset: 0B]
	je	.L240	#,
# blockquick.h:118:     while (lower >= startL) {
	cmpl	%edx, %r14d	# _648, startL
	jg	.L275	#,
	movslq	%r12d, %r8	# low, low
	movslq	%edi, %rsi	# upper, upper
	addq	%r8, %rsi	# low, tmp404
	movslq	%edx, %rdx	# _648, ivtmp.424
	subq	%rdx, %rsi	# ivtmp.424, tmp408
	leaq	(%rbx,%rsi,4), %r8	#, _690
	.p2align 4,,10
	.p2align 3
.L242:
# blockquick.h:119:       swap(&array[low + upper--], &array[low + offsetsL[lower--]]);
	movl	(%rcx,%rdx,4), %esi	# MEM[base: offsetsL.0_202, index: ivtmp.424_669, step: 4, offset: 0B], tmp410
# swap.h:2:   int t = *a;
	movl	(%r8,%rdx,4), %r9d	# MEM[base: _690, index: ivtmp.424_669, step: 4, offset: 0B], t
# blockquick.h:119:       swap(&array[low + upper--], &array[low + offsetsL[lower--]]);
	addl	%r12d, %esi	# low, tmp410
	movslq	%esi, %rsi	# tmp410, tmp412
# blockquick.h:119:       swap(&array[low + upper--], &array[low + offsetsL[lower--]]);
	leaq	(%rbx,%rsi,4), %rsi	#, _90
# swap.h:3:   *a = *b;
	movl	(%rsi), %r11d	# *_90, _269
# swap.h:3:   *a = *b;
	movl	%r11d, (%r8,%rdx,4)	# _269, MEM[base: _690, index: ivtmp.424_669, step: 4, offset: 0B]
# blockquick.h:118:     while (lower >= startL) {
	decq	%rdx	# ivtmp.424
# swap.h:4:   *b = t;
	movl	%r9d, (%rsi)	# t, *_90
# blockquick.h:118:     while (lower >= startL) {
	cmpl	%edx, %r14d	# ivtmp.424, startL
	jle	.L242	#,
	subl	%r10d, %r14d	# _648, tmp415
	leal	-1(%rdi,%r14), %r10d	#, _703
# blockquick.h:121:     swap(&array[pivot_position], &array[low + upper + 1]);
	addl	%r12d, %r10d	# low, high
.L238:
# blockquick.h:121:     swap(&array[pivot_position], &array[low + upper + 1]);
	movslq	%r10d, %rdx	# high, high
# blockquick.h:121:     swap(&array[pivot_position], &array[low + upper + 1]);
	leaq	4(%rbx,%rdx,4), %rdx	#, _100
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# *_735, t
# swap.h:3:   *a = *b;
	movl	(%rdx), %esi	# *_100, _271
# blockquick.h:122:     return low + upper + 1;
	leal	1(%r10), %r12d	#, <retval>
# swap.h:3:   *a = *b;
	movl	%esi, (%rax)	# _271, *_735
# swap.h:4:   *b = t;
	movl	%ecx, (%rdx)	# t, *_100
# blockquick.h:122:     return low + upper + 1;
	jmp	.L205	#
.L281:
# blockquick.h:124:     int lower = startR + numR - 1;
	movl	-80(%rbp), %edx	# %sfp, startR
	movl	-68(%rbp), %ecx	# %sfp, numR
# blockquick.h:125:     int upper = high - low;
	movl	%r10d, %edi	# high, upper
# blockquick.h:124:     int lower = startR + numR - 1;
	leal	-1(%rcx,%rdx), %ecx	#, lower
# blockquick.h:125:     int upper = high - low;
	subl	%r12d, %edi	# <retval>, upper
	movslq	%ecx, %rdx	# lower, ivtmp.458
# blockquick.h:126:     while (lower >= startR && offsetsR[lower] == upper) {
	cmpl	%r15d, %ecx	# prephitmp_665, lower
	jge	.L244	#,
	jmp	.L235	#
	.p2align 4,,10
	.p2align 3
.L246:
	decq	%rdx	# ivtmp.458
# blockquick.h:127:       upper--;
	decl	%edi	# upper
# blockquick.h:126:     while (lower >= startR && offsetsR[lower] == upper) {
	cmpl	%edx, %r15d	# ivtmp.458, prephitmp_665
	jg	.L276	#,
.L244:
	movl	%edx, %r9d	# ivtmp.458, _610
# blockquick.h:126:     while (lower >= startR && offsetsR[lower] == upper) {
	cmpl	%edi, (%rsi,%rdx,4)	# upper, MEM[base: offsetsR.1_205, index: ivtmp.458_614, step: 4, offset: 0B]
	je	.L246	#,
# blockquick.h:130:     while (lower >= startR) {
	cmpl	%r15d, %edx	# prephitmp_665, _610
	jl	.L276	#,
	movslq	%edx, %rdx	# _610, lower
	leaq	(%rsi,%rdx,4), %rsi	#, ivtmp.449
	movslq	%r10d, %rcx	# high, high
	movslq	%edi, %rdx	# upper, upper
	movl	%r9d, %r8d	# _610, tmp425
	subq	%rdx, %rcx	# upper, _635
	subl	%r15d, %r8d	# prephitmp_665, tmp425
	leaq	(%rbx,%rcx,4), %rdx	#, ivtmp.450
	addq	%r8, %rcx	# tmp425, tmp426
	leaq	4(%rbx,%rcx,4), %r12	#, _615
	.p2align 4,,10
	.p2align 3
.L248:
# blockquick.h:131:       swap(&array[high - upper--], &array[high - offsetsR[lower--]]);
	movl	%r10d, %ecx	# high, tmp429
	subl	(%rsi), %ecx	# MEM[base: _632, offset: 0B], tmp429
	movslq	%ecx, %rcx	# tmp429, tmp430
# blockquick.h:131:       swap(&array[high - upper--], &array[high - offsetsR[lower--]]);
	leaq	(%rbx,%rcx,4), %rcx	#, _112
# swap.h:3:   *a = *b;
	movl	(%rcx), %r11d	# *_112, _273
# swap.h:2:   int t = *a;
	movl	(%rdx), %r8d	# MEM[base: _631, offset: 0B], t
# swap.h:3:   *a = *b;
	movl	%r11d, (%rdx)	# _273, MEM[base: _631, offset: 0B]
# blockquick.h:130:     while (lower >= startR) {
	addq	$4, %rdx	#, ivtmp.450
# swap.h:4:   *b = t;
	movl	%r8d, (%rcx)	# t, *_112
# blockquick.h:130:     while (lower >= startR) {
	subq	$4, %rsi	#, ivtmp.449
	cmpq	%rdx, %r12	# ivtmp.450, _615
	jne	.L248	#,
	subl	%r9d, %r15d	# _610, tmp433
	leal	-1(%rdi,%r15), %edx	#, _693
# blockquick.h:133:     swap(&array[pivot_position], &array[high - upper]);
	subl	%edx, %r10d	# _693, high
	movl	%r10d, %r12d	# high, <retval>
	jmp	.L235	#
.L254:
# blockquick.h:64:     startR = 0;
	movl	$0, -80(%rbp)	#, %sfp
# blockquick.h:63:     startL = 0;
	movl	$0, -76(%rbp)	#, %sfp
	jmp	.L227	#
.L228:
	movl	%edi, %r11d	# shiftL, shiftL
# blockquick.h:87:     for (int j = 0; j < shiftR; j++) {
	testl	%edi, %edi	# shiftL
	jle	.L230	#,
	movslq	%r10d, %rdx	# high, high
	leaq	(%rbx,%rdx,4), %r8	#, ivtmp.486
	xorl	%edi, %edi	# numR
# blockquick.h:87:     for (int j = 0; j < shiftR; j++) {
	xorl	%edx, %edx	# j
.L231:
# blockquick.h:88:       offsetsR[numR] = j;
	movslq	%edi, %r9	# numR, numR
	movl	%edx, (%rsi,%r9,4)	# j, (*offsetsR.1_205)[numR_336]
# blockquick.h:89:       numR += pivot >= array[high - j];
	xorl	%r9d, %r9d	# tmp386
	cmpl	%eax, (%r8)	# pivot, MEM[base: _559, offset: 0B]
	setle	%r9b	#, tmp386
# blockquick.h:87:     for (int j = 0; j < shiftR; j++) {
	incl	%edx	# j
# blockquick.h:89:       numR += pivot >= array[high - j];
	addl	%r9d, %edi	# tmp386, numR
# blockquick.h:87:     for (int j = 0; j < shiftR; j++) {
	subq	$4, %r8	#, ivtmp.486
	cmpl	%r11d, %edx	# shiftL, j
	jne	.L231	#,
	movl	-84(%rbp), %eax	# %sfp, shiftL
# blockquick.h:86:     startR = 0;
	movl	$0, -80(%rbp)	#, %sfp
	movl	%eax, -88(%rbp)	# shiftL, %sfp
# blockquick.h:89:       numR += pivot >= array[high - j];
	movl	%edi, -68(%rbp)	# numR, %sfp
# blockquick.h:85:     shiftL = blocksize;
	movl	$128, -84(%rbp)	#, %sfp
	jmp	.L227	#
.L275:
# blockquick.h:119:       swap(&array[low + upper--], &array[low + offsetsL[lower--]]);
	leal	(%r12,%rdi), %r10d	#, high
	jmp	.L238	#
.L276:
# blockquick.h:131:       swap(&array[high - upper--], &array[high - offsetsR[lower--]]);
	subl	%edi, %r10d	# upper, high
	movl	%r10d, %r12d	# high, <retval>
	jmp	.L235	#
.L253:
# blockquick.h:65:     for (int j = 0; j < shiftL; j++) {
	movl	$0, -68(%rbp)	#, %sfp
	movl	$0, -72(%rbp)	#, %sfp
	jmp	.L225	#
.L255:
# blockquick.h:77:     shiftR = blocksize;
	movl	$128, -88(%rbp)	#, %sfp
# blockquick.h:78:     startL = 0;
	movl	$0, -76(%rbp)	#, %sfp
	jmp	.L227	#
.L230:
# minmax.h:3: inline int min(int x, int y) { return (x < y) ? x : y; }
	movl	-72(%rbp), %eax	# %sfp, numL
	movl	-68(%rbp), %r14d	# %sfp, numR
# blockquick.h:86:     startR = 0;
	movl	$0, -80(%rbp)	#, %sfp
# minmax.h:3: inline int min(int x, int y) { return (x < y) ? x : y; }
	cmpl	%r14d, %eax	# numR, numL
	cmovle	%eax, %r14d	# numL,, _56
	movl	-84(%rbp), %eax	# %sfp, shiftL
	movl	%r14d, %r15d	# _56, prephitmp_665
	movl	%eax, -88(%rbp)	# shiftL, %sfp
# blockquick.h:85:     shiftL = blocksize;
	movl	$128, -84(%rbp)	#, %sfp
	jmp	.L232	#
.L282:
# blockquick.h:139: }
	call	__stack_chk_fail@PLT	#
	.cfi_endproc
.LFE39:
	.size	partition_quick_block, .-partition_quick_block
	.p2align 4
	.globl	sort_quick_block
	.type	sort_quick_block, @function
sort_quick_block:
.LFB40:
	.cfi_startproc
	endbr64	
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$72, %rsp	#,
	.cfi_def_cfa_offset 128
# blockquick.h:141: void sort_quick_block(int array[], int low, int high) {
	movl	%edx, 16(%rsp)	# high, %sfp
# blockquick.h:142:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jge	.L415	#,
	movl	%edx, %eax	# tmp295, high
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	subl	%esi, %eax	# low, _232
	movq	%rdi, %rbx	# tmp293, array
	movl	%esi, %ebp	# tmp294, low
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _232
	jle	.L286	#,
	movl	%esi, %r12d	# low, low
	movq	%rdi, %rbp	# array, array
.L285:
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	16(%rsp), %edx	# %sfp,
	movl	%r12d, %esi	# low,
	movq	%rbp, %rdi	# array,
	call	partition_quick_block	#
	movl	%eax, 40(%rsp)	# pi, %sfp
# blockquick.h:145:       sort_quick_block(array, low, pi - 1);
	decl	%eax	# _2
	movl	%eax, 8(%rsp)	# _2, %sfp
# blockquick.h:142:   if (low < high) {
	cmpl	%r12d, %eax	# low, _2
	jle	.L294	#,
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	subl	%r12d, %eax	# low, _169
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _169
	jle	.L291	#,
	movl	%r12d, %r15d	# low, low
	movq	%rbp, %r12	# array, array
.L290:
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	8(%rsp), %edx	# %sfp,
	movl	%r15d, %esi	# low,
	movq	%r12, %rdi	# array,
	call	partition_quick_block	#
	movl	%eax, 44(%rsp)	# pi, %sfp
# blockquick.h:145:       sort_quick_block(array, low, pi - 1);
	decl	%eax	# _22
	movl	%eax, 12(%rsp)	# _22, %sfp
# blockquick.h:142:   if (low < high) {
	cmpl	%r15d, %eax	# low, _22
	jle	.L299	#,
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	subl	%r15d, %eax	# low, _106
	movq	%r12, %r13	# array, array
	movl	%r15d, %r14d	# low, low
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _106
	jle	.L296	#,
.L295:
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	12(%rsp), %edx	# %sfp,
	movl	%r14d, %esi	# low,
	movq	%r13, %rdi	# array,
	call	partition_quick_block	#
# blockquick.h:145:       sort_quick_block(array, low, pi - 1);
	leal	-1(%rax), %r15d	#, _31
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	%eax, 48(%rsp)	# pi, %sfp
# blockquick.h:142:   if (low < high) {
	cmpl	%r14d, %r15d	# low, _31
	jle	.L304	#,
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	%r15d, %eax	# _31, _69
	subl	%r14d, %eax	# low, _69
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _69
	jle	.L301	#,
	movl	%r15d, 20(%rsp)	# _31, %sfp
	movl	%r14d, %r15d	# low, low
.L300:
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	20(%rsp), %edx	# %sfp,
	movl	%r15d, %esi	# low,
	movq	%r13, %rdi	# array,
	call	partition_quick_block	#
# blockquick.h:145:       sort_quick_block(array, low, pi - 1);
	leal	-1(%rax), %r12d	#, _40
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	%eax, 52(%rsp)	# pi, %sfp
# blockquick.h:142:   if (low < high) {
	cmpl	%r15d, %r12d	# low, _40
	jle	.L309	#,
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	%r12d, %eax	# _40, _42
	subl	%r15d, %eax	# low, _42
	movl	%r15d, %r14d	# low, low
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _42
	jle	.L306	#,
.L305:
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	%r12d, %edx	# _40,
	movl	%r14d, %esi	# low,
	movq	%r13, %rdi	# array,
	call	partition_quick_block	#
# blockquick.h:145:       sort_quick_block(array, low, pi - 1);
	leal	-1(%rax), %r15d	#, _49
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	%eax, 56(%rsp)	# pi, %sfp
# blockquick.h:142:   if (low < high) {
	cmpl	%r14d, %r15d	# low, _49
	jle	.L314	#,
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	%r15d, %eax	# _49, _56
	subl	%r14d, %eax	# low, _56
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _56
	jle	.L311	#,
	movl	%r12d, 24(%rsp)	# _40, %sfp
	movl	%r14d, %r12d	# low, low
.L310:
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	%r15d, %edx	# _49,
	movl	%r12d, %esi	# low,
	movq	%r13, %rdi	# array,
	call	partition_quick_block	#
# blockquick.h:145:       sort_quick_block(array, low, pi - 1);
	leal	-1(%rax), %ebx	#, _58
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	%eax, 60(%rsp)	# pi, %sfp
# blockquick.h:142:   if (low < high) {
	cmpl	%r12d, %ebx	# low, _58
	jle	.L319	#,
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	%ebx, %eax	# _58, _65
	subl	%r12d, %eax	# low, _65
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _65
	jle	.L316	#,
	movl	%r15d, 28(%rsp)	# _49, %sfp
.L315:
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	%ebx, %edx	# _58,
	movl	%r12d, %esi	# low,
	movq	%r13, %rdi	# array,
	call	partition_quick_block	#
# blockquick.h:145:       sort_quick_block(array, low, pi - 1);
	leal	-1(%rax), %r15d	#, _67
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	%eax, %ebp	# tmp302, pi
# blockquick.h:142:   if (low < high) {
	cmpl	%r12d, %r15d	# low, _67
	jle	.L324	#,
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	%r15d, %eax	# _67, _170
	subl	%r12d, %eax	# low, _170
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _170
	jle	.L321	#,
	movl	%ebx, 32(%rsp)	# _58, %sfp
	movl	%ebp, 36(%rsp)	# pi, %sfp
	movl	%r15d, %ebx	# _67, _67
	movq	%r13, %rbp	# array, array
.L320:
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	%ebx, %edx	# _67,
	movl	%r12d, %esi	# low,
	movq	%rbp, %rdi	# array,
	call	partition_quick_block	#
# blockquick.h:145:       sort_quick_block(array, low, pi - 1);
	leal	-1(%rax), %r14d	#, _76
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	%eax, %r13d	# tmp303, pi
# blockquick.h:142:   if (low < high) {
	cmpl	%r12d, %r14d	# low, _76
	jle	.L328	#,
.L327:
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	%r14d, %eax	# _76, _83
	subl	%r12d, %eax	# low, _83
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _83
	jle	.L326	#,
# blockquick.h:144:       int pi = partition_quick_block(array, low, high);
	movl	%r12d, %esi	# low,
	movl	%r14d, %edx	# _76,
	movq	%rbp, %rdi	# array,
	call	partition_quick_block	#
	movl	%eax, %r15d	# tmp304, pi
# blockquick.h:145:       sort_quick_block(array, low, pi - 1);
	movl	%r12d, %esi	# low,
	leal	-1(%rax), %edx	#, tmp247
	movq	%rbp, %rdi	# array,
# blockquick.h:146:       sort_quick_block(array, pi + 1, high);
	leal	1(%r15), %r12d	#, low
# blockquick.h:145:       sort_quick_block(array, low, pi - 1);
	call	sort_quick_block	#
# blockquick.h:142:   if (low < high) {
	cmpl	%r12d, %r14d	# low, _76
	jg	.L327	#,
	.p2align 4,,10
	.p2align 3
.L328:
# blockquick.h:146:       sort_quick_block(array, pi + 1, high);
	leal	1(%r13), %r12d	#, low
# blockquick.h:142:   if (low < high) {
	cmpl	%r12d, %ebx	# low, _67
	jle	.L417	#,
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	%ebx, %eax	# _67, _170
	subl	%r12d, %eax	# low, _170
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _170
	jg	.L320	#,
	movq	%rbp, %r13	# array, array
	movl	32(%rsp), %ebx	# %sfp, _58
	movl	36(%rsp), %ebp	# %sfp, pi
.L321:
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	movslq	%r12d, %r12	# low, low
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	leaq	0(%r13,%r12,4), %r9	#, _81
	leaq	4(%r9), %rsi	#, ivtmp.691
	cltq
	xorl	%ecx, %ecx	# ivtmp.688
.L336:
	leaq	0(,%rcx,4), %rdx	#, tmp255
	leaq	-4(%rsi), %r8	#, tmp254
# insertionssort.h:6:     element = array[i];
	movl	(%rsi), %r10d	# MEM[base: _360, offset: 0B], element
	subq	%rdx, %r8	# tmp255, _368
	movq	%rsi, %rdx	# ivtmp.691, ivtmp.680
.L333:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rdx), %r11d	# MEM[base: _378, offset: -4B], _122
	movq	%rdx, %rdi	# ivtmp.680, _378
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r11d, %r10d	# _122, element
	jge	.L334	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r11d, (%rdx)	# _122, MEM[base: _378, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rdi), %rdx	#, ivtmp.680
	cmpq	%rdx, %r8	# ivtmp.680, _368
	jne	.L333	#,
	movq	%r9, %rdi	# _81, _378
.L334:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%rcx	# ivtmp.688
# insertionssort.h:13:     array[j + 1] = element;
	movl	%r10d, (%rdi)	# element, *prephitmp_684
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %rsi	#, ivtmp.691
	cmpq	%rcx, %rax	# ivtmp.688, _355
	jne	.L336	#,
.L324:
# blockquick.h:146:       sort_quick_block(array, pi + 1, high);
	leal	1(%rbp), %r12d	#, low
# blockquick.h:142:   if (low < high) {
	cmpl	%r12d, %ebx	# low, _58
	jle	.L418	#,
.L318:
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	%ebx, %eax	# _58, _65
	subl	%r12d, %eax	# low, _65
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _65
	jg	.L315	#,
	movl	28(%rsp), %r15d	# %sfp, _49
.L316:
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	movslq	%r12d, %rsi	# low, low
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	leaq	0(%r13,%rsi,4), %r9	#, _72
	leaq	4(%r9), %rsi	#, ivtmp.669
	cltq
	xorl	%ecx, %ecx	# ivtmp.666
.L340:
	leaq	0(,%rcx,4), %rdx	#, tmp259
	leaq	-4(%rsi), %r8	#, tmp258
# insertionssort.h:6:     element = array[i];
	movl	(%rsi), %r10d	# MEM[base: _393, offset: 0B], element
	subq	%rdx, %r8	# tmp259, _401
	movq	%rsi, %rdx	# ivtmp.669, ivtmp.658
.L337:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rdx), %r11d	# MEM[base: _411, offset: -4B], _143
	movq	%rdx, %rdi	# ivtmp.658, _411
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r11d, %r10d	# _143, element
	jge	.L338	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r11d, (%rdx)	# _143, MEM[base: _411, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rdi), %rdx	#, ivtmp.658
	cmpq	%rdx, %r8	# ivtmp.658, _401
	jne	.L337	#,
	movq	%r9, %rdi	# _72, _411
.L338:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%rcx	# ivtmp.666
# insertionssort.h:13:     array[j + 1] = element;
	movl	%r10d, (%rdi)	# element, *prephitmp_709
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %rsi	#, ivtmp.669
	cmpq	%rcx, %rax	# ivtmp.666, _388
	jne	.L340	#,
.L319:
# blockquick.h:146:       sort_quick_block(array, pi + 1, high);
	movl	60(%rsp), %r12d	# %sfp, pi
	incl	%r12d	# pi
# blockquick.h:142:   if (low < high) {
	cmpl	%r12d, %r15d	# low, _49
	jle	.L419	#,
.L313:
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	%r15d, %eax	# _49, _56
	subl	%r12d, %eax	# low, _56
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _56
	jg	.L310	#,
	movl	%r12d, %r14d	# low, low
	movl	24(%rsp), %r12d	# %sfp, _40
.L311:
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	movslq	%r14d, %rsi	# low, low
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	leaq	0(%r13,%rsi,4), %r9	#, _63
	leaq	4(%r9), %rdx	#, ivtmp.647
	cltq
	xorl	%esi, %esi	# ivtmp.644
.L344:
	leaq	0(,%rsi,4), %rcx	#, tmp263
	leaq	-4(%rdx), %r8	#, tmp262
# insertionssort.h:6:     element = array[i];
	movl	(%rdx), %r10d	# MEM[base: _516, offset: 0B], element
	subq	%rcx, %r8	# tmp263, _524
	movq	%rdx, %rcx	# ivtmp.647, ivtmp.636
.L341:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rcx), %r11d	# MEM[base: _534, offset: -4B], _164
	movq	%rcx, %rdi	# ivtmp.636, _534
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r11d, %r10d	# _164, element
	jge	.L342	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r11d, (%rcx)	# _164, MEM[base: _534, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rdi), %rcx	#, ivtmp.636
	cmpq	%rcx, %r8	# ivtmp.636, _524
	jne	.L341	#,
	movq	%r9, %rdi	# _63, _534
.L342:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%rsi	# ivtmp.644
# insertionssort.h:13:     array[j + 1] = element;
	movl	%r10d, (%rdi)	# element, *prephitmp_734
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %rdx	#, ivtmp.647
	cmpq	%rsi, %rax	# ivtmp.644, _511
	jne	.L344	#,
.L314:
# blockquick.h:146:       sort_quick_block(array, pi + 1, high);
	movl	56(%rsp), %r14d	# %sfp, pi
	incl	%r14d	# pi
# blockquick.h:142:   if (low < high) {
	cmpl	%r14d, %r12d	# low, _40
	jle	.L309	#,
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	%r12d, %eax	# _40, _42
	subl	%r14d, %eax	# low, _42
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _42
	jg	.L305	#,
	movl	%r14d, %r15d	# low, low
.L306:
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	movslq	%r15d, %rsi	# low, low
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	leaq	0(%r13,%rsi,4), %r9	#, _54
	leaq	4(%r9), %rdx	#, ivtmp.625
	cltq
	xorl	%esi, %esi	# ivtmp.622
.L348:
	leaq	0(,%rsi,4), %rcx	#, tmp267
	leaq	-4(%rdx), %r8	#, tmp266
# insertionssort.h:6:     element = array[i];
	movl	(%rdx), %r10d	# MEM[base: _549, offset: 0B], element
	subq	%rcx, %r8	# tmp267, _557
	movq	%rdx, %rcx	# ivtmp.625, ivtmp.614
.L345:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rcx), %r11d	# MEM[base: _567, offset: -4B], _185
	movq	%rcx, %rdi	# ivtmp.614, _567
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r11d, %r10d	# _185, element
	jge	.L346	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r11d, (%rcx)	# _185, MEM[base: _567, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rdi), %rcx	#, ivtmp.614
	cmpq	%rcx, %r8	# ivtmp.614, _557
	jne	.L345	#,
	movq	%r9, %rdi	# _54, _567
.L346:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%rsi	# ivtmp.622
# insertionssort.h:13:     array[j + 1] = element;
	movl	%r10d, (%rdi)	# element, *prephitmp_759
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %rdx	#, ivtmp.625
	cmpq	%rsi, %rax	# ivtmp.622, _544
	jne	.L348	#,
.L309:
# blockquick.h:146:       sort_quick_block(array, pi + 1, high);
	movl	52(%rsp), %r15d	# %sfp, pi
	incl	%r15d	# pi
# blockquick.h:142:   if (low < high) {
	cmpl	%r15d, 20(%rsp)	# low, %sfp
	jle	.L304	#,
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	20(%rsp), %eax	# %sfp, _69
	subl	%r15d, %eax	# low, _69
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _69
	jg	.L300	#,
	movl	%r15d, %r14d	# low, low
.L301:
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	movslq	%r14d, %rsi	# low, low
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	leaq	0(%r13,%rsi,4), %r9	#, _45
	leaq	4(%r9), %rdx	#, ivtmp.603
	cltq
	xorl	%esi, %esi	# ivtmp.600
.L352:
	leaq	0(,%rsi,4), %rcx	#, tmp271
	leaq	-4(%rdx), %r8	#, tmp270
# insertionssort.h:6:     element = array[i];
	movl	(%rdx), %r10d	# MEM[base: _582, offset: 0B], element
	subq	%rcx, %r8	# tmp271, _590
	movq	%rdx, %rcx	# ivtmp.603, ivtmp.592
.L349:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rcx), %r11d	# MEM[base: _600, offset: -4B], _206
	movq	%rcx, %rdi	# ivtmp.592, _600
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r11d, %r10d	# _206, element
	jge	.L350	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r11d, (%rcx)	# _206, MEM[base: _600, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rdi), %rcx	#, ivtmp.592
	cmpq	%rcx, %r8	# ivtmp.592, _590
	jne	.L349	#,
	movq	%r9, %rdi	# _45, _600
.L350:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%rsi	# ivtmp.600
# insertionssort.h:13:     array[j + 1] = element;
	movl	%r10d, (%rdi)	# element, *prephitmp_784
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %rdx	#, ivtmp.603
	cmpq	%rsi, %rax	# ivtmp.600, _577
	jne	.L352	#,
.L304:
# blockquick.h:146:       sort_quick_block(array, pi + 1, high);
	movl	48(%rsp), %r14d	# %sfp, pi
	incl	%r14d	# pi
# blockquick.h:142:   if (low < high) {
	cmpl	%r14d, 12(%rsp)	# low, %sfp
	jle	.L420	#,
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	12(%rsp), %eax	# %sfp, _106
	subl	%r14d, %eax	# low, _106
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _106
	jg	.L295	#,
	movq	%r13, %r12	# array, array
	movl	%r14d, %r15d	# low, low
.L296:
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	movslq	%r15d, %rsi	# low, low
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	leaq	(%r12,%rsi,4), %r9	#, _36
	leaq	4(%r9), %rdx	#, ivtmp.581
	cltq
	xorl	%esi, %esi	# ivtmp.578
.L356:
	leaq	0(,%rsi,4), %rcx	#, tmp275
	leaq	-4(%rdx), %r8	#, tmp274
# insertionssort.h:6:     element = array[i];
	movl	(%rdx), %r10d	# MEM[base: _615, offset: 0B], element
	subq	%rcx, %r8	# tmp275, _623
	movq	%rdx, %rcx	# ivtmp.581, ivtmp.570
.L353:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rcx), %r11d	# MEM[base: _633, offset: -4B], _227
	movq	%rcx, %rdi	# ivtmp.570, _633
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r11d, %r10d	# _227, element
	jge	.L354	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r11d, (%rcx)	# _227, MEM[base: _633, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rdi), %rcx	#, ivtmp.570
	cmpq	%rcx, %r8	# ivtmp.570, _623
	jne	.L353	#,
	movq	%r9, %rdi	# _36, _633
.L354:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%rsi	# ivtmp.578
# insertionssort.h:13:     array[j + 1] = element;
	movl	%r10d, (%rdi)	# element, *prephitmp_809
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %rdx	#, ivtmp.581
	cmpq	%rsi, %rax	# ivtmp.578, _610
	jne	.L356	#,
.L299:
# blockquick.h:146:       sort_quick_block(array, pi + 1, high);
	movl	44(%rsp), %r15d	# %sfp, pi
	incl	%r15d	# pi
# blockquick.h:142:   if (low < high) {
	cmpl	%r15d, 8(%rsp)	# low, %sfp
	jle	.L421	#,
.L293:
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	8(%rsp), %eax	# %sfp, _169
	subl	%r15d, %eax	# low, _169
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _169
	jg	.L290	#,
	movq	%r12, %rbp	# array, array
	movl	%r15d, %r12d	# low, low
.L291:
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	movslq	%r12d, %rsi	# low, low
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	leaq	0(%rbp,%rsi,4), %r9	#, _27
	leaq	4(%r9), %rdx	#, ivtmp.559
	cltq
	xorl	%esi, %esi	# ivtmp.556
.L360:
	leaq	0(,%rsi,4), %rcx	#, tmp279
	leaq	-4(%rdx), %r8	#, tmp278
# insertionssort.h:6:     element = array[i];
	movl	(%rdx), %r10d	# MEM[base: _697, offset: 0B], element
	subq	%rcx, %r8	# tmp279, _724
	movq	%rdx, %rcx	# ivtmp.559, ivtmp.548
.L357:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rcx), %r11d	# MEM[base: _772, offset: -4B], _248
	movq	%rcx, %rdi	# ivtmp.548, _772
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r11d, %r10d	# _248, element
	jge	.L358	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r11d, (%rcx)	# _248, MEM[base: _772, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rdi), %rcx	#, ivtmp.548
	cmpq	%rcx, %r8	# ivtmp.548, _724
	jne	.L357	#,
	movq	%r9, %rdi	# _27, _772
.L358:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%rsi	# ivtmp.556
# insertionssort.h:13:     array[j + 1] = element;
	movl	%r10d, (%rdi)	# element, *prephitmp_834
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %rdx	#, ivtmp.559
	cmpq	%rsi, %rax	# ivtmp.556, _673
	jne	.L360	#,
.L294:
# blockquick.h:146:       sort_quick_block(array, pi + 1, high);
	movl	40(%rsp), %r12d	# %sfp, pi
	incl	%r12d	# pi
# blockquick.h:142:   if (low < high) {
	cmpl	16(%rsp), %r12d	# %sfp, low
	jge	.L415	#,
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	movl	16(%rsp), %eax	# %sfp, _232
	subl	%r12d, %eax	# low, _232
# blockquick.h:143:     if (high - low > INSERTION_SORT_THRESH_BLOCK) {
	cmpl	$20, %eax	#, _232
	jg	.L285	#,
	movq	%rbp, %rbx	# array, array
	movl	%r12d, %ebp	# low, low
.L286:
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	movslq	%ebp, %rsi	# low, low
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	leaq	(%rbx,%rsi,4), %r9	#, _8
	leaq	4(%r9), %rdx	#, ivtmp.537
	cltq
	xorl	%esi, %esi	# ivtmp.534
.L364:
	leaq	0(,%rsi,4), %rcx	#, tmp283
	leaq	-4(%rdx), %r8	#, tmp282
# insertionssort.h:6:     element = array[i];
	movl	(%rdx), %r10d	# MEM[base: _825, offset: 0B], element
	subq	%rcx, %r8	# tmp283, _852
	movq	%rdx, %rcx	# ivtmp.537, ivtmp.526
.L361:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rcx), %r11d	# MEM[base: _14, offset: -4B], _269
	movq	%rcx, %rdi	# ivtmp.526, _14
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r11d, %r10d	# _269, element
	jge	.L362	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r11d, (%rcx)	# _269, MEM[base: _14, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rdi), %rcx	#, ivtmp.526
	cmpq	%r8, %rcx	# _852, ivtmp.526
	jne	.L361	#,
	movq	%r9, %rdi	# _8, _14
.L362:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%rsi	# ivtmp.534
# insertionssort.h:13:     array[j + 1] = element;
	movl	%r10d, (%rdi)	# element, *prephitmp_859
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %rdx	#, ivtmp.537
	cmpq	%rsi, %rax	# ivtmp.534, _801
	jne	.L364	#,
.L415:
# blockquick.h:151: }
	addq	$72, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L417:
	.cfi_restore_state
	movq	%rbp, %r13	# array, array
	movl	36(%rsp), %ebp	# %sfp, pi
	movl	32(%rsp), %ebx	# %sfp, _58
# blockquick.h:146:       sort_quick_block(array, pi + 1, high);
	leal	1(%rbp), %r12d	#, low
# blockquick.h:142:   if (low < high) {
	cmpl	%r12d, %ebx	# low, _58
	jg	.L318	#,
.L418:
# blockquick.h:146:       sort_quick_block(array, pi + 1, high);
	movl	60(%rsp), %r12d	# %sfp, pi
	movl	28(%rsp), %r15d	# %sfp, _49
	incl	%r12d	# pi
# blockquick.h:142:   if (low < high) {
	cmpl	%r12d, %r15d	# low, _49
	jg	.L313	#,
.L419:
	movl	24(%rsp), %r12d	# %sfp, _40
	jmp	.L314	#
	.p2align 4,,10
	.p2align 3
.L326:
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	movslq	%r12d, %r12	# low, low
# blockquick.h:148:       insertionSort(array + low, high - low + 1);
	leaq	0(%rbp,%r12,4), %r12	#, _90
	leaq	4(%r12), %r10	#, ivtmp.713
	movslq	%eax, %r9	# _83, _207
	xorl	%r11d, %r11d	# ivtmp.710
.L332:
	leaq	0(,%r11,4), %rax	#, tmp251
	leaq	-4(%r10), %rcx	#, tmp250
# insertionssort.h:6:     element = array[i];
	movl	(%r10), %esi	# MEM[base: _253, offset: 0B], element
	subq	%rax, %rcx	# tmp251, _296
	movq	%r10, %rax	# ivtmp.713, ivtmp.702
.L329:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %edi	# MEM[base: _306, offset: -4B], _101
	movq	%rax, %rdx	# ivtmp.702, _306
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edi, %esi	# _101, element
	jge	.L330	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edi, (%rax)	# _101, MEM[base: _306, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rdx), %rax	#, ivtmp.702
	cmpq	%rax, %rcx	# ivtmp.702, _296
	jne	.L329	#,
	movq	%r12, %rdx	# _90, _306
.L330:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%r11	# ivtmp.710
# insertionssort.h:13:     array[j + 1] = element;
	movl	%esi, (%rdx)	# element, *prephitmp_659
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %r10	#, ivtmp.713
	cmpq	%r11, %r9	# ivtmp.710, _207
	je	.L328	#,
	jmp	.L332	#
.L420:
# blockquick.h:146:       sort_quick_block(array, pi + 1, high);
	movl	44(%rsp), %r15d	# %sfp, pi
	movq	%r13, %r12	# array, array
	incl	%r15d	# pi
# blockquick.h:142:   if (low < high) {
	cmpl	%r15d, 8(%rsp)	# low, %sfp
	jg	.L293	#,
.L421:
	movq	%r12, %rbp	# array, array
	jmp	.L294	#
	.cfi_endproc
.LFE40:
	.size	sort_quick_block, .-sort_quick_block
	.p2align 4
	.globl	sort_quick_hoare
	.type	sort_quick_hoare, @function
sort_quick_hoare:
.LFB5437:
	.cfi_startproc
	endbr64	
# quickuhoare.h:27:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jge	.L442	#,
# quickuhoare.h:26: void sort_quick_hoare(int array[], int low, int high) {
	pushq	%r14	#
	.cfi_def_cfa_offset 16
	.cfi_offset 14, -16
# quickuhoare.h:28:     if (high - low > 30) {
	movl	%edx, %eax	# high, _1
	subl	%esi, %eax	# low, _1
# quickuhoare.h:26: void sort_quick_hoare(int array[], int low, int high) {
	pushq	%r13	#
	.cfi_def_cfa_offset 24
	.cfi_offset 13, -24
	movl	%esi, %r14d	# tmp125, low
	movq	%rdi, %r13	# tmp124, array
	pushq	%r12	#
	.cfi_def_cfa_offset 32
	.cfi_offset 12, -32
	pushq	%rbp	#
	.cfi_def_cfa_offset 40
	.cfi_offset 6, -40
	pushq	%rbx	#
	.cfi_def_cfa_offset 48
	.cfi_offset 3, -48
	movl	%edx, %ebx	# tmp126, high
# quickuhoare.h:28:     if (high - low > 30) {
	cmpl	$30, %eax	#, _1
	jle	.L436	#,
# quickuhoare.h:15:   int j = high + 1;
	leal	1(%rdx), %ebp	#, _117
.L425:
# quickuhoare.h:12:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%ebx, %edx	# high,
	movl	%r14d, %esi	# low,
	movq	%r13, %rdi	# array,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %esi	# tmp127, pivot
	movslq	%r14d, %r8	# low, ivtmp.760
# quickuhoare.h:15:   int j = high + 1;
	movl	%ebp, %edx	# _117, j
	.p2align 4,,10
	.p2align 3
.L426:
# quickuhoare.h:17:     do {i++;} while (array[i] < pivot);
	movl	0(%r13,%r8,4), %r9d	# MEM[base: array_12(D), index: ivtmp.760_80, step: 4, offset: 0B], _26
# quickuhoare.h:17:     do {i++;} while (array[i] < pivot);
	cmpl	%r9d, %esi	# _26, pivot
	jg	.L427	#,
	movslq	%edx, %rax	# j, j
	leaq	-4(%r13,%rax,4), %rax	#, ivtmp.752
	.p2align 4,,10
	.p2align 3
.L428:
# quickuhoare.h:18:     do {j--;} while (array[j] > pivot);
	movq	%rax, %rdi	# ivtmp.752, _31
	movl	(%rax), %ecx	# MEM[base: _81, offset: 4B], _32
	movslq	%edx, %r12	# j,
# quickuhoare.h:18:     do {j--;} while (array[j] > pivot);
	subq	$4, %rax	#, ivtmp.752
# quickuhoare.h:18:     do {j--;} while (array[j] > pivot);
	decl	%edx	# j
# quickuhoare.h:18:     do {j--;} while (array[j] > pivot);
	cmpl	%ecx, %esi	# _32, pivot
	jl	.L428	#,
# quickuhoare.h:19:     if (i >= j) {
	cmpl	%r8d, %edx	# ivtmp.760, j
	jle	.L445	#,
# swap.h:3:   *a = *b;
	movl	%ecx, 0(%r13,%r8,4)	# _32, MEM[base: array_12(D), index: ivtmp.760_80, step: 4, offset: 0B]
# swap.h:4:   *b = t;
	movl	%r9d, (%rdi)	# _26, *_31
.L427:
	incq	%r8	# ivtmp.760
	jmp	.L426	#
	.p2align 4,,10
	.p2align 3
.L445:
# quickuhoare.h:30:       sort_quick_hoare(array, low, pi);
	movl	%r14d, %esi	# low,
	movq	%r13, %rdi	# array,
	call	sort_quick_hoare	#
# quickuhoare.h:27:   if (low < high) {
	cmpl	%r12d, %ebx	# low, high
	jle	.L440	#,
# quickuhoare.h:28:     if (high - low > 30) {
	movl	%ebx, %eax	# high, _1
	subl	%r12d, %eax	# low, _1
# quickuhoare.h:28:     if (high - low > 30) {
	cmpl	$30, %eax	#, _1
	jle	.L424	#,
	movl	%r12d, %r14d	# low, low
	jmp	.L425	#
.L436:
	movslq	%esi, %r12	# low,
.L424:
# quickuhoare.h:33:       insertionSort(array + low, high - low + 1);
	leaq	0(%r13,%r12,4), %r11	#, _7
	leaq	4(%r11), %r8	#, ivtmp.739
	movslq	%eax, %r10	# _1, _96
	xorl	%r9d, %r9d	# ivtmp.736
	.p2align 4,,10
	.p2align 3
.L435:
	leaq	0(,%r9,4), %rax	#, tmp122
	leaq	-4(%r8), %rsi	#, tmp121
# insertionssort.h:6:     element = array[i];
	movl	(%r8), %edi	# MEM[base: _101, offset: 0B], element
	subq	%rax, %rsi	# tmp122, _109
	movq	%r8, %rax	# ivtmp.739, ivtmp.728
	.p2align 4,,10
	.p2align 3
.L432:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %edx	# MEM[base: _123, offset: -4B], _50
	movq	%rax, %rcx	# ivtmp.728, _123
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %edi	# _50, element
	jge	.L433	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, (%rax)	# _50, MEM[base: _123, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rcx), %rax	#, ivtmp.728
	cmpq	%rax, %rsi	# ivtmp.728, _109
	jne	.L432	#,
	movq	%r11, %rcx	# _7, _123
.L433:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%r9	# ivtmp.736
# insertionssort.h:13:     array[j + 1] = element;
	movl	%edi, (%rcx)	# element, *prephitmp_153
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %r8	#, ivtmp.739
	cmpq	%r9, %r10	# ivtmp.736, _96
	jne	.L435	#,
.L440:
# quickuhoare.h:36: }
	popq	%rbx	#
	.cfi_def_cfa_offset 40
	popq	%rbp	#
	.cfi_def_cfa_offset 32
	popq	%r12	#
	.cfi_def_cfa_offset 24
	popq	%r13	#
	.cfi_def_cfa_offset 16
	popq	%r14	#
	.cfi_def_cfa_offset 8
	ret	
.L442:
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	.cfi_restore 14
	ret	
	.cfi_endproc
.LFE5437:
	.size	sort_quick_hoare, .-sort_quick_hoare
	.p2align 4
	.globl	sort_quick_optimized_swap_asm
	.type	sort_quick_optimized_swap_asm, @function
sort_quick_optimized_swap_asm:
.LFB5431:
	.cfi_startproc
	endbr64	
# quickoswapasm.h:55:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jge	.L460	#,
# quickoswapasm.h:54: void sort_quick_optimized_swap_asm(int array[], int low, int high) {
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
# quickoswapasm.h:56:     if (high - low > INSERTION_SORT_THRESH) {
	movl	%edx, %eax	# high, _1
	subl	%esi, %eax	# low, _1
# quickoswapasm.h:54: void sort_quick_optimized_swap_asm(int array[], int low, int high) {
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movl	%edx, %r15d	# tmp116, high
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	movq	%rdi, %r13	# tmp114, array
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	movl	%esi, %ebp	# tmp115, low
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$8, %rsp	#,
	.cfi_def_cfa_offset 64
# quickoswapasm.h:56:     if (high - low > INSERTION_SORT_THRESH) {
	cmpl	$20, %eax	#, _1
	jle	.L448	#,
# quickoswapasm.h:57:       int pi = partition_quick_optimized_swap_asm(array, low, high);
	movslq	%edx, %r14	# high, _80
.L449:
# quickoswapasm.h:22:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%r15d, %edx	# high,
	movl	%ebp, %esi	# low,
	movq	%r13, %rdi	# array,
	call	median_of_three_of_median_of_three	#
# quickoswapasm.h:57:       int pi = partition_quick_optimized_swap_asm(array, low, high);
	movslq	%ebp, %rbx	# low, low
# quickoswapasm.h:25:   asm volatile("    movq    %[i], %%r12\n"
#APP
# 25 "quickoswapasm.h" 1
	    movq    %rbx, %r12	# low
1:

    movl     (%r13,%r12,4), %r8d	# array
    movl     (%r13,%rbx,4), %r9d	# array, low
    xorq      %r10, %r10
    cmp      %eax, %r8d	# tmp117
    setl     %r10b
    movl     %r9d, %r11d
    cmovll   %r8d, %r11d
    movl     %r11d, (%r13,%rbx,4)	# array, low
    cmovll   %r9d, %r8d
    movl     %r8d, (%r13,%r12,4)	# array
    addq     %r10, %rbx	# low

    incq     %r12
    cmp      %r12, %r14	# _80
    jne      1b

    movl     (%r13,%rbx,4), %r9d	# array, low
    movl     (%r13,%r14,4), %r8d	# array, _80
    movl     %r9d, (%r13,%r14,4)	# array, _80
    movl     %r8d, (%r13,%rbx,4)	# array, low

# 0 "" 2
# quickoswapasm.h:58:       sort_quick_optimized_swap_asm(array, low, pi - 1);
#NO_APP
	movl	%ebp, %esi	# low,
	leal	-1(%rbx), %edx	#, tmp108
	movq	%r13, %rdi	# array,
# quickoswapasm.h:59:       sort_quick_optimized_swap_asm(array, pi + 1, high);
	leal	1(%rbx), %ebp	#, low
# quickoswapasm.h:58:       sort_quick_optimized_swap_asm(array, low, pi - 1);
	call	sort_quick_optimized_swap_asm	#
# quickoswapasm.h:55:   if (low < high) {
	cmpl	%r15d, %ebp	# high, low
	jge	.L458	#,
# quickoswapasm.h:56:     if (high - low > INSERTION_SORT_THRESH) {
	movl	%r15d, %eax	# high, _1
	subl	%ebp, %eax	# low, _1
# quickoswapasm.h:56:     if (high - low > INSERTION_SORT_THRESH) {
	cmpl	$20, %eax	#, _1
	jg	.L449	#,
.L448:
# quickoswapasm.h:61:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%ebp, %rbp	# low, low
# quickoswapasm.h:61:       insertionSortOptimized(array + low, high - low + 1);
	leaq	0(%r13,%rbp,4), %r11	#, _10
	leaq	4(%r11), %r8	#, ivtmp.784
	movslq	%eax, %r10	# _1, _21
	xorl	%r9d, %r9d	# ivtmp.781
	.p2align 4,,10
	.p2align 3
.L455:
	leaq	0(,%r9,4), %rax	#, tmp112
	leaq	-4(%r8), %rsi	#, tmp111
# insertionssort.h:6:     element = array[i];
	movl	(%r8), %edi	# MEM[base: _47, offset: 0B], element
	subq	%rax, %rsi	# tmp112, _69
	movq	%r8, %rax	# ivtmp.784, ivtmp.773
	.p2align 4,,10
	.p2align 3
.L452:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %edx	# MEM[base: _79, offset: -4B], _36
	movq	%rax, %rcx	# ivtmp.773, _79
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %edi	# _36, element
	jge	.L453	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, (%rax)	# _36, MEM[base: _79, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rcx), %rax	#, ivtmp.773
	cmpq	%rsi, %rax	# _69, ivtmp.773
	jne	.L452	#,
	movq	%r11, %rcx	# _10, _79
.L453:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%r9	# ivtmp.781
# insertionssort.h:13:     array[j + 1] = element;
	movl	%edi, (%rcx)	# element, *prephitmp_104
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %r8	#, ivtmp.784
	cmpq	%r9, %r10	# ivtmp.781, _21
	jne	.L455	#,
.L458:
# quickoswapasm.h:64: }
	addq	$8, %rsp	#,
	.cfi_def_cfa_offset 56
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
.L460:
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	.cfi_restore 14
	.cfi_restore 15
	ret	
	.cfi_endproc
.LFE5431:
	.size	sort_quick_optimized_swap_asm, .-sort_quick_optimized_swap_asm
	.p2align 4
	.globl	sort_quick_lomuto
	.type	sort_quick_lomuto, @function
sort_quick_lomuto:
.LFB5439:
	.cfi_startproc
	endbr64	
# quickulomuto.h:26:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jge	.L480	#,
# quickulomuto.h:25: void sort_quick_lomuto(int array[], int low, int high) {
	pushq	%r14	#
	.cfi_def_cfa_offset 16
	.cfi_offset 14, -16
# quickulomuto.h:27:     if (high - low > 30) {
	movl	%edx, %eax	# high, _1
	subl	%esi, %eax	# low, _1
# quickulomuto.h:25: void sort_quick_lomuto(int array[], int low, int high) {
	pushq	%r13	#
	.cfi_def_cfa_offset 24
	.cfi_offset 13, -24
	movl	%esi, %r14d	# tmp132, low
	pushq	%r12	#
	.cfi_def_cfa_offset 32
	.cfi_offset 12, -32
	movl	%edx, %r12d	# tmp133, high
	pushq	%rbp	#
	.cfi_def_cfa_offset 40
	.cfi_offset 6, -40
	pushq	%rbx	#
	.cfi_def_cfa_offset 48
	.cfi_offset 3, -48
	movq	%rdi, %rbx	# tmp131, array
# quickulomuto.h:27:     if (high - low > 30) {
	cmpl	$30, %eax	#, _1
	jle	.L465	#,
# quickulomuto.h:21:   swap(&array[i + 1], &array[high]);
	movslq	%edx, %rax	# high, high
# quickulomuto.h:21:   swap(&array[i + 1], &array[high]);
	leaq	(%rdi,%rax,4), %r13	#, _35
.L466:
# quickulomuto.h:12:   int pivot = median_of_three_of_median_of_three(array, low, high); //
	movl	%r14d, %esi	# low,
	movl	%r12d, %edx	# high,
	movq	%rbx, %rdi	# array,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %esi	# tmp134, pivot
# quickulomuto.h:14:   int i = (low - 1);
	leal	-1(%r14), %ebp	#, i
	movslq	%r14d, %rax	# low, ivtmp.820
	.p2align 4,,10
	.p2align 3
.L468:
# quickulomuto.h:16:     if (array[j] <= pivot) {
	movl	(%rbx,%rax,4), %edx	# MEM[base: array_13(D), index: ivtmp.820_105, step: 4, offset: 0B], _131
# quickulomuto.h:16:     if (array[j] <= pivot) {
	cmpl	%edx, %esi	# _131, pivot
	jl	.L467	#,
# quickulomuto.h:17:       i++;
	incl	%ebp	# i
# quickulomuto.h:18:       swap(&array[i], &array[j]);
	movslq	%ebp, %rcx	# i, i
# quickulomuto.h:18:       swap(&array[i], &array[j]);
	leaq	(%rbx,%rcx,4), %rcx	#, _127
# swap.h:2:   int t = *a;
	movl	(%rcx), %edi	# *_127, t
# swap.h:3:   *a = *b;
	movl	%edx, (%rcx)	# _131, *_127
# swap.h:4:   *b = t;
	movl	%edi, (%rbx,%rax,4)	# t, MEM[base: array_13(D), index: ivtmp.820_105, step: 4, offset: 0B]
.L467:
# quickulomuto.h:15:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.820
	cmpl	%eax, %r12d	# ivtmp.820, high
	jg	.L468	#,
# quickulomuto.h:21:   swap(&array[i + 1], &array[high]);
	movslq	%ebp, %rax	# i, i
# quickulomuto.h:21:   swap(&array[i + 1], &array[high]);
	leaq	4(%rbx,%rax,4), %rax	#, _40
# swap.h:2:   int t = *a;
	movl	(%rax), %edx	# *_40, t
# swap.h:3:   *a = *b;
	movl	0(%r13), %ecx	# *_35, _42
# quickulomuto.h:29:       sort_quick_lomuto(array, low, pi - 1);
	movl	%r14d, %esi	# low,
# swap.h:3:   *a = *b;
	movl	%ecx, (%rax)	# _42, *_40
# swap.h:4:   *b = t;
	movl	%edx, 0(%r13)	# t, *_35
# quickulomuto.h:29:       sort_quick_lomuto(array, low, pi - 1);
	movq	%rbx, %rdi	# array,
	movl	%ebp, %edx	# i,
# quickulomuto.h:30:       sort_quick_lomuto(array, pi + 1, high);
	leal	2(%rbp), %r14d	#, low
# quickulomuto.h:29:       sort_quick_lomuto(array, low, pi - 1);
	call	sort_quick_lomuto	#
# quickulomuto.h:26:   if (low < high) {
	cmpl	%r12d, %r14d	# high, low
	jge	.L478	#,
# quickulomuto.h:27:     if (high - low > 30) {
	movl	%r12d, %eax	# high, _1
	subl	%r14d, %eax	# low, _1
# quickulomuto.h:27:     if (high - low > 30) {
	cmpl	$30, %eax	#, _1
	jg	.L466	#,
.L465:
# quickulomuto.h:32:       insertionSort(array + low, high - low + 1);
	movslq	%r14d, %r14	# low, low
# quickulomuto.h:32:       insertionSort(array + low, high - low + 1);
	leaq	(%rbx,%r14,4), %r11	#, _8
	leaq	4(%r11), %r8	#, ivtmp.811
	movslq	%eax, %r10	# _1, _107
	xorl	%r9d, %r9d	# ivtmp.808
	.p2align 4,,10
	.p2align 3
.L474:
	leaq	0(,%r9,4), %rax	#, tmp129
	leaq	-4(%r8), %rsi	#, tmp128
# insertionssort.h:6:     element = array[i];
	movl	(%r8), %edi	# MEM[base: _112, offset: 0B], element
	subq	%rax, %rsi	# tmp129, _32
	movq	%r8, %rax	# ivtmp.811, ivtmp.800
	.p2align 4,,10
	.p2align 3
.L471:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %edx	# MEM[base: _25, offset: -4B], _55
	movq	%rax, %rcx	# ivtmp.800, _25
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %edi	# _55, element
	jge	.L472	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, (%rax)	# _55, MEM[base: _25, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rcx), %rax	#, ivtmp.800
	cmpq	%rax, %rsi	# ivtmp.800, _32
	jne	.L471	#,
	movq	%r11, %rcx	# _8, _25
.L472:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%r9	# ivtmp.808
# insertionssort.h:13:     array[j + 1] = element;
	movl	%edi, (%rcx)	# element, *prephitmp_155
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %r8	#, ivtmp.811
	cmpq	%r9, %r10	# ivtmp.808, _107
	jne	.L474	#,
.L478:
# quickulomuto.h:35: }
	popq	%rbx	#
	.cfi_def_cfa_offset 40
	popq	%rbp	#
	.cfi_def_cfa_offset 32
	popq	%r12	#
	.cfi_def_cfa_offset 24
	popq	%r13	#
	.cfi_def_cfa_offset 16
	popq	%r14	#
	.cfi_def_cfa_offset 8
	ret	
.L480:
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	.cfi_restore 14
	ret	
	.cfi_endproc
.LFE5439:
	.size	sort_quick_lomuto, .-sort_quick_lomuto
	.p2align 4
	.globl	sort_quick_optimized_swap_array
	.type	sort_quick_optimized_swap_array, @function
sort_quick_optimized_swap_array:
.LFB5429:
	.cfi_startproc
	endbr64	
# quickoswaparray.h:38:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jge	.L499	#,
# quickoswaparray.h:37: void sort_quick_optimized_swap_array(int array[], int low, int high) {
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
# quickoswaparray.h:39:     if (high - low > INSERTION_SORT_THRESH) {
	movl	%edx, %eax	# high, _1
	subl	%esi, %eax	# low, _1
# quickoswaparray.h:37: void sort_quick_optimized_swap_array(int array[], int low, int high) {
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movl	%esi, %r8d	# tmp149, low
	movl	%edx, %r14d	# tmp150, high
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	movq	%rdi, %rbx	# tmp148, array
	subq	$24, %rsp	#,
	.cfi_def_cfa_offset 80
# quickoswaparray.h:39:     if (high - low > INSERTION_SORT_THRESH) {
	cmpl	$20, %eax	#, _1
	jle	.L485	#,
# quickoswaparray.h:33:   swap(&array[i], &array[high]);
	movslq	%edx, %rax	# high, high
# quickoswaparray.h:33:   swap(&array[i], &array[high]);
	leaq	(%rdi,%rax,4), %rbp	#, _40
	leaq	x(%rip), %r13	#, tmp146
# quickoswaparray.h:29:     array[j] = x[1 - c];
	movl	$1, %r15d	#, tmp135
.L486:
# quickoswaparray.h:22:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%r8d, %esi	# low,
	movq	%rbx, %rdi	# array,
	movl	%r14d, %edx	# high,
	movl	%r8d, 12(%rsp)	# low, %sfp
	call	median_of_three_of_median_of_three	#
	movl	%eax, %edi	# tmp151, pivot
	movslq	12(%rsp), %rax	# %sfp,
	movq	%rax, %r8	#,
	movl	%eax, %r12d	# low, i
	.p2align 4,,10
	.p2align 3
.L487:
# quickoswaparray.h:27:     x[0] = array[i];
	movslq	%r12d, %rcx	# i, i
	leaq	(%rbx,%rcx,4), %rsi	#, _30
	movl	(%rsi), %ecx	# *_30, _31
# quickoswaparray.h:26:     int c = pivot > array[j];
	xorl	%edx, %edx	# tmp127
	cmpl	(%rbx,%rax,4), %edi	# MEM[base: array_13(D), index: ivtmp.853_108, step: 4, offset: 0B], pivot
# quickoswaparray.h:27:     x[0] = array[i];
	movl	%ecx, 0(%r13)	# _31, x[0]
# quickoswaparray.h:26:     int c = pivot > array[j];
	setg	%dl	#, tmp127
# quickoswaparray.h:31:     i += c;
	addl	%edx, %r12d	# tmp127, i
# quickoswaparray.h:28:     x[1] = array[j];
	movl	(%rbx,%rax,4), %ecx	# MEM[base: array_13(D), index: ivtmp.853_108, step: 4, offset: 0B], _32
# quickoswaparray.h:28:     x[1] = array[j];
	movl	%ecx, 4+x(%rip)	# _32, x[1]
# quickoswaparray.h:29:     array[j] = x[1 - c];
	movl	%r15d, %ecx	# tmp135, tmp134
	subl	%edx, %ecx	# tmp127, tmp134
# quickoswaparray.h:29:     array[j] = x[1 - c];
	movslq	%ecx, %rcx	# tmp134, tmp136
	movl	0(%r13,%rcx,4), %ecx	# x[_33], _34
# quickoswaparray.h:29:     array[j] = x[1 - c];
	movl	%ecx, (%rbx,%rax,4)	# _34, MEM[base: array_13(D), index: ivtmp.853_108, step: 4, offset: 0B]
# quickoswaparray.h:30:     array[i] = x[c];
	movslq	%edx, %rcx	# tmp127, c
# quickoswaparray.h:25:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.853
# quickoswaparray.h:30:     array[i] = x[c];
	movl	0(%r13,%rcx,4), %ecx	# x[c_26], _35
# quickoswaparray.h:30:     array[i] = x[c];
	movl	%ecx, (%rsi)	# _35, *_30
# quickoswaparray.h:25:   for (int j = low; j < high; j++) {
	cmpl	%eax, %r14d	# ivtmp.853, high
	jg	.L487	#,
# quickoswaparray.h:33:   swap(&array[i], &array[high]);
	movslq	%r12d, %rax	# i, i
# quickoswaparray.h:33:   swap(&array[i], &array[high]);
	leaq	(%rbx,%rax,4), %rax	#, _44
# swap.h:2:   int t = *a;
	movl	(%rax), %edx	# *_44, t
# swap.h:3:   *a = *b;
	movl	0(%rbp), %ecx	# *_40, _46
# quickoswaparray.h:41:       sort_quick_optimized_swap_array(array, low, pi - 1);
	movl	%r8d, %esi	# low,
# swap.h:3:   *a = *b;
	movl	%ecx, (%rax)	# _46, *_44
# swap.h:4:   *b = t;
	movl	%edx, 0(%rbp)	# t, *_40
# quickoswaparray.h:41:       sort_quick_optimized_swap_array(array, low, pi - 1);
	movq	%rbx, %rdi	# array,
	leal	-1(%r12), %edx	#, tmp141
	call	sort_quick_optimized_swap_array	#
# quickoswaparray.h:42:       sort_quick_optimized_swap_array(array, pi + 1, high);
	leal	1(%r12), %r8d	#, low
# quickoswaparray.h:38:   if (low < high) {
	cmpl	%r14d, %r8d	# high, low
	jge	.L497	#,
# quickoswaparray.h:39:     if (high - low > INSERTION_SORT_THRESH) {
	movl	%r14d, %eax	# high, _1
	subl	%r8d, %eax	# low, _1
# quickoswaparray.h:39:     if (high - low > INSERTION_SORT_THRESH) {
	cmpl	$20, %eax	#, _1
	jg	.L486	#,
.L485:
# quickoswaparray.h:44:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%r8d, %r8	# low, low
# quickoswaparray.h:44:       insertionSortOptimized(array + low, high - low + 1);
	leaq	(%rbx,%r8,4), %r11	#, _8
	leaq	4(%r11), %r8	#, ivtmp.844
	movslq	%eax, %r10	# _1, _110
	xorl	%r9d, %r9d	# ivtmp.841
	.p2align 4,,10
	.p2align 3
.L493:
	leaq	0(,%r9,4), %rax	#, tmp145
	leaq	-4(%r8), %rsi	#, tmp144
# insertionssort.h:6:     element = array[i];
	movl	(%r8), %edi	# MEM[base: _115, offset: 0B], element
	subq	%rax, %rsi	# tmp145, _123
	movq	%r8, %rax	# ivtmp.844, ivtmp.833
	.p2align 4,,10
	.p2align 3
.L490:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %edx	# MEM[base: _151, offset: -4B], _57
	movq	%rax, %rcx	# ivtmp.833, _151
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %edi	# _57, element
	jge	.L491	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, (%rax)	# _57, MEM[base: _151, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rcx), %rax	#, ivtmp.833
	cmpq	%rax, %rsi	# ivtmp.833, _123
	jne	.L490	#,
	movq	%r11, %rcx	# _8, _151
.L491:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%r9	# ivtmp.841
# insertionssort.h:13:     array[j + 1] = element;
	movl	%edi, (%rcx)	# element, *prephitmp_158
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %r8	#, ivtmp.844
	cmpq	%r9, %r10	# ivtmp.841, _110
	jne	.L493	#,
.L497:
# quickoswaparray.h:47: }
	addq	$24, %rsp	#,
	.cfi_def_cfa_offset 56
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
.L499:
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	.cfi_restore 14
	.cfi_restore 15
	ret	
	.cfi_endproc
.LFE5429:
	.size	sort_quick_optimized_swap_array, .-sort_quick_optimized_swap_array
	.p2align 4
	.globl	sort_quick_optimized_swap_cmov
	.type	sort_quick_optimized_swap_cmov, @function
sort_quick_optimized_swap_cmov:
.LFB5433:
	.cfi_startproc
	endbr64	
# quickoswapcmov.h:37:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jge	.L522	#,
# quickoswapcmov.h:36: void sort_quick_optimized_swap_cmov(int array[], int low, int high) {
	pushq	%r14	#
	.cfi_def_cfa_offset 16
	.cfi_offset 14, -16
# quickoswapcmov.h:38:     if (high - low > INSERTION_SORT_THRESH) {
	movl	%edx, %eax	# high, _1
	subl	%esi, %eax	# low, _1
# quickoswapcmov.h:36: void sort_quick_optimized_swap_cmov(int array[], int low, int high) {
	pushq	%r13	#
	.cfi_def_cfa_offset 24
	.cfi_offset 13, -24
	movl	%esi, %r14d	# tmp134, low
	movl	%edx, %r13d	# tmp135, high
	pushq	%r12	#
	.cfi_def_cfa_offset 32
	.cfi_offset 12, -32
	pushq	%rbp	#
	.cfi_def_cfa_offset 40
	.cfi_offset 6, -40
	pushq	%rbx	#
	.cfi_def_cfa_offset 48
	.cfi_offset 3, -48
	movq	%rdi, %rbx	# tmp133, array
# quickoswapcmov.h:38:     if (high - low > INSERTION_SORT_THRESH) {
	cmpl	$20, %eax	#, _1
	jle	.L504	#,
# quickosimple.h:24:   swap(&array[i], &array[high]);
	movslq	%edx, %rax	# high, high
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	(%rdi,%rax,4), %r12	#, _38
.L505:
# quickosimple.h:14:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%r14d, %esi	# low,
	movl	%r13d, %edx	# high,
	movq	%rbx, %rdi	# array,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %r8d	# tmp136, pivot
	movslq	%r14d, %rax	# low, ivtmp.887
	movl	%r14d, %ebp	# low, i
	movq	%rax, %rsi	# ivtmp.887, i
	.p2align 4,,10
	.p2align 3
.L509:
# quickosimple.h:17:     int c = pivot > array[j];
	movl	(%rbx,%rax,4), %ecx	# MEM[base: array_13(D), index: ivtmp.887_84, step: 4, offset: 0B], _126
# quickosimple.h:18:     int y = array[i];
	leaq	(%rbx,%rsi,4), %rdx	#, _121
# quickosimple.h:18:     int y = array[i];
	movl	(%rdx), %edi	# *_121, y
# quickosimple.h:20:     array[i] = c ? z : y;
	cmpl	%ecx, %r8d	# _126, pivot
	jg	.L506	#,
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.887
	cmpl	%eax, %r13d	# ivtmp.887, high
	jg	.L509	#,
.L508:
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	(%rbx,%rsi,4), %rax	#, _42
# swap.h:2:   int t = *a;
	movl	(%rax), %edx	# *_42, t
# swap.h:3:   *a = *b;
	movl	(%r12), %ecx	# *_38, _44
# quickoswapcmov.h:40:       sort_quick_optimized_swap_cmov(array, low, pi - 1);
	movl	%r14d, %esi	# low,
# swap.h:3:   *a = *b;
	movl	%ecx, (%rax)	# _44, *_42
# swap.h:4:   *b = t;
	movl	%edx, (%r12)	# t, *_38
# quickoswapcmov.h:40:       sort_quick_optimized_swap_cmov(array, low, pi - 1);
	movq	%rbx, %rdi	# array,
	leal	-1(%rbp), %edx	#, tmp126
# quickoswapcmov.h:41:       sort_quick_optimized_swap_cmov(array, pi + 1, high);
	leal	1(%rbp), %r14d	#, low
# quickoswapcmov.h:40:       sort_quick_optimized_swap_cmov(array, low, pi - 1);
	call	sort_quick_optimized_swap_cmov	#
# quickoswapcmov.h:37:   if (low < high) {
	cmpl	%r13d, %r14d	# high, low
	jge	.L520	#,
# quickoswapcmov.h:38:     if (high - low > INSERTION_SORT_THRESH) {
	movl	%r13d, %eax	# high, _1
	subl	%r14d, %eax	# low, _1
# quickoswapcmov.h:38:     if (high - low > INSERTION_SORT_THRESH) {
	cmpl	$20, %eax	#, _1
	jg	.L505	#,
.L504:
# quickoswapcmov.h:43:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%r14d, %r14	# low, low
# quickoswapcmov.h:43:       insertionSortOptimized(array + low, high - low + 1);
	leaq	(%rbx,%r14,4), %r11	#, _8
	leaq	4(%r11), %r8	#, ivtmp.878
	movslq	%eax, %r10	# _1, _86
	xorl	%r9d, %r9d	# ivtmp.875
	.p2align 4,,10
	.p2align 3
.L515:
	leaq	0(,%r9,4), %rax	#, tmp130
	leaq	-4(%r8), %rsi	#, tmp129
# insertionssort.h:6:     element = array[i];
	movl	(%r8), %edi	# MEM[base: _91, offset: 0B], element
	subq	%rax, %rsi	# tmp130, _76
	movq	%r8, %rax	# ivtmp.878, ivtmp.867
	.p2align 4,,10
	.p2align 3
.L512:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %edx	# MEM[base: _24, offset: -4B], _55
	movq	%rax, %rcx	# ivtmp.867, _24
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %edi	# _55, element
	jge	.L513	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, (%rax)	# _55, MEM[base: _24, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rcx), %rax	#, ivtmp.867
	cmpq	%rax, %rsi	# ivtmp.867, _76
	jne	.L512	#,
	movq	%r11, %rcx	# _8, _24
.L513:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%r9	# ivtmp.875
# insertionssort.h:13:     array[j + 1] = element;
	movl	%edi, (%rcx)	# element, *prephitmp_150
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %r8	#, ivtmp.878
	cmpq	%r9, %r10	# ivtmp.875, _86
	jne	.L515	#,
.L520:
# quickoswapcmov.h:46: }
	popq	%rbx	#
	.cfi_remember_state
	.cfi_def_cfa_offset 40
	popq	%rbp	#
	.cfi_def_cfa_offset 32
	popq	%r12	#
	.cfi_def_cfa_offset 24
	popq	%r13	#
	.cfi_def_cfa_offset 16
	popq	%r14	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L506:
	.cfi_restore_state
	movl	%ecx, (%rdx)	# _126, *_121
# quickosimple.h:22:     i += c;
	incl	%ebp	# i
# quickosimple.h:21:     array[j] = c ? y : z;
	movl	%edi, (%rbx,%rax,4)	# y, MEM[base: array_13(D), index: ivtmp.887_84, step: 4, offset: 0B]
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.887
	movslq	%ebp, %rsi	# i, i
	cmpl	%eax, %r13d	# ivtmp.887, high
	jg	.L509	#,
	jmp	.L508	#
.L522:
	.cfi_def_cfa_offset 8
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	.cfi_restore 14
	ret	
	.cfi_endproc
.LFE5433:
	.size	sort_quick_optimized_swap_cmov, .-sort_quick_optimized_swap_cmov
	.p2align 4
	.globl	sort_indexes_opti
	.type	sort_indexes_opti, @function
sort_indexes_opti:
.LFB60:
	.cfi_startproc
	endbr64	
# median.h:141:   int y = *i2;
	movslq	(%rdx), %r9	# *i2_17(D),
# median.h:139: void sort_indexes_opti(int array[], int *i1, int *i2, int *sorted) {
	movq	%rdi, %r8	# array, tmp108
# median.h:140:   int x = *i1;
	movslq	(%rsi), %r10	# *i1_15(D),
# median.h:142:   int c = array[*i1] <= array[*i2];
	movl	(%r8,%r9,4), %r11d	# *_7, tmp115
# median.h:140:   int x = *i1;
	movq	%r10, %rax	#,
# median.h:142:   int c = array[*i1] <= array[*i2];
	cmpl	%r11d, (%r8,%r10,4)	# tmp115, *_3
# median.h:142:   int c = array[*i1] <= array[*i2];
	setle	%r8b	#, c
# median.h:141:   int y = *i2;
	movq	%r9, %rdi	#,
# median.h:142:   int c = array[*i1] <= array[*i2];
	movzbl	%r8b, %r8d	# c, c
# median.h:143:   *i1 = c ? x : y;
	jg	.L526	#,
# median.h:144:   *i2 = c ? y : x;
	movl	%edi, %eax	# y, x
# median.h:143:   *i1 = c ? x : y;
	movl	%r10d, %edi	# x, y
.L526:
	movl	%edi, (%rsi)	# y, *i1_15(D)
# median.h:144:   *i2 = c ? y : x;
	movl	%eax, (%rdx)	# x, *i2_17(D)
# median.h:145:   *sorted += c;
	addl	%r8d, (%rcx)	# c, *sorted_23(D)
# median.h:146: }
	ret	
	.cfi_endproc
.LFE60:
	.size	sort_indexes_opti, .-sort_indexes_opti
	.p2align 4
	.globl	median_of_three_opti
	.type	median_of_three_opti, @function
median_of_three_opti:
.LFB61:
	.cfi_startproc
	endbr64	
# median.h:150:     return array[high];
	movslq	%edx, %rax	# high, high
	leaq	(%rdi,%rax,4), %r9	#, prephitmp_59
# median.h:149:   if (high - low < 2) {
	movl	%edx, %eax	# high, tmp115
	subl	%esi, %eax	# low, tmp115
# median.h:149:   if (high - low < 2) {
	cmpl	$1, %eax	#, tmp115
	jle	.L533	#,
# median.h:154:   int m = (low + high) / 2;
	leal	(%rdx,%rsi), %eax	#, tmp116
# median.h:154:   int m = (low + high) / 2;
	movl	%eax, %r8d	# tmp116, tmp117
	shrl	$31, %r8d	#, tmp117
	addl	%eax, %r8d	# tmp116, tmp118
	sarl	%r8d	# tmp119
# median.h:142:   int c = array[*i1] <= array[*i2];
	movslq	%esi, %r10	# low, low
# median.h:142:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%r10,4), %r11	#, _37
# median.h:142:   int c = array[*i1] <= array[*i2];
	movslq	%r8d, %r10	# <retval>, <retval>
# median.h:142:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%r10,4), %r10	#, _41
# median.h:142:   int c = array[*i1] <= array[*i2];
	movl	(%r10), %edi	# *_41, tmp158
# median.h:154:   int m = (low + high) / 2;
	movl	%r8d, %eax	# tmp119, <retval>
# median.h:142:   int c = array[*i1] <= array[*i2];
	cmpl	%edi, (%r11)	# tmp158, *_37
# median.h:142:   int c = array[*i1] <= array[*i2];
	setle	%dil	#, c
	movzbl	%dil, %edi	# c, c
# median.h:143:   *i1 = c ? x : y;
	jg	.L534	#,
.L530:
# median.h:145:   *sorted += c;
	addl	(%rcx), %edi	# *sorted_13(D), _48
	movl	%edi, (%rcx)	# _48, *sorted_13(D)
# median.h:142:   int c = array[*i1] <= array[*i2];
	movl	(%r9), %r8d	# *_62, tmp159
	cmpl	%r8d, (%r10)	# tmp159, *prephitmp_52
# median.h:142:   int c = array[*i1] <= array[*i2];
	setle	%r8b	#, c
	movzbl	%r8b, %r8d	# c, c
# median.h:143:   *i1 = c ? x : y;
	cmovle	%r10, %r9	# prephitmp_59,, _41, prephitmp_59
	cmovg	%edx, %eax	# high,, <retval>
# median.h:145:   *sorted += c;
	addl	%r8d, %edi	# c, tmp129
	movl	%edi, (%rcx)	# tmp129, *sorted_13(D)
# median.h:9:   *i2 = c ? y : x;
	movl	(%r9), %ecx	# *prephitmp_59, tmp160
	cmpl	%ecx, (%r11)	# tmp160, *prephitmp_45
	cmovg	%esi, %eax	# <retval>,, low, <retval>
# median.h:164: }
	ret	
	.p2align 4,,10
	.p2align 3
.L534:
# median.h:143:   *i1 = c ? x : y;
	movq	%r11, %rax	# _37, _37
	movq	%r10, %r11	# _41, _37
	movq	%rax, %r10	# _37, _41
# median.h:144:   *i2 = c ? y : x;
	movl	%esi, %eax	# low, <retval>
# median.h:143:   *i1 = c ? x : y;
	movl	%r8d, %esi	# tmp119, low
	jmp	.L530	#
	.p2align 4,,10
	.p2align 3
.L533:
# median.h:150:     return array[high];
	movl	(%r9), %eax	# *_62, <retval>
	ret	
	.cfi_endproc
.LFE61:
	.size	median_of_three_opti, .-median_of_three_opti
	.p2align 4
	.globl	median_of_three_of_median_of_three_opti
	.type	median_of_three_of_median_of_three_opti, @function
median_of_three_of_median_of_three_opti:
.LFB62:
	.cfi_startproc
	endbr64	
	movl	%edx, %r8d	# tmp269, high
# median.h:167:   if (high - low < 50) {
	subl	%esi, %edx	# low, _1
# median.h:167:   if (high - low < 50) {
	cmpl	$49, %edx	#, _1
	jle	.L556	#,
# median.h:166: int median_of_three_of_median_of_three_opti(int array[], int low, int high, int *sorted) {
	pushq	%r14	#
	.cfi_def_cfa_offset 16
	.cfi_offset 14, -16
# median.h:170:     int offset = (high - low) / 9;
	movslq	%edx, %rax	# _1, _1
	imulq	$954437177, %rax, %rax	#, _1, tmp170
# median.h:166: int median_of_three_of_median_of_three_opti(int array[], int low, int high, int *sorted) {
	pushq	%r13	#
	.cfi_def_cfa_offset 24
	.cfi_offset 13, -24
# median.h:170:     int offset = (high - low) / 9;
	sarl	$31, %edx	#, tmp173
	sarq	$33, %rax	#, tmp172
# median.h:166: int median_of_three_of_median_of_three_opti(int array[], int low, int high, int *sorted) {
	pushq	%r12	#
	.cfi_def_cfa_offset 32
	.cfi_offset 12, -32
# median.h:170:     int offset = (high - low) / 9;
	subl	%edx, %eax	# tmp173, offset
# median.h:173:     int b = low + offset;
	leal	(%rsi,%rax), %r9d	#, <retval>
# median.h:166: int median_of_three_of_median_of_three_opti(int array[], int low, int high, int *sorted) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 40
	.cfi_offset 6, -40
# median.h:142:   int c = array[*i1] <= array[*i2];
	movslq	%esi, %r10	# low, low
# median.h:142:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%r10,4), %r11	#, _144
# median.h:166: int median_of_three_of_median_of_three_opti(int array[], int low, int high, int *sorted) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 48
	.cfi_offset 3, -48
# median.h:142:   int c = array[*i1] <= array[*i2];
	movslq	%r9d, %r10	# <retval>, <retval>
# median.h:142:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%r10,4), %r10	#, _148
# median.h:142:   int c = array[*i1] <= array[*i2];
	movl	(%r10), %ebx	# *_148, tmp303
# median.h:142:   int c = array[*i1] <= array[*i2];
	xorl	%r13d, %r13d	# c
	cmpl	%ebx, (%r11)	# tmp303, *_144
# median.h:174:     int c = low + offset * 2;
	leal	(%r9,%rax), %edx	#, _4
# median.h:142:   int c = array[*i1] <= array[*i2];
	setle	%r13b	#, c
# median.h:143:   *i1 = c ? x : y;
	jg	.L557	#,
.L537:
# median.h:145:   *sorted += c;
	addl	(%rcx), %r13d	# *sorted_22(D), _155
	movl	%r13d, (%rcx)	# _155, *sorted_22(D)
# median.h:142:   int c = array[*i1] <= array[*i2];
	movslq	%edx, %rbx	# _4, _4
# median.h:142:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rbx,4), %rbp	#, prephitmp_42
# median.h:142:   int c = array[*i1] <= array[*i2];
	movl	0(%rbp), %ebx	# *_136, tmp304
	cmpl	%ebx, (%r10)	# tmp304, *prephitmp_180
# median.h:142:   int c = array[*i1] <= array[*i2];
	setle	%bl	#, c
	movzbl	%bl, %ebx	# c, c
# median.h:143:   *i1 = c ? x : y;
	cmovle	%r10, %rbp	# prephitmp_42,, _148, prephitmp_42
	cmovg	%edx, %r9d	# _4,, <retval>
# median.h:145:   *sorted += c;
	addl	%ebx, %r13d	# c, _141
	movl	%r13d, (%rcx)	# _141, *sorted_22(D)
# median.h:9:   *i2 = c ? y : x;
	movl	0(%rbp), %ebx	# *prephitmp_42, tmp305
	cmpl	%ebx, (%r11)	# tmp305, *prephitmp_184
	jg	.L558	#,
.L539:
# median.h:179:     int d = low + offset * 3;
	addl	%eax, %edx	# offset, _6
# median.h:180:     int e = low + offset * 4;
	leal	(%rdx,%rax), %r11d	#, iftmp.14_95
# median.h:142:   int c = array[*i1] <= array[*i2];
	movslq	%edx, %rsi	# _6, _6
# median.h:142:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rsi,4), %r14	#, prephitmp_39
# median.h:142:   int c = array[*i1] <= array[*i2];
	movslq	%r11d, %rsi	# iftmp.14_95, iftmp.14_95
# median.h:142:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rsi,4), %r12	#, prephitmp_36
# median.h:142:   int c = array[*i1] <= array[*i2];
	movl	(%r12), %ebx	# *_114, tmp306
# median.h:142:   int c = array[*i1] <= array[*i2];
	xorl	%esi, %esi	# c
	cmpl	%ebx, (%r14)	# tmp306, *_110
# median.h:181:     int f = low + offset * 5;
	leal	(%r11,%rax), %r10d	#, _10
# median.h:142:   int c = array[*i1] <= array[*i2];
	setle	%sil	#, c
# median.h:143:   *i1 = c ? x : y;
	jg	.L559	#,
.L540:
# median.h:145:   *sorted += c;
	addl	%r13d, %esi	# _141, _120
	movl	%esi, (%rcx)	# _120, *sorted_22(D)
# median.h:142:   int c = array[*i1] <= array[*i2];
	movslq	%r10d, %rbx	# _10, _10
# median.h:142:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rbx,4), %rbx	#, prephitmp_174
# median.h:142:   int c = array[*i1] <= array[*i2];
	movl	(%rbx), %r13d	# *_102, tmp307
	cmpl	%r13d, (%r12)	# tmp307, *prephitmp_36
# median.h:142:   int c = array[*i1] <= array[*i2];
	setle	%r13b	#, c
	movzbl	%r13b, %r13d	# c, c
# median.h:143:   *i1 = c ? x : y;
	cmovle	%r12, %rbx	# prephitmp_174,, prephitmp_36, prephitmp_174
	cmovg	%r10d, %r11d	# _10,, iftmp.14_95
# median.h:145:   *sorted += c;
	addl	%esi, %r13d	# _120, _107
	movl	%r13d, (%rcx)	# _107, *sorted_22(D)
# median.h:9:   *i2 = c ? y : x;
	movl	(%rbx), %esi	# *prephitmp_168, tmp308
	cmpl	%esi, (%r14)	# tmp308, *prephitmp_39
	jg	.L560	#,
.L542:
# median.h:186:     int g = low + offset * 6;
	addl	%eax, %r10d	# offset, _12
# median.h:187:     int h = low + offset * 7;
	addl	%r10d, %eax	# _12, _14
# median.h:142:   int c = array[*i1] <= array[*i2];
	movslq	%r10d, %rdx	# _12, _12
# median.h:142:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rdx,4), %r12	#, _76
# median.h:142:   int c = array[*i1] <= array[*i2];
	movslq	%eax, %rdx	# _14, _14
# median.h:142:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rdx,4), %r14	#, _80
# median.h:142:   int c = array[*i1] <= array[*i2];
	movl	(%r14), %esi	# *_80, tmp309
	cmpl	%esi, (%r12)	# tmp309, *_76
# median.h:142:   int c = array[*i1] <= array[*i2];
	setle	%sil	#, c
	movzbl	%sil, %esi	# c, c
# median.h:143:   *i1 = c ? x : y;
	jg	.L543	#,
	movq	%r14, %rdx	# _80, _80
	movq	%r12, %r14	# _76, _80
	movq	%rdx, %r12	# _80, _76
	movl	%r10d, %edx	# _12, _12
# median.h:144:   *i2 = c ? y : x;
	movl	%eax, %r10d	# _14, _12
# median.h:143:   *i1 = c ? x : y;
	movl	%edx, %eax	# _12, _14
.L543:
# median.h:145:   *sorted += c;
	addl	%r13d, %esi	# _107, _86
	movl	%esi, (%rcx)	# _86, *sorted_22(D)
# median.h:142:   int c = array[*i1] <= array[*i2];
	movslq	%r8d, %rdx	# high, high
# median.h:142:   int c = array[*i1] <= array[*i2];
	leaq	(%rdi,%rdx,4), %rdx	#, _68
# median.h:142:   int c = array[*i1] <= array[*i2];
	movl	(%rdx), %edi	# *_68, tmp310
	cmpl	%edi, (%r12)	# tmp310, *prephitmp_176
# median.h:142:   int c = array[*i1] <= array[*i2];
	setle	%dil	#, c
	movzbl	%dil, %edi	# c, c
# median.h:143:   *i1 = c ? x : y;
	cmovle	%r12, %rdx	# _68,, _76, _68
	cmovle	%r10d, %r8d	# high,, _12, high
# median.h:145:   *sorted += c;
	addl	%edi, %esi	# c, tmp207
	movl	%esi, (%rcx)	# tmp207, *sorted_22(D)
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%r14), %ecx	# *prephitmp_177, _56
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%rdx), %edx	# *prephitmp_192, _60
# median.h:9:   *i2 = c ? y : x;
	cmpl	%edx, %ecx	# _60, _56
	jg	.L545	#,
	movl	%edx, %ecx	# _60, _56
	movl	%r8d, %eax	# high, _14
.L545:
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	0(%rbp), %edx	# *prephitmp_52, _46
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%rbx), %esi	# *prephitmp_174, _50
# median.h:8:   *i1 = c ? x : y;
	cmpl	%esi, %edx	# _50, _46
	jg	.L547	#,
	movl	%esi, %edx	# _50, _46
	movl	%r9d, %esi	# <retval>, <retval>
	movq	%rbp, %rbx	# prephitmp_42, prephitmp_174
# median.h:9:   *i2 = c ? y : x;
	movl	%r11d, %r9d	# iftmp.14_95, <retval>
# median.h:8:   *i1 = c ? x : y;
	movl	%esi, %r11d	# <retval>, iftmp.14_95
.L547:
	cmpl	%edx, %ecx	# _46, _56
	jge	.L535	#,
# median.h:9:   *i2 = c ? y : x;
	cmpl	%ecx, (%rbx)	# _56, *prephitmp_203
	jle	.L552	#,
	movl	%r11d, %r9d	# iftmp.14_95, <retval>
.L535:
# median.h:201: }
	popq	%rbx	#
	.cfi_remember_state
	.cfi_def_cfa_offset 40
	popq	%rbp	#
	.cfi_def_cfa_offset 32
	popq	%r12	#
	.cfi_def_cfa_offset 24
	popq	%r13	#
	.cfi_def_cfa_offset 16
	movl	%r9d, %eax	# <retval>,
	popq	%r14	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L560:
	.cfi_restore_state
# median.h:9:   *i2 = c ? y : x;
	movq	%r14, %rbx	# prephitmp_39, prephitmp_174
	movl	%edx, %r11d	# _6, iftmp.14_95
	jmp	.L542	#
	.p2align 4,,10
	.p2align 3
.L559:
# median.h:143:   *i1 = c ? x : y;
	movq	%r14, %rbx	# prephitmp_39, prephitmp_39
	movq	%r12, %r14	# prephitmp_36, prephitmp_39
	movq	%rbx, %r12	# prephitmp_39, prephitmp_36
	movl	%r11d, %ebx	# iftmp.14_95, iftmp.14_95
# median.h:144:   *i2 = c ? y : x;
	movl	%edx, %r11d	# _6, iftmp.14_95
# median.h:143:   *i1 = c ? x : y;
	movl	%ebx, %edx	# iftmp.14_95, _6
	jmp	.L540	#
	.p2align 4,,10
	.p2align 3
.L558:
# median.h:9:   *i2 = c ? y : x;
	movq	%r11, %rbp	# _144, prephitmp_42
	movl	%esi, %r9d	# low, <retval>
	jmp	.L539	#
	.p2align 4,,10
	.p2align 3
.L557:
# median.h:143:   *i1 = c ? x : y;
	movq	%r11, %rbx	# _144, _144
	movq	%r10, %r11	# _148, _144
	movq	%rbx, %r10	# _144, _148
	movl	%r9d, %ebx	# <retval>, <retval>
# median.h:144:   *i2 = c ? y : x;
	movl	%esi, %r9d	# low, <retval>
# median.h:143:   *i1 = c ? x : y;
	movl	%ebx, %esi	# <retval>, low
	jmp	.L537	#
	.p2align 4,,10
	.p2align 3
.L556:
	.cfi_def_cfa_offset 8
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	.cfi_restore 14
# median.h:168:     return median_of_three_opti(array, low, high, sorted);
	movl	%r8d, %edx	# high,
	jmp	median_of_three_opti	#
.L552:
	.cfi_def_cfa_offset 48
	.cfi_offset 3, -48
	.cfi_offset 6, -40
	.cfi_offset 12, -32
	.cfi_offset 13, -24
	.cfi_offset 14, -16
# median.h:8:   *i1 = c ? x : y;
	movl	%eax, %r9d	# _14, <retval>
	jmp	.L535	#
	.cfi_endproc
.LFE62:
	.size	median_of_three_of_median_of_three_opti, .-median_of_three_of_median_of_three_opti
	.p2align 4
	.globl	sign
	.type	sign, @function
sign:
.LFB5399:
	.cfi_startproc
	endbr64	
# mergeo.h:13: int sign(int x) { return (x >> (CHAR_BIT * sizeof(x) - 1)) | (!!x); }
	movl	%edi, %eax	# x, tmp88
	sarl	$31, %eax	#, tmp88
# mergeo.h:13: int sign(int x) { return (x >> (CHAR_BIT * sizeof(x) - 1)) | (!!x); }
	xorl	%edx, %edx	# tmp89
	testl	%edi, %edi	# x
	setne	%dl	#, tmp89
# mergeo.h:13: int sign(int x) { return (x >> (CHAR_BIT * sizeof(x) - 1)) | (!!x); }
	orl	%edx, %eax	# tmp89, tmp87
# mergeo.h:13: int sign(int x) { return (x >> (CHAR_BIT * sizeof(x) - 1)) | (!!x); }
	ret	
	.cfi_endproc
.LFE5399:
	.size	sign, .-sign
	.p2align 4
	.globl	merging_optimized
	.type	merging_optimized, @function
merging_optimized:
.LFB5400:
	.cfi_startproc
	endbr64	
	pushq	%rbp	#
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
# mergeo.h:18:   l2 = mid + 1;
	leal	1(%rdx), %eax	#, tmp384
# mergeo.h:15: void merging_optimized(int a[], int low, int mid, int high, int *b) {
	movl	%edx, %r9d	# tmp387, mid
	movq	%rsp, %rbp	#,
	.cfi_def_cfa_register 6
	pushq	%r15	#
	.cfi_offset 15, -24
	movl	%esi, %r15d	# tmp386, low
	pushq	%r14	#
	pushq	%r13	#
	pushq	%r12	#
	pushq	%rbx	#
	andq	$-32, %rsp	#,
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
# mergeo.h:18:   l2 = mid + 1;
	movl	%eax, -12(%rsp)	# tmp384, %sfp
# mergeo.h:21:   for (i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%edx, %esi	# mid, low
	jg	.L592	#,
	cmpl	%ecx, %eax	# high, tmp384
	jg	.L592	#,
	leal	1(%rsi), %r10d	#, tmp300
	movslq	%r10d, %r10	# tmp300, ivtmp.1026
# mergeo.h:24:     l1 += 1 - c;
	movl	$1, %ebx	#, tmp307
	.p2align 4,,10
	.p2align 3
.L564:
# mergeo.h:22:     int c = a[l1] > a[l2];
	movslq	%esi, %rdx	# tmp.961, tmp.961
# mergeo.h:22:     int c = a[l1] > a[l2];
	movslq	%eax, %r11	# tmp.941, tmp.941
# mergeo.h:22:     int c = a[l1] > a[l2];
	movl	(%rdi,%rdx,4), %edx	# *_3, _4
# mergeo.h:22:     int c = a[l1] > a[l2];
	movl	(%rdi,%r11,4), %r11d	# *_7, _8
# mergeo.h:22:     int c = a[l1] > a[l2];
	xorl	%r12d, %r12d	# tmp303
	cmpl	%r11d, %edx	# _8, _4
# mergeo.h:23:     b[i] = c ? a[l2] : a[l1];
	cmovg	%r11d, %edx	# _4,, _8, tmp305
# mergeo.h:22:     int c = a[l1] > a[l2];
	setg	%r12b	#, tmp303
# mergeo.h:23:     b[i] = c ? a[l2] : a[l1];
	movl	%edx, -4(%r8,%r10,4)	# tmp305, MEM[base: b_57(D), index: ivtmp.1026_342, step: 4, offset: -4B]
# mergeo.h:24:     l1 += 1 - c;
	movl	%ebx, %edx	# tmp307, tmp306
	subl	%r12d, %edx	# tmp303, tmp306
# mergeo.h:24:     l1 += 1 - c;
	addl	%edx, %esi	# tmp306, tmp.961
# mergeo.h:25:     l2 += c;
	addl	%r12d, %eax	# tmp303, tmp.941
# mergeo.h:21:   for (i = low; l1 <= mid && l2 <= high; i++) {
	movl	%r10d, %edx	# ivtmp.1026, tmp.942
# mergeo.h:21:   for (i = low; l1 <= mid && l2 <= high; i++) {
	incq	%r10	# ivtmp.1026
	cmpl	%esi, %r9d	# tmp.961, mid
	jl	.L566	#,
	cmpl	%eax, %ecx	# tmp.941, high
	jge	.L564	#,
.L563:
# mergeo.h:28:   while (l1 <= mid) {
	cmpl	%esi, %r9d	# tmp.961, mid
	jl	.L566	#,
	movslq	%edx, %r14	# tmp.942, _351
	movl	%r9d, %ebx	# mid, _349
	movslq	%esi, %r10	# tmp.961, ivtmp.1007
	subl	%esi, %ebx	# tmp.961, _349
	leaq	0(,%r14,4), %r12	#, _352
	leaq	1(%r10), %r11	#, ivtmp.1007
	leaq	0(,%r11,4), %r13	#, _356
	movl	%ebx, -8(%rsp)	# _349, %sfp
	leaq	(%r8,%r12), %rbx	#, _353
	movq	%r14, -24(%rsp)	# _351, %sfp
	movq	%r13, -32(%rsp)	# _356, %sfp
	movq	%rbx, %r14	# _353, tmp314
	addq	%rdi, %r13	# a, tmp313
	subq	%r13, %r14	# tmp313, tmp314
	movl	%esi, -16(%rsp)	# tmp.961, %sfp
	cmpq	$24, %r14	#, tmp314
	jbe	.L567	#,
	cmpl	$2, -8(%rsp)	#, %sfp
	jbe	.L567	#,
	movl	-12(%rsp), %r14d	# %sfp, niters.948
	subl	%esi, %r14d	# tmp.961, niters.948
	cmpl	$6, -8(%rsp)	#, %sfp
	movl	%r14d, %r13d	# niters.948, niters.948
	jbe	.L593	#,
	movq	-32(%rsp), %r14	# %sfp, _356
	movl	%r13d, %r12d	# niters.948, bnd.949
	shrl	$3, %r12d	#,
	leaq	-4(%rdi,%r14), %r14	#, vectp.954
	salq	$5, %r12	#, _202
	xorl	%r11d, %r11d	# ivtmp.1019
	.p2align 4,,10
	.p2align 3
.L569:
# mergeo.h:29:     b[i++] = a[l1++];
	vmovdqu	(%r14,%r11), %ymm1	# MEM[base: vectp.954_410, index: ivtmp.1019_205, offset: 0B], tmp471
	vmovdqu	%ymm1, (%rbx,%r11)	# tmp471, MEM[base: _353, index: ivtmp.1019_205, offset: 0B]
	addq	$32, %r11	#, ivtmp.1019
	cmpq	%r11, %r12	# ivtmp.1019, _202
	jne	.L569	#,
	movl	%r13d, %r11d	# niters.948, niters_vector_mult_vf.950
	andl	$-8, %r11d	#,
	addl	%r11d, %esi	# niters_vector_mult_vf.950, tmp.961
	leal	(%rdx,%r11), %ebx	#, tmp.962
	cmpl	%r11d, %r13d	# niters_vector_mult_vf.950, niters.948
	je	.L574	#,
	movl	-8(%rsp), %r12d	# %sfp, _349
	subl	%r11d, %r13d	# niters_vector_mult_vf.950, niters.948
	subl	%r11d, %r12d	# niters_vector_mult_vf.950, _349
	cmpl	$2, %r12d	#, tmp324
	jbe	.L571	#,
.L568:
# mergeo.h:29:     b[i++] = a[l1++];
	addq	%r11, %r10	# _460, tmp325
	vmovdqu	(%rdi,%r10,4), %xmm0	# MEM <vector(4) int> [(int *)vectp.964_458], MEM <vector(4) int> [(int *)vectp.964_458]
	movl	%r13d, %r10d	# niters.948, niters_vector_mult_vf.960
	andl	$-4, %r10d	#, niters_vector_mult_vf.960
# mergeo.h:29:     b[i++] = a[l1++];
	addq	-24(%rsp), %r11	# %sfp, tmp327
	vmovdqu	%xmm0, (%r8,%r11,4)	# MEM <vector(4) int> [(int *)vectp.964_458], MEM <vector(4) int> [(int *)vectp.967_466]
	addl	%r10d, %esi	# niters_vector_mult_vf.960, tmp.961
	addl	%r10d, %ebx	# niters_vector_mult_vf.960, tmp.962
	cmpl	%r10d, %r13d	# niters_vector_mult_vf.960, niters.948
	je	.L574	#,
.L571:
# mergeo.h:29:     b[i++] = a[l1++];
	movslq	%esi, %r12	# tmp.961, tmp.961
# mergeo.h:29:     b[i++] = a[l1++];
	movl	(%rdi,%r12,4), %r12d	# *_35, _115
# mergeo.h:29:     b[i++] = a[l1++];
	leal	1(%rbx), %r11d	#, i
# mergeo.h:29:     b[i++] = a[l1++];
	leal	1(%rsi), %r10d	#, l1
# mergeo.h:29:     b[i++] = a[l1++];
	movslq	%ebx, %rbx	# tmp.962, tmp.962
# mergeo.h:29:     b[i++] = a[l1++];
	movl	%r12d, (%r8,%rbx,4)	# _115, *_306
# mergeo.h:28:   while (l1 <= mid) {
	cmpl	%r10d, %r9d	# l1, mid
	jl	.L574	#,
# mergeo.h:29:     b[i++] = a[l1++];
	movslq	%r10d, %r10	# l1, l1
# mergeo.h:29:     b[i++] = a[l1++];
	movl	(%rdi,%r10,4), %r10d	# *_172, _157
# mergeo.h:29:     b[i++] = a[l1++];
	movslq	%r11d, %r11	# i, i
# mergeo.h:29:     b[i++] = a[l1++];
	addl	$2, %esi	#, l1
# mergeo.h:29:     b[i++] = a[l1++];
	movl	%r10d, (%r8,%r11,4)	# _157, *_239
# mergeo.h:29:     b[i++] = a[l1++];
	leaq	0(,%r11,4), %rbx	#, _287
# mergeo.h:28:   while (l1 <= mid) {
	cmpl	%esi, %r9d	# l1, mid
	jl	.L574	#,
# mergeo.h:29:     b[i++] = a[l1++];
	movslq	%esi, %rsi	# l1, l1
# mergeo.h:29:     b[i++] = a[l1++];
	movl	(%rdi,%rsi,4), %esi	# *_436, _441
# mergeo.h:29:     b[i++] = a[l1++];
	movl	%esi, 4(%r8,%rbx)	# _441, *_440
.L574:
	addl	-12(%rsp), %edx	# %sfp, tmp338
# mergeo.h:29:     b[i++] = a[l1++];
	subl	-16(%rsp), %edx	# %sfp, tmp.942
.L566:
# mergeo.h:32:   while (l2 <= high) {
	cmpl	%eax, %ecx	# tmp.941, high
	jl	.L575	#,
	movslq	%edx, %r11	# tmp.942, _215
	movslq	%eax, %rsi	# tmp.941, ivtmp.988
	leaq	1(%rsi), %r14	#, ivtmp.988
	leaq	0(,%r11,4), %r13	#, _216
	leaq	(%r8,%r13), %r10	#, _217
	leaq	0(,%r14,4), %r12	#, _220
	movq	%r14, -8(%rsp)	# ivtmp.988, %sfp
	movq	%r10, %r9	# _217, tmp341
	leaq	(%rdi,%r12), %r14	#, tmp340
	movl	%ecx, %ebx	# high, _213
	subq	%r14, %r9	# tmp340, tmp341
	subl	%eax, %ebx	# tmp.941, _213
	cmpq	$24, %r9	#, tmp341
	jbe	.L576	#,
	cmpl	$2, %ebx	#, _213
	jbe	.L576	#,
	leal	1(%rcx), %r13d	#, tmp346
	subl	%eax, %r13d	# tmp.941, niters.928
	cmpl	$6, %ebx	#, _213
	jbe	.L594	#,
	leaq	-4(%rdi,%r12), %r14	#, vectp.934
	movl	%r13d, %r12d	# niters.928, bnd.929
	shrl	$3, %r12d	#,
	salq	$5, %r12	#, _345
	xorl	%r9d, %r9d	# ivtmp.1000
	.p2align 4,,10
	.p2align 3
.L578:
# mergeo.h:33:     b[i++] = a[l2++];
	vmovdqu	(%r14,%r9), %ymm2	# MEM[base: vectp.934_273, index: ivtmp.1000_189, offset: 0B], tmp480
	vmovdqu	%ymm2, (%r10,%r9)	# tmp480, MEM[base: _217, index: ivtmp.1000_189, offset: 0B]
	addq	$32, %r9	#, ivtmp.1000
	cmpq	%r12, %r9	# _345, ivtmp.1000
	jne	.L578	#,
	movl	%r13d, %r9d	# niters.928, niters_vector_mult_vf.930
	andl	$-8, %r9d	#,
	addl	%r9d, %eax	# niters_vector_mult_vf.930, tmp.941
	addl	%r9d, %edx	# niters_vector_mult_vf.930, tmp.942
	cmpl	%r9d, %r13d	# niters_vector_mult_vf.930, niters.928
	je	.L575	#,
	subl	%r9d, %ebx	# niters_vector_mult_vf.930, tmp351
	subl	%r9d, %r13d	# niters_vector_mult_vf.930, niters.928
	cmpl	$2, %ebx	#, tmp351
	jbe	.L580	#,
.L577:
# mergeo.h:33:     b[i++] = a[l2++];
	addq	%r9, %rsi	# _323, tmp352
	vmovdqu	(%rdi,%rsi,4), %xmm0	# MEM <vector(4) int> [(int *)vectp.944_321], MEM <vector(4) int> [(int *)vectp.944_321]
	movl	%r13d, %esi	# niters.928, niters_vector_mult_vf.940
	andl	$-4, %esi	#, niters_vector_mult_vf.940
# mergeo.h:33:     b[i++] = a[l2++];
	addq	%r11, %r9	# _215, tmp354
	vmovdqu	%xmm0, (%r8,%r9,4)	# MEM <vector(4) int> [(int *)vectp.944_321], MEM <vector(4) int> [(int *)vectp.947_329]
	addl	%esi, %eax	# niters_vector_mult_vf.940, tmp.941
	addl	%esi, %edx	# niters_vector_mult_vf.940, tmp.942
	cmpl	%esi, %r13d	# niters_vector_mult_vf.940, niters.928
	je	.L575	#,
.L580:
# mergeo.h:33:     b[i++] = a[l2++];
	movslq	%eax, %r10	# tmp.941, tmp.941
# mergeo.h:33:     b[i++] = a[l2++];
	movl	(%rdi,%r10,4), %r10d	# *_89, _62
# mergeo.h:33:     b[i++] = a[l2++];
	leal	1(%rdx), %r9d	#, i
# mergeo.h:33:     b[i++] = a[l2++];
	leal	1(%rax), %esi	#, l2
# mergeo.h:33:     b[i++] = a[l2++];
	movslq	%edx, %rdx	# tmp.942, tmp.942
# mergeo.h:33:     b[i++] = a[l2++];
	movl	%r10d, (%r8,%rdx,4)	# _62, *_28
# mergeo.h:32:   while (l2 <= high) {
	cmpl	%esi, %ecx	# l2, high
	jl	.L575	#,
# mergeo.h:33:     b[i++] = a[l2++];
	movslq	%esi, %rsi	# l2, l2
# mergeo.h:33:     b[i++] = a[l2++];
	movl	(%rdi,%rsi,4), %esi	# *_247, _252
# mergeo.h:33:     b[i++] = a[l2++];
	movslq	%r9d, %rdx	# i, i
# mergeo.h:33:     b[i++] = a[l2++];
	addl	$2, %eax	#, l2
# mergeo.h:33:     b[i++] = a[l2++];
	movl	%esi, (%r8,%rdx,4)	# _252, *_251
# mergeo.h:33:     b[i++] = a[l2++];
	leaq	0(,%rdx,4), %r9	#, _250
# mergeo.h:32:   while (l2 <= high) {
	cmpl	%eax, %ecx	# l2, high
	jl	.L575	#,
# mergeo.h:33:     b[i++] = a[l2++];
	cltq
# mergeo.h:33:     b[i++] = a[l2++];
	movl	(%rdi,%rax,4), %eax	# *_299, _304
# mergeo.h:33:     b[i++] = a[l2++];
	movl	%eax, 4(%r8,%r9)	# _304, *_303
.L575:
# mergeo.h:36:   for (i = low; i <= high; i++) {
	cmpl	%ecx, %r15d	# high, low
	jg	.L634	#,
	movslq	%r15d, %rdx	# low, ivtmp.971
	leaq	0(,%rdx,4), %rsi	#, _139
	leaq	(%rdi,%rsi), %rbx	#, _138
	leaq	4(%r8,%rsi), %r9	#, tmp365
	movq	%rbx, %rax	# _138, tmp366
	movl	%ecx, %r11d	# high, _142
	subq	%r9, %rax	# tmp365, tmp366
	subl	%r15d, %r11d	# low, _142
	cmpq	$24, %rax	#, tmp366
	jbe	.L614	#,
	cmpl	$2, %r11d	#, _142
	jbe	.L614	#,
	leal	1(%rcx), %r9d	#, tmp371
	subl	%r15d, %r9d	# low, niters.910
	cmpl	$6, %r11d	#, _142
	jbe	.L595	#,
	movl	%r9d, %r10d	# niters.910, bnd.911
	shrl	$3, %r10d	#,
	addq	%r8, %rsi	# b, vectp.915
	salq	$5, %r10	#, _391
	xorl	%eax, %eax	# ivtmp.982
	.p2align 4,,10
	.p2align 3
.L587:
# mergeo.h:37:     a[i] = b[i];
	vmovdqu	(%rsi,%rax), %ymm3	# MEM[base: vectp.915_50, index: ivtmp.982_471, offset: 0B], tmp487
	vmovdqu	%ymm3, (%rbx,%rax)	# tmp487, MEM[base: _138, index: ivtmp.982_471, offset: 0B]
	addq	$32, %rax	#, ivtmp.982
	cmpq	%rax, %r10	# ivtmp.982, _391
	jne	.L587	#,
	movl	%r9d, %eax	# niters.910, niters_vector_mult_vf.912
	andl	$-8, %eax	#,
	addl	%eax, %r15d	# niters_vector_mult_vf.912, low
	cmpl	%r9d, %eax	# niters.910, niters_vector_mult_vf.912
	je	.L634	#,
	subl	%eax, %r11d	# niters_vector_mult_vf.912, tmp375
	subl	%eax, %r9d	# niters_vector_mult_vf.912, niters.910
	cmpl	$2, %r11d	#, tmp375
	jbe	.L589	#,
.L586:
	addq	%rax, %rdx	# niters_vector_mult_vf.912, tmp377
# mergeo.h:37:     a[i] = b[i];
	vmovdqu	(%r8,%rdx,4), %xmm4	# MEM <vector(4) int> [(int *)vectp.924_184], tmp489
	movl	%r9d, %eax	# niters.910, niters_vector_mult_vf.921
	andl	$-4, %eax	#, niters_vector_mult_vf.921
	vmovdqu	%xmm4, (%rdi,%rdx,4)	# tmp489, MEM <vector(4) int> [(int *)vectp.927_192]
	addl	%eax, %r15d	# niters_vector_mult_vf.921, low
	cmpl	%r9d, %eax	# niters.910, niters_vector_mult_vf.921
	je	.L634	#,
.L589:
# mergeo.h:37:     a[i] = b[i];
	movslq	%r15d, %rax	# low, low
	movl	(%r8,%rax,4), %edx	# *_20, _65
# mergeo.h:37:     a[i] = b[i];
	movl	%edx, (%rdi,%rax,4)	# _65, *_21
# mergeo.h:36:   for (i = low; i <= high; i++) {
	leal	1(%r15), %eax	#, i
# mergeo.h:36:   for (i = low; i <= high; i++) {
	cmpl	%ecx, %eax	# high, i
	jg	.L634	#,
# mergeo.h:37:     a[i] = b[i];
	cltq
	movl	(%r8,%rax,4), %edx	# *_384, _386
# mergeo.h:36:   for (i = low; i <= high; i++) {
	leal	2(%r15), %esi	#, i
# mergeo.h:37:     a[i] = b[i];
	movl	%edx, (%rdi,%rax,4)	# _386, *_385
# mergeo.h:36:   for (i = low; i <= high; i++) {
	cmpl	%esi, %ecx	# i, high
	jl	.L634	#,
# mergeo.h:37:     a[i] = b[i];
	movslq	%esi, %rsi	# i, i
	movl	(%r8,%rsi,4), %eax	# *_167, _169
# mergeo.h:37:     a[i] = b[i];
	movl	%eax, (%rdi,%rsi,4)	# _169, *_168
.L634:
	vzeroupper
# mergeo.h:39: }
	leaq	-40(%rbp), %rsp	#,
	popq	%rbx	#
	popq	%r12	#
	popq	%r13	#
	popq	%r14	#
	popq	%r15	#
	popq	%rbp	#
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret	
	.p2align 4,,10
	.p2align 3
.L614:
	.cfi_restore_state
# mergeo.h:37:     a[i] = b[i];
	movl	(%r8,%rdx,4), %eax	# MEM[base: b_57(D), index: ivtmp.971_257, step: 4, offset: 0B], _123
# mergeo.h:37:     a[i] = b[i];
	movl	%eax, (%rdi,%rdx,4)	# _123, MEM[base: a_58(D), index: ivtmp.971_257, step: 4, offset: 0B]
# mergeo.h:36:   for (i = low; i <= high; i++) {
	incq	%rdx	# ivtmp.971
	cmpl	%edx, %ecx	# ivtmp.971, high
	jl	.L634	#,
# mergeo.h:37:     a[i] = b[i];
	movl	(%r8,%rdx,4), %eax	# MEM[base: b_57(D), index: ivtmp.971_257, step: 4, offset: 0B], _123
# mergeo.h:37:     a[i] = b[i];
	movl	%eax, (%rdi,%rdx,4)	# _123, MEM[base: a_58(D), index: ivtmp.971_257, step: 4, offset: 0B]
# mergeo.h:36:   for (i = low; i <= high; i++) {
	incq	%rdx	# ivtmp.971
	cmpl	%edx, %ecx	# ivtmp.971, high
	jge	.L614	#,
	jmp	.L634	#
	.p2align 4,,10
	.p2align 3
.L576:
	movq	%rsi, %rax	# ivtmp.988, tmp361
	negq	%rax	# tmp361
	leaq	0(%r13,%rax,4), %rdx	#, tmp363
	movq	-8(%rsp), %r9	# %sfp, ivtmp.988
	addq	%r8, %rdx	# b, _200
	jmp	.L582	#
	.p2align 4,,10
	.p2align 3
.L637:
	incq	%r9	# ivtmp.988
.L582:
# mergeo.h:33:     b[i++] = a[l2++];
	movl	(%rdi,%rsi,4), %eax	# MEM[base: a_58(D), index: ivtmp.988_390, step: 4, offset: 0B], _237
# mergeo.h:33:     b[i++] = a[l2++];
	movl	%eax, (%rdx,%rsi,4)	# _237, MEM[base: _200, index: ivtmp.988_390, step: 4, offset: 0B]
# mergeo.h:32:   while (l2 <= high) {
	movq	%r9, %rsi	# ivtmp.988, ivtmp.988
	cmpl	%r9d, %ecx	# ivtmp.988, high
	jge	.L637	#,
	jmp	.L575	#
	.p2align 4,,10
	.p2align 3
.L567:
	movq	%r10, %rsi	# ivtmp.1007, tmp334
	negq	%rsi	# tmp334
	leaq	(%r12,%rsi,4), %rbx	#, tmp336
	addq	%r8, %rbx	# b, _103
	jmp	.L573	#
	.p2align 4,,10
	.p2align 3
.L638:
	incq	%r11	# ivtmp.1007
.L573:
# mergeo.h:29:     b[i++] = a[l1++];
	movl	(%rdi,%r10,4), %esi	# MEM[base: a_58(D), index: ivtmp.1007_344, step: 4, offset: 0B], _373
# mergeo.h:29:     b[i++] = a[l1++];
	movl	%esi, (%rbx,%r10,4)	# _373, MEM[base: _103, index: ivtmp.1007_344, step: 4, offset: 0B]
# mergeo.h:28:   while (l1 <= mid) {
	movq	%r11, %r10	# ivtmp.1007, ivtmp.1007
	cmpl	%r11d, %r9d	# ivtmp.1007, mid
	jge	.L638	#,
	jmp	.L574	#
	.p2align 4,,10
	.p2align 3
.L592:
# mergeo.h:21:   for (i = low; l1 <= mid && l2 <= high; i++) {
	movl	%r15d, %edx	# low, tmp.942
	movl	%r15d, %esi	# low, tmp.961
	jmp	.L563	#
.L593:
# mergeo.h:28:   while (l1 <= mid) {
	movl	%edx, %ebx	# tmp.942, tmp.962
	xorl	%r11d, %r11d	#
	jmp	.L568	#
.L595:
# mergeo.h:36:   for (i = low; i <= high; i++) {
	xorl	%eax, %eax	#
	jmp	.L586	#
.L594:
# mergeo.h:32:   while (l2 <= high) {
	xorl	%r9d, %r9d	#
	jmp	.L577	#
	.cfi_endproc
.LFE5400:
	.size	merging_optimized, .-merging_optimized
	.p2align 4
	.type	sort_merge_o.part.0, @function
sort_merge_o.part.0:
.LFB5712:
	.cfi_startproc
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
# mergeo.h:45:     mid = (low + high) / 2;
	leal	(%rsi,%rdx), %eax	#, tmp107
# mergeo.h:41: void sort_merge_o(int a[], int low, int high, int *b) {
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movq	%rdi, %r14	# tmp135, a
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	movl	%edx, %r13d	# tmp137, high
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
# mergeo.h:45:     mid = (low + high) / 2;
	movl	%eax, %r12d	# tmp107, tmp108
	shrl	$31, %r12d	#, tmp108
# mergeo.h:41: void sort_merge_o(int a[], int low, int high, int *b) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
# mergeo.h:45:     mid = (low + high) / 2;
	addl	%eax, %r12d	# tmp107, tmp109
	sarl	%r12d	# tmp110
# mergeo.h:41: void sort_merge_o(int a[], int low, int high, int *b) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	movl	%esi, %ebp	# tmp136, low
	movq	%rcx, %rbx	# tmp138, b
	subq	$24, %rsp	#,
	.cfi_def_cfa_offset 80
# mergeo.h:44:   if (low < high) {
	cmpl	%r12d, %esi	# tmp110, low
	jl	.L655	#,
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r12), %r15d	#, _7
# mergeo.h:44:   if (low < high) {
	cmpl	%r15d, %r13d	# _7, high
	jg	.L656	#,
.L647:
# mergeo.h:50: }
	addq	$24, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 56
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movq	%rbx, %r8	# b,
# mergeo.h:50: }
	popq	%rbx	#
	.cfi_def_cfa_offset 48
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movl	%ebp, %esi	# low,
# mergeo.h:50: }
	popq	%rbp	#
	.cfi_def_cfa_offset 40
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movl	%r12d, %edx	# tmp110,
# mergeo.h:50: }
	popq	%r12	#
	.cfi_def_cfa_offset 32
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movl	%r13d, %ecx	# high,
# mergeo.h:50: }
	popq	%r13	#
	.cfi_def_cfa_offset 24
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movq	%r14, %rdi	# a,
# mergeo.h:50: }
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	jmp	merging_optimized	#
	.p2align 4,,10
	.p2align 3
.L655:
	.cfi_restore_state
# mergeo.h:45:     mid = (low + high) / 2;
	leal	(%rsi,%r12), %eax	#, tmp111
# mergeo.h:45:     mid = (low + high) / 2;
	movl	%eax, %r15d	# tmp111, tmp112
	shrl	$31, %r15d	#, tmp112
	addl	%eax, %r15d	# tmp111, tmp113
	sarl	%r15d	# tmp114
# mergeo.h:44:   if (low < high) {
	cmpl	%r15d, %esi	# tmp114, low
	jl	.L657	#,
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r15), %r9d	#, _14
# mergeo.h:44:   if (low < high) {
	cmpl	%r9d, %r12d	# _14, tmp110
	jg	.L658	#,
.L644:
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movl	%r15d, %edx	# tmp114,
	movq	%rbx, %r8	# b,
	movl	%r12d, %ecx	# tmp110,
	movl	%ebp, %esi	# low,
	movq	%r14, %rdi	# a,
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r12), %r15d	#, _7
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	call	merging_optimized	#
# mergeo.h:44:   if (low < high) {
	cmpl	%r15d, %r13d	# _7, high
	jle	.L647	#,
.L656:
# mergeo.h:45:     mid = (low + high) / 2;
	leal	0(%r13,%r15), %eax	#, tmp123
# mergeo.h:45:     mid = (low + high) / 2;
	movl	%eax, %r9d	# tmp123, tmp124
	shrl	$31, %r9d	#, tmp124
	addl	%eax, %r9d	# tmp123, tmp125
	sarl	%r9d	# tmp126
# mergeo.h:44:   if (low < high) {
	cmpl	%r9d, %r15d	# tmp126, _7
	jl	.L659	#,
.L648:
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r9), %r10d	#, _23
# mergeo.h:44:   if (low < high) {
	cmpl	%r10d, %r13d	# _23, high
	jg	.L660	#,
.L651:
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movq	%rbx, %r8	# b,
	movl	%r13d, %ecx	# high,
	movl	%r9d, %edx	# tmp126,
	movl	%r15d, %esi	# _7,
	movq	%r14, %rdi	# a,
	call	merging_optimized	#
	jmp	.L647	#
	.p2align 4,,10
	.p2align 3
.L657:
# mergeo.h:45:     mid = (low + high) / 2;
	leal	(%rsi,%r15), %eax	#, tmp115
# mergeo.h:45:     mid = (low + high) / 2;
	movl	%eax, %r9d	# tmp115, tmp116
	shrl	$31, %r9d	#, tmp116
	addl	%eax, %r9d	# tmp115, tmp117
	sarl	%r9d	# tmp118
# mergeo.h:44:   if (low < high) {
	cmpl	%r9d, %esi	# tmp118, low
	jl	.L661	#,
.L642:
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r9), %esi	#, _17
# mergeo.h:44:   if (low < high) {
	cmpl	%esi, %r15d	# _17, tmp114
	jg	.L662	#,
.L643:
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movl	%r9d, %edx	# tmp118,
	movq	%rbx, %r8	# b,
	movl	%r15d, %ecx	# tmp114,
	movl	%ebp, %esi	# low,
	movq	%r14, %rdi	# a,
	call	merging_optimized	#
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r15), %r9d	#, _14
# mergeo.h:44:   if (low < high) {
	cmpl	%r9d, %r12d	# _14, tmp110
	jle	.L644	#,
.L658:
# mergeo.h:45:     mid = (low + high) / 2;
	leal	(%r12,%r9), %eax	#, tmp119
# mergeo.h:45:     mid = (low + high) / 2;
	movl	%eax, %r10d	# tmp119, tmp120
	shrl	$31, %r10d	#, tmp120
	addl	%eax, %r10d	# tmp119, tmp121
	sarl	%r10d	# tmp122
# mergeo.h:44:   if (low < high) {
	cmpl	%r10d, %r9d	# tmp122, _14
	jl	.L663	#,
.L645:
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r10), %esi	#, _20
# mergeo.h:44:   if (low < high) {
	cmpl	%esi, %r12d	# _20, tmp110
	jg	.L664	#,
.L646:
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movq	%rbx, %r8	# b,
	movl	%r12d, %ecx	# tmp110,
	movl	%r10d, %edx	# tmp122,
	movl	%r9d, %esi	# _14,
	movq	%r14, %rdi	# a,
	call	merging_optimized	#
	jmp	.L644	#
	.p2align 4,,10
	.p2align 3
.L660:
# mergeo.h:45:     mid = (low + high) / 2;
	leal	0(%r13,%r10), %eax	#, tmp131
# mergeo.h:45:     mid = (low + high) / 2;
	movl	%eax, %r11d	# tmp131, tmp132
	shrl	$31, %r11d	#, tmp132
	addl	%eax, %r11d	# tmp131, tmp133
	sarl	%r11d	# tmp134
# mergeo.h:44:   if (low < high) {
	cmpl	%r11d, %r10d	# tmp134, _23
	jl	.L665	#,
.L652:
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r11), %esi	#, _29
# mergeo.h:44:   if (low < high) {
	cmpl	%esi, %r13d	# _29, high
	jg	.L666	#,
.L653:
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movq	%rbx, %r8	# b,
	movl	%r13d, %ecx	# high,
	movl	%r11d, %edx	# tmp134,
	movl	%r10d, %esi	# _23,
	movq	%r14, %rdi	# a,
	movl	%r9d, 4(%rsp)	# tmp126, %sfp
	call	merging_optimized	#
	movl	4(%rsp), %r9d	# %sfp, tmp126
	jmp	.L651	#
	.p2align 4,,10
	.p2align 3
.L659:
# mergeo.h:45:     mid = (low + high) / 2;
	leal	(%r15,%r9), %eax	#, tmp127
# mergeo.h:45:     mid = (low + high) / 2;
	movl	%eax, %r10d	# tmp127, tmp128
	shrl	$31, %r10d	#, tmp128
	addl	%eax, %r10d	# tmp127, tmp129
	sarl	%r10d	# tmp130
# mergeo.h:44:   if (low < high) {
	cmpl	%r10d, %r15d	# tmp130, _7
	jl	.L667	#,
.L649:
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r10), %esi	#, _26
# mergeo.h:44:   if (low < high) {
	cmpl	%esi, %r9d	# _26, tmp126
	jg	.L668	#,
.L650:
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movl	%r9d, %ecx	# tmp126,
	movq	%rbx, %r8	# b,
	movl	%r10d, %edx	# tmp130,
	movl	%r15d, %esi	# _7,
	movq	%r14, %rdi	# a,
	movl	%r9d, 4(%rsp)	# tmp126, %sfp
	call	merging_optimized	#
	movl	4(%rsp), %r9d	# %sfp, tmp126
	jmp	.L648	#
	.p2align 4,,10
	.p2align 3
.L661:
	movl	%r9d, %edx	# tmp118,
	movl	%r9d, 4(%rsp)	# tmp118, %sfp
	call	sort_merge_o.part.0	#
	movl	4(%rsp), %r9d	# %sfp, tmp118
	jmp	.L642	#
	.p2align 4,,10
	.p2align 3
.L664:
	movq	%rbx, %rcx	# b,
	movl	%r12d, %edx	# tmp110,
	movq	%r14, %rdi	# a,
	movl	%r10d, 8(%rsp)	# tmp122, %sfp
	movl	%r9d, 4(%rsp)	# _14, %sfp
	call	sort_merge_o.part.0	#
	movl	8(%rsp), %r10d	# %sfp, tmp122
	movl	4(%rsp), %r9d	# %sfp, _14
	jmp	.L646	#
	.p2align 4,,10
	.p2align 3
.L663:
	movl	%r10d, %edx	# tmp122,
	movl	%r9d, %esi	# _14,
	movq	%rbx, %rcx	# b,
	movq	%r14, %rdi	# a,
	movl	%r10d, 8(%rsp)	# tmp122, %sfp
	movl	%r9d, 4(%rsp)	# _14, %sfp
	call	sort_merge_o.part.0	#
	movl	8(%rsp), %r10d	# %sfp, tmp122
	movl	4(%rsp), %r9d	# %sfp, _14
	jmp	.L645	#
	.p2align 4,,10
	.p2align 3
.L668:
	movl	%r9d, %edx	# tmp126,
	movq	%rbx, %rcx	# b,
	movq	%r14, %rdi	# a,
	movl	%r10d, 8(%rsp)	# tmp130, %sfp
	movl	%r9d, 4(%rsp)	# tmp126, %sfp
	call	sort_merge_o.part.0	#
	movl	8(%rsp), %r10d	# %sfp, tmp130
	movl	4(%rsp), %r9d	# %sfp, tmp126
	jmp	.L650	#
	.p2align 4,,10
	.p2align 3
.L667:
	movl	%r10d, %edx	# tmp130,
	movq	%rbx, %rcx	# b,
	movl	%r15d, %esi	# _7,
	movq	%r14, %rdi	# a,
	movl	%r9d, 8(%rsp)	# tmp126, %sfp
	movl	%r10d, 4(%rsp)	# tmp130, %sfp
	call	sort_merge_o.part.0	#
	movl	8(%rsp), %r9d	# %sfp, tmp126
	movl	4(%rsp), %r10d	# %sfp, tmp130
	jmp	.L649	#
	.p2align 4,,10
	.p2align 3
.L666:
	movq	%rbx, %rcx	# b,
	movl	%r13d, %edx	# high,
	movq	%r14, %rdi	# a,
	movl	%r11d, 12(%rsp)	# tmp134, %sfp
	movl	%r9d, 8(%rsp)	# tmp126, %sfp
	movl	%r10d, 4(%rsp)	# _23, %sfp
	call	sort_merge_o.part.0	#
	movl	12(%rsp), %r11d	# %sfp, tmp134
	movl	8(%rsp), %r9d	# %sfp, tmp126
	movl	4(%rsp), %r10d	# %sfp, _23
	jmp	.L653	#
	.p2align 4,,10
	.p2align 3
.L665:
	movl	%r11d, %edx	# tmp134,
	movl	%r10d, %esi	# _23,
	movq	%rbx, %rcx	# b,
	movq	%r14, %rdi	# a,
	movl	%r9d, 12(%rsp)	# tmp126, %sfp
	movl	%r11d, 8(%rsp)	# tmp134, %sfp
	movl	%r10d, 4(%rsp)	# _23, %sfp
	call	sort_merge_o.part.0	#
	movl	12(%rsp), %r9d	# %sfp, tmp126
	movl	8(%rsp), %r11d	# %sfp, tmp134
	movl	4(%rsp), %r10d	# %sfp, _23
	jmp	.L652	#
	.p2align 4,,10
	.p2align 3
.L662:
	movq	%rbx, %rcx	# b,
	movl	%r15d, %edx	# tmp114,
	movq	%r14, %rdi	# a,
	movl	%r9d, 4(%rsp)	# tmp118, %sfp
	call	sort_merge_o.part.0	#
	movl	4(%rsp), %r9d	# %sfp, tmp118
	jmp	.L643	#
	.cfi_endproc
.LFE5712:
	.size	sort_merge_o.part.0, .-sort_merge_o.part.0
	.p2align 4
	.globl	sort_merge_optimized
	.type	sort_merge_optimized, @function
sort_merge_optimized:
.LFB5402:
	.cfi_startproc
	endbr64	
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	movl	%edx, %r13d	# tmp118, high
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	movq	%rdi, %r12	# tmp116, a
# mergeo.h:53:   int *b = (int*) malloc(sizeof(int32_t) * (high - low + 1));
	movl	%edx, %edi	# high, tmp99
# mergeo.h:52: void sort_merge_optimized(int a[], int low, int high) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
# mergeo.h:53:   int *b = (int*) malloc(sizeof(int32_t) * (high - low + 1));
	subl	%esi, %edi	# low, tmp99
# mergeo.h:53:   int *b = (int*) malloc(sizeof(int32_t) * (high - low + 1));
	incl	%edi	# tmp100
# mergeo.h:52: void sort_merge_optimized(int a[], int low, int high) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
# mergeo.h:53:   int *b = (int*) malloc(sizeof(int32_t) * (high - low + 1));
	movslq	%edi, %rdi	# tmp100, tmp101
# mergeo.h:53:   int *b = (int*) malloc(sizeof(int32_t) * (high - low + 1));
	salq	$2, %rdi	#, tmp102
# mergeo.h:52: void sort_merge_optimized(int a[], int low, int high) {
	subq	$24, %rsp	#,
	.cfi_def_cfa_offset 80
# mergeo.h:52: void sort_merge_optimized(int a[], int low, int high) {
	movl	%esi, %ebp	# tmp117, low
# mergeo.h:53:   int *b = (int*) malloc(sizeof(int32_t) * (high - low + 1));
	call	malloc@PLT	#
	movq	%rax, %r14	# tmp119, b
# mergeo.h:44:   if (low < high) {
	cmpl	%ebp, %r13d	# low, high
	jg	.L678	#,
.L670:
# mergeo.h:56: }
	addq	$24, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
# mergeo.h:55:   free(b);
	movq	%r14, %rdi	# b,
# mergeo.h:56: }
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
# mergeo.h:55:   free(b);
	jmp	free@PLT	#
	.p2align 4,,10
	.p2align 3
.L678:
	.cfi_restore_state
# mergeo.h:45:     mid = (low + high) / 2;
	leal	0(%r13,%rbp), %eax	#, tmp104
# mergeo.h:45:     mid = (low + high) / 2;
	movl	%eax, %r15d	# tmp104, tmp105
	shrl	$31, %r15d	#, tmp105
	addl	%eax, %r15d	# tmp104, tmp106
	sarl	%r15d	# tmp107
# mergeo.h:44:   if (low < high) {
	cmpl	%r15d, %ebp	# tmp107, low
	jl	.L679	#,
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r15), %ebx	#, _16
# mergeo.h:44:   if (low < high) {
	cmpl	%ebx, %r13d	# _16, high
	jg	.L680	#,
.L674:
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movq	%r14, %r8	# b,
	movl	%r13d, %ecx	# high,
	movl	%r15d, %edx	# tmp107,
	movl	%ebp, %esi	# low,
	movq	%r12, %rdi	# a,
	call	merging_optimized	#
	jmp	.L670	#
	.p2align 4,,10
	.p2align 3
.L679:
# mergeo.h:45:     mid = (low + high) / 2;
	leal	0(%rbp,%r15), %eax	#, tmp108
# mergeo.h:45:     mid = (low + high) / 2;
	movl	%eax, %ebx	# tmp108, tmp109
	shrl	$31, %ebx	#, tmp109
	addl	%eax, %ebx	# tmp108, tmp110
	sarl	%ebx	# tmp111
# mergeo.h:44:   if (low < high) {
	cmpl	%ebx, %ebp	# tmp111, low
	jl	.L681	#,
.L672:
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%rbx), %esi	#, _19
# mergeo.h:44:   if (low < high) {
	cmpl	%esi, %r15d	# _19, tmp107
	jg	.L682	#,
.L673:
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movl	%ebx, %edx	# tmp111,
	movq	%r14, %r8	# b,
	movl	%r15d, %ecx	# tmp107,
	movl	%ebp, %esi	# low,
	movq	%r12, %rdi	# a,
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r15), %ebx	#, _16
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	call	merging_optimized	#
# mergeo.h:44:   if (low < high) {
	cmpl	%ebx, %r13d	# _16, high
	jle	.L674	#,
.L680:
# mergeo.h:45:     mid = (low + high) / 2;
	leal	0(%r13,%rbx), %eax	#, tmp112
# mergeo.h:45:     mid = (low + high) / 2;
	movl	%eax, %r9d	# tmp112, tmp113
	shrl	$31, %r9d	#, tmp113
	addl	%eax, %r9d	# tmp112, tmp114
	sarl	%r9d	# tmp115
# mergeo.h:44:   if (low < high) {
	cmpl	%r9d, %ebx	# tmp115, _16
	jl	.L683	#,
.L675:
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r9), %esi	#, _22
# mergeo.h:44:   if (low < high) {
	cmpl	%esi, %r13d	# _22, high
	jg	.L684	#,
.L676:
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movq	%r14, %r8	# b,
	movl	%r13d, %ecx	# high,
	movl	%r9d, %edx	# tmp115,
	movl	%ebx, %esi	# _16,
	movq	%r12, %rdi	# a,
	call	merging_optimized	#
	jmp	.L674	#
	.p2align 4,,10
	.p2align 3
.L681:
	movq	%r14, %rcx	# b,
	movl	%ebx, %edx	# tmp111,
	movl	%ebp, %esi	# low,
	movq	%r12, %rdi	# a,
	call	sort_merge_o.part.0	#
	jmp	.L672	#
	.p2align 4,,10
	.p2align 3
.L684:
	movq	%r14, %rcx	# b,
	movl	%r13d, %edx	# high,
	movq	%r12, %rdi	# a,
	movl	%r9d, 12(%rsp)	# tmp115, %sfp
	call	sort_merge_o.part.0	#
	movl	12(%rsp), %r9d	# %sfp, tmp115
	jmp	.L676	#
	.p2align 4,,10
	.p2align 3
.L683:
	movl	%r9d, %edx	# tmp115,
	movq	%r14, %rcx	# b,
	movl	%ebx, %esi	# _16,
	movq	%r12, %rdi	# a,
	movl	%r9d, 12(%rsp)	# tmp115, %sfp
	call	sort_merge_o.part.0	#
	movl	12(%rsp), %r9d	# %sfp, tmp115
	jmp	.L675	#
	.p2align 4,,10
	.p2align 3
.L682:
	movq	%r14, %rcx	# b,
	movl	%r15d, %edx	# tmp107,
	movq	%r12, %rdi	# a,
	call	sort_merge_o.part.0	#
	jmp	.L673	#
	.cfi_endproc
.LFE5402:
	.size	sort_merge_optimized, .-sort_merge_optimized
	.p2align 4
	.globl	sort_merge_o
	.type	sort_merge_o, @function
sort_merge_o:
.LFB5401:
	.cfi_startproc
	endbr64	
# mergeo.h:44:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jl	.L697	#,
	ret	
	.p2align 4,,10
	.p2align 3
.L697:
# mergeo.h:41: void sort_merge_o(int a[], int low, int high, int *b) {
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
# mergeo.h:45:     mid = (low + high) / 2;
	leal	(%rsi,%rdx), %eax	#, tmp95
# mergeo.h:41: void sort_merge_o(int a[], int low, int high, int *b) {
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
# mergeo.h:45:     mid = (low + high) / 2;
	movl	%eax, %r13d	# tmp95, tmp96
	shrl	$31, %r13d	#, tmp96
# mergeo.h:41: void sort_merge_o(int a[], int low, int high, int *b) {
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
# mergeo.h:45:     mid = (low + high) / 2;
	addl	%eax, %r13d	# tmp95, tmp97
	sarl	%r13d	# tmp98
# mergeo.h:41: void sort_merge_o(int a[], int low, int high, int *b) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	movl	%edx, %r12d	# tmp109, high
	movl	%esi, %ebp	# tmp108, low
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	movq	%rcx, %rbx	# tmp110, b
	subq	$24, %rsp	#,
	.cfi_def_cfa_offset 80
# mergeo.h:44:   if (low < high) {
	cmpl	%r13d, %esi	# tmp98, low
	jl	.L698	#,
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r13), %r14d	#, _10
# mergeo.h:44:   if (low < high) {
	cmpl	%r14d, %r12d	# _10, high
	jg	.L699	#,
.L690:
# mergeo.h:50: }
	addq	$24, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 56
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movq	%rbx, %r8	# b,
# mergeo.h:50: }
	popq	%rbx	#
	.cfi_restore 3
	.cfi_def_cfa_offset 48
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movl	%ebp, %esi	# low,
# mergeo.h:50: }
	popq	%rbp	#
	.cfi_restore 6
	.cfi_def_cfa_offset 40
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movl	%r12d, %ecx	# high,
# mergeo.h:50: }
	popq	%r12	#
	.cfi_restore 12
	.cfi_def_cfa_offset 32
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movl	%r13d, %edx	# tmp98,
# mergeo.h:50: }
	popq	%r13	#
	.cfi_restore 13
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_restore 14
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_restore 15
	.cfi_def_cfa_offset 8
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	jmp	merging_optimized	#
	.p2align 4,,10
	.p2align 3
.L698:
	.cfi_restore_state
# mergeo.h:45:     mid = (low + high) / 2;
	leal	(%rsi,%r13), %eax	#, tmp99
# mergeo.h:45:     mid = (low + high) / 2;
	movl	%eax, %r14d	# tmp99, tmp100
	shrl	$31, %r14d	#, tmp100
	addl	%eax, %r14d	# tmp99, tmp101
	sarl	%r14d	# tmp102
# mergeo.h:44:   if (low < high) {
	cmpl	%r14d, %esi	# tmp102, low
	jl	.L700	#,
.L688:
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r14), %esi	#, _13
# mergeo.h:44:   if (low < high) {
	cmpl	%esi, %r13d	# _13, tmp98
	jg	.L701	#,
.L689:
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movl	%r14d, %edx	# tmp102,
	movq	%rbx, %r8	# b,
	movl	%r13d, %ecx	# tmp98,
	movl	%ebp, %esi	# low,
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r13), %r14d	#, _10
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	call	merging_optimized	#
# mergeo.h:44:   if (low < high) {
	cmpl	%r14d, %r12d	# _10, high
	jle	.L690	#,
.L699:
# mergeo.h:45:     mid = (low + high) / 2;
	leal	(%r12,%r14), %eax	#, tmp103
# mergeo.h:45:     mid = (low + high) / 2;
	movl	%eax, %r15d	# tmp103, tmp104
	shrl	$31, %r15d	#, tmp104
	addl	%eax, %r15d	# tmp103, tmp105
	sarl	%r15d	# tmp106
# mergeo.h:44:   if (low < high) {
	cmpl	%r15d, %r14d	# tmp106, _10
	jl	.L702	#,
.L691:
# mergeo.h:47:     sort_merge_o(a, mid + 1, high, b);
	leal	1(%r15), %esi	#, _16
# mergeo.h:44:   if (low < high) {
	cmpl	%esi, %r12d	# _16, high
	jg	.L703	#,
.L692:
# mergeo.h:48:     merging_optimized(a, low, mid, high, b);
	movq	%rbx, %r8	# b,
	movl	%r12d, %ecx	# high,
	movl	%r15d, %edx	# tmp106,
	movl	%r14d, %esi	# _10,
	call	merging_optimized	#
	jmp	.L690	#
	.p2align 4,,10
	.p2align 3
.L700:
	movl	%r14d, %edx	# tmp102,
	movq	%rdi, 8(%rsp)	# a, %sfp
	call	sort_merge_o.part.0	#
	movq	8(%rsp), %rdi	# %sfp, a
	jmp	.L688	#
	.p2align 4,,10
	.p2align 3
.L703:
	movq	%rbx, %rcx	# b,
	movl	%r12d, %edx	# high,
	movq	%rdi, 8(%rsp)	# a, %sfp
	call	sort_merge_o.part.0	#
	movq	8(%rsp), %rdi	# %sfp, a
	jmp	.L692	#
	.p2align 4,,10
	.p2align 3
.L702:
	movq	%rbx, %rcx	# b,
	movl	%r15d, %edx	# tmp106,
	movl	%r14d, %esi	# _10,
	movq	%rdi, 8(%rsp)	# a, %sfp
	call	sort_merge_o.part.0	#
	movq	8(%rsp), %rdi	# %sfp, a
	jmp	.L691	#
	.p2align 4,,10
	.p2align 3
.L701:
	movq	%rbx, %rcx	# b,
	movl	%r13d, %edx	# tmp98,
	movq	%rdi, 8(%rsp)	# a, %sfp
	call	sort_merge_o.part.0	#
	movq	8(%rsp), %rdi	# %sfp, a
	jmp	.L689	#
	.cfi_endproc
.LFE5401:
	.size	sort_merge_o, .-sort_merge_o
	.p2align 4
	.globl	merging_standard
	.type	merging_standard, @function
merging_standard:
.LFB5403:
	.cfi_startproc
	endbr64	
	pushq	%rbp	#
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
# mergeu.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	leal	1(%rdx), %eax	#, tmp375
# mergeu.h:4: void merging_standard(int a[], int low, int mid, int high, int *b) {
	movl	%edx, %r9d	# tmp378, mid
	movq	%rsp, %rbp	#,
	.cfi_def_cfa_register 6
	pushq	%r15	#
	.cfi_offset 15, -24
	movl	%esi, %r15d	# tmp377, low
	pushq	%r14	#
	pushq	%r13	#
	pushq	%r12	#
	pushq	%rbx	#
	andq	$-32, %rsp	#,
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	.cfi_offset 3, -56
# mergeu.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	movl	%eax, -12(%rsp)	# tmp375, %sfp
# mergeu.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%edx, %esi	# mid, low
	jg	.L740	#,
	cmpl	%ecx, %eax	# high, tmp375
	jg	.L740	#,
	leal	1(%rsi), %r10d	#, tmp296
	movslq	%r10d, %r10	# tmp296, ivtmp.1164
	jmp	.L708	#
	.p2align 4,,10
	.p2align 3
.L787:
# mergeu.h:9:       b[i] = a[l1];
	movl	%r11d, -4(%r8,%r10,4)	# _131, MEM[base: b_60(D), index: ivtmp.1164_150, step: 4, offset: -4B]
# mergeu.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	movl	%r10d, %edx	# ivtmp.1164, tmp.1080
# mergeu.h:10:       l1++;
	incl	%esi	# tmp.1099
# mergeu.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%r10	# ivtmp.1164
	cmpl	%eax, %ecx	# tmp.1079, high
	jl	.L705	#,
.L788:
	cmpl	%esi, %r9d	# tmp.1099, mid
	jl	.L710	#,
.L708:
# mergeu.h:8:     if (a[l1] <= a[l2]) {
	movslq	%esi, %rdx	# tmp.1099, tmp.1099
	movl	(%rdi,%rdx,4), %r11d	# *_132, _131
# mergeu.h:8:     if (a[l1] <= a[l2]) {
	movslq	%eax, %rdx	# tmp.1079, tmp.1079
	movl	(%rdi,%rdx,4), %edx	# *_128, _127
# mergeu.h:8:     if (a[l1] <= a[l2]) {
	cmpl	%r11d, %edx	# _131, _127
	jge	.L787	#,
# mergeu.h:13:       l2++;
	incl	%eax	# tmp.1079
# mergeu.h:12:       b[i] = a[l2];
	movl	%edx, -4(%r8,%r10,4)	# _127, MEM[base: b_60(D), index: ivtmp.1164_150, step: 4, offset: -4B]
# mergeu.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	movl	%r10d, %edx	# ivtmp.1164, tmp.1080
# mergeu.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%r10	# ivtmp.1164
	cmpl	%eax, %ecx	# tmp.1079, high
	jge	.L788	#,
.L705:
# mergeu.h:17:   while (l1 <= mid)
	cmpl	%esi, %r9d	# tmp.1099, mid
	jl	.L710	#,
	movslq	%edx, %r14	# tmp.1080, _383
	movl	%r9d, %ebx	# mid, _381
	movslq	%esi, %r10	# tmp.1099, ivtmp.1145
	subl	%esi, %ebx	# tmp.1099, _381
	leaq	0(,%r14,4), %r12	#, _384
	leaq	1(%r10), %r11	#, ivtmp.1145
	leaq	0(,%r11,4), %r13	#, _388
	movl	%ebx, -8(%rsp)	# _381, %sfp
	leaq	(%r8,%r12), %rbx	#, _385
	movq	%r14, -24(%rsp)	# _383, %sfp
	movq	%r13, -32(%rsp)	# _388, %sfp
	movq	%rbx, %r14	# _385, tmp305
	addq	%rdi, %r13	# a, tmp304
	subq	%r13, %r14	# tmp304, tmp305
	movl	%esi, -16(%rsp)	# tmp.1099, %sfp
	cmpq	$24, %r14	#, tmp305
	jbe	.L711	#,
	cmpl	$2, -8(%rsp)	#, %sfp
	jbe	.L711	#,
	movl	-12(%rsp), %r14d	# %sfp, niters.1086
	subl	%esi, %r14d	# tmp.1099, niters.1086
	cmpl	$6, -8(%rsp)	#, %sfp
	movl	%r14d, %r13d	# niters.1086, niters.1086
	jbe	.L741	#,
	movq	-32(%rsp), %r14	# %sfp, _388
	movl	%r13d, %r12d	# niters.1086, bnd.1087
	shrl	$3, %r12d	#,
	leaq	-4(%rdi,%r14), %r14	#, vectp.1092
	salq	$5, %r12	#, _149
	xorl	%r11d, %r11d	# ivtmp.1157
	.p2align 4,,10
	.p2align 3
.L713:
# mergeu.h:18:     b[i++] = a[l1++];
	vmovdqu	(%r14,%r11), %ymm1	# MEM[base: vectp.1092_442, index: ivtmp.1157_7, offset: 0B], tmp461
	vmovdqu	%ymm1, (%rbx,%r11)	# tmp461, MEM[base: _385, index: ivtmp.1157_7, offset: 0B]
	addq	$32, %r11	#, ivtmp.1157
	cmpq	%r12, %r11	# _149, ivtmp.1157
	jne	.L713	#,
	movl	%r13d, %r11d	# niters.1086, niters_vector_mult_vf.1088
	andl	$-8, %r11d	#,
	addl	%r11d, %esi	# niters_vector_mult_vf.1088, tmp.1099
	leal	(%rdx,%r11), %ebx	#, tmp.1100
	cmpl	%r11d, %r13d	# niters_vector_mult_vf.1088, niters.1086
	je	.L719	#,
	movl	-8(%rsp), %r12d	# %sfp, _381
	subl	%r11d, %r13d	# niters_vector_mult_vf.1088, niters.1086
	subl	%r11d, %r12d	# niters_vector_mult_vf.1088, _381
	cmpl	$2, %r12d	#, tmp317
	jbe	.L716	#,
.L712:
# mergeu.h:18:     b[i++] = a[l1++];
	addq	%r11, %r10	# _492, tmp318
	vmovdqu	(%rdi,%r10,4), %xmm0	# MEM <vector(4) int> [(int *)vectp.1102_490], MEM <vector(4) int> [(int *)vectp.1102_490]
	movl	%r13d, %r10d	# niters.1086, niters_vector_mult_vf.1098
	andl	$-4, %r10d	#, niters_vector_mult_vf.1098
# mergeu.h:18:     b[i++] = a[l1++];
	addq	-24(%rsp), %r11	# %sfp, tmp320
	vmovdqu	%xmm0, (%r8,%r11,4)	# MEM <vector(4) int> [(int *)vectp.1102_490], MEM <vector(4) int> [(int *)vectp.1105_498]
	addl	%r10d, %esi	# niters_vector_mult_vf.1098, tmp.1099
	addl	%r10d, %ebx	# niters_vector_mult_vf.1098, tmp.1100
	cmpl	%r10d, %r13d	# niters_vector_mult_vf.1098, niters.1086
	je	.L719	#,
.L716:
# mergeu.h:18:     b[i++] = a[l1++];
	movslq	%esi, %r12	# tmp.1099, tmp.1099
# mergeu.h:18:     b[i++] = a[l1++];
	movl	(%rdi,%r12,4), %r12d	# *_33, _63
# mergeu.h:18:     b[i++] = a[l1++];
	leal	1(%rbx), %r11d	#, i
# mergeu.h:18:     b[i++] = a[l1++];
	leal	1(%rsi), %r10d	#, l1
# mergeu.h:18:     b[i++] = a[l1++];
	movslq	%ebx, %rbx	# tmp.1100, tmp.1100
# mergeu.h:18:     b[i++] = a[l1++];
	movl	%r12d, (%r8,%rbx,4)	# _63, *_39
# mergeu.h:17:   while (l1 <= mid)
	cmpl	%r10d, %r9d	# l1, mid
	jl	.L719	#,
# mergeu.h:18:     b[i++] = a[l1++];
	movslq	%r10d, %r10	# l1, l1
# mergeu.h:18:     b[i++] = a[l1++];
	movl	(%rdi,%r10,4), %r10d	# *_161, _319
# mergeu.h:18:     b[i++] = a[l1++];
	movslq	%r11d, %r11	# i, i
# mergeu.h:18:     b[i++] = a[l1++];
	addl	$2, %esi	#, l1
# mergeu.h:18:     b[i++] = a[l1++];
	movl	%r10d, (%r8,%r11,4)	# _319, *_412
# mergeu.h:18:     b[i++] = a[l1++];
	leaq	0(,%r11,4), %rbx	#, _456
# mergeu.h:17:   while (l1 <= mid)
	cmpl	%esi, %r9d	# l1, mid
	jl	.L719	#,
# mergeu.h:18:     b[i++] = a[l1++];
	movslq	%esi, %rsi	# l1, l1
# mergeu.h:18:     b[i++] = a[l1++];
	movl	(%rdi,%rsi,4), %esi	# *_468, _473
# mergeu.h:18:     b[i++] = a[l1++];
	movl	%esi, 4(%r8,%rbx)	# _473, *_472
.L719:
	addl	-12(%rsp), %edx	# %sfp, tmp316
# mergeu.h:18:     b[i++] = a[l1++];
	subl	-16(%rsp), %edx	# %sfp, tmp.1080
.L710:
# mergeu.h:20:   while (l2 <= high)
	cmpl	%eax, %ecx	# tmp.1079, high
	jl	.L727	#,
	movslq	%edx, %r11	# tmp.1080, _247
	movslq	%eax, %rsi	# tmp.1079, ivtmp.1126
	leaq	1(%rsi), %r14	#, ivtmp.1126
	leaq	0(,%r11,4), %r13	#, _248
	leaq	(%r8,%r13), %r10	#, _249
	leaq	0(,%r14,4), %r12	#, _252
	movq	%r14, -8(%rsp)	# ivtmp.1126, %sfp
	movq	%r10, %r9	# _249, tmp332
	leaq	(%rdi,%r12), %r14	#, tmp331
	movl	%ecx, %ebx	# high, _245
	subq	%r14, %r9	# tmp331, tmp332
	subl	%eax, %ebx	# tmp.1079, _245
	cmpq	$24, %r9	#, tmp332
	jbe	.L723	#,
	cmpl	$2, %ebx	#, _245
	jbe	.L723	#,
	leal	1(%rcx), %r13d	#, tmp337
	subl	%eax, %r13d	# tmp.1079, niters.1066
	cmpl	$6, %ebx	#, _245
	jbe	.L742	#,
	leaq	-4(%rdi,%r12), %r14	#, vectp.1072
	movl	%r13d, %r12d	# niters.1066, bnd.1067
	shrl	$3, %r12d	#,
	salq	$5, %r12	#, _14
	xorl	%r9d, %r9d	# ivtmp.1138
	.p2align 4,,10
	.p2align 3
.L725:
# mergeu.h:21:     b[i++] = a[l2++];
	vmovdqu	(%r14,%r9), %ymm2	# MEM[base: vectp.1072_305, index: ivtmp.1138_221, offset: 0B], tmp470
	vmovdqu	%ymm2, (%r10,%r9)	# tmp470, MEM[base: _249, index: ivtmp.1138_221, offset: 0B]
	addq	$32, %r9	#, ivtmp.1138
	cmpq	%r9, %r12	# ivtmp.1138, _14
	jne	.L725	#,
	movl	%r13d, %r9d	# niters.1066, niters_vector_mult_vf.1068
	andl	$-8, %r9d	#,
	addl	%r9d, %eax	# niters_vector_mult_vf.1068, tmp.1079
	addl	%r9d, %edx	# niters_vector_mult_vf.1068, tmp.1080
	cmpl	%r9d, %r13d	# niters_vector_mult_vf.1068, niters.1066
	je	.L727	#,
	subl	%r9d, %ebx	# niters_vector_mult_vf.1068, tmp342
	subl	%r9d, %r13d	# niters_vector_mult_vf.1068, niters.1066
	cmpl	$2, %ebx	#, tmp342
	jbe	.L729	#,
.L724:
# mergeu.h:21:     b[i++] = a[l2++];
	addq	%r9, %rsi	# _355, tmp343
	vmovdqu	(%rdi,%rsi,4), %xmm0	# MEM <vector(4) int> [(int *)vectp.1082_353], MEM <vector(4) int> [(int *)vectp.1082_353]
	movl	%r13d, %esi	# niters.1066, niters_vector_mult_vf.1078
	andl	$-4, %esi	#, niters_vector_mult_vf.1078
# mergeu.h:21:     b[i++] = a[l2++];
	addq	%r11, %r9	# _247, tmp345
	vmovdqu	%xmm0, (%r8,%r9,4)	# MEM <vector(4) int> [(int *)vectp.1082_353], MEM <vector(4) int> [(int *)vectp.1085_361]
	addl	%esi, %eax	# niters_vector_mult_vf.1078, tmp.1079
	addl	%esi, %edx	# niters_vector_mult_vf.1078, tmp.1080
	cmpl	%r13d, %esi	# niters.1066, niters_vector_mult_vf.1078
	je	.L727	#,
.L729:
# mergeu.h:21:     b[i++] = a[l2++];
	movslq	%eax, %r10	# tmp.1079, tmp.1079
# mergeu.h:21:     b[i++] = a[l2++];
	movl	(%rdi,%r10,4), %r10d	# *_426, _27
# mergeu.h:21:     b[i++] = a[l2++];
	leal	1(%rdx), %r9d	#, i
# mergeu.h:21:     b[i++] = a[l2++];
	leal	1(%rax), %esi	#, l2
# mergeu.h:21:     b[i++] = a[l2++];
	movslq	%edx, %rdx	# tmp.1080, tmp.1080
# mergeu.h:21:     b[i++] = a[l2++];
	movl	%r10d, (%r8,%rdx,4)	# _27, *_26
# mergeu.h:20:   while (l2 <= high)
	cmpl	%esi, %ecx	# l2, high
	jl	.L727	#,
# mergeu.h:21:     b[i++] = a[l2++];
	movslq	%esi, %rsi	# l2, l2
# mergeu.h:21:     b[i++] = a[l2++];
	movl	(%rdi,%rsi,4), %esi	# *_277, _282
# mergeu.h:21:     b[i++] = a[l2++];
	movslq	%r9d, %rdx	# i, i
# mergeu.h:21:     b[i++] = a[l2++];
	addl	$2, %eax	#, l2
# mergeu.h:21:     b[i++] = a[l2++];
	movl	%esi, (%r8,%rdx,4)	# _282, *_281
# mergeu.h:21:     b[i++] = a[l2++];
	leaq	0(,%rdx,4), %r9	#, _280
# mergeu.h:20:   while (l2 <= high)
	cmpl	%ecx, %eax	# high, l2
	jg	.L727	#,
# mergeu.h:21:     b[i++] = a[l2++];
	cltq
# mergeu.h:21:     b[i++] = a[l2++];
	movl	(%rdi,%rax,4), %eax	# *_331, _336
# mergeu.h:21:     b[i++] = a[l2++];
	movl	%eax, 4(%r8,%r9)	# _336, *_335
.L727:
# mergeu.h:23:   for (i = low; i <= high; i++)
	cmpl	%ecx, %r15d	# high, low
	jg	.L783	#,
	movslq	%r15d, %rdx	# low, ivtmp.1109
	leaq	0(,%rdx,4), %rsi	#, _77
	leaq	(%rdi,%rsi), %rbx	#, _76
	leaq	4(%r8,%rsi), %r9	#, tmp356
	movq	%rbx, %rax	# _76, tmp357
	movl	%ecx, %r11d	# high, _80
	subq	%r9, %rax	# tmp356, tmp357
	subl	%r15d, %r11d	# low, _80
	cmpq	$24, %rax	#, tmp357
	jbe	.L762	#,
	cmpl	$2, %r11d	#, _80
	jbe	.L762	#,
	leal	1(%rcx), %r9d	#, tmp362
	subl	%r15d, %r9d	# low, niters.1048
	cmpl	$6, %r11d	#, _80
	jbe	.L743	#,
	movl	%r9d, %r10d	# niters.1048, bnd.1049
	shrl	$3, %r10d	#,
	addq	%r8, %rsi	# b, vectp.1053
	salq	$5, %r10	#, _421
	xorl	%eax, %eax	# ivtmp.1119
	.p2align 4,,10
	.p2align 3
.L735:
# mergeu.h:24:     a[i] = b[i];
	vmovdqu	(%rsi,%rax), %ymm3	# MEM[base: vectp.1053_175, index: ivtmp.1119_503, offset: 0B], tmp477
	vmovdqu	%ymm3, (%rbx,%rax)	# tmp477, MEM[base: _76, index: ivtmp.1119_503, offset: 0B]
	addq	$32, %rax	#, ivtmp.1119
	cmpq	%rax, %r10	# ivtmp.1119, _421
	jne	.L735	#,
	movl	%r9d, %eax	# niters.1048, niters_vector_mult_vf.1050
	andl	$-8, %eax	#,
	addl	%eax, %r15d	# niters_vector_mult_vf.1050, low
	cmpl	%eax, %r9d	# niters_vector_mult_vf.1050, niters.1048
	je	.L783	#,
	subl	%eax, %r11d	# niters_vector_mult_vf.1050, tmp366
	subl	%eax, %r9d	# niters_vector_mult_vf.1050, niters.1048
	cmpl	$2, %r11d	#, tmp366
	jbe	.L737	#,
.L734:
	addq	%rax, %rdx	# niters_vector_mult_vf.1050, tmp368
# mergeu.h:24:     a[i] = b[i];
	vmovdqu	(%r8,%rdx,4), %xmm4	# MEM <vector(4) int> [(int *)vectp.1062_216], tmp479
	movl	%r9d, %eax	# niters.1048, niters_vector_mult_vf.1059
	andl	$-4, %eax	#, niters_vector_mult_vf.1059
	vmovdqu	%xmm4, (%rdi,%rdx,4)	# tmp479, MEM <vector(4) int> [(int *)vectp.1065_224]
	addl	%eax, %r15d	# niters_vector_mult_vf.1059, low
	cmpl	%eax, %r9d	# niters_vector_mult_vf.1059, niters.1048
	je	.L783	#,
.L737:
# mergeu.h:24:     a[i] = b[i];
	movslq	%r15d, %rax	# low, low
	movl	(%r8,%rax,4), %edx	# *_67, _20
# mergeu.h:24:     a[i] = b[i];
	movl	%edx, (%rdi,%rax,4)	# _20, *_19
# mergeu.h:23:   for (i = low; i <= high; i++)
	leal	1(%r15), %eax	#, i
# mergeu.h:23:   for (i = low; i <= high; i++)
	cmpl	%eax, %ecx	# i, high
	jl	.L783	#,
# mergeu.h:24:     a[i] = b[i];
	cltq
	movl	(%r8,%rax,4), %edx	# *_414, _416
# mergeu.h:23:   for (i = low; i <= high; i++)
	leal	2(%r15), %esi	#, i
# mergeu.h:24:     a[i] = b[i];
	movl	%edx, (%rdi,%rax,4)	# _416, *_413
# mergeu.h:23:   for (i = low; i <= high; i++)
	cmpl	%esi, %ecx	# i, high
	jl	.L783	#,
# mergeu.h:24:     a[i] = b[i];
	movslq	%esi, %rsi	# i, i
	movl	(%r8,%rsi,4), %eax	# *_199, _201
# mergeu.h:24:     a[i] = b[i];
	movl	%eax, (%rdi,%rsi,4)	# _201, *_200
.L783:
	vzeroupper
# mergeu.h:25: }
	leaq	-40(%rbp), %rsp	#,
	popq	%rbx	#
	popq	%r12	#
	popq	%r13	#
	popq	%r14	#
	popq	%r15	#
	popq	%rbp	#
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret	
	.p2align 4,,10
	.p2align 3
.L762:
	.cfi_restore_state
# mergeu.h:24:     a[i] = b[i];
	movl	(%r8,%rdx,4), %eax	# MEM[base: b_60(D), index: ivtmp.1109_286, step: 4, offset: 0B], _36
# mergeu.h:24:     a[i] = b[i];
	movl	%eax, (%rdi,%rdx,4)	# _36, MEM[base: a_61(D), index: ivtmp.1109_286, step: 4, offset: 0B]
# mergeu.h:23:   for (i = low; i <= high; i++)
	incq	%rdx	# ivtmp.1109
	cmpl	%edx, %ecx	# ivtmp.1109, high
	jl	.L783	#,
# mergeu.h:24:     a[i] = b[i];
	movl	(%r8,%rdx,4), %eax	# MEM[base: b_60(D), index: ivtmp.1109_286, step: 4, offset: 0B], _36
# mergeu.h:24:     a[i] = b[i];
	movl	%eax, (%rdi,%rdx,4)	# _36, MEM[base: a_61(D), index: ivtmp.1109_286, step: 4, offset: 0B]
# mergeu.h:23:   for (i = low; i <= high; i++)
	incq	%rdx	# ivtmp.1109
	cmpl	%edx, %ecx	# ivtmp.1109, high
	jge	.L762	#,
	jmp	.L783	#
	.p2align 4,,10
	.p2align 3
.L711:
	movq	%r10, %rsi	# ivtmp.1145, tmp327
	negq	%rsi	# tmp327
	leaq	(%r12,%rsi,4), %rbx	#, tmp329
	addq	%r8, %rbx	# b, _5
	jmp	.L718	#
	.p2align 4,,10
	.p2align 3
.L789:
	incq	%r11	# ivtmp.1145
.L718:
# mergeu.h:18:     b[i++] = a[l1++];
	movl	(%rdi,%r10,4), %esi	# MEM[base: a_61(D), index: ivtmp.1145_99, step: 4, offset: 0B], _405
# mergeu.h:18:     b[i++] = a[l1++];
	movl	%esi, (%rbx,%r10,4)	# _405, MEM[base: _5, index: ivtmp.1145_99, step: 4, offset: 0B]
# mergeu.h:17:   while (l1 <= mid)
	movq	%r11, %r10	# ivtmp.1145, ivtmp.1145
	cmpl	%r11d, %r9d	# ivtmp.1145, mid
	jge	.L789	#,
	addl	-12(%rsp), %edx	# %sfp, tmp316
# mergeu.h:18:     b[i++] = a[l1++];
	subl	-16(%rsp), %edx	# %sfp, tmp.1080
	jmp	.L710	#
	.p2align 4,,10
	.p2align 3
.L723:
	movq	%rsi, %rax	# ivtmp.1126, tmp352
	negq	%rax	# tmp352
	leaq	0(%r13,%rax,4), %rdx	#, tmp354
	movq	-8(%rsp), %r9	# %sfp, ivtmp.1126
	addq	%r8, %rdx	# b, _232
	jmp	.L731	#
	.p2align 4,,10
	.p2align 3
.L790:
	incq	%r9	# ivtmp.1126
.L731:
# mergeu.h:21:     b[i++] = a[l2++];
	movl	(%rdi,%rsi,4), %eax	# MEM[base: a_61(D), index: ivtmp.1126_420, step: 4, offset: 0B], _269
# mergeu.h:21:     b[i++] = a[l2++];
	movl	%eax, (%rdx,%rsi,4)	# _269, MEM[base: _232, index: ivtmp.1126_420, step: 4, offset: 0B]
# mergeu.h:20:   while (l2 <= high)
	movq	%r9, %rsi	# ivtmp.1126, ivtmp.1126
	cmpl	%r9d, %ecx	# ivtmp.1126, high
	jge	.L790	#,
	jmp	.L727	#
	.p2align 4,,10
	.p2align 3
.L740:
# mergeu.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	movl	%r15d, %edx	# low, tmp.1080
	movl	%r15d, %esi	# low, tmp.1099
	jmp	.L705	#
.L742:
# mergeu.h:20:   while (l2 <= high)
	xorl	%r9d, %r9d	#
	jmp	.L724	#
.L743:
# mergeu.h:23:   for (i = low; i <= high; i++)
	xorl	%eax, %eax	#
	jmp	.L734	#
.L741:
# mergeu.h:17:   while (l1 <= mid)
	movl	%edx, %ebx	# tmp.1080, tmp.1100
	xorl	%r11d, %r11d	#
	jmp	.L712	#
	.cfi_endproc
.LFE5403:
	.size	merging_standard, .-merging_standard
	.p2align 4
	.type	sort_merge_standard_h.part.0, @function
sort_merge_standard_h.part.0:
.LFB5713:
	.cfi_startproc
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
# mergeu.h:29:     int mid = (low + high) / 2;
	leal	(%rsi,%rdx), %eax	#, tmp107
# mergeu.h:27: void sort_merge_standard_h(int a[], int low, int high, int *b) {
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movq	%rdi, %r14	# tmp135, a
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	movl	%edx, %r13d	# tmp137, high
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
# mergeu.h:29:     int mid = (low + high) / 2;
	movl	%eax, %r12d	# tmp107, tmp108
	shrl	$31, %r12d	#, tmp108
# mergeu.h:27: void sort_merge_standard_h(int a[], int low, int high, int *b) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
# mergeu.h:29:     int mid = (low + high) / 2;
	addl	%eax, %r12d	# tmp107, tmp109
	sarl	%r12d	# tmp110
# mergeu.h:27: void sort_merge_standard_h(int a[], int low, int high, int *b) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	movl	%esi, %ebp	# tmp136, low
	movq	%rcx, %rbx	# tmp138, b
	subq	$24, %rsp	#,
	.cfi_def_cfa_offset 80
# mergeu.h:28:   if (low < high) {
	cmpl	%r12d, %esi	# tmp110, low
	jl	.L807	#,
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r12), %r15d	#, _7
# mergeu.h:28:   if (low < high) {
	cmpl	%r15d, %r13d	# _7, high
	jg	.L808	#,
.L799:
# mergeu.h:34: }
	addq	$24, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 56
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movq	%rbx, %r8	# b,
# mergeu.h:34: }
	popq	%rbx	#
	.cfi_def_cfa_offset 48
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movl	%ebp, %esi	# low,
# mergeu.h:34: }
	popq	%rbp	#
	.cfi_def_cfa_offset 40
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movl	%r12d, %edx	# tmp110,
# mergeu.h:34: }
	popq	%r12	#
	.cfi_def_cfa_offset 32
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movl	%r13d, %ecx	# high,
# mergeu.h:34: }
	popq	%r13	#
	.cfi_def_cfa_offset 24
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movq	%r14, %rdi	# a,
# mergeu.h:34: }
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	jmp	merging_standard	#
	.p2align 4,,10
	.p2align 3
.L807:
	.cfi_restore_state
# mergeu.h:29:     int mid = (low + high) / 2;
	leal	(%rsi,%r12), %eax	#, tmp111
# mergeu.h:29:     int mid = (low + high) / 2;
	movl	%eax, %r15d	# tmp111, tmp112
	shrl	$31, %r15d	#, tmp112
	addl	%eax, %r15d	# tmp111, tmp113
	sarl	%r15d	# tmp114
# mergeu.h:28:   if (low < high) {
	cmpl	%r15d, %esi	# tmp114, low
	jl	.L809	#,
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r15), %r9d	#, _14
# mergeu.h:28:   if (low < high) {
	cmpl	%r9d, %r12d	# _14, tmp110
	jg	.L810	#,
.L796:
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movl	%r15d, %edx	# tmp114,
	movq	%rbx, %r8	# b,
	movl	%r12d, %ecx	# tmp110,
	movl	%ebp, %esi	# low,
	movq	%r14, %rdi	# a,
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r12), %r15d	#, _7
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	call	merging_standard	#
# mergeu.h:28:   if (low < high) {
	cmpl	%r15d, %r13d	# _7, high
	jle	.L799	#,
.L808:
# mergeu.h:29:     int mid = (low + high) / 2;
	leal	0(%r13,%r15), %eax	#, tmp123
# mergeu.h:29:     int mid = (low + high) / 2;
	movl	%eax, %r9d	# tmp123, tmp124
	shrl	$31, %r9d	#, tmp124
	addl	%eax, %r9d	# tmp123, tmp125
	sarl	%r9d	# tmp126
# mergeu.h:28:   if (low < high) {
	cmpl	%r9d, %r15d	# tmp126, _7
	jl	.L811	#,
.L800:
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r9), %r10d	#, _23
# mergeu.h:28:   if (low < high) {
	cmpl	%r10d, %r13d	# _23, high
	jg	.L812	#,
.L803:
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movq	%rbx, %r8	# b,
	movl	%r13d, %ecx	# high,
	movl	%r9d, %edx	# tmp126,
	movl	%r15d, %esi	# _7,
	movq	%r14, %rdi	# a,
	call	merging_standard	#
	jmp	.L799	#
	.p2align 4,,10
	.p2align 3
.L809:
# mergeu.h:29:     int mid = (low + high) / 2;
	leal	(%rsi,%r15), %eax	#, tmp115
# mergeu.h:29:     int mid = (low + high) / 2;
	movl	%eax, %r9d	# tmp115, tmp116
	shrl	$31, %r9d	#, tmp116
	addl	%eax, %r9d	# tmp115, tmp117
	sarl	%r9d	# tmp118
# mergeu.h:28:   if (low < high) {
	cmpl	%r9d, %esi	# tmp118, low
	jl	.L813	#,
.L794:
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r9), %esi	#, _17
# mergeu.h:28:   if (low < high) {
	cmpl	%esi, %r15d	# _17, tmp114
	jg	.L814	#,
.L795:
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movl	%r9d, %edx	# tmp118,
	movq	%rbx, %r8	# b,
	movl	%r15d, %ecx	# tmp114,
	movl	%ebp, %esi	# low,
	movq	%r14, %rdi	# a,
	call	merging_standard	#
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r15), %r9d	#, _14
# mergeu.h:28:   if (low < high) {
	cmpl	%r9d, %r12d	# _14, tmp110
	jle	.L796	#,
.L810:
# mergeu.h:29:     int mid = (low + high) / 2;
	leal	(%r12,%r9), %eax	#, tmp119
# mergeu.h:29:     int mid = (low + high) / 2;
	movl	%eax, %r10d	# tmp119, tmp120
	shrl	$31, %r10d	#, tmp120
	addl	%eax, %r10d	# tmp119, tmp121
	sarl	%r10d	# tmp122
# mergeu.h:28:   if (low < high) {
	cmpl	%r10d, %r9d	# tmp122, _14
	jl	.L815	#,
.L797:
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r10), %esi	#, _20
# mergeu.h:28:   if (low < high) {
	cmpl	%esi, %r12d	# _20, tmp110
	jg	.L816	#,
.L798:
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movq	%rbx, %r8	# b,
	movl	%r12d, %ecx	# tmp110,
	movl	%r10d, %edx	# tmp122,
	movl	%r9d, %esi	# _14,
	movq	%r14, %rdi	# a,
	call	merging_standard	#
	jmp	.L796	#
	.p2align 4,,10
	.p2align 3
.L812:
# mergeu.h:29:     int mid = (low + high) / 2;
	leal	0(%r13,%r10), %eax	#, tmp131
# mergeu.h:29:     int mid = (low + high) / 2;
	movl	%eax, %r11d	# tmp131, tmp132
	shrl	$31, %r11d	#, tmp132
	addl	%eax, %r11d	# tmp131, tmp133
	sarl	%r11d	# tmp134
# mergeu.h:28:   if (low < high) {
	cmpl	%r11d, %r10d	# tmp134, _23
	jl	.L817	#,
.L804:
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r11), %esi	#, _29
# mergeu.h:28:   if (low < high) {
	cmpl	%esi, %r13d	# _29, high
	jg	.L818	#,
.L805:
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movq	%rbx, %r8	# b,
	movl	%r13d, %ecx	# high,
	movl	%r11d, %edx	# tmp134,
	movl	%r10d, %esi	# _23,
	movq	%r14, %rdi	# a,
	movl	%r9d, 4(%rsp)	# tmp126, %sfp
	call	merging_standard	#
	movl	4(%rsp), %r9d	# %sfp, tmp126
	jmp	.L803	#
	.p2align 4,,10
	.p2align 3
.L811:
# mergeu.h:29:     int mid = (low + high) / 2;
	leal	(%r15,%r9), %eax	#, tmp127
# mergeu.h:29:     int mid = (low + high) / 2;
	movl	%eax, %r10d	# tmp127, tmp128
	shrl	$31, %r10d	#, tmp128
	addl	%eax, %r10d	# tmp127, tmp129
	sarl	%r10d	# tmp130
# mergeu.h:28:   if (low < high) {
	cmpl	%r10d, %r15d	# tmp130, _7
	jl	.L819	#,
.L801:
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r10), %esi	#, _26
# mergeu.h:28:   if (low < high) {
	cmpl	%esi, %r9d	# _26, tmp126
	jg	.L820	#,
.L802:
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movl	%r9d, %ecx	# tmp126,
	movq	%rbx, %r8	# b,
	movl	%r10d, %edx	# tmp130,
	movl	%r15d, %esi	# _7,
	movq	%r14, %rdi	# a,
	movl	%r9d, 4(%rsp)	# tmp126, %sfp
	call	merging_standard	#
	movl	4(%rsp), %r9d	# %sfp, tmp126
	jmp	.L800	#
	.p2align 4,,10
	.p2align 3
.L813:
	movl	%r9d, %edx	# tmp118,
	movl	%r9d, 4(%rsp)	# tmp118, %sfp
	call	sort_merge_standard_h.part.0	#
	movl	4(%rsp), %r9d	# %sfp, tmp118
	jmp	.L794	#
	.p2align 4,,10
	.p2align 3
.L816:
	movq	%rbx, %rcx	# b,
	movl	%r12d, %edx	# tmp110,
	movq	%r14, %rdi	# a,
	movl	%r10d, 8(%rsp)	# tmp122, %sfp
	movl	%r9d, 4(%rsp)	# _14, %sfp
	call	sort_merge_standard_h.part.0	#
	movl	8(%rsp), %r10d	# %sfp, tmp122
	movl	4(%rsp), %r9d	# %sfp, _14
	jmp	.L798	#
	.p2align 4,,10
	.p2align 3
.L815:
	movl	%r10d, %edx	# tmp122,
	movl	%r9d, %esi	# _14,
	movq	%rbx, %rcx	# b,
	movq	%r14, %rdi	# a,
	movl	%r10d, 8(%rsp)	# tmp122, %sfp
	movl	%r9d, 4(%rsp)	# _14, %sfp
	call	sort_merge_standard_h.part.0	#
	movl	8(%rsp), %r10d	# %sfp, tmp122
	movl	4(%rsp), %r9d	# %sfp, _14
	jmp	.L797	#
	.p2align 4,,10
	.p2align 3
.L820:
	movl	%r9d, %edx	# tmp126,
	movq	%rbx, %rcx	# b,
	movq	%r14, %rdi	# a,
	movl	%r10d, 8(%rsp)	# tmp130, %sfp
	movl	%r9d, 4(%rsp)	# tmp126, %sfp
	call	sort_merge_standard_h.part.0	#
	movl	8(%rsp), %r10d	# %sfp, tmp130
	movl	4(%rsp), %r9d	# %sfp, tmp126
	jmp	.L802	#
	.p2align 4,,10
	.p2align 3
.L819:
	movl	%r10d, %edx	# tmp130,
	movq	%rbx, %rcx	# b,
	movl	%r15d, %esi	# _7,
	movq	%r14, %rdi	# a,
	movl	%r9d, 8(%rsp)	# tmp126, %sfp
	movl	%r10d, 4(%rsp)	# tmp130, %sfp
	call	sort_merge_standard_h.part.0	#
	movl	8(%rsp), %r9d	# %sfp, tmp126
	movl	4(%rsp), %r10d	# %sfp, tmp130
	jmp	.L801	#
	.p2align 4,,10
	.p2align 3
.L818:
	movq	%rbx, %rcx	# b,
	movl	%r13d, %edx	# high,
	movq	%r14, %rdi	# a,
	movl	%r11d, 12(%rsp)	# tmp134, %sfp
	movl	%r9d, 8(%rsp)	# tmp126, %sfp
	movl	%r10d, 4(%rsp)	# _23, %sfp
	call	sort_merge_standard_h.part.0	#
	movl	12(%rsp), %r11d	# %sfp, tmp134
	movl	8(%rsp), %r9d	# %sfp, tmp126
	movl	4(%rsp), %r10d	# %sfp, _23
	jmp	.L805	#
	.p2align 4,,10
	.p2align 3
.L817:
	movl	%r11d, %edx	# tmp134,
	movl	%r10d, %esi	# _23,
	movq	%rbx, %rcx	# b,
	movq	%r14, %rdi	# a,
	movl	%r9d, 12(%rsp)	# tmp126, %sfp
	movl	%r11d, 8(%rsp)	# tmp134, %sfp
	movl	%r10d, 4(%rsp)	# _23, %sfp
	call	sort_merge_standard_h.part.0	#
	movl	12(%rsp), %r9d	# %sfp, tmp126
	movl	8(%rsp), %r11d	# %sfp, tmp134
	movl	4(%rsp), %r10d	# %sfp, _23
	jmp	.L804	#
	.p2align 4,,10
	.p2align 3
.L814:
	movq	%rbx, %rcx	# b,
	movl	%r15d, %edx	# tmp114,
	movq	%r14, %rdi	# a,
	movl	%r9d, 4(%rsp)	# tmp118, %sfp
	call	sort_merge_standard_h.part.0	#
	movl	4(%rsp), %r9d	# %sfp, tmp118
	jmp	.L795	#
	.cfi_endproc
.LFE5713:
	.size	sort_merge_standard_h.part.0, .-sort_merge_standard_h.part.0
	.p2align 4
	.globl	sort_merge_standard
	.type	sort_merge_standard, @function
sort_merge_standard:
.LFB5405:
	.cfi_startproc
	endbr64	
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	movl	%edx, %r13d	# tmp118, high
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	movq	%rdi, %r12	# tmp116, a
# mergeu.h:37:   int *b = (int*) malloc(sizeof(int32_t) * (high - low + 1));
	movl	%edx, %edi	# high, tmp99
# mergeu.h:36: void sort_merge_standard(int a[], int low, int high) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
# mergeu.h:37:   int *b = (int*) malloc(sizeof(int32_t) * (high - low + 1));
	subl	%esi, %edi	# low, tmp99
# mergeu.h:37:   int *b = (int*) malloc(sizeof(int32_t) * (high - low + 1));
	incl	%edi	# tmp100
# mergeu.h:36: void sort_merge_standard(int a[], int low, int high) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
# mergeu.h:37:   int *b = (int*) malloc(sizeof(int32_t) * (high - low + 1));
	movslq	%edi, %rdi	# tmp100, tmp101
# mergeu.h:37:   int *b = (int*) malloc(sizeof(int32_t) * (high - low + 1));
	salq	$2, %rdi	#, tmp102
# mergeu.h:36: void sort_merge_standard(int a[], int low, int high) {
	subq	$24, %rsp	#,
	.cfi_def_cfa_offset 80
# mergeu.h:36: void sort_merge_standard(int a[], int low, int high) {
	movl	%esi, %ebp	# tmp117, low
# mergeu.h:37:   int *b = (int*) malloc(sizeof(int32_t) * (high - low + 1));
	call	malloc@PLT	#
	movq	%rax, %r14	# tmp119, b
# mergeu.h:28:   if (low < high) {
	cmpl	%ebp, %r13d	# low, high
	jg	.L830	#,
.L822:
# mergeu.h:40: }
	addq	$24, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
# mergeu.h:39:   free(b);
	movq	%r14, %rdi	# b,
# mergeu.h:40: }
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
# mergeu.h:39:   free(b);
	jmp	free@PLT	#
	.p2align 4,,10
	.p2align 3
.L830:
	.cfi_restore_state
# mergeu.h:29:     int mid = (low + high) / 2;
	leal	0(%r13,%rbp), %eax	#, tmp104
# mergeu.h:29:     int mid = (low + high) / 2;
	movl	%eax, %r15d	# tmp104, tmp105
	shrl	$31, %r15d	#, tmp105
	addl	%eax, %r15d	# tmp104, tmp106
	sarl	%r15d	# tmp107
# mergeu.h:28:   if (low < high) {
	cmpl	%r15d, %ebp	# tmp107, low
	jl	.L831	#,
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r15), %ebx	#, _16
# mergeu.h:28:   if (low < high) {
	cmpl	%ebx, %r13d	# _16, high
	jg	.L832	#,
.L826:
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movq	%r14, %r8	# b,
	movl	%r13d, %ecx	# high,
	movl	%r15d, %edx	# tmp107,
	movl	%ebp, %esi	# low,
	movq	%r12, %rdi	# a,
	call	merging_standard	#
	jmp	.L822	#
	.p2align 4,,10
	.p2align 3
.L831:
# mergeu.h:29:     int mid = (low + high) / 2;
	leal	0(%rbp,%r15), %eax	#, tmp108
# mergeu.h:29:     int mid = (low + high) / 2;
	movl	%eax, %ebx	# tmp108, tmp109
	shrl	$31, %ebx	#, tmp109
	addl	%eax, %ebx	# tmp108, tmp110
	sarl	%ebx	# tmp111
# mergeu.h:28:   if (low < high) {
	cmpl	%ebx, %ebp	# tmp111, low
	jl	.L833	#,
.L824:
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%rbx), %esi	#, _19
# mergeu.h:28:   if (low < high) {
	cmpl	%esi, %r15d	# _19, tmp107
	jg	.L834	#,
.L825:
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movl	%ebx, %edx	# tmp111,
	movq	%r14, %r8	# b,
	movl	%r15d, %ecx	# tmp107,
	movl	%ebp, %esi	# low,
	movq	%r12, %rdi	# a,
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r15), %ebx	#, _16
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	call	merging_standard	#
# mergeu.h:28:   if (low < high) {
	cmpl	%ebx, %r13d	# _16, high
	jle	.L826	#,
.L832:
# mergeu.h:29:     int mid = (low + high) / 2;
	leal	0(%r13,%rbx), %eax	#, tmp112
# mergeu.h:29:     int mid = (low + high) / 2;
	movl	%eax, %r9d	# tmp112, tmp113
	shrl	$31, %r9d	#, tmp113
	addl	%eax, %r9d	# tmp112, tmp114
	sarl	%r9d	# tmp115
# mergeu.h:28:   if (low < high) {
	cmpl	%r9d, %ebx	# tmp115, _16
	jl	.L835	#,
.L827:
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r9), %esi	#, _22
# mergeu.h:28:   if (low < high) {
	cmpl	%esi, %r13d	# _22, high
	jg	.L836	#,
.L828:
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movq	%r14, %r8	# b,
	movl	%r13d, %ecx	# high,
	movl	%r9d, %edx	# tmp115,
	movl	%ebx, %esi	# _16,
	movq	%r12, %rdi	# a,
	call	merging_standard	#
	jmp	.L826	#
	.p2align 4,,10
	.p2align 3
.L833:
	movq	%r14, %rcx	# b,
	movl	%ebx, %edx	# tmp111,
	movl	%ebp, %esi	# low,
	movq	%r12, %rdi	# a,
	call	sort_merge_standard_h.part.0	#
	jmp	.L824	#
	.p2align 4,,10
	.p2align 3
.L836:
	movq	%r14, %rcx	# b,
	movl	%r13d, %edx	# high,
	movq	%r12, %rdi	# a,
	movl	%r9d, 12(%rsp)	# tmp115, %sfp
	call	sort_merge_standard_h.part.0	#
	movl	12(%rsp), %r9d	# %sfp, tmp115
	jmp	.L828	#
	.p2align 4,,10
	.p2align 3
.L835:
	movl	%r9d, %edx	# tmp115,
	movq	%r14, %rcx	# b,
	movl	%ebx, %esi	# _16,
	movq	%r12, %rdi	# a,
	movl	%r9d, 12(%rsp)	# tmp115, %sfp
	call	sort_merge_standard_h.part.0	#
	movl	12(%rsp), %r9d	# %sfp, tmp115
	jmp	.L827	#
	.p2align 4,,10
	.p2align 3
.L834:
	movq	%r14, %rcx	# b,
	movl	%r15d, %edx	# tmp107,
	movq	%r12, %rdi	# a,
	call	sort_merge_standard_h.part.0	#
	jmp	.L825	#
	.cfi_endproc
.LFE5405:
	.size	sort_merge_standard, .-sort_merge_standard
	.p2align 4
	.globl	sort_merge_standard_h
	.type	sort_merge_standard_h, @function
sort_merge_standard_h:
.LFB5404:
	.cfi_startproc
	endbr64	
# mergeu.h:28:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jl	.L849	#,
	ret	
	.p2align 4,,10
	.p2align 3
.L849:
# mergeu.h:27: void sort_merge_standard_h(int a[], int low, int high, int *b) {
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
# mergeu.h:29:     int mid = (low + high) / 2;
	leal	(%rsi,%rdx), %eax	#, tmp95
# mergeu.h:27: void sort_merge_standard_h(int a[], int low, int high, int *b) {
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
# mergeu.h:29:     int mid = (low + high) / 2;
	movl	%eax, %r13d	# tmp95, tmp96
	shrl	$31, %r13d	#, tmp96
# mergeu.h:27: void sort_merge_standard_h(int a[], int low, int high, int *b) {
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
# mergeu.h:29:     int mid = (low + high) / 2;
	addl	%eax, %r13d	# tmp95, tmp97
	sarl	%r13d	# tmp98
# mergeu.h:27: void sort_merge_standard_h(int a[], int low, int high, int *b) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	movl	%edx, %r12d	# tmp109, high
	movl	%esi, %ebp	# tmp108, low
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	movq	%rcx, %rbx	# tmp110, b
	subq	$24, %rsp	#,
	.cfi_def_cfa_offset 80
# mergeu.h:28:   if (low < high) {
	cmpl	%r13d, %esi	# tmp98, low
	jl	.L850	#,
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r13), %r14d	#, _10
# mergeu.h:28:   if (low < high) {
	cmpl	%r14d, %r12d	# _10, high
	jg	.L851	#,
.L842:
# mergeu.h:34: }
	addq	$24, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 56
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movq	%rbx, %r8	# b,
# mergeu.h:34: }
	popq	%rbx	#
	.cfi_restore 3
	.cfi_def_cfa_offset 48
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movl	%ebp, %esi	# low,
# mergeu.h:34: }
	popq	%rbp	#
	.cfi_restore 6
	.cfi_def_cfa_offset 40
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movl	%r12d, %ecx	# high,
# mergeu.h:34: }
	popq	%r12	#
	.cfi_restore 12
	.cfi_def_cfa_offset 32
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movl	%r13d, %edx	# tmp98,
# mergeu.h:34: }
	popq	%r13	#
	.cfi_restore 13
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_restore 14
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_restore 15
	.cfi_def_cfa_offset 8
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	jmp	merging_standard	#
	.p2align 4,,10
	.p2align 3
.L850:
	.cfi_restore_state
# mergeu.h:29:     int mid = (low + high) / 2;
	leal	(%rsi,%r13), %eax	#, tmp99
# mergeu.h:29:     int mid = (low + high) / 2;
	movl	%eax, %r14d	# tmp99, tmp100
	shrl	$31, %r14d	#, tmp100
	addl	%eax, %r14d	# tmp99, tmp101
	sarl	%r14d	# tmp102
# mergeu.h:28:   if (low < high) {
	cmpl	%r14d, %esi	# tmp102, low
	jl	.L852	#,
.L840:
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r14), %esi	#, _13
# mergeu.h:28:   if (low < high) {
	cmpl	%esi, %r13d	# _13, tmp98
	jg	.L853	#,
.L841:
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movl	%r14d, %edx	# tmp102,
	movq	%rbx, %r8	# b,
	movl	%r13d, %ecx	# tmp98,
	movl	%ebp, %esi	# low,
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r13), %r14d	#, _10
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	call	merging_standard	#
# mergeu.h:28:   if (low < high) {
	cmpl	%r14d, %r12d	# _10, high
	jle	.L842	#,
.L851:
# mergeu.h:29:     int mid = (low + high) / 2;
	leal	(%r12,%r14), %eax	#, tmp103
# mergeu.h:29:     int mid = (low + high) / 2;
	movl	%eax, %r15d	# tmp103, tmp104
	shrl	$31, %r15d	#, tmp104
	addl	%eax, %r15d	# tmp103, tmp105
	sarl	%r15d	# tmp106
# mergeu.h:28:   if (low < high) {
	cmpl	%r15d, %r14d	# tmp106, _10
	jl	.L854	#,
.L843:
# mergeu.h:31:     sort_merge_standard_h(a, mid + 1, high, b);
	leal	1(%r15), %esi	#, _16
# mergeu.h:28:   if (low < high) {
	cmpl	%esi, %r12d	# _16, high
	jg	.L855	#,
.L844:
# mergeu.h:32:     merging_standard(a, low, mid, high, b);
	movq	%rbx, %r8	# b,
	movl	%r12d, %ecx	# high,
	movl	%r15d, %edx	# tmp106,
	movl	%r14d, %esi	# _10,
	call	merging_standard	#
	jmp	.L842	#
	.p2align 4,,10
	.p2align 3
.L852:
	movl	%r14d, %edx	# tmp102,
	movq	%rdi, 8(%rsp)	# a, %sfp
	call	sort_merge_standard_h.part.0	#
	movq	8(%rsp), %rdi	# %sfp, a
	jmp	.L840	#
	.p2align 4,,10
	.p2align 3
.L855:
	movq	%rbx, %rcx	# b,
	movl	%r12d, %edx	# high,
	movq	%rdi, 8(%rsp)	# a, %sfp
	call	sort_merge_standard_h.part.0	#
	movq	8(%rsp), %rdi	# %sfp, a
	jmp	.L844	#
	.p2align 4,,10
	.p2align 3
.L854:
	movq	%rbx, %rcx	# b,
	movl	%r15d, %edx	# tmp106,
	movl	%r14d, %esi	# _10,
	movq	%rdi, 8(%rsp)	# a, %sfp
	call	sort_merge_standard_h.part.0	#
	movq	8(%rsp), %rdi	# %sfp, a
	jmp	.L843	#
	.p2align 4,,10
	.p2align 3
.L853:
	movq	%rbx, %rcx	# b,
	movl	%r13d, %edx	# tmp98,
	movq	%rdi, 8(%rsp)	# a, %sfp
	call	sort_merge_standard_h.part.0	#
	movq	8(%rsp), %rdi	# %sfp, a
	jmp	.L841	#
	.cfi_endproc
.LFE5404:
	.size	sort_merge_standard_h, .-sort_merge_standard_h
	.p2align 4
	.globl	merging_inplace
	.type	merging_inplace, @function
merging_inplace:
.LFB5406:
	.cfi_startproc
	endbr64	
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	leal	1(%rdx), %eax	#, l2
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%ecx, %eax	# tmp108, l2
	jg	.L865	#,
	cmpl	%edx, %esi	# mid, low
	jg	.L865	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	cltq
	leaq	(%rdi,%rax,4), %rax	#, _7
	vmovd	(%rax), %xmm1	# *_7, tmp109
	movslq	%esi, %rsi	# low, ivtmp.1185
	.p2align 4,,10
	.p2align 3
.L859:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rdi,%rsi,4), %xmm0	# MEM[base: a_20(D), index: ivtmp.1185_39, step: 4, offset: 0B], tmp110
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_9, _4, tmp104
	vmovd	%xmm2, (%rdi,%rsi,4)	# tmp104, MEM[base: a_20(D), index: ivtmp.1185_39, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _4, iftmp.54_9, iftmp.54_9
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rsi	# ivtmp.1185
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rax)	# iftmp.54_9, *_7
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%esi, %edx	# ivtmp.1185, mid
	jge	.L859	#,
.L865:
# mergeinplace.h:26: }
	ret	
	.cfi_endproc
.LFE5406:
	.size	merging_inplace, .-merging_inplace
	.p2align 4
	.globl	sort_merge_inplace
	.type	sort_merge_inplace, @function
sort_merge_inplace:
.LFB5407:
	.cfi_startproc
	endbr64	
# mergeinplace.h:31:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jl	.L1015	#,
	ret	
	.p2align 4,,10
	.p2align 3
.L1015:
# mergeinplace.h:28: void sort_merge_inplace(int a[], int low, int high) {
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	(%rsi,%rdx), %eax	#, tmp295
# mergeinplace.h:28: void sort_merge_inplace(int a[], int low, int high) {
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	movl	%edx, %r13d	# tmp462, high
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %r12d	# tmp295, tmp296
	shrl	$31, %r12d	#, tmp296
# mergeinplace.h:28: void sort_merge_inplace(int a[], int low, int high) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
# mergeinplace.h:32:     mid = (low + high) / 2;
	addl	%eax, %r12d	# tmp295, tmp297
	sarl	%r12d	# tmp298
# mergeinplace.h:28: void sort_merge_inplace(int a[], int low, int high) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	movl	%esi, %ebp	# tmp461, low
	movq	%rdi, %rbx	# tmp460, a
	subq	$40, %rsp	#,
	.cfi_def_cfa_offset 96
# mergeinplace.h:31:   if (low < high) {
	cmpl	%r12d, %esi	# tmp298, low
	jge	.L886	#,
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	(%rsi,%r12), %eax	#, tmp299
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %r14d	# tmp299, tmp300
	shrl	$31, %r14d	#, tmp300
	addl	%eax, %r14d	# tmp299, tmp301
	sarl	%r14d	# tmp302
# mergeinplace.h:31:   if (low < high) {
	cmpl	%r14d, %esi	# tmp302, low
	jl	.L871	#,
.L881:
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	leal	1(%r14), %ecx	#, _49
# mergeinplace.h:31:   if (low < high) {
	cmpl	%ecx, %r12d	# _49, tmp298
	jg	.L1016	#,
.L873:
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%ecx, %r12d	# _49, tmp298
	jl	.L886	#,
	cmpl	%r14d, %ebp	# tmp302, low
	jg	.L886	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	movslq	%ecx, %rcx	# _49, _49
	leaq	(%rbx,%rcx,4), %rdx	#, _57
	vmovd	(%rdx), %xmm1	# *_57, tmp475
	movslq	%ebp, %rax	# low, ivtmp.1266
	.p2align 4,,10
	.p2align 3
.L896:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1266_481, step: 4, offset: 0B], tmp476
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_60, _54, tmp375
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp375, MEM[base: a_8(D), index: ivtmp.1266_481, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _54, iftmp.54_60, iftmp.54_60
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1266
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_60, *_57
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %r14d	# ivtmp.1266, tmp302
	jge	.L896	#,
.L886:
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	leal	1(%r12), %r14d	#, _2
# mergeinplace.h:31:   if (low < high) {
	cmpl	%r13d, %r14d	# high, _2
	jge	.L870	#,
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	(%r14,%r13), %eax	#, tmp380
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %r15d	# tmp380, tmp381
	shrl	$31, %r15d	#, tmp381
	addl	%eax, %r15d	# tmp380, tmp382
	sarl	%r15d	# tmp383
# mergeinplace.h:31:   if (low < high) {
	cmpl	%r15d, %r14d	# tmp383, _2
	jl	.L900	#,
.L910:
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	leal	1(%r15), %r8d	#, _31
# mergeinplace.h:31:   if (low < high) {
	cmpl	%r8d, %r13d	# _31, high
	jg	.L1017	#,
.L902:
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%r15d, %r14d	# tmp383, _2
	jg	.L870	#,
	cmpl	%r8d, %r13d	# _31, high
	jl	.L870	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	movslq	%r8d, %r8	# _31, _31
	leaq	(%rbx,%r8,4), %rdx	#, _39
	vmovd	(%rdx), %xmm1	# *_39, tmp489
	movslq	%r14d, %rax	# _2, ivtmp.1217
	.p2align 4,,10
	.p2align 3
.L924:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1217_507, step: 4, offset: 0B], tmp490
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_42, _36, tmp456
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp456, MEM[base: a_8(D), index: ivtmp.1217_507, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _36, iftmp.54_42, iftmp.54_42
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1217
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_42, *_39
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %r15d	# ivtmp.1217, tmp383
	jge	.L924	#,
.L870:
	cmpl	%r13d, %r14d	# high, _2
	jg	.L1010	#,
	cmpl	%r12d, %ebp	# tmp298, low
	jg	.L1010	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	movslq	%r14d, %r14	# _2, _2
	leaq	(%rbx,%r14,4), %rax	#, _18
	vmovd	(%rax), %xmm1	# *_18, tmp491
	movslq	%ebp, %rsi	# low, ivtmp.1210
	.p2align 4,,10
	.p2align 3
.L925:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rsi,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1210_499, step: 4, offset: 0B], tmp492
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_21, _15, tmp459
	vmovd	%xmm2, (%rbx,%rsi,4)	# tmp459, MEM[base: a_8(D), index: ivtmp.1210_499, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _15, iftmp.54_21, iftmp.54_21
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rsi	# ivtmp.1210
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rax)	# iftmp.54_21, *_18
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%esi, %r12d	# ivtmp.1210, tmp298
	jge	.L925	#,
.L1010:
# mergeinplace.h:39: }
	addq	$40, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1017:
	.cfi_restore_state
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	0(%r13,%r8), %eax	#, tmp421
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %ecx	# tmp421, tmp422
	shrl	$31, %ecx	#, tmp422
	addl	%eax, %ecx	# tmp421, tmp423
	sarl	%ecx	# tmp424
# mergeinplace.h:31:   if (low < high) {
	cmpl	%ecx, %r8d	# tmp424, _31
	jge	.L918	#,
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	(%r8,%rcx), %eax	#, tmp425
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %r9d	# tmp425, tmp426
	shrl	$31, %r9d	#, tmp426
	addl	%eax, %r9d	# tmp425, tmp427
	sarl	%r9d	# tmp428
# mergeinplace.h:33:     sort_merge_inplace(a, low, mid);
	movl	%r8d, %esi	# _31,
	movl	%r9d, %edx	# tmp428,
	movq	%rbx, %rdi	# a,
	movl	%r8d, 24(%rsp)	# _31, %sfp
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%ecx, 16(%rsp)	# tmp424, %sfp
# mergeinplace.h:33:     sort_merge_inplace(a, low, mid);
	movl	%r9d, 12(%rsp)	# tmp428, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	movl	12(%rsp), %r9d	# %sfp, tmp428
	movl	16(%rsp), %ecx	# %sfp, tmp424
	leal	1(%r9), %eax	#, _265
	movl	%ecx, %edx	# tmp424,
	movl	%eax, %esi	# _265,
	movq	%rbx, %rdi	# a,
	movl	%eax, 12(%rsp)	# _265, %sfp
	movl	%r9d, 20(%rsp)	# tmp428, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	movslq	12(%rsp), %rax	# %sfp,
	movl	16(%rsp), %ecx	# %sfp, tmp424
	movl	24(%rsp), %r8d	# %sfp, _31
	cmpl	%eax, %ecx	# _265, tmp424
	jl	.L918	#,
	movl	20(%rsp), %r9d	# %sfp, tmp428
	cmpl	%r9d, %r8d	# tmp428, _31
	jg	.L918	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	leaq	(%rbx,%rax,4), %rdx	#, _273
	vmovd	(%rdx), %xmm1	# *_273, tmp483
	movslq	%r8d, %rax	# _31, ivtmp.1238
	.p2align 4,,10
	.p2align 3
.L919:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1238_290, step: 4, offset: 0B], tmp484
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_276, _270, tmp435
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp435, MEM[base: a_8(D), index: ivtmp.1238_290, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _270, iftmp.54_276, iftmp.54_276
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1238
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_276, *_273
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %r9d	# ivtmp.1238, tmp428
	jge	.L919	#,
.L918:
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	leal	1(%rcx), %r10d	#, _175
# mergeinplace.h:31:   if (low < high) {
	cmpl	%r10d, %r13d	# _175, high
	jle	.L917	#,
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	0(%r13,%r10), %eax	#, tmp440
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %r9d	# tmp440, tmp441
	shrl	$31, %r9d	#, tmp441
	addl	%eax, %r9d	# tmp440, tmp442
	sarl	%r9d	# tmp443
# mergeinplace.h:33:     sort_merge_inplace(a, low, mid);
	movl	%r10d, %esi	# _175,
	movl	%r9d, %edx	# tmp443,
	movq	%rbx, %rdi	# a,
	movl	%ecx, 28(%rsp)	# tmp424, %sfp
	movl	%r8d, 24(%rsp)	# _31, %sfp
	movl	%r10d, 20(%rsp)	# _175, %sfp
	movl	%r9d, 12(%rsp)	# tmp443, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	movl	12(%rsp), %r9d	# %sfp, tmp443
	movl	%r13d, %edx	# high,
	leal	1(%r9), %eax	#, _247
	movl	%eax, %esi	# _247,
	movq	%rbx, %rdi	# a,
	movl	%r9d, 16(%rsp)	# tmp443, %sfp
	movl	%eax, 12(%rsp)	# _247, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	movl	16(%rsp), %r9d	# %sfp, tmp443
	movl	20(%rsp), %r10d	# %sfp, _175
	movl	24(%rsp), %r8d	# %sfp, _31
	cmpl	%r9d, %r10d	# tmp443, _175
	movl	28(%rsp), %ecx	# %sfp, tmp424
	jg	.L917	#,
	movslq	12(%rsp), %rax	# %sfp,
	cmpl	%eax, %r13d	# _247, high
	jl	.L917	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	leaq	(%rbx,%rax,4), %rdx	#, _255
	vmovd	(%rdx), %xmm1	# *_255, tmp485
	movslq	%r10d, %rax	# _175, ivtmp.1231
	.p2align 4,,10
	.p2align 3
.L922:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1231_523, step: 4, offset: 0B], tmp486
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_258, _252, tmp450
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp450, MEM[base: a_8(D), index: ivtmp.1231_523, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _252, iftmp.54_258, iftmp.54_258
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1231
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_258, *_255
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %r9d	# ivtmp.1231, tmp443
	jge	.L922	#,
.L917:
	cmpl	%r10d, %r13d	# _175, high
	jl	.L902	#,
	cmpl	%ecx, %r8d	# tmp424, _31
	jg	.L902	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	movslq	%r10d, %r10	# _175, _175
	leaq	(%rbx,%r10,4), %rdx	#, _183
	vmovd	(%rdx), %xmm1	# *_183, tmp487
	movslq	%r8d, %rax	# _31, ivtmp.1224
	.p2align 4,,10
	.p2align 3
.L923:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1224_514, step: 4, offset: 0B], tmp488
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_186, _180, tmp453
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp453, MEM[base: a_8(D), index: ivtmp.1224_514, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _180, iftmp.54_186, iftmp.54_186
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1224
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_186, *_183
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %ecx	# ivtmp.1224, tmp424
	jge	.L923	#,
	jmp	.L902	#
	.p2align 4,,10
	.p2align 3
.L900:
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	(%r14,%r15), %eax	#, tmp384
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %ecx	# tmp384, tmp385
	shrl	$31, %ecx	#, tmp385
	addl	%eax, %ecx	# tmp384, tmp386
	sarl	%ecx	# tmp387
# mergeinplace.h:31:   if (low < high) {
	cmpl	%ecx, %r14d	# tmp387, _2
	jge	.L906	#,
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	(%r14,%rcx), %eax	#, tmp388
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %r8d	# tmp388, tmp389
	shrl	$31, %r8d	#, tmp389
	addl	%eax, %r8d	# tmp388, tmp390
	sarl	%r8d	# tmp391
# mergeinplace.h:33:     sort_merge_inplace(a, low, mid);
	movl	%r8d, %edx	# tmp391,
	movl	%r14d, %esi	# _2,
	movq	%rbx, %rdi	# a,
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%ecx, 16(%rsp)	# tmp387, %sfp
# mergeinplace.h:33:     sort_merge_inplace(a, low, mid);
	movl	%r8d, 12(%rsp)	# tmp391, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	movl	12(%rsp), %r8d	# %sfp, tmp391
	movl	16(%rsp), %ecx	# %sfp, tmp387
	leal	1(%r8), %eax	#, _229
	movl	%ecx, %edx	# tmp387,
	movl	%eax, %esi	# _229,
	movq	%rbx, %rdi	# a,
	movl	%eax, 12(%rsp)	# _229, %sfp
	movl	%r8d, 20(%rsp)	# tmp391, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	movslq	12(%rsp), %rax	# %sfp,
	movl	16(%rsp), %ecx	# %sfp, tmp387
	cmpl	%eax, %ecx	# _229, tmp387
	jl	.L906	#,
	movl	20(%rsp), %r8d	# %sfp, tmp391
	cmpl	%r8d, %r14d	# tmp391, _2
	jg	.L906	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	leaq	(%rbx,%rax,4), %rdx	#, _237
	vmovd	(%rdx), %xmm1	# *_237, tmp477
	movslq	%r14d, %rax	# _2, ivtmp.1259
	.p2align 4,,10
	.p2align 3
.L907:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1259_492, step: 4, offset: 0B], tmp478
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_240, _234, tmp398
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp398, MEM[base: a_8(D), index: ivtmp.1259_492, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _234, iftmp.54_240, iftmp.54_240
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1259
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_240, *_237
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %r8d	# ivtmp.1259, tmp391
	jge	.L907	#,
.L906:
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	leal	1(%rcx), %r9d	#, _193
# mergeinplace.h:31:   if (low < high) {
	cmpl	%r9d, %r15d	# _193, tmp383
	jle	.L905	#,
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	(%r15,%r9), %eax	#, tmp403
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %r8d	# tmp403, tmp404
	shrl	$31, %r8d	#, tmp404
	addl	%eax, %r8d	# tmp403, tmp405
	sarl	%r8d	# tmp406
# mergeinplace.h:33:     sort_merge_inplace(a, low, mid);
	movl	%r9d, %esi	# _193,
	movl	%r8d, %edx	# tmp406,
	movq	%rbx, %rdi	# a,
	movl	%ecx, 24(%rsp)	# tmp387, %sfp
	movl	%r9d, 20(%rsp)	# _193, %sfp
	movl	%r8d, 12(%rsp)	# tmp406, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	movl	12(%rsp), %r8d	# %sfp, tmp406
	movl	%r15d, %edx	# tmp383,
	leal	1(%r8), %eax	#, _211
	movl	%eax, %esi	# _211,
	movq	%rbx, %rdi	# a,
	movl	%eax, 12(%rsp)	# _211, %sfp
	movl	%r8d, 16(%rsp)	# tmp406, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	movslq	12(%rsp), %rax	# %sfp,
	movl	20(%rsp), %r9d	# %sfp, _193
	cmpl	%eax, %r15d	# _211, tmp383
	movl	24(%rsp), %ecx	# %sfp, tmp387
	jl	.L905	#,
	movl	16(%rsp), %r8d	# %sfp, tmp406
	cmpl	%r8d, %r9d	# tmp406, _193
	jg	.L905	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	leaq	(%rbx,%rax,4), %rdx	#, _219
	vmovd	(%rdx), %xmm1	# *_219, tmp479
	movslq	%r9d, %rax	# _193, ivtmp.1252
	.p2align 4,,10
	.p2align 3
.L911:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1252_302, step: 4, offset: 0B], tmp480
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_222, _216, tmp413
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp413, MEM[base: a_8(D), index: ivtmp.1252_302, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _216, iftmp.54_222, iftmp.54_222
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1252
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_222, *_219
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %r8d	# ivtmp.1252, tmp406
	jge	.L911	#,
.L905:
	cmpl	%r9d, %r15d	# _193, tmp383
	jl	.L910	#,
	cmpl	%ecx, %r14d	# tmp387, _2
	jg	.L910	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	movslq	%r9d, %r9	# _193, _193
	leaq	(%rbx,%r9,4), %rdx	#, _201
	vmovd	(%rdx), %xmm1	# *_201, tmp481
	movslq	%r14d, %rax	# _2, ivtmp.1245
	.p2align 4,,10
	.p2align 3
.L912:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1245_300, step: 4, offset: 0B], tmp482
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_204, _198, tmp416
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp416, MEM[base: a_8(D), index: ivtmp.1245_300, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _198, iftmp.54_204, iftmp.54_204
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1245
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_204, *_201
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %ecx	# ivtmp.1245, tmp387
	jge	.L912	#,
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	leal	1(%r15), %r8d	#, _31
# mergeinplace.h:31:   if (low < high) {
	cmpl	%r8d, %r13d	# _31, high
	jle	.L902	#,
	jmp	.L1017	#
	.p2align 4,,10
	.p2align 3
.L1016:
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	(%r12,%rcx), %eax	#, tmp340
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %r15d	# tmp340, tmp341
	shrl	$31, %r15d	#, tmp341
	addl	%eax, %r15d	# tmp340, tmp342
	sarl	%r15d	# tmp343
# mergeinplace.h:31:   if (low < high) {
	cmpl	%r15d, %ecx	# tmp343, _49
	jge	.L890	#,
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	(%rcx,%r15), %eax	#, tmp344
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %r8d	# tmp344, tmp345
	shrl	$31, %r8d	#, tmp345
	addl	%eax, %r8d	# tmp344, tmp346
	sarl	%r8d	# tmp347
# mergeinplace.h:33:     sort_merge_inplace(a, low, mid);
	movl	%ecx, %esi	# _49,
	movl	%r8d, %edx	# tmp347,
	movq	%rbx, %rdi	# a,
	movl	%ecx, 20(%rsp)	# _49, %sfp
	movl	%r8d, 12(%rsp)	# tmp347, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	movl	12(%rsp), %r8d	# %sfp, tmp347
	movl	%r15d, %edx	# tmp343,
	leal	1(%r8), %eax	#, _157
	movl	%eax, %esi	# _157,
	movq	%rbx, %rdi	# a,
	movl	%r8d, 16(%rsp)	# tmp347, %sfp
	movl	%eax, 12(%rsp)	# _157, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	movl	16(%rsp), %r8d	# %sfp, tmp347
	movl	20(%rsp), %ecx	# %sfp, _49
	cmpl	%r8d, %ecx	# tmp347, _49
	jg	.L890	#,
	movslq	12(%rsp), %rax	# %sfp,
	cmpl	%eax, %r15d	# _157, tmp343
	jl	.L890	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	leaq	(%rbx,%rax,4), %rdx	#, _165
	vmovd	(%rdx), %xmm1	# *_165, tmp469
	movslq	%ecx, %rax	# _49, ivtmp.1287
	.p2align 4,,10
	.p2align 3
.L891:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1287_447, step: 4, offset: 0B], tmp470
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_168, _162, tmp354
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp354, MEM[base: a_8(D), index: ivtmp.1287_447, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _162, iftmp.54_168, iftmp.54_168
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1287
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_168, *_165
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %r8d	# ivtmp.1287, tmp347
	jge	.L891	#,
.L890:
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	leal	1(%r15), %r9d	#, _67
# mergeinplace.h:31:   if (low < high) {
	cmpl	%r9d, %r12d	# _67, tmp298
	jle	.L889	#,
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	(%r12,%r9), %eax	#, tmp359
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %r8d	# tmp359, tmp360
	shrl	$31, %r8d	#, tmp360
	addl	%eax, %r8d	# tmp359, tmp361
	sarl	%r8d	# tmp362
# mergeinplace.h:33:     sort_merge_inplace(a, low, mid);
	movl	%r9d, %esi	# _67,
	movl	%r8d, %edx	# tmp362,
	movq	%rbx, %rdi	# a,
	movl	%ecx, 24(%rsp)	# _49, %sfp
	movl	%r9d, 20(%rsp)	# _67, %sfp
	movl	%r8d, 12(%rsp)	# tmp362, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	movl	12(%rsp), %r8d	# %sfp, tmp362
	movl	%r12d, %edx	# tmp298,
	leal	1(%r8), %eax	#, _139
	movl	%eax, %esi	# _139,
	movq	%rbx, %rdi	# a,
	movl	%eax, 12(%rsp)	# _139, %sfp
	movl	%r8d, 16(%rsp)	# tmp362, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	movslq	12(%rsp), %rax	# %sfp,
	movl	20(%rsp), %r9d	# %sfp, _67
	cmpl	%eax, %r12d	# _139, tmp298
	movl	24(%rsp), %ecx	# %sfp, _49
	jl	.L889	#,
	movl	16(%rsp), %r8d	# %sfp, tmp362
	cmpl	%r8d, %r9d	# tmp362, _67
	jg	.L889	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	leaq	(%rbx,%rax,4), %rdx	#, _147
	vmovd	(%rdx), %xmm1	# *_147, tmp471
	movslq	%r9d, %rax	# _67, ivtmp.1280
	.p2align 4,,10
	.p2align 3
.L894:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1280_463, step: 4, offset: 0B], tmp472
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_150, _144, tmp369
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp369, MEM[base: a_8(D), index: ivtmp.1280_463, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _144, iftmp.54_150, iftmp.54_150
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1280
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_150, *_147
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %r8d	# ivtmp.1280, tmp362
	jge	.L894	#,
.L889:
	cmpl	%r9d, %r12d	# _67, tmp298
	jl	.L873	#,
	cmpl	%r15d, %ecx	# tmp343, _49
	jg	.L873	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	movslq	%r9d, %r9	# _67, _67
	leaq	(%rbx,%r9,4), %rdx	#, _75
	vmovd	(%rdx), %xmm1	# *_75, tmp473
	movslq	%ecx, %rax	# _49, ivtmp.1273
	.p2align 4,,10
	.p2align 3
.L895:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1273_475, step: 4, offset: 0B], tmp474
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_78, _72, tmp372
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp372, MEM[base: a_8(D), index: ivtmp.1273_475, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _72, iftmp.54_78, iftmp.54_78
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1273
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_78, *_75
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %r15d	# ivtmp.1273, tmp343
	jge	.L895	#,
	jmp	.L873	#
	.p2align 4,,10
	.p2align 3
.L871:
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	(%rsi,%r14), %eax	#, tmp303
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %r15d	# tmp303, tmp304
	shrl	$31, %r15d	#, tmp304
	addl	%eax, %r15d	# tmp303, tmp305
	sarl	%r15d	# tmp306
# mergeinplace.h:31:   if (low < high) {
	cmpl	%r15d, %esi	# tmp306, low
	jge	.L877	#,
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	(%rsi,%r15), %eax	#, tmp307
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %ecx	# tmp307, tmp308
	shrl	$31, %ecx	#, tmp308
	addl	%eax, %ecx	# tmp307, tmp309
	sarl	%ecx	# tmp310
# mergeinplace.h:33:     sort_merge_inplace(a, low, mid);
	movl	%ecx, %edx	# tmp310,
	movl	%ecx, 12(%rsp)	# tmp310, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	movl	12(%rsp), %ecx	# %sfp, tmp310
	movl	%r15d, %edx	# tmp306,
	leal	1(%rcx), %eax	#, _121
	movl	%eax, %esi	# _121,
	movq	%rbx, %rdi	# a,
	movl	%eax, 12(%rsp)	# _121, %sfp
	movl	%ecx, 16(%rsp)	# tmp310, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	movslq	12(%rsp), %rax	# %sfp,
	cmpl	%eax, %r15d	# _121, tmp306
	jl	.L877	#,
	movl	16(%rsp), %ecx	# %sfp, tmp310
	cmpl	%ecx, %ebp	# tmp310, low
	jg	.L877	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	leaq	(%rbx,%rax,4), %rdx	#, _129
	vmovd	(%rdx), %xmm1	# *_129, tmp463
	movslq	%ebp, %rax	# low, ivtmp.1308
	.p2align 4,,10
	.p2align 3
.L878:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1308_389, step: 4, offset: 0B], tmp464
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_132, _126, tmp317
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp317, MEM[base: a_8(D), index: ivtmp.1308_389, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _126, iftmp.54_132, iftmp.54_132
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1308
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_132, *_129
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %ecx	# ivtmp.1308, tmp310
	jge	.L878	#,
.L877:
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	leal	1(%r15), %r8d	#, _85
# mergeinplace.h:31:   if (low < high) {
	cmpl	%r8d, %r14d	# _85, tmp302
	jle	.L876	#,
# mergeinplace.h:32:     mid = (low + high) / 2;
	leal	(%r14,%r8), %eax	#, tmp322
# mergeinplace.h:32:     mid = (low + high) / 2;
	movl	%eax, %ecx	# tmp322, tmp323
	shrl	$31, %ecx	#, tmp323
	addl	%eax, %ecx	# tmp322, tmp324
	sarl	%ecx	# tmp325
# mergeinplace.h:33:     sort_merge_inplace(a, low, mid);
	movl	%r8d, %esi	# _85,
	movl	%ecx, %edx	# tmp325,
	movq	%rbx, %rdi	# a,
	movl	%r8d, 20(%rsp)	# _85, %sfp
	movl	%ecx, 12(%rsp)	# tmp325, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	movl	12(%rsp), %ecx	# %sfp, tmp325
	movl	%r14d, %edx	# tmp302,
	leal	1(%rcx), %eax	#, _103
	movl	%eax, %esi	# _103,
	movq	%rbx, %rdi	# a,
	movl	%ecx, 16(%rsp)	# tmp325, %sfp
	movl	%eax, 12(%rsp)	# _103, %sfp
	call	sort_merge_inplace	#
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	movl	16(%rsp), %ecx	# %sfp, tmp325
	movl	20(%rsp), %r8d	# %sfp, _85
	cmpl	%ecx, %r8d	# tmp325, _85
	jg	.L876	#,
	movslq	12(%rsp), %rax	# %sfp,
	cmpl	%eax, %r14d	# _103, tmp302
	jl	.L876	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	leaq	(%rbx,%rax,4), %rdx	#, _111
	vmovd	(%rdx), %xmm1	# *_111, tmp465
	movslq	%r8d, %rax	# _85, ivtmp.1301
	.p2align 4,,10
	.p2align 3
.L882:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1301_400, step: 4, offset: 0B], tmp466
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_114, _108, tmp332
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp332, MEM[base: a_8(D), index: ivtmp.1301_400, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _108, iftmp.54_114, iftmp.54_114
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1301
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_114, *_111
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %ecx	# ivtmp.1301, tmp325
	jge	.L882	#,
.L876:
	cmpl	%r8d, %r14d	# _85, tmp302
	jl	.L881	#,
	cmpl	%r15d, %ebp	# tmp306, low
	jg	.L881	#,
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	movslq	%r8d, %r8	# _85, _85
	leaq	(%rbx,%r8,4), %rdx	#, _93
	vmovd	(%rdx), %xmm1	# *_93, tmp467
	movslq	%ebp, %rax	# low, ivtmp.1294
	.p2align 4,,10
	.p2align 3
.L883:
# mergeinplace.h:8:     int c = a[l1] <= a[l2];
	vmovd	(%rbx,%rax,4), %xmm0	# MEM[base: a_8(D), index: ivtmp.1294_417, step: 4, offset: 0B], tmp468
# mergeinplace.h:12:     a[l1] = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# iftmp.54_96, _90, tmp335
	vmovd	%xmm2, (%rbx,%rax,4)	# tmp335, MEM[base: a_8(D), index: ivtmp.1294_417, step: 4, offset: 0B]
	vpmaxsd	%xmm0, %xmm1, %xmm1	# _90, iftmp.54_96, iftmp.54_96
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	incq	%rax	# ivtmp.1294
# mergeinplace.h:13:     a[l2] = c ? y : x;
	vmovd	%xmm1, (%rdx)	# iftmp.54_96, *_93
# mergeinplace.h:7:   for (l1 = low, l2 = mid + 1, i = low; l1 <= mid && l2 <= high; i++) {
	cmpl	%eax, %r15d	# ivtmp.1294, tmp306
	jge	.L883	#,
# mergeinplace.h:34:     sort_merge_inplace(a, mid + 1, high);
	leal	1(%r14), %ecx	#, _49
# mergeinplace.h:31:   if (low < high) {
	cmpl	%ecx, %r12d	# _49, tmp298
	jle	.L873	#,
	jmp	.L1016	#
	.cfi_endproc
.LFE5407:
	.size	sort_merge_inplace, .-sort_merge_inplace
	.p2align 4
	.globl	min
	.type	min, @function
min:
.LFB5408:
	.cfi_startproc
	endbr64	
# minmax.h:3: inline int min(int x, int y) { return (x < y) ? x : y; }
	vmovd	%edi, %xmm1	# tmp86, tmp89
	vmovd	%esi, %xmm0	# tmp87, tmp90
# minmax.h:3: inline int min(int x, int y) { return (x < y) ? x : y; }
	vpminsd	%xmm1, %xmm0, %xmm0	# tmp89, tmp90, tmp88
	vmovd	%xmm0, %eax	# tmp88, tmp85
# minmax.h:3: inline int min(int x, int y) { return (x < y) ? x : y; }
	ret	
	.cfi_endproc
.LFE5408:
	.size	min, .-min
	.p2align 4
	.globl	max
	.type	max, @function
max:
.LFB5409:
	.cfi_startproc
	endbr64	
# minmax.h:4: inline int max(int x, int y) { return (x > y) ? x : y; }
	vmovd	%edi, %xmm1	# tmp86, tmp89
	vmovd	%esi, %xmm0	# tmp87, tmp90
# minmax.h:4: inline int max(int x, int y) { return (x > y) ? x : y; }
	vpmaxsd	%xmm1, %xmm0, %xmm0	# tmp89, tmp90, tmp88
	vmovd	%xmm0, %eax	# tmp88, tmp85
# minmax.h:4: inline int max(int x, int y) { return (x > y) ? x : y; }
	ret	
	.cfi_endproc
.LFE5409:
	.size	max, .-max
	.p2align 4
	.globl	partition_equal
	.type	partition_equal, @function
partition_equal:
.LFB5410:
	.cfi_startproc
	endbr64	
# quicko.h:13:   int pivot = array[high];
	movslq	%edx, %rdx	# tmp99, high
# quicko.h:12: int partition_equal(int array[], int low, int high) {
	pushq	%r12	#
	.cfi_def_cfa_offset 16
	.cfi_offset 12, -16
# quicko.h:28:   asm volatile("    movq    %[i], %%r12\n"
	movl	(%rdi,%rdx,4), %ecx	# *_3, *_3
# quicko.h:26:   int64_t i = low;
	movslq	%esi, %rax	# tmp98, i
# quicko.h:28:   asm volatile("    movq    %[i], %%r12\n"
#APP
# 28 "quicko.h" 1
	    movq    %rax, %r12	# i
1:

    movl     (%rdi,%r12,4), %r8d	# array
    movl     (%rdi,%rax,4), %r9d	# array, i
    xorq      %r10, %r10
    cmp      %ecx, %r8d	# *_3
    sete     %r10b
    movl     %r9d, %r11d
    cmovel   %r8d, %r11d
    movl     %r11d, (%rdi,%rax,4)	# array, i
    cmovel   %r9d, %r8d
    movl     %r8d, (%rdi,%r12,4)	# array
    addq     %r10, %rax	# i

    incq     %r12
    cmp      %r12, %rdx	# high
    jne      1b

    movl     (%rdi,%rax,4), %r9d	# array, i
    movl     (%rdi,%rdx,4), %r8d	# array, high
    movl     %r9d, (%rdi,%rdx,4)	# array, high
    movl     %r8d, (%rdi,%rax,4)	# array, i

# 0 "" 2
# quicko.h:57: }
#NO_APP
	popq	%r12	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE5410:
	.size	partition_equal, .-partition_equal
	.p2align 4
	.globl	partition_lomuto
	.type	partition_lomuto, @function
partition_lomuto:
.LFB5411:
	.cfi_startproc
	endbr64	
# quicko.h:60:   int pivot = array[high];
	movslq	%edx, %rax	# high, high
	leaq	(%rdi,%rax,4), %r11	#, _3
# quicko.h:59: int partition_lomuto(int array[], int low, int high) {
	movq	%rdi, %r8	# tmp131, array
# quicko.h:62:   int i = (low - 1);
	leal	-1(%rsi), %ecx	#, i
# quicko.h:60:   int pivot = array[high];
	movl	(%r11), %edi	# *_3, pivot
# quicko.h:63:   for (int j = low; j < high; j++) {
	cmpl	%esi, %edx	# low, high
	jle	.L1026	#,
	movslq	%esi, %r9	# low, _42
	notl	%esi	# tmp119
	addl	%esi, %edx	# tmp119,
	addq	%r9, %rdx	# _42, tmp122
	leaq	(%r8,%r9,4), %rax	#, ivtmp.1330
	leaq	4(%r8,%rdx,4), %r9	#, _29
	.p2align 4,,10
	.p2align 3
.L1025:
# quicko.h:64:     if (array[j] <= pivot) {
	movl	(%rax), %edx	# MEM[base: _5, offset: 0B], _52
# quicko.h:64:     if (array[j] <= pivot) {
	cmpl	%edx, %edi	# _52, pivot
	jl	.L1024	#,
# quicko.h:65:       i++;
	incl	%ecx	# i
# quicko.h:66:       swap(&array[i], &array[j]);
	movslq	%ecx, %rsi	# i, i
# quicko.h:66:       swap(&array[i], &array[j]);
	leaq	(%r8,%rsi,4), %rsi	#, _48
# swap.h:2:   int t = *a;
	movl	(%rsi), %r10d	# *_48, t
# swap.h:3:   *a = *b;
	movl	%edx, (%rsi)	# _52, *_48
# swap.h:4:   *b = t;
	movl	%r10d, (%rax)	# t, MEM[base: _5, offset: 0B]
.L1024:
# quicko.h:63:   for (int j = low; j < high; j++) {
	addq	$4, %rax	#, ivtmp.1330
	cmpq	%r9, %rax	# _29, ivtmp.1330
	jne	.L1025	#,
# quicko.h:70:   return (i + 1);
	leal	1(%rcx), %eax	#, <retval>
# quicko.h:69:   swap(&array[i + 1], &array[high]);
	movslq	%ecx, %rcx	# i, i
# quicko.h:69:   swap(&array[i + 1], &array[high]);
	leaq	4(%r8,%rcx,4), %rdx	#, _15
# swap.h:3:   *a = *b;
	movl	(%r11), %edi	# *_3, pivot
# swap.h:2:   int t = *a;
	movl	(%rdx), %ecx	# *_15, t
# swap.h:3:   *a = *b;
	movl	%edi, (%rdx)	# pivot, *_15
# swap.h:4:   *b = t;
	movl	%ecx, (%r11)	# t, *_3
# quicko.h:71: }
	ret	
	.p2align 4,,10
	.p2align 3
.L1026:
# quicko.h:69:   swap(&array[i + 1], &array[high]);
	movslq	%ecx, %rcx	# i, i
# quicko.h:69:   swap(&array[i + 1], &array[high]);
	leaq	4(%r8,%rcx,4), %rdx	#, _15
# swap.h:2:   int t = *a;
	movl	(%rdx), %ecx	# *_15, t
# quicko.h:63:   for (int j = low; j < high; j++) {
	movl	%esi, %eax	# low, <retval>
# swap.h:3:   *a = *b;
	movl	%edi, (%rdx)	# pivot, *_15
# swap.h:4:   *b = t;
	movl	%ecx, (%r11)	# t, *_3
# quicko.h:71: }
	ret	
	.cfi_endproc
.LFE5411:
	.size	partition_lomuto, .-partition_lomuto
	.p2align 4
	.globl	sort_lomuto
	.type	sort_lomuto, @function
sort_lomuto:
.LFB5412:
	.cfi_startproc
	endbr64	
# quicko.h:74:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jge	.L1049	#,
# quicko.h:73: void sort_lomuto(int array[], int low, int high, int leftmost) {
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	movl	%esi, %r15d	# tmp150, low
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movq	%rdi, %r14	# tmp149, array
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	movl	%edx, %ebx	# tmp151, high
# quicko.h:75:     if (high - low > INSERTION_SORT_THRESH) {
	subl	%esi, %edx	# low, _1
# quicko.h:73: void sort_lomuto(int array[], int low, int high, int leftmost) {
	subq	$24, %rsp	#,
	.cfi_def_cfa_offset 80
# quicko.h:75:     if (high - low > INSERTION_SORT_THRESH) {
	cmpl	$20, %edx	#, _1
	jle	.L1030	#,
# quicko.h:13:   int pivot = array[high];
	movslq	%ebx, %rax	# high, h
	movq	%rax, 8(%rsp)	# h, %sfp
	movl	%ecx, %r13d	# tmp152, leftmost
	leaq	(%rdi,%rax,4), %rbp	#, _62
.L1031:
# quicko.h:76:       int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%ebx, %edx	# high,
	movl	%r15d, %esi	# low,
	movq	%r14, %rdi	# array,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %edx	# tmp153, pivot
	movslq	%r15d, %rax	# low, ivtmp.1363
# quicko.h:78:       if (leftmost || array[low - 1] != pivot) {
	testl	%r13d, %r13d	# leftmost
	jne	.L1033	#,
# quicko.h:78:       if (leftmost || array[low - 1] != pivot) {
	cmpl	%edx, -4(%r14,%rax,4)	# pivot, *_5
	je	.L1034	#,
.L1033:
# quicko.h:60:   int pivot = array[high];
	movl	0(%rbp), %esi	# *_62, pivot
# quicko.h:62:   int i = (low - 1);
	leal	-1(%r15), %r12d	#, i
	.p2align 4,,10
	.p2align 3
.L1036:
# quicko.h:64:     if (array[j] <= pivot) {
	movl	(%r14,%rax,4), %edx	# MEM[base: array_19(D), index: ivtmp.1363_106, step: 4, offset: 0B], _151
# quicko.h:64:     if (array[j] <= pivot) {
	cmpl	%edx, %esi	# _151, pivot
	jl	.L1035	#,
# quicko.h:65:       i++;
	incl	%r12d	# i
# quicko.h:66:       swap(&array[i], &array[j]);
	movslq	%r12d, %rcx	# i, i
# quicko.h:66:       swap(&array[i], &array[j]);
	leaq	(%r14,%rcx,4), %rcx	#, _147
# swap.h:2:   int t = *a;
	movl	(%rcx), %edi	# *_147, t
# swap.h:3:   *a = *b;
	movl	%edx, (%rcx)	# _151, *_147
# swap.h:4:   *b = t;
	movl	%edi, (%r14,%rax,4)	# t, MEM[base: array_19(D), index: ivtmp.1363_106, step: 4, offset: 0B]
.L1035:
# quicko.h:63:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1363
	cmpl	%eax, %ebx	# ivtmp.1363, high
	jg	.L1036	#,
# quicko.h:69:   swap(&array[i + 1], &array[high]);
	movslq	%r12d, %rax	# i, i
# quicko.h:69:   swap(&array[i + 1], &array[high]);
	leaq	4(%r14,%rax,4), %rax	#, _55
# swap.h:2:   int t = *a;
	movl	(%rax), %edx	# *_55, t
# swap.h:3:   *a = *b;
	movl	0(%rbp), %ecx	# *_62, _57
# quicko.h:80:         sort_lomuto(array, low, new_pivot_index - 1, leftmost);
	movl	%r15d, %esi	# low,
# swap.h:3:   *a = *b;
	movl	%ecx, (%rax)	# _57, *_55
# swap.h:4:   *b = t;
	movl	%edx, 0(%rbp)	# t, *_62
# quicko.h:80:         sort_lomuto(array, low, new_pivot_index - 1, leftmost);
	movl	%r13d, %ecx	# leftmost,
	movl	%r12d, %edx	# i,
	movq	%r14, %rdi	# array,
	call	sort_lomuto	#
# quicko.h:81:         sort_lomuto(array, new_pivot_index + 1, high, false);
	leal	2(%r12), %r15d	#, low
.L1037:
# quicko.h:74:   if (low < high) {
	cmpl	%r15d, %ebx	# low, high
	jle	.L1047	#,
# quicko.h:75:     if (high - low > INSERTION_SORT_THRESH) {
	movl	%ebx, %edx	# high, _1
	subl	%r15d, %edx	# low, _1
	xorl	%r13d, %r13d	# leftmost
# quicko.h:75:     if (high - low > INSERTION_SORT_THRESH) {
	cmpl	$20, %edx	#, _1
	jg	.L1031	#,
.L1030:
# quicko.h:87:       insertionSort(array + low, high - low + 1);
	movslq	%r15d, %rax	# low, low
# quicko.h:87:       insertionSort(array + low, high - low + 1);
	leaq	(%r14,%rax,4), %r11	#, _14
	leaq	4(%r11), %r8	#, ivtmp.1354
	movslq	%edx, %r10	# _1, _108
	xorl	%r9d, %r9d	# ivtmp.1351
	.p2align 4,,10
	.p2align 3
.L1041:
	leaq	0(,%r9,4), %rax	#, tmp144
	leaq	-4(%r8), %rsi	#, tmp143
# insertionssort.h:6:     element = array[i];
	movl	(%r8), %edi	# MEM[base: _126, offset: 0B], element
	subq	%rax, %rsi	# tmp144, _50
	movq	%r8, %rax	# ivtmp.1354, ivtmp.1343
	.p2align 4,,10
	.p2align 3
.L1038:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %edx	# MEM[base: _43, offset: -4B], _78
	movq	%rax, %rcx	# ivtmp.1343, _43
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %edi	# _78, element
	jge	.L1039	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, (%rax)	# _78, MEM[base: _43, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rcx), %rax	#, ivtmp.1343
	cmpq	%rax, %rsi	# ivtmp.1343, _50
	jne	.L1038	#,
	movq	%r11, %rcx	# _14, _43
.L1039:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%r9	# ivtmp.1351
# insertionssort.h:13:     array[j + 1] = element;
	movl	%edi, (%rcx)	# element, *prephitmp_175
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %r8	#, ivtmp.1354
	cmpq	%r9, %r10	# ivtmp.1351, _108
	jne	.L1041	#,
.L1047:
# quicko.h:90: }
	addq	$24, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1034:
	.cfi_restore_state
# quicko.h:28:   asm volatile("    movq    %[i], %%r12\n"
	movl	0(%rbp), %edx	# *_62, *_62
	movq	8(%rsp), %rdi	# %sfp, h
#APP
# 28 "quicko.h" 1
	    movq    %rax, %r12	# i
1:

    movl     (%r14,%r12,4), %r8d	# array
    movl     (%r14,%rax,4), %r9d	# array, i
    xorq      %r10, %r10
    cmp      %edx, %r8d	# *_62
    sete     %r10b
    movl     %r9d, %r11d
    cmovel   %r8d, %r11d
    movl     %r11d, (%r14,%rax,4)	# array, i
    cmovel   %r9d, %r8d
    movl     %r8d, (%r14,%r12,4)	# array
    addq     %r10, %rax	# i

    incq     %r12
    cmp      %r12, %rdi	# h
    jne      1b

    movl     (%r14,%rax,4), %r9d	# array, i
    movl     (%r14,%rdi,4), %r8d	# array, h
    movl     %r9d, (%r14,%rdi,4)	# array, h
    movl     %r8d, (%r14,%rax,4)	# array, i

# 0 "" 2
# quicko.h:84:         sort_lomuto(array, new_pivot_index + 1, high, false);
#NO_APP
	leal	1(%rax), %r15d	#, low
	jmp	.L1037	#
.L1049:
	.cfi_def_cfa_offset 8
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	.cfi_restore 14
	.cfi_restore 15
	ret	
	.cfi_endproc
.LFE5412:
	.size	sort_lomuto, .-sort_lomuto
	.p2align 4
	.globl	partition_cmov
	.type	partition_cmov, @function
partition_cmov:
.LFB5413:
	.cfi_startproc
	endbr64	
# quicko.h:93:   int pivot = array[high];
	movslq	%edx, %rdx	# tmp99, high
# quicko.h:92: int partition_cmov(int array[], int low, int high) {
	pushq	%r12	#
	.cfi_def_cfa_offset 16
	.cfi_offset 12, -16
# quicko.h:109:   asm volatile("    movq    %[i], %%r12\n"
	movl	(%rdi,%rdx,4), %ecx	# *_3, *_3
# quicko.h:107:   int64_t i = low;
	movslq	%esi, %rax	# tmp98, i
# quicko.h:109:   asm volatile("    movq    %[i], %%r12\n"
#APP
# 109 "quicko.h" 1
	    movq    %rax, %r12	# i
1:

    movl     (%rdi,%r12,4), %r8d	# array
    movl     (%rdi,%rax,4), %r9d	# array, i
    xorq      %r10, %r10
    cmp      %ecx, %r8d	# *_3
    setl     %r10b
    movl     %r9d, %r11d
    cmovll   %r8d, %r11d
    movl     %r11d, (%rdi,%rax,4)	# array, i
    cmovll   %r9d, %r8d
    movl     %r8d, (%rdi,%r12,4)	# array
    addq     %r10, %rax	# i

    incq     %r12
    cmp      %r12, %rdx	# high
    jne      1b

    movl     (%rdi,%rax,4), %r9d	# array, i
    movl     (%rdi,%rdx,4), %r8d	# array, high
    movl     %r9d, (%rdi,%rdx,4)	# array, high
    movl     %r8d, (%rdi,%rax,4)	# array, i

# 0 "" 2
# quicko.h:149: }
#NO_APP
	popq	%r12	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE5413:
	.size	partition_cmov, .-partition_cmov
	.p2align 4
	.globl	sort_cmov
	.type	sort_cmov, @function
sort_cmov:
.LFB5414:
	.cfi_startproc
	endbr64	
# quicko.h:152:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jge	.L1070	#,
# quicko.h:151: void sort_cmov(int array[], int low, int high, int leftmost) {
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
# quicko.h:153:     if (high - low > INSERTION_SORT_THRESH) {
	movl	%edx, %eax	# high, _1
	subl	%esi, %eax	# low, _1
# quicko.h:151: void sort_cmov(int array[], int low, int high, int leftmost) {
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movq	%rdi, %r14	# tmp133, array
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	movl	%edx, %r13d	# tmp135, high
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	movl	%esi, %ebp	# tmp134, low
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$24, %rsp	#,
	.cfi_def_cfa_offset 80
# quicko.h:153:     if (high - low > INSERTION_SORT_THRESH) {
	cmpl	$20, %eax	#, _1
	jle	.L1056	#,
# quicko.h:13:   int pivot = array[high];
	movslq	%edx, %rax	# high, _136
	movq	%rax, 8(%rsp)	# _136, %sfp
	leaq	(%rdi,%rax,4), %r15	#, _44
.L1057:
# quicko.h:154:       int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%r13d, %edx	# high,
	movl	%ebp, %esi	# low,
	movq	%r14, %rdi	# array,
	movl	%ecx, 4(%rsp)	# leftmost, %sfp
	call	median_of_three_of_median_of_three	#
# quicko.h:156:       if (leftmost || array[low - 1] != pivot) {
	movl	4(%rsp), %ecx	# %sfp, leftmost
# quicko.h:26:   int64_t i = low;
	movslq	%ebp, %rbx	# low, i
# quicko.h:156:       if (leftmost || array[low - 1] != pivot) {
	testl	%ecx, %ecx	# leftmost
	jne	.L1059	#,
# quicko.h:156:       if (leftmost || array[low - 1] != pivot) {
	cmpl	%eax, -4(%r14,%rbx,4)	# pivot, *_5
	je	.L1060	#,
.L1059:
# quicko.h:109:   asm volatile("    movq    %[i], %%r12\n"
	movl	(%r15), %eax	# *_44, *_44
	movq	8(%rsp), %rdi	# %sfp, _136
#APP
# 109 "quicko.h" 1
	    movq    %rbx, %r12	# i
1:

    movl     (%r14,%r12,4), %r8d	# array
    movl     (%r14,%rbx,4), %r9d	# array, i
    xorq      %r10, %r10
    cmp      %eax, %r8d	# *_44
    setl     %r10b
    movl     %r9d, %r11d
    cmovll   %r8d, %r11d
    movl     %r11d, (%r14,%rbx,4)	# array, i
    cmovll   %r9d, %r8d
    movl     %r8d, (%r14,%r12,4)	# array
    addq     %r10, %rbx	# i

    incq     %r12
    cmp      %r12, %rdi	# _136
    jne      1b

    movl     (%r14,%rbx,4), %r9d	# array, i
    movl     (%r14,%rdi,4), %r8d	# array, _136
    movl     %r9d, (%r14,%rdi,4)	# array, _136
    movl     %r8d, (%r14,%rbx,4)	# array, i

# 0 "" 2
# quicko.h:158:         sort_cmov(array, low, new_pivot_index - 1, leftmost);
#NO_APP
	movl	%ebp, %esi	# low,
	leal	-1(%rbx), %edx	#, tmp123
	movq	%r14, %rdi	# array,
	call	sort_cmov	#
# quicko.h:159:         sort_cmov(array, new_pivot_index + 1, high, false);
	leal	1(%rbx), %ebp	#, low
.L1061:
# quicko.h:152:   if (low < high) {
	cmpl	%ebp, %r13d	# low, high
	jle	.L1068	#,
# quicko.h:153:     if (high - low > INSERTION_SORT_THRESH) {
	movl	%r13d, %eax	# high, _1
	subl	%ebp, %eax	# low, _1
	xorl	%ecx, %ecx	# leftmost
# quicko.h:153:     if (high - low > INSERTION_SORT_THRESH) {
	cmpl	$20, %eax	#, _1
	jg	.L1057	#,
.L1056:
# quicko.h:166:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%ebp, %rbp	# low, low
# quicko.h:166:       insertionSortOptimized(array + low, high - low + 1);
	leaq	(%r14,%rbp,4), %r11	#, _14
	leaq	4(%r11), %r8	#, ivtmp.1390
	movslq	%eax, %r10	# _1, _27
	xorl	%r9d, %r9d	# ivtmp.1387
	.p2align 4,,10
	.p2align 3
.L1065:
	leaq	0(,%r9,4), %rax	#, tmp129
	leaq	-4(%r8), %rsi	#, tmp128
# insertionssort.h:6:     element = array[i];
	movl	(%r8), %edi	# MEM[base: _75, offset: 0B], element
	subq	%rax, %rsi	# tmp129, _92
	movq	%r8, %rax	# ivtmp.1390, ivtmp.1379
	.p2align 4,,10
	.p2align 3
.L1062:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %edx	# MEM[base: _102, offset: -4B], _60
	movq	%rax, %rcx	# ivtmp.1379, _102
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %edi	# _60, element
	jge	.L1063	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, (%rax)	# _60, MEM[base: _102, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rcx), %rax	#, ivtmp.1379
	cmpq	%rsi, %rax	# _92, ivtmp.1379
	jne	.L1062	#,
	movq	%r11, %rcx	# _14, _102
.L1063:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%r9	# ivtmp.1387
# insertionssort.h:13:     array[j + 1] = element;
	movl	%edi, (%rcx)	# element, *prephitmp_126
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %r8	#, ivtmp.1390
	cmpq	%r9, %r10	# ivtmp.1387, _27
	jne	.L1065	#,
.L1068:
# quicko.h:169: }
	addq	$24, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1060:
	.cfi_restore_state
# quicko.h:28:   asm volatile("    movq    %[i], %%r12\n"
	movl	(%r15), %eax	# *_44, *_44
	movq	8(%rsp), %rsi	# %sfp, _136
#APP
# 28 "quicko.h" 1
	    movq    %rbx, %r12	# i
1:

    movl     (%r14,%r12,4), %r8d	# array
    movl     (%r14,%rbx,4), %r9d	# array, i
    xorq      %r10, %r10
    cmp      %eax, %r8d	# *_44
    sete     %r10b
    movl     %r9d, %r11d
    cmovel   %r8d, %r11d
    movl     %r11d, (%r14,%rbx,4)	# array, i
    cmovel   %r9d, %r8d
    movl     %r8d, (%r14,%r12,4)	# array
    addq     %r10, %rbx	# i

    incq     %r12
    cmp      %r12, %rsi	# _136
    jne      1b

    movl     (%r14,%rbx,4), %r9d	# array, i
    movl     (%r14,%rsi,4), %r8d	# array, _136
    movl     %r9d, (%r14,%rsi,4)	# array, _136
    movl     %r8d, (%r14,%rbx,4)	# array, i

# 0 "" 2
# quicko.h:162:         sort_cmov(array, new_pivot_index + 1, high, false);
#NO_APP
	leal	1(%rbx), %ebp	#, low
	jmp	.L1061	#
.L1070:
	.cfi_def_cfa_offset 8
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	.cfi_restore 14
	.cfi_restore 15
	ret	
	.cfi_endproc
.LFE5414:
	.size	sort_cmov, .-sort_cmov
	.p2align 4
	.globl	peqsort
	.type	peqsort, @function
peqsort:
.LFB5417:
	.cfi_startproc
	endbr64	
# quicko.h:194:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jge	.L1183	#,
# quicko.h:193: void peqsort(int array[], int low, int high) {
	pushq	%r13	#
	.cfi_def_cfa_offset 16
	.cfi_offset 13, -16
	leaq	16(%rsp), %r13	#,
	.cfi_def_cfa 13, 0
	andq	$-32, %rsp	#,
	pushq	-8(%r13)	#
	pushq	%rbp	#
	movq	%rsp, %rbp	#,
	.cfi_escape 0x10,0x6,0x2,0x76,0
	pushq	%r15	#
	pushq	%r14	#
	.cfi_escape 0x10,0xf,0x2,0x76,0x78
	.cfi_escape 0x10,0xe,0x2,0x76,0x70
	movl	%edx, %r14d	# tmp796, high
	pushq	%r13	#
	.cfi_escape 0xf,0x3,0x76,0x68,0x6
	movl	%esi, %r13d	# tmp795, low
	pushq	%r12	#
	.cfi_escape 0x10,0xc,0x2,0x76,0x60
	movq	%rdi, %r12	# tmp794, array
	pushq	%rbx	#
	.cfi_escape 0x10,0x3,0x2,0x76,0x58
# quicko.h:195:     if (high - low > INSERTION_SORT_THRESH) {
	movl	%edx, %ebx	# high, _7
	subl	%esi, %ebx	# low, _7
# quicko.h:193: void peqsort(int array[], int low, int high) {
	subq	$40, %rsp	#,
# quicko.h:195:     if (high - low > INSERTION_SORT_THRESH) {
	cmpl	$20, %ebx	#, _7
	jg	.L1186	#,
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	leal	1(%rsi), %eax	#, i
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	cmpl	%eax, %edx	# i, high
	jl	.L1181	#,
	cltq
	leaq	-1(%rax), %rdi	#, ivtmp.1675
	.p2align 4,,10
	.p2align 3
.L1135:
# insertionssort.h:35:     element = array[i];
	movl	4(%r12,%rdi,4), %ecx	# MEM[base: array_6(D), index: ivtmp.1675_1017, step: 4, offset: 4B], element
	movslq	%esi, %rax	# ivtmp.1674, ivtmp.1663
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	testl	%esi, %esi	# ivtmp.1674
	jns	.L1133	#,
	jmp	.L1187	#
	.p2align 4,,10
	.p2align 3
.L1134:
# insertionssort.h:39:       array[j + 1] = array[j];
	movl	%edx, 4(%r12,%rax,4)	# _160, MEM[base: array_6(D), index: ivtmp.1663_1006, step: 4, offset: 4B]
	leal	-1(%rax), %edx	#, _1012
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	decq	%rax	# ivtmp.1663
	cmpl	$-1, %eax	#, ivtmp.1663
	je	.L1188	#,
.L1133:
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	movl	(%r12,%rax,4), %edx	# MEM[base: array_6(D), index: ivtmp.1663_1006, step: 4, offset: 0B], _160
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %ecx	# _160, element
	jl	.L1134	#,
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incl	%esi	# ivtmp.1674
# insertionssort.h:42:     array[j + 1] = element;
	movl	%ecx, 4(%r12,%rax,4)	# element, *_169
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incq	%rdi	# ivtmp.1675
	cmpl	%r14d, %esi	# high, ivtmp.1674
	jne	.L1135	#,
.L1181:
# quicko.h:241: }
	addq	$40, %rsp	#,
	popq	%rbx	#
	popq	%r12	#
	popq	%r13	#
	.cfi_remember_state
	.cfi_def_cfa 13, 0
	popq	%r14	#
	popq	%r15	#
	popq	%rbp	#
	leaq	-16(%r13), %rsp	#,
	.cfi_def_cfa 7, 16
	popq	%r13	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1186:
	.cfi_restore_state
# quicko.h:196:       int size = high - low + 1;
	incl	%ebx	# size
# quicko.h:197:       int sample_size = log2(size) * 2.0;
	vxorpd	%xmm6, %xmm6, %xmm6	# tmp805
	vcvtsi2sdl	%ebx, %xmm6, %xmm3	# size, tmp805, tmp801
	movslq	%r13d, %r15	# low, ivtmp.1600
	vmovsd	%xmm3, %xmm3, %xmm0	# _9,
	vmovsd	%xmm3, -56(%rbp)	# _9, %sfp
	call	log2@PLT	#
# quicko.h:197:       int sample_size = log2(size) * 2.0;
	vaddsd	%xmm0, %xmm0, %xmm0	# tmp797, tmp797, tmp542
# quicko.h:199:       int offset = size / sample_size;
	movl	%ebx, %eax	# size, offset
	cltd
# quicko.h:197:       int sample_size = log2(size) * 2.0;
	vcvttsd2sil	%xmm0, %r8d	# tmp542, sample_size
# quicko.h:200:       int not_ascending = 0;
	vmovsd	-56(%rbp), %xmm3	# %sfp, _9
# quicko.h:201:       int not_descending = 0;
	xorl	%edi, %edi	# not_descending
# quicko.h:200:       int not_ascending = 0;
	xorl	%esi, %esi	# not_ascending
# quicko.h:199:       int offset = size / sample_size;
	idivl	%r8d	# sample_size
	movslq	%eax, %r10	# offset, _1003
	movq	%r15, %rax	# ivtmp.1600, ivtmp.1652
	.p2align 4,,10
	.p2align 3
.L1077:
# quicko.h:204:         not_ascending += array[index] > array[index + 1];
	movl	4(%r12,%rax,4), %edx	# MEM[base: array_6(D), index: ivtmp.1652_1001, step: 4, offset: 4B], _22
# quicko.h:204:         not_ascending += array[index] > array[index + 1];
	movl	(%r12,%rax,4), %ecx	# MEM[base: array_6(D), index: ivtmp.1652_1001, step: 4, offset: 0B], _18
# quicko.h:204:         not_ascending += array[index] > array[index + 1];
	xorl	%r9d, %r9d	# tmp546
	cmpl	%edx, %ecx	# _22, _18
	setg	%r9b	#, tmp546
# quicko.h:204:         not_ascending += array[index] > array[index + 1];
	addl	%r9d, %esi	# tmp546, not_ascending
# quicko.h:205:         not_descending += array[index] < array[index + 1];
	cmpl	%edx, %ecx	# _22, _18
	setl	%dl	#, tmp548
	movzbl	%dl, %edx	# tmp548, tmp548
# quicko.h:203:       for (int index = low; index < high; index += offset) {
	addq	%r10, %rax	# _1003, ivtmp.1652
# quicko.h:205:         not_descending += array[index] < array[index + 1];
	addl	%edx, %edi	# tmp548, not_descending
# quicko.h:203:       for (int index = low; index < high; index += offset) {
	cmpl	%eax, %r14d	# ivtmp.1652, high
	jg	.L1077	#,
# quicko.h:208:       if (not_ascending > 1 && not_descending > 1 && not_ascending < sample_size - 1 && not_descending < sample_size - 1) {
	cmpl	$1, %esi	#, not_ascending
	jle	.L1078	#,
	cmpl	$1, %edi	#, not_descending
	jle	.L1078	#,
# quicko.h:208:       if (not_ascending > 1 && not_descending > 1 && not_ascending < sample_size - 1 && not_descending < sample_size - 1) {
	decl	%r8d	# tmp554
# quicko.h:208:       if (not_ascending > 1 && not_descending > 1 && not_ascending < sample_size - 1 && not_descending < sample_size - 1) {
	cmpl	%edi, %esi	# not_descending, not_ascending
	cmovl	%edi, %esi	# not_ascending,, not_descending, tmp555
	cmpl	%esi, %r8d	# tmp555, tmp554
	jg	.L1119	#,
.L1078:
	leal	-1(%r14), %r9d	#, tmp556
	movl	%r14d, %r8d	# high, niters.1504
	subl	%r13d, %r9d	# low, _777
	movl	%r13d, %esi	# low, ivtmp.1599
	subl	%r13d, %r8d	# low, niters.1504
	cmpl	$6, %r9d	#, _777
	jbe	.L1136	#,
	movl	%r8d, %edx	# niters.1504, bnd.1505
	leaq	0(,%r15,4), %rax	#, _793
	shrl	$3, %edx	#,
# quicko.h:200:       int not_ascending = 0;
	vpxor	%xmm4, %xmm4, %xmm4	# vect_not_descending_54.1522
	leaq	(%r12,%rax), %rdi	#, vectp.1511
	leaq	4(%r12,%rax), %rcx	#, vectp.1514
	salq	$5, %rdx	#, _1000
	xorl	%eax, %eax	# ivtmp.1643
	vmovdqa	%ymm4, %ymm2	#, vect_not_ascending_50.1518
	.p2align 4,,10
	.p2align 3
.L1080:
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	vmovdqu	(%rdi,%rax), %ymm1	# MEM[base: vectp.1511_791, index: ivtmp.1643_997, offset: 0B], MEM[base: vectp.1511_791, index: ivtmp.1643_997, offset: 0B]
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	vmovdqu	(%rcx,%rax), %ymm0	# MEM[base: vectp.1514_797, index: ivtmp.1643_997, offset: 0B], MEM[base: vectp.1514_797, index: ivtmp.1643_997, offset: 0B]
	addq	$32, %rax	#, ivtmp.1643
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	vpcmpgtd	%ymm0, %ymm1, %ymm5	# MEM[base: vectp.1514_797, index: ivtmp.1643_997, offset: 0B], MEM[base: vectp.1511_791, index: ivtmp.1643_997, offset: 0B], tmp563
# quicko.h:216:           not_descending += array[index] < array[index + 1];
	vpcmpgtd	%ymm1, %ymm0, %ymm0	# MEM[base: vectp.1511_791, index: ivtmp.1643_997, offset: 0B], MEM[base: vectp.1514_797, index: ivtmp.1643_997, offset: 0B], tmp565
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	vpsubd	%ymm5, %ymm2, %ymm2	# tmp563, vect_not_ascending_50.1518, vect_not_ascending_50.1518
# quicko.h:216:           not_descending += array[index] < array[index + 1];
	vpsubd	%ymm0, %ymm4, %ymm4	# tmp565, vect_not_descending_54.1522, vect_not_descending_54.1522
	cmpq	%rdx, %rax	# _1000, ivtmp.1643
	jne	.L1080	#,
	vmovdqa	%xmm4, %xmm0	# vect_not_descending_54.1522, tmp566
	vextracti128	$0x1, %ymm4, %xmm4	# vect_not_descending_54.1522, tmp567
	vpaddd	%xmm4, %xmm0, %xmm4	# tmp567, tmp566, _826
	vpsrldq	$8, %xmm4, %xmm0	#, _826, tmp569
	vpaddd	%xmm0, %xmm4, %xmm0	# tmp569, _826, _828
	vpsrldq	$4, %xmm0, %xmm1	#, _828, tmp571
	vpaddd	%xmm1, %xmm0, %xmm0	# tmp571, _828, tmp572
	vmovd	%xmm0, %ecx	# tmp572, stmp_not_descending_54.1523
	vmovdqa	%xmm2, %xmm0	# vect_not_ascending_50.1518, tmp573
	vextracti128	$0x1, %ymm2, %xmm2	# vect_not_ascending_50.1518, tmp574
	vpaddd	%xmm2, %xmm0, %xmm2	# tmp574, tmp573, _812
	vpsrldq	$8, %xmm2, %xmm0	#, _812, tmp576
	vpaddd	%xmm0, %xmm2, %xmm0	# tmp576, _812, _814
	vpsrldq	$4, %xmm0, %xmm1	#, _814, tmp578
	movl	%r8d, %eax	# niters.1504, niters_vector_mult_vf.1506
	vpaddd	%xmm1, %xmm0, %xmm0	# tmp578, _814, tmp579
	andl	$-8, %eax	#,
	vmovd	%xmm0, %edx	# tmp579, stmp_not_ascending_50.1519
	leal	(%rax,%r13), %edi	#, tmp.1527
	cmpl	%eax, %r8d	# niters_vector_mult_vf.1506, niters.1504
	je	.L1189	#,
	vzeroupper
.L1079:
	subl	%eax, %r9d	# niters_vector_mult_vf.1506, tmp580
	subl	%eax, %r8d	# niters_vector_mult_vf.1506, niters.1524
	cmpl	$3, %r9d	#, tmp580
	jbe	.L1082	#,
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	addq	%r15, %rax	# ivtmp.1600, tmp581
	vmovdqu	(%r12,%rax,4), %xmm4	# MEM <vector(4) int> [(int *)vectp.1531_876], MEM <vector(4) int> [(int *)vectp.1531_876]
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	vmovdqu	4(%r12,%rax,4), %xmm0	# MEM <vector(4) int> [(int *)vectp.1534_884], MEM <vector(4) int> [(int *)vectp.1534_884]
	vmovdqa	.LC4(%rip), %xmm2	#, tmp586
	vpcmpgtd	%xmm0, %xmm4, %xmm1	# MEM <vector(4) int> [(int *)vectp.1534_884], MEM <vector(4) int> [(int *)vectp.1531_876], tmp587
	vpcmpgtd	%xmm4, %xmm0, %xmm0	# MEM <vector(4) int> [(int *)vectp.1531_876], MEM <vector(4) int> [(int *)vectp.1534_884], tmp589
	vpand	%xmm2, %xmm1, %xmm1	# tmp586, tmp587, vect_patt_749.1537
	vpand	%xmm2, %xmm0, %xmm0	# tmp586, tmp589, vect_patt_750.1541
	vpsrldq	$8, %xmm0, %xmm2	#, vect_patt_750.1541, tmp591
	vpaddd	%xmm2, %xmm0, %xmm0	# tmp591, vect_patt_750.1541, _912
	vpsrldq	$4, %xmm0, %xmm2	#, _912, tmp593
	vpaddd	%xmm2, %xmm0, %xmm0	# tmp593, _912, tmp594
	vmovd	%xmm0, %eax	# tmp594, stmp_not_descending_770.1543
	vpsrldq	$8, %xmm1, %xmm0	#, vect_patt_749.1537, tmp597
	vpaddd	%xmm0, %xmm1, %xmm0	# tmp597, vect_patt_749.1537, _900
	vpsrldq	$4, %xmm0, %xmm1	#, _900, tmp599
	vpaddd	%xmm1, %xmm0, %xmm0	# tmp599, _900, tmp600
	addl	%eax, %ecx	# stmp_not_descending_770.1543, stmp_not_descending_54.1523
	vmovd	%xmm0, %eax	# tmp600, stmp_not_ascending_767.1539
	addl	%eax, %edx	# stmp_not_ascending_767.1539, stmp_not_ascending_50.1519
	movl	%r8d, %eax	# niters.1524, niters_vector_mult_vf.1526
	andl	$-4, %eax	#, niters_vector_mult_vf.1526
	addl	%eax, %edi	# niters_vector_mult_vf.1526, tmp.1527
	cmpl	%eax, %r8d	# niters_vector_mult_vf.1526, niters.1524
	je	.L1081	#,
.L1082:
	movslq	%edi, %rax	# tmp.1527, tmp.1527
	movl	(%r12,%rax,4), %r8d	# *_243, _41
	movl	4(%r12,%rax,4), %eax	# *_622, _623
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	xorl	%r9d, %r9d	# tmp603
	cmpl	%eax, %r8d	# _623, _41
	setg	%r9b	#, tmp603
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	addl	%r9d, %edx	# tmp603, stmp_not_ascending_50.1519
# quicko.h:216:           not_descending += array[index] < array[index + 1];
	cmpl	%eax, %r8d	# _623, _41
	setl	%r8b	#, tmp605
	movzbl	%r8b, %r8d	# tmp605, tmp605
# quicko.h:216:           not_descending += array[index] < array[index + 1];
	addl	%r8d, %ecx	# tmp605, stmp_not_descending_54.1523
# quicko.h:214:         for (int index = low; index < high; index++) {
	leal	1(%rdi), %r8d	#, index
# quicko.h:214:         for (int index = low; index < high; index++) {
	cmpl	%r8d, %r14d	# index, high
	jle	.L1081	#,
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	movslq	%r8d, %r8	# index, index
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	movl	4(%r12,%r8,4), %r8d	# *_254, _312
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	xorl	%r9d, %r9d	# tmp609
	cmpl	%eax, %r8d	# _623, _312
	setl	%r9b	#, tmp609
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	addl	%r9d, %edx	# tmp609, stmp_not_ascending_50.1519
# quicko.h:216:           not_descending += array[index] < array[index + 1];
	cmpl	%eax, %r8d	# _623, _312
	setg	%al	#, tmp611
	movzbl	%al, %eax	# tmp611, tmp611
# quicko.h:216:           not_descending += array[index] < array[index + 1];
	addl	%eax, %ecx	# tmp611, stmp_not_descending_54.1523
# quicko.h:214:         for (int index = low; index < high; index++) {
	leal	2(%rdi), %eax	#, index
# quicko.h:214:         for (int index = low; index < high; index++) {
	cmpl	%eax, %r14d	# index, high
	jle	.L1081	#,
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	cltq
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	movl	4(%r12,%rax,4), %eax	# *_744, _743
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	xorl	%r9d, %r9d	# tmp615
	cmpl	%eax, %r8d	# _743, _312
	setg	%r9b	#, tmp615
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	addl	%r9d, %edx	# tmp615, stmp_not_ascending_50.1519
# quicko.h:216:           not_descending += array[index] < array[index + 1];
	cmpl	%eax, %r8d	# _743, _312
	setl	%r8b	#, tmp617
	movzbl	%r8b, %r8d	# tmp617, tmp617
# quicko.h:214:         for (int index = low; index < high; index++) {
	addl	$3, %edi	#, index
# quicko.h:216:           not_descending += array[index] < array[index + 1];
	addl	%r8d, %ecx	# tmp617, stmp_not_descending_54.1523
# quicko.h:214:         for (int index = low; index < high; index++) {
	cmpl	%edi, %r14d	# index, high
	jle	.L1081	#,
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	movslq	%edi, %rdi	# index, index
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	movl	4(%r12,%rdi,4), %edi	# *_849, _850
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	xorl	%r8d, %r8d	# tmp621
	cmpl	%edi, %eax	# _850, _743
	setg	%r8b	#, tmp621
# quicko.h:215:           not_ascending += array[index] > array[index + 1];
	addl	%r8d, %edx	# tmp621, stmp_not_ascending_50.1519
# quicko.h:216:           not_descending += array[index] < array[index + 1];
	cmpl	%edi, %eax	# _850, _743
	setl	%al	#, tmp623
	movzbl	%al, %eax	# tmp623, tmp623
# quicko.h:216:           not_descending += array[index] < array[index + 1];
	addl	%eax, %ecx	# tmp623, stmp_not_descending_54.1523
.L1081:
# quicko.h:219:         if (not_ascending == 0) {
	testl	%edx, %edx	# stmp_not_ascending_50.1519
	je	.L1181	#,
# quicko.h:221:         if (not_ascending < log(size)) {
	vxorpd	%xmm7, %xmm7, %xmm7	# tmp811
	vcvtsi2sdl	%edx, %xmm7, %xmm1	# stmp_not_ascending_50.1519, tmp811, tmp802
# quicko.h:221:         if (not_ascending < log(size)) {
	vmovsd	%xmm3, %xmm3, %xmm0	# _9,
	movl	%esi, -72(%rbp)	# ivtmp.1599, %sfp
	movl	%ecx, -68(%rbp)	# stmp_not_descending_54.1523, %sfp
# quicko.h:221:         if (not_ascending < log(size)) {
	vmovsd	%xmm1, -64(%rbp)	# _57, %sfp
# quicko.h:221:         if (not_ascending < log(size)) {
	vmovsd	%xmm3, -56(%rbp)	# _9, %sfp
	call	log@PLT	#
# quicko.h:221:         if (not_ascending < log(size)) {
	vmovsd	-64(%rbp), %xmm1	# %sfp, _57
	vmovsd	-56(%rbp), %xmm3	# %sfp, _9
	vcomisd	%xmm1, %xmm0	# _57, tmp798
	movl	-68(%rbp), %ecx	# %sfp, stmp_not_descending_54.1523
	movl	-72(%rbp), %esi	# %sfp, ivtmp.1599
	ja	.L1190	#,
# quicko.h:223:         } else if (not_ascending < 0.15 * size) {
	vmulsd	.LC5(%rip), %xmm3, %xmm2	#, _9, _59
# quicko.h:223:         } else if (not_ascending < 0.15 * size) {
	vcomisd	%xmm1, %xmm2	# _57, _59
	ja	.L1125	#,
# quicko.h:225:         } else if (not_descending == 0) {
	testl	%ecx, %ecx	# stmp_not_descending_54.1523
	jne	.L1094	#,
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	sarl	%ebx	# _53
	movslq	%ebx, %rdx	# _53, _354
	movslq	%r14d, %rdi	# high, high
	movq	%rdx, %rsi	# _354, tmp629
	salq	$2, %rdi	#, _346
	leaq	4(%rdi), %rcx	#, _119
	negq	%rsi	# tmp629
	addq	%r15, %rdx	# ivtmp.1600, tmp632
	leaq	(%rcx,%rsi,4), %rsi	#, tmp631
	salq	$2, %rdx	#, tmp633
	leal	-1(%rbx), %r8d	#,
	leaq	0(,%r15,4), %rax	#, _336
	cmpq	%rdx, %rsi	# tmp633, tmp631
	jge	.L1138	#,
	cmpq	%rcx, %rax	# _119, _336
	jl	.L1095	#,
.L1138:
	movl	%ebx, %r9d	# _53, bnd.1409
	shrl	$3, %r9d	#,
	vmovdqa	.LC6(%rip), %ymm1	#, tmp793
	leaq	(%r12,%rax), %rdx	#, vectp.1413
	leaq	-28(%r12,%rdi), %rsi	#, vectp.1416
	salq	$5, %r9	#, _298
	xorl	%eax, %eax	# ivtmp.1577
	xorl	%ecx, %ecx	# ivtmp.1574
.L1097:
# swap.h:2:   int t = *a;
	vmovdqu	(%rdx,%rax), %ymm0	# MEM[base: vectp.1413_284, index: ivtmp.1577_194, offset: 0B], MEM[base: vectp.1413_284, index: ivtmp.1577_194, offset: 0B]
# swap.h:3:   *a = *b;
	vpermd	(%rsi,%rcx), %ymm1, %ymm2	# MEM[base: vectp.1416_278, index: ivtmp.1574_452, offset: 0B], tmp793, vect__71.1418
# swap.h:4:   *b = t;
	vpermd	%ymm0, %ymm1, %ymm0	# MEM[base: vectp.1413_284, index: ivtmp.1577_194, offset: 0B], tmp793, vect_t_70.1423
# swap.h:3:   *a = *b;
	vmovdqu	%ymm2, (%rdx,%rax)	# vect__71.1418, MEM[base: vectp.1413_284, index: ivtmp.1577_194, offset: 0B]
	addq	$32, %rax	#, ivtmp.1577
# swap.h:4:   *b = t;
	vmovdqu	%ymm0, (%rsi,%rcx)	# vect_t_70.1423, MEM[base: vectp.1416_278, index: ivtmp.1574_452, offset: 0B]
	subq	$32, %rcx	#, ivtmp.1574
	cmpq	%r9, %rax	# _298, ivtmp.1577
	jne	.L1097	#,
	movl	%ebx, %eax	# _53, tmp.1411
	andl	$-8, %eax	#, tmp.1411
	testb	$7, %bl	#, _53
	je	.L1176	#,
	movl	%ebx, %ecx	# _53, niters.1424
	subl	%eax, %r8d	# tmp.1411, tmp647
	subl	%eax, %ecx	# tmp.1411, niters.1424
	cmpl	$2, %r8d	#, tmp647
	jbe	.L1100	#,
	movl	%eax, %edx	# tmp.1411, _172
	addq	%rdx, %r15	# _172, tmp648
	leaq	(%r12,%r15,4), %rsi	#, vectp.1429
# swap.h:2:   int t = *a;
	vmovdqu	(%rsi), %xmm0	# MEM <vector(4) int> [(int *)vectp.1429_174], MEM <vector(4) int> [(int *)vectp.1429_174]
	negq	%rdx	# tmp652
	leaq	-12(%rdi,%rdx,4), %rdx	#, tmp654
# swap.h:4:   *b = t;
	vpshufd	$27, %xmm0, %xmm0	#, MEM <vector(4) int> [(int *)vectp.1429_174], vect_t_300.1439
# swap.h:3:   *a = *b;
	vpshufd	$27, (%r12,%rdx), %xmm1	#, MEM <vector(4) int> [(int *)vectp.1432_128], vect__299.1434
# swap.h:3:   *a = *b;
	vmovdqu	%xmm1, (%rsi)	# vect__299.1434, MEM <vector(4) int> [(int *)vectp.1429_174]
# swap.h:4:   *b = t;
	vmovdqu	%xmm0, (%r12,%rdx)	# vect_t_300.1439, MEM <vector(4) int> [(int *)vectp.1432_128]
	movl	%ecx, %edx	# niters.1424, niters_vector_mult_vf.1426
	andl	$-4, %edx	#, niters_vector_mult_vf.1426
	addl	%edx, %eax	# niters_vector_mult_vf.1426, tmp.1411
	cmpl	%ecx, %edx	# niters.1424, niters_vector_mult_vf.1426
	je	.L1176	#,
.L1100:
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movl	%r14d, %edx	# high, tmp659
	subl	%eax, %edx	# tmp.1411, tmp659
	movslq	%edx, %rdx	# tmp659, tmp660
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%r12,%rdx,4), %rcx	#, _47
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leal	0(%r13,%rax), %edx	#, tmp662
	movslq	%edx, %rdx	# tmp662, tmp663
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%r12,%rdx,4), %rdx	#, _52
# swap.h:3:   *a = *b;
	movl	(%rcx), %edi	# *_47, _55
# swap.h:2:   int t = *a;
	movl	(%rdx), %esi	# *_52, t
# swap.h:3:   *a = *b;
	movl	%edi, (%rdx)	# _55, *_52
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	leal	1(%rax), %edx	#, index
# swap.h:4:   *b = t;
	movl	%esi, (%rcx)	# t, *_47
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	cmpl	%edx, %ebx	# index, _53
	jle	.L1176	#,
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movl	%r14d, %ecx	# high, tmp665
	subl	%edx, %ecx	# index, tmp665
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	addl	%r13d, %edx	# low, tmp668
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movslq	%ecx, %rcx	# tmp665, tmp666
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movslq	%edx, %rdx	# tmp668, tmp669
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%r12,%rcx,4), %rcx	#, _762
	leaq	(%r12,%rdx,4), %rdx	#, _766
# swap.h:2:   int t = *a;
	movl	(%rdx), %esi	# *_766, t
# swap.h:3:   *a = *b;
	movl	(%rcx), %edi	# *_762, _768
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	addl	$2, %eax	#, index
# swap.h:3:   *a = *b;
	movl	%edi, (%rdx)	# _768, *_766
# swap.h:4:   *b = t;
	movl	%esi, (%rcx)	# t, *_762
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	cmpl	%eax, %ebx	# index, _53
	jle	.L1176	#,
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movl	%r14d, %edx	# high, high
	subl	%eax, %edx	# index, high
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	addl	%r13d, %eax	# low, tmp674
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movslq	%edx, %rdx	# tmp671, tmp672
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	cltq
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%r12,%rdx,4), %rdx	#, _246
	leaq	(%r12,%rax,4), %rax	#, _235
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# *_235, t
# swap.h:3:   *a = *b;
	movl	(%rdx), %esi	# *_246, _232
# swap.h:3:   *a = *b;
	movl	%esi, (%rax)	# _232, *_235
# swap.h:4:   *b = t;
	movl	%ecx, (%rdx)	# t, *_246
	vzeroupper
	jmp	.L1181	#
	.p2align 4,,10
	.p2align 3
.L1188:
# insertionssort.h:42:     array[j + 1] = element;
	movslq	%edx, %rax	# _1012, ivtmp.1663
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incl	%esi	# ivtmp.1674
# insertionssort.h:42:     array[j + 1] = element;
	movl	%ecx, 4(%r12,%rax,4)	# element, *_169
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incq	%rdi	# ivtmp.1675
	cmpl	%r14d, %esi	# high, ivtmp.1674
	jne	.L1135	#,
	jmp	.L1181	#
	.p2align 4,,10
	.p2align 3
.L1183:
	.cfi_def_cfa 7, 8
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	.cfi_restore 14
	.cfi_restore 15
	ret	
.L1187:
	.cfi_escape 0xf,0x3,0x76,0x68,0x6
	.cfi_escape 0x10,0x3,0x2,0x76,0x58
	.cfi_escape 0x10,0x6,0x2,0x76,0
	.cfi_escape 0x10,0xc,0x2,0x76,0x60
	.cfi_offset 13, -16
	.cfi_escape 0x10,0xe,0x2,0x76,0x70
	.cfi_escape 0x10,0xf,0x2,0x76,0x78
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rax	# ivtmp.1675, ivtmp.1663
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incl	%esi	# ivtmp.1674
# insertionssort.h:42:     array[j + 1] = element;
	movl	%ecx, 4(%r12,%rax,4)	# element, *_169
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incq	%rdi	# ivtmp.1675
	cmpl	%r14d, %esi	# high, ivtmp.1674
	jne	.L1135	#,
	jmp	.L1181	#
.L1189:
	vzeroupper
	jmp	.L1081	#
.L1119:
# quicko.h:241: }
	addq	$40, %rsp	#,
	popq	%rbx	#
	.cfi_remember_state
	.cfi_restore 3
# quicko.h:209:         sort_cmov(array, low, high, true);
	movq	%r12, %rdi	# array,
# quicko.h:241: }
	popq	%r12	#
	.cfi_restore 12
# quicko.h:209:         sort_cmov(array, low, high, true);
	movl	%r13d, %esi	# low,
# quicko.h:241: }
	popq	%r13	#
	.cfi_restore 13
	.cfi_def_cfa 13, 0
# quicko.h:209:         sort_cmov(array, low, high, true);
	movl	%r14d, %edx	# high,
# quicko.h:241: }
	popq	%r14	#
	.cfi_restore 14
	popq	%r15	#
	.cfi_restore 15
	popq	%rbp	#
	.cfi_restore 6
	leaq	-16(%r13), %rsp	#,
	.cfi_def_cfa 7, 16
# quicko.h:209:         sort_cmov(array, low, high, true);
	movl	$1, %ecx	#,
# quicko.h:241: }
	popq	%r13	#
	.cfi_restore 13
	.cfi_def_cfa_offset 8
# quicko.h:209:         sort_cmov(array, low, high, true);
	jmp	sort_cmov	#
.L1171:
	.cfi_restore_state
# quicko.h:230:         } else if (not_descending < 0.15 * size) {
	vcomisd	%xmm1, %xmm2	# _74, _59
	jbe	.L1119	#,
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	sarl	%ebx	# _233
	movslq	%r14d, %rdx	# high, high
	movslq	%ebx, %rsi	# _233, _578
	salq	$2, %rdx	#, _586
	leaq	(%rsi,%r15), %rdi	#, tmp737
	leaq	4(%rdx), %r8	#, _274
	negq	%rsi	# tmp740
	salq	$2, %rdi	#, tmp738
	leaq	(%r8,%rsi,4), %rsi	#, tmp742
	leal	-1(%rbx), %ecx	#,
	leaq	0(,%r15,4), %rax	#, _596
	cmpq	%rsi, %rdi	# tmp742, tmp738
	jle	.L1142	#,
	cmpq	%rax, %r8	# _596, _274
	jg	.L1121	#,
.L1142:
	movl	%ebx, %edi	# _233, bnd.1473
	shrl	$3, %edi	#,
	vmovdqa	.LC6(%rip), %ymm1	#, tmp793
	addq	%r12, %rax	# array, vectp.1477
	leaq	-28(%r12,%rdx), %r9	#, vectp.1480
	salq	$5, %rdi	#, _996
	xorl	%r8d, %r8d	# ivtmp.1633
	xorl	%esi, %esi	# ivtmp.1630
.L1123:
# swap.h:2:   int t = *a;
	vmovdqu	(%rax,%rsi), %ymm0	# MEM[base: vectp.1477_644, index: ivtmp.1630_991, offset: 0B], MEM[base: vectp.1477_644, index: ivtmp.1630_991, offset: 0B]
# swap.h:3:   *a = *b;
	vpermd	(%r9,%r8), %ymm1, %ymm2	# MEM[base: vectp.1480_650, index: ivtmp.1633_993, offset: 0B], tmp793, vect__99.1482
# swap.h:4:   *b = t;
	vpermd	%ymm0, %ymm1, %ymm0	# MEM[base: vectp.1477_644, index: ivtmp.1630_991, offset: 0B], tmp793, vect_t_98.1487
# swap.h:3:   *a = *b;
	vmovdqu	%ymm2, (%rax,%rsi)	# vect__99.1482, MEM[base: vectp.1477_644, index: ivtmp.1630_991, offset: 0B]
	addq	$32, %rsi	#, ivtmp.1630
# swap.h:4:   *b = t;
	vmovdqu	%ymm0, (%r9,%r8)	# vect_t_98.1487, MEM[base: vectp.1480_650, index: ivtmp.1633_993, offset: 0B]
	subq	$32, %r8	#, ivtmp.1633
	cmpq	%rdi, %rsi	# _996, ivtmp.1630
	jne	.L1123	#,
	movl	%ebx, %eax	# _233, tmp.1491
	andl	$-8, %eax	#, tmp.1491
	testb	$7, %bl	#, _233
	je	.L1125	#,
	movl	%ebx, %esi	# _233, niters.1488
	subl	%eax, %ecx	# tmp.1491, tmp756
	subl	%eax, %esi	# tmp.1491, niters.1488
	cmpl	$2, %ecx	#, tmp756
	jbe	.L1127	#,
	movl	%eax, %ecx	# tmp.1491, _705
	addq	%rcx, %r15	# _705, tmp757
	leaq	(%r12,%r15,4), %rdi	#, vectp.1493
# swap.h:2:   int t = *a;
	vmovdqu	(%rdi), %xmm0	# MEM <vector(4) int> [(int *)vectp.1493_703], MEM <vector(4) int> [(int *)vectp.1493_703]
	negq	%rcx	# tmp761
	leaq	-12(%rdx,%rcx,4), %rdx	#, tmp763
# swap.h:4:   *b = t;
	vpshufd	$27, %xmm0, %xmm0	#, MEM <vector(4) int> [(int *)vectp.1493_703], vect_t_628.1503
# swap.h:3:   *a = *b;
	vpshufd	$27, (%r12,%rdx), %xmm1	#, MEM <vector(4) int> [(int *)vectp.1496_711], vect__629.1498
# swap.h:3:   *a = *b;
	vmovdqu	%xmm1, (%rdi)	# vect__629.1498, MEM <vector(4) int> [(int *)vectp.1493_703]
# swap.h:4:   *b = t;
	vmovdqu	%xmm0, (%r12,%rdx)	# vect_t_628.1503, MEM <vector(4) int> [(int *)vectp.1496_711]
	movl	%esi, %edx	# niters.1488, niters_vector_mult_vf.1490
	andl	$-4, %edx	#, niters_vector_mult_vf.1490
	addl	%edx, %eax	# niters_vector_mult_vf.1490, tmp.1491
	cmpl	%edx, %esi	# niters_vector_mult_vf.1490, niters.1488
	je	.L1125	#,
.L1127:
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movl	%r14d, %edx	# high, tmp768
	subl	%eax, %edx	# tmp.1491, tmp768
	movslq	%edx, %rdx	# tmp768, tmp769
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%r12,%rdx,4), %rcx	#, _302
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leal	0(%r13,%rax), %edx	#, tmp771
	movslq	%edx, %rdx	# tmp771, tmp772
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%r12,%rdx,4), %rdx	#, _296
# swap.h:3:   *a = *b;
	movl	(%rcx), %edi	# *_302, _227
# swap.h:2:   int t = *a;
	movl	(%rdx), %esi	# *_296, t
# swap.h:3:   *a = *b;
	movl	%edi, (%rdx)	# _227, *_296
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	leal	1(%rax), %edx	#, index
# swap.h:4:   *b = t;
	movl	%esi, (%rcx)	# t, *_302
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	cmpl	%ebx, %edx	# _233, index
	jge	.L1125	#,
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movl	%r14d, %ecx	# high, tmp774
	subl	%edx, %ecx	# index, tmp774
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	addl	%r13d, %edx	# low, tmp777
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movslq	%ecx, %rcx	# tmp774, tmp775
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movslq	%edx, %rdx	# tmp777, tmp778
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%r12,%rcx,4), %rcx	#, _98
	leaq	(%r12,%rdx,4), %rdx	#, _441
# swap.h:2:   int t = *a;
	movl	(%rdx), %esi	# *_441, t
# swap.h:3:   *a = *b;
	movl	(%rcx), %edi	# *_98, _443
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	addl	$2, %eax	#, index
# swap.h:3:   *a = *b;
	movl	%edi, (%rdx)	# _443, *_441
# swap.h:4:   *b = t;
	movl	%esi, (%rcx)	# t, *_98
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	cmpl	%eax, %ebx	# index, _233
	jle	.L1125	#,
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movl	%r14d, %edx	# high, tmp780
	subl	%eax, %edx	# index, tmp780
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	addl	%r13d, %eax	# low, tmp783
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movslq	%edx, %rdx	# tmp780, tmp781
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	cltq
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%r12,%rdx,4), %rdx	#, _682
	leaq	(%r12,%rax,4), %rax	#, _686
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# *_686, t
# swap.h:3:   *a = *b;
	movl	(%rdx), %esi	# *_682, _688
# swap.h:3:   *a = *b;
	movl	%esi, (%rax)	# _688, *_686
# swap.h:4:   *b = t;
	movl	%ecx, (%rdx)	# t, *_682
.L1125:
# quicko.h:241: }
	addq	$40, %rsp	#,
	popq	%rbx	#
	.cfi_remember_state
	.cfi_restore 3
# quicko.h:224:           sort_lomuto(array, low, high, true);
	movq	%r12, %rdi	# array,
# quicko.h:241: }
	popq	%r12	#
	.cfi_restore 12
# quicko.h:224:           sort_lomuto(array, low, high, true);
	movl	%r13d, %esi	# low,
# quicko.h:241: }
	popq	%r13	#
	.cfi_restore 13
	.cfi_def_cfa 13, 0
# quicko.h:224:           sort_lomuto(array, low, high, true);
	movl	%r14d, %edx	# high,
# quicko.h:241: }
	popq	%r14	#
	.cfi_restore 14
	popq	%r15	#
	.cfi_restore 15
	popq	%rbp	#
	.cfi_restore 6
	leaq	-16(%r13), %rsp	#,
	.cfi_def_cfa 7, 16
# quicko.h:224:           sort_lomuto(array, low, high, true);
	movl	$1, %ecx	#,
# quicko.h:241: }
	popq	%r13	#
	.cfi_restore 13
	.cfi_def_cfa_offset 8
# quicko.h:224:           sort_lomuto(array, low, high, true);
	jmp	sort_lomuto	#
.L1190:
	.cfi_restore_state
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	cmpl	%r14d, %r13d	# high, low
	jge	.L1181	#,
	.p2align 4,,10
	.p2align 3
.L1091:
# insertionssort.h:35:     element = array[i];
	movl	4(%r12,%r15,4), %ecx	# MEM[base: array_6(D), index: ivtmp.1562_306, step: 4, offset: 4B], element
	movslq	%esi, %rax	# ivtmp.1599, ivtmp.1550
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	testl	%esi, %esi	# ivtmp.1599
	jns	.L1089	#,
	jmp	.L1191	#
	.p2align 4,,10
	.p2align 3
.L1090:
# insertionssort.h:39:       array[j + 1] = array[j];
	movl	%edx, 4(%r12,%rax,4)	# _116, MEM[base: array_6(D), index: ivtmp.1550_910, step: 4, offset: 4B]
	leal	-1(%rax), %edx	#, _917
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	decq	%rax	# ivtmp.1550
	cmpl	$-1, %eax	#, ivtmp.1550
	je	.L1192	#,
.L1089:
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	movl	(%r12,%rax,4), %edx	# MEM[base: array_6(D), index: ivtmp.1550_910, step: 4, offset: 0B], _116
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %ecx	# _116, element
	jl	.L1090	#,
.L1088:
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incl	%esi	# ivtmp.1599
# insertionssort.h:42:     array[j + 1] = element;
	movl	%ecx, 4(%r12,%rax,4)	# element, *_125
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incq	%r15	# ivtmp.1600
	cmpl	%esi, %r14d	# ivtmp.1599, high
	jne	.L1091	#,
	jmp	.L1181	#
.L1192:
# insertionssort.h:42:     array[j + 1] = element;
	movslq	%edx, %rax	# _917, ivtmp.1550
	jmp	.L1088	#
.L1136:
# quicko.h:200:       int not_ascending = 0;
	movl	%r13d, %edi	# low, tmp.1527
	xorl	%eax, %eax	#
	xorl	%ecx, %ecx	# stmp_not_descending_54.1523
	xorl	%edx, %edx	# stmp_not_ascending_50.1519
	jmp	.L1079	#
.L1191:
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	movq	%r15, %rax	# ivtmp.1600, ivtmp.1550
	jmp	.L1088	#
.L1176:
	vzeroupper
	jmp	.L1181	#
.L1094:
# quicko.h:227:         } else if (not_descending < log(size)) {
	vxorpd	%xmm7, %xmm7, %xmm7	# tmp820
	vcvtsi2sdl	%ecx, %xmm7, %xmm1	# stmp_not_descending_54.1523, tmp820, tmp803
# quicko.h:227:         } else if (not_descending < log(size)) {
	vmovsd	%xmm3, %xmm3, %xmm0	# _9,
	vmovsd	%xmm2, -64(%rbp)	# _59, %sfp
	movl	%esi, -68(%rbp)	# ivtmp.1599, %sfp
# quicko.h:227:         } else if (not_descending < log(size)) {
	vmovsd	%xmm1, -56(%rbp)	# _74, %sfp
# quicko.h:227:         } else if (not_descending < log(size)) {
	call	log@PLT	#
# quicko.h:227:         } else if (not_descending < log(size)) {
	vmovsd	-56(%rbp), %xmm1	# %sfp, _74
	vmovsd	-64(%rbp), %xmm2	# %sfp, _59
	vcomisd	%xmm1, %xmm0	# _74, tmp799
	jbe	.L1171	#,
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	sarl	%ebx	# _237
	movslq	%r14d, %rax	# high, high
	movslq	%ebx, %r8	# _237, _385
	leaq	0(,%rax,4), %rcx	#, _406
	leaq	4(%rcx), %r9	#, _21
	leaq	(%r8,%r15), %rax	#, tmp682
	negq	%r8	# tmp685
	salq	$2, %rax	#, tmp683
	leaq	(%r9,%r8,4), %r8	#, tmp687
	cmpq	%r8, %rax	# tmp687, tmp683
	movl	-68(%rbp), %esi	# %sfp, ivtmp.1599
	leal	-1(%rbx), %edi	#, _135
	leaq	0(,%r15,4), %rdx	#, _416
	jle	.L1140	#,
	cmpq	%rdx, %r9	# _416, _21
	jg	.L1106	#,
.L1140:
	movl	%ebx, %r8d	# _237, bnd.1441
	shrl	$3, %r8d	#,
	vmovdqa	.LC6(%rip), %ymm1	#, tmp793
	addq	%r12, %rdx	# array, vectp.1445
	leaq	-28(%r12,%rcx), %r9	#, vectp.1448
	salq	$5, %r8	#, _965
	xorl	%r10d, %r10d	# ivtmp.1614
	xorl	%eax, %eax	# ivtmp.1611
.L1108:
# swap.h:2:   int t = *a;
	vmovdqu	(%rdx,%rax), %ymm0	# MEM[base: vectp.1445_465, index: ivtmp.1611_960, offset: 0B], MEM[base: vectp.1445_465, index: ivtmp.1611_960, offset: 0B]
# swap.h:3:   *a = *b;
	vpermd	(%r9,%r10), %ymm1, %ymm2	# MEM[base: vectp.1448_471, index: ivtmp.1614_962, offset: 0B], tmp793, vect__86.1450
# swap.h:4:   *b = t;
	vpermd	%ymm0, %ymm1, %ymm0	# MEM[base: vectp.1445_465, index: ivtmp.1611_960, offset: 0B], tmp793, vect_t_85.1455
# swap.h:3:   *a = *b;
	vmovdqu	%ymm2, (%rdx,%rax)	# vect__86.1450, MEM[base: vectp.1445_465, index: ivtmp.1611_960, offset: 0B]
	addq	$32, %rax	#, ivtmp.1611
# swap.h:4:   *b = t;
	vmovdqu	%ymm0, (%r9,%r10)	# vect_t_85.1455, MEM[base: vectp.1448_471, index: ivtmp.1614_962, offset: 0B]
	subq	$32, %r10	#, ivtmp.1614
	cmpq	%r8, %rax	# _965, ivtmp.1611
	jne	.L1108	#,
	movl	%ebx, %eax	# _237, tmp.1459
	andl	$-8, %eax	#, tmp.1459
	testb	$7, %bl	#, _237
	je	.L1180	#,
	movl	%ebx, %r8d	# _237, niters.1456
	subl	%eax, %edi	# tmp.1459, tmp701
	subl	%eax, %r8d	# tmp.1459, niters.1456
	cmpl	$2, %edi	#, tmp701
	jbe	.L1110	#,
	movl	%eax, %edx	# tmp.1459, _526
	leaq	(%rdx,%r15), %rdi	#, tmp702
	leaq	(%r12,%rdi,4), %rdi	#, vectp.1461
# swap.h:2:   int t = *a;
	vmovdqu	(%rdi), %xmm0	# MEM <vector(4) int> [(int *)vectp.1461_524], MEM <vector(4) int> [(int *)vectp.1461_524]
	negq	%rdx	# tmp706
	leaq	-12(%rcx,%rdx,4), %rdx	#, tmp708
# swap.h:4:   *b = t;
	vpshufd	$27, %xmm0, %xmm0	#, MEM <vector(4) int> [(int *)vectp.1461_524], vect_t_449.1471
# swap.h:3:   *a = *b;
	vpshufd	$27, (%r12,%rdx), %xmm1	#, MEM <vector(4) int> [(int *)vectp.1464_532], vect__450.1466
# swap.h:3:   *a = *b;
	vmovdqu	%xmm1, (%rdi)	# vect__450.1466, MEM <vector(4) int> [(int *)vectp.1461_524]
# swap.h:4:   *b = t;
	vmovdqu	%xmm0, (%r12,%rdx)	# vect_t_449.1471, MEM <vector(4) int> [(int *)vectp.1464_532]
	movl	%r8d, %edx	# niters.1456, niters_vector_mult_vf.1458
	andl	$-4, %edx	#, niters_vector_mult_vf.1458
	addl	%edx, %eax	# niters_vector_mult_vf.1458, tmp.1459
	cmpl	%edx, %r8d	# niters_vector_mult_vf.1458, niters.1456
	je	.L1180	#,
.L1110:
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movl	%r14d, %edx	# high, tmp713
	subl	%eax, %edx	# tmp.1459, tmp713
	movslq	%edx, %rdx	# tmp713, tmp714
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%r12,%rdx,4), %rcx	#, _62
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leal	0(%r13,%rax), %edx	#, tmp716
	movslq	%edx, %rdx	# tmp716, tmp717
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%r12,%rdx,4), %rdx	#, _66
# swap.h:3:   *a = *b;
	movl	(%rcx), %r8d	# *_62, _68
# swap.h:2:   int t = *a;
	movl	(%rdx), %edi	# *_66, t
# swap.h:3:   *a = *b;
	movl	%r8d, (%rdx)	# _68, *_66
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	leal	1(%rax), %edx	#, index
# swap.h:4:   *b = t;
	movl	%edi, (%rcx)	# t, *_62
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	cmpl	%ebx, %edx	# _237, index
	jge	.L1180	#,
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movl	%r14d, %ecx	# high, tmp719
	subl	%edx, %ecx	# index, tmp719
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	addl	%r13d, %edx	# low, tmp722
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movslq	%ecx, %rcx	# tmp719, tmp720
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movslq	%edx, %rdx	# tmp722, tmp723
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%r12,%rcx,4), %rcx	#, _80
	leaq	(%r12,%rdx,4), %rdx	#, _84
# swap.h:2:   int t = *a;
	movl	(%rdx), %edi	# *_84, t
# swap.h:3:   *a = *b;
	movl	(%rcx), %r8d	# *_80, _86
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	addl	$2, %eax	#, index
# swap.h:3:   *a = *b;
	movl	%r8d, (%rdx)	# _86, *_84
# swap.h:4:   *b = t;
	movl	%edi, (%rcx)	# t, *_80
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	cmpl	%eax, %ebx	# index, _237
	jle	.L1180	#,
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movl	%r14d, %edx	# high, tmp725
	subl	%eax, %edx	# index, tmp725
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	addl	%r13d, %eax	# low, tmp728
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movslq	%edx, %rdx	# tmp725, tmp726
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	cltq
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%r12,%rdx,4), %rdx	#, _503
	leaq	(%r12,%rax,4), %rax	#, _507
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# *_507, t
# swap.h:3:   *a = *b;
	movl	(%rdx), %edi	# *_503, _509
# swap.h:3:   *a = *b;
	movl	%edi, (%rax)	# _509, *_507
# swap.h:4:   *b = t;
	movl	%ecx, (%rdx)	# t, *_503
	vzeroupper
.L1113:
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	cmpl	%r14d, %r13d	# high, low
	jge	.L1181	#,
.L1118:
# insertionssort.h:35:     element = array[i];
	movl	4(%r12,%r15,4), %ecx	# MEM[base: array_6(D), index: ivtmp.1600_928, step: 4, offset: 4B], element
	movslq	%esi, %rax	# ivtmp.1599, ivtmp.1588
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	testl	%esi, %esi	# ivtmp.1599
	jns	.L1116	#,
	jmp	.L1193	#
	.p2align 4,,10
	.p2align 3
.L1117:
# insertionssort.h:39:       array[j + 1] = array[j];
	movl	%edx, 4(%r12,%rax,4)	# _138, MEM[base: array_6(D), index: ivtmp.1588_196, step: 4, offset: 4B]
	leal	-1(%rax), %edx	#, _923
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	decq	%rax	# ivtmp.1588
	cmpl	$-1, %eax	#, ivtmp.1588
	je	.L1194	#,
.L1116:
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	movl	(%r12,%rax,4), %edx	# MEM[base: array_6(D), index: ivtmp.1588_196, step: 4, offset: 0B], _138
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %ecx	# _138, element
	jl	.L1117	#,
.L1115:
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incl	%esi	# ivtmp.1599
# insertionssort.h:42:     array[j + 1] = element;
	movl	%ecx, 4(%r12,%rax,4)	# element, *_147
# insertionssort.h:34:   for (i = low + 1; i <= high; i++) {
	incq	%r15	# ivtmp.1600
	cmpl	%esi, %r14d	# ivtmp.1599, high
	jne	.L1118	#,
	jmp	.L1181	#
.L1194:
# insertionssort.h:42:     array[j + 1] = element;
	movslq	%edx, %rax	# _923, ivtmp.1588
	jmp	.L1115	#
.L1180:
	vzeroupper
	jmp	.L1113	#
.L1095:
	addq	%r8, %r15	# _361, tmp678
	addq	%r12, %rax	# array, ivtmp.1567
	addq	%r12, %rdi	# array, ivtmp.1568
	leaq	4(%r12,%r15,4), %rdx	#, _189
.L1102:
# swap.h:3:   *a = *b;
	movl	(%rdi), %esi	# MEM[base: _89, offset: 0B], _316
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# MEM[base: _376, offset: 0B], t
# swap.h:3:   *a = *b;
	movl	%esi, (%rax)	# _316, MEM[base: _376, offset: 0B]
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	addq	$4, %rax	#, ivtmp.1567
# swap.h:4:   *b = t;
	movl	%ecx, (%rdi)	# t, MEM[base: _89, offset: 0B]
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	subq	$4, %rdi	#, ivtmp.1568
	cmpq	%rax, %rdx	# ivtmp.1567, _189
	jne	.L1102	#,
	jmp	.L1181	#
.L1106:
	leaq	(%r12,%rcx), %rax	#, ivtmp.1606
	movl	%edi, %ecx	# _135, _135
	addq	%r15, %rcx	# ivtmp.1600, tmp732
	addq	%r12, %rdx	# array, ivtmp.1605
	leaq	4(%r12,%rcx,4), %rcx	#, _959
.L1112:
# swap.h:3:   *a = *b;
	movl	(%rax), %r8d	# MEM[base: _949, offset: 0B], _432
# swap.h:2:   int t = *a;
	movl	(%rdx), %edi	# MEM[base: _947, offset: 0B], t
# swap.h:3:   *a = *b;
	movl	%r8d, (%rdx)	# _432, MEM[base: _947, offset: 0B]
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	addq	$4, %rdx	#, ivtmp.1605
# swap.h:4:   *b = t;
	movl	%edi, (%rax)	# t, MEM[base: _949, offset: 0B]
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	subq	$4, %rax	#, ivtmp.1606
	cmpq	%rcx, %rdx	# _959, ivtmp.1605
	jne	.L1112	#,
	jmp	.L1113	#
.L1193:
# insertionssort.h:38:     while (j >= 0 && array[j] > element) {
	movq	%r15, %rax	# ivtmp.1600, ivtmp.1588
	jmp	.L1115	#
.L1121:
	addq	%rcx, %r15	# _574, tmp787
	addq	%r12, %rax	# array, ivtmp.1624
	addq	%r12, %rdx	# array, ivtmp.1625
	leaq	4(%r12,%r15,4), %rcx	#, _990
.L1129:
# swap.h:3:   *a = *b;
	movl	(%rdx), %edi	# MEM[base: _980, offset: 0B], _612
# swap.h:2:   int t = *a;
	movl	(%rax), %esi	# MEM[base: _978, offset: 0B], t
# swap.h:3:   *a = *b;
	movl	%edi, (%rax)	# _612, MEM[base: _978, offset: 0B]
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	addq	$4, %rax	#, ivtmp.1624
# swap.h:4:   *b = t;
	movl	%esi, (%rdx)	# t, MEM[base: _980, offset: 0B]
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	subq	$4, %rdx	#, ivtmp.1625
	cmpq	%rcx, %rax	# _990, ivtmp.1624
	jne	.L1129	#,
	jmp	.L1125	#
	.cfi_endproc
.LFE5417:
	.size	peqsort, .-peqsort
	.p2align 4
	.globl	insertion_sort
	.type	insertion_sort, @function
insertion_sort:
.LFB5721:
	.cfi_startproc
	endbr64	
	leal	1(%rsi), %eax	#, i
	movslq	%eax, %r8	# i, i
	movl	%edx, %r9d	# tmp105, high
	decq	%r8	# ivtmp.1699
	cmpl	%eax, %edx	# i, high
	jl	.L1207	#,
	.p2align 4,,10
	.p2align 3
.L1201:
	movl	4(%rdi,%r8,4), %ecx	# MEM[base: array_2(D), index: ivtmp.1699_54, step: 4, offset: 4B], element
	movslq	%esi, %rax	# ivtmp.1698, ivtmp.1684
	testl	%esi, %esi	# ivtmp.1698
	jns	.L1199	#,
	jmp	.L1208	#
	.p2align 4,,10
	.p2align 3
.L1200:
	movl	%edx, 4(%rdi,%rax,4)	# _17, MEM[base: array_2(D), index: ivtmp.1684_40, step: 4, offset: 4B]
	leal	-1(%rax), %edx	#, _60
	decq	%rax	# ivtmp.1684
	cmpl	$-1, %eax	#, ivtmp.1684
	je	.L1209	#,
.L1199:
	movl	(%rdi,%rax,4), %edx	# MEM[base: array_2(D), index: ivtmp.1684_40, step: 4, offset: 0B], _17
	cmpl	%edx, %ecx	# _17, element
	jl	.L1200	#,
	incl	%esi	# ivtmp.1698
	movl	%ecx, 4(%rdi,%rax,4)	# element, *_26
	incq	%r8	# ivtmp.1699
	cmpl	%esi, %r9d	# ivtmp.1698, high
	jne	.L1201	#,
.L1207:
	ret	
	.p2align 4,,10
	.p2align 3
.L1209:
	movslq	%edx, %rax	# _60, ivtmp.1684
	incl	%esi	# ivtmp.1698
	movl	%ecx, 4(%rdi,%rax,4)	# element, *_26
	incq	%r8	# ivtmp.1699
	cmpl	%esi, %r9d	# ivtmp.1698, high
	jne	.L1201	#,
	jmp	.L1207	#
.L1208:
	movq	%r8, %rax	# ivtmp.1699, ivtmp.1684
	incl	%esi	# ivtmp.1698
	movl	%ecx, 4(%rdi,%rax,4)	# element, *_26
	incq	%r8	# ivtmp.1699
	cmpl	%esi, %r9d	# ivtmp.1698, high
	jne	.L1201	#,
	jmp	.L1207	#
	.cfi_endproc
.LFE5721:
	.size	insertion_sort, .-insertion_sort
	.p2align 4
	.globl	reverse
	.type	reverse, @function
reverse:
.LFB5416:
	.cfi_startproc
	endbr64	
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	movl	%edx, %ecx	# high, _25
	subl	%esi, %ecx	# low, _25
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	leal	1(%rcx), %eax	#, tmp184
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	movl	%eax, %r8d	# tmp184, tmp185
	shrl	$31, %r8d	#, tmp185
	addl	%eax, %r8d	# tmp184, tmp186
	sarl	%r8d	# tmp187
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	testl	%ecx, %ecx	# _25
	jle	.L1232	#,
# quicko.h:187: void reverse(int array[], int low, int high) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movslq	%edx, %rax	# high, high
	movl	%esi, %r9d	# tmp250, low
	movq	%rsp, %rbp	#,
	.cfi_def_cfa_register 6
	pushq	%r12	#
	.cfi_offset 12, -24
	movslq	%esi, %r12	# low, _24
	leaq	0(,%r12,4), %rsi	#, _23
	movl	%edx, %r10d	# tmp251, high
	movl	%r8d, %edx	# tmp187, _40
	leaq	(%rsi,%rdx,4), %r11	#, tmp192
	pushq	%rbx	#
	.cfi_offset 3, -32
	negq	%rdx	# tmp195
	leaq	4(,%rax,4), %rbx	#, _32
	salq	$2, %rax	#, _51
	leaq	4(%rax,%rdx,4), %rdx	#, tmp198
	cmpq	%rdx, %r11	# tmp198, tmp192
	setle	%r11b	#, tmp200
	cmpq	%rbx, %rsi	# _32, _23
	setge	%dl	#, tmp202
	orb	%dl, %r11b	# tmp202, tmp200
	je	.L1212	#,
	cmpl	$6, %ecx	#, _25
	jle	.L1212	#,
	cmpl	$14, %ecx	#, _25
	jle	.L1220	#,
	movl	%r8d, %r11d	# tmp187, bnd.1706
	shrl	$3, %r11d	#,
	vmovdqa	.LC6(%rip), %ymm1	#, tmp248
	addq	%rdi, %rsi	# array, vectp.1710
	leaq	-32(%rdi,%rbx), %rcx	#, vectp.1713
	salq	$5, %r11	#, _209
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	xorl	%edx, %edx	# ivtmp.1749
	xorl	%eax, %eax	# ivtmp.1746
	.p2align 4,,10
	.p2align 3
.L1214:
# swap.h:2:   int t = *a;
	vmovdqu	(%rsi,%rax), %ymm0	# MEM[base: vectp.1710_104, index: ivtmp.1746_21, offset: 0B], MEM[base: vectp.1710_104, index: ivtmp.1746_21, offset: 0B]
# swap.h:3:   *a = *b;
	vpermd	(%rcx,%rdx), %ymm1, %ymm2	# MEM[base: vectp.1713_110, index: ivtmp.1749_206, offset: 0B], tmp248, vect__20.1715
# swap.h:4:   *b = t;
	vpermd	%ymm0, %ymm1, %ymm0	# MEM[base: vectp.1710_104, index: ivtmp.1746_21, offset: 0B], tmp248, vect_t_19.1720
# swap.h:3:   *a = *b;
	vmovdqu	%ymm2, (%rsi,%rax)	# vect__20.1715, MEM[base: vectp.1710_104, index: ivtmp.1746_21, offset: 0B]
	addq	$32, %rax	#, ivtmp.1746
# swap.h:4:   *b = t;
	vmovdqu	%ymm0, (%rcx,%rdx)	# vect_t_19.1720, MEM[base: vectp.1713_110, index: ivtmp.1749_206, offset: 0B]
	subq	$32, %rdx	#, ivtmp.1749
	cmpq	%r11, %rax	# _209, ivtmp.1746
	jne	.L1214	#,
	movl	%r8d, %eax	# tmp187, niters_vector_mult_vf.1707
	andl	$-8, %eax	#,
	movl	%eax, %edx	# niters_vector_mult_vf.1707, tmp.1724
	cmpl	%eax, %r8d	# niters_vector_mult_vf.1707, tmp187
	je	.L1235	#,
	vzeroupper
.L1213:
	leal	-1(%r8), %esi	#, tmp217
	movl	%r8d, %ecx	# tmp187, niters.1721
	subl	%eax, %esi	# niters_vector_mult_vf.1707, tmp218
	subl	%eax, %ecx	# niters_vector_mult_vf.1707, niters.1721
	cmpl	$2, %esi	#, tmp218
	jbe	.L1216	#,
	addq	%rax, %r12	# _167, tmp219
	leaq	(%rdi,%r12,4), %rsi	#, vectp.1726
# swap.h:2:   int t = *a;
	vmovdqu	(%rsi), %xmm0	# MEM <vector(4) int> [(int *)vectp.1726_165], MEM <vector(4) int> [(int *)vectp.1726_165]
	negq	%rax	# tmp223
	leaq	-16(%rbx,%rax,4), %rax	#, tmp225
# swap.h:4:   *b = t;
	vpshufd	$27, %xmm0, %xmm0	#, MEM <vector(4) int> [(int *)vectp.1726_165], vect_t_90.1736
# swap.h:3:   *a = *b;
	vpshufd	$27, (%rdi,%rax), %xmm1	#, MEM <vector(4) int> [(int *)vectp.1729_173], vect__91.1731
# swap.h:3:   *a = *b;
	vmovdqu	%xmm1, (%rsi)	# vect__91.1731, MEM <vector(4) int> [(int *)vectp.1726_165]
# swap.h:4:   *b = t;
	vmovdqu	%xmm0, (%rdi,%rax)	# vect_t_90.1736, MEM <vector(4) int> [(int *)vectp.1729_173]
	movl	%ecx, %eax	# niters.1721, niters_vector_mult_vf.1723
	andl	$-4, %eax	#, niters_vector_mult_vf.1723
	addl	%eax, %edx	# niters_vector_mult_vf.1723, tmp.1724
	cmpl	%eax, %ecx	# niters_vector_mult_vf.1723, niters.1721
	je	.L1230	#,
.L1216:
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movl	%r10d, %eax	# high, tmp230
	subl	%edx, %eax	# tmp.1724, tmp230
	cltq
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%rdi,%rax,4), %rcx	#, _5
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leal	(%r9,%rdx), %eax	#, tmp233
	cltq
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%rdi,%rax,4), %rax	#, _19
# swap.h:3:   *a = *b;
	movl	(%rcx), %r11d	# *_5, _18
# swap.h:2:   int t = *a;
	movl	(%rax), %esi	# *_19, t
# swap.h:3:   *a = *b;
	movl	%r11d, (%rax)	# _18, *_19
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	leal	1(%rdx), %eax	#, index
# swap.h:4:   *b = t;
	movl	%esi, (%rcx)	# t, *_5
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	cmpl	%eax, %r8d	# index, tmp187
	jle	.L1230	#,
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movl	%r10d, %ecx	# high, tmp236
	subl	%eax, %ecx	# index, tmp236
	movslq	%ecx, %rcx	# tmp236, tmp237
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	addl	%r9d, %eax	# low, tmp239
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%rdi,%rcx,4), %rcx	#, _89
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	cltq
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%rdi,%rax,4), %rax	#, _95
# swap.h:3:   *a = *b;
	movl	(%rcx), %r11d	# *_89, _134
# swap.h:2:   int t = *a;
	movl	(%rax), %esi	# *_95, t
# swap.h:3:   *a = *b;
	movl	%r11d, (%rax)	# _134, *_95
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	leal	2(%rdx), %eax	#, index
# swap.h:4:   *b = t;
	movl	%esi, (%rcx)	# t, *_89
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	cmpl	%eax, %r8d	# index, tmp187
	jle	.L1230	#,
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	subl	%eax, %r10d	# index, tmp242
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	addl	%r9d, %eax	# low, tmp245
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	movslq	%r10d, %r10	# tmp242, tmp243
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	cltq
# quicko.h:189:     swap(&array[low + index], &array[high - index]);
	leaq	(%rdi,%r10,4), %rdx	#, _143
	leaq	(%rdi,%rax,4), %rax	#, _147
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# *_147, t
# swap.h:3:   *a = *b;
	movl	(%rdx), %esi	# *_143, _149
# swap.h:3:   *a = *b;
	movl	%esi, (%rax)	# _149, *_147
# swap.h:4:   *b = t;
	movl	%ecx, (%rdx)	# t, *_143
.L1230:
# quicko.h:191: }
	popq	%rbx	#
	popq	%r12	#
	popq	%rbp	#
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1212:
	.cfi_restore_state
	addq	%rdi, %rax	# array, ivtmp.1741
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	xorl	%edx, %edx	# ivtmp.1738
	addq	%rsi, %rdi	# _23, _44
	.p2align 4,,10
	.p2align 3
.L1218:
# swap.h:3:   *a = *b;
	movl	(%rax), %esi	# MEM[base: _93, offset: 0B], _73
# swap.h:2:   int t = *a;
	movl	(%rdi,%rdx,4), %ecx	# MEM[base: _44, index: ivtmp.1738_1, step: 4, offset: 0B], t
# swap.h:3:   *a = *b;
	movl	%esi, (%rdi,%rdx,4)	# _73, MEM[base: _44, index: ivtmp.1738_1, step: 4, offset: 0B]
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	incq	%rdx	# ivtmp.1738
# swap.h:4:   *b = t;
	movl	%ecx, (%rax)	# t, MEM[base: _93, offset: 0B]
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	subq	$4, %rax	#, ivtmp.1741
	cmpl	%edx, %r8d	# ivtmp.1738, tmp187
	jg	.L1218	#,
# quicko.h:191: }
	popq	%rbx	#
	popq	%r12	#
	popq	%rbp	#
	.cfi_def_cfa 7, 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1232:
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	ret	
.L1235:
	.cfi_def_cfa 6, 16
	.cfi_offset 3, -32
	.cfi_offset 6, -16
	.cfi_offset 12, -24
	vzeroupper
	jmp	.L1230	#
.L1220:
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	xorl	%eax, %eax	#
# quicko.h:188:   for (int index = 0; index < (high - low + 1) / 2; index++) {
	xorl	%edx, %edx	# tmp.1724
	jmp	.L1213	#
	.cfi_endproc
.LFE5416:
	.size	reverse, .-reverse
	.p2align 4
	.globl	partition_quick_simd
	.type	partition_quick_simd, @function
partition_quick_simd:
.LFB5418:
	.cfi_startproc
	endbr64	
	pushq	%rbp	#
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
	movl	%esi, %r11d	# tmp567, low
	movq	%rsp, %rbp	#,
	.cfi_def_cfa_register 6
	pushq	%r13	#
	pushq	%r12	#
	pushq	%rbx	#
	.cfi_offset 13, -24
	.cfi_offset 12, -32
	.cfi_offset 3, -40
	movslq	%edx, %rbx	# tmp568,
# quickosimd.h:25:   int pivot = median_of_three_auto_finish(array, low, high, &done);
	movl	%ebx, %edx	# high,
# quickosimd.h:22: int partition_quick_simd(int array[], int low, int high) {
	andq	$-32, %rsp	#,
	subq	$32, %rsp	#,
# quickosimd.h:25:   int pivot = median_of_three_auto_finish(array, low, high, &done);
	leaq	12(%rsp), %rcx	#, tmp331
# quickosimd.h:22: int partition_quick_simd(int array[], int low, int high) {
	movq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], tmp570
	movq	%rax, 24(%rsp)	# tmp570, D.41400
	xorl	%eax, %eax	# tmp570
# quickosimd.h:24:   int done = 0;
	movl	$0, 12(%rsp)	#, done
# quickosimd.h:25:   int pivot = median_of_three_auto_finish(array, low, high, &done);
	call	median_of_three_auto_finish	#
# quickosimd.h:26:   if (done) {
	movl	12(%rsp), %edx	# done,
	testl	%edx, %edx	#
	jne	.L1247	#,
# /usr/lib/gcc/x86_64-linux-gnu/10/include/avxintrin.h:1321:   return __extension__ (__m256i)(__v8si){ __A, __A, __A, __A,
	vmovd	%eax, %xmm3	# pivot, _66
	movl	%eax, %esi	# tmp569, pivot
# quickosimd.h:32:   for (; j < high - 7;) {
	leal	-7(%rbx), %eax	#, tmp337
# /usr/lib/gcc/x86_64-linux-gnu/10/include/avxintrin.h:1321:   return __extension__ (__m256i)(__v8si){ __A, __A, __A, __A,
	vpbroadcastd	%xmm3, %ymm3	# _66, _66
# quickosimd.h:32:   for (; j < high - 7;) {
	cmpl	%eax, %r11d	# tmp337, low
	jge	.L1244	#,
	leal	-8(%rbx), %r9d	#, tmp339
	subl	%r11d, %r9d	# low, tmp340
	shrl	$3, %r9d	#, _477
	movslq	%r11d, %rdx	# low, _505
	movl	%r9d, %ecx	# _477, _477
	leaq	(%rdi,%rdx,4), %rax	#, ivtmp.1799
	leaq	(%rdx,%rcx,8), %rdx	#, tmp343
	leaq	32(%rdi,%rdx,4), %r8	#, _469
	movl	%r11d, %r10d	# low, <retval>
# /usr/lib/gcc/x86_64-linux-gnu/10/include/avx2intrin.h:817:   return (__m256i) ((__v8su)__A - (__v8su)__B);
	vpxor	%xmm4, %xmm4, %xmm4	# tmp349
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	$1, %edx	#, tmp359
	.p2align 4,,10
	.p2align 3
.L1240:
# quickosimd.h:51:       x[0] = array[i];
	movslq	%r10d, %r12	# <retval>, <retval>
# /usr/lib/gcc/x86_64-linux-gnu/10/include/avx2intrin.h:275:   return (__m256i) ((__v8si)__A > (__v8si)__B);
	vpcmpgtd	(%rax), %ymm3, %ymm0	# MEM[base: _502, offset: 0B], _66, tmp348
# quickosimd.h:51:       x[0] = array[i];
	leaq	(%rdi,%r12,4), %r12	#, _95
# quickosimd.h:51:       x[0] = array[i];
	vmovd	(%r12), %xmm5	# *_95, tmp573
# /usr/lib/gcc/x86_64-linux-gnu/10/include/avx2intrin.h:817:   return (__m256i) ((__v8su)__A - (__v8su)__B);
	vpsubd	%ymm0, %ymm4, %ymm0	# tmp348, tmp349, _80
# quickosimd.h:51:       x[0] = array[i];
	vpinsrd	$1, (%rax), %xmm5, %xmm2	# MEM[base: _502, offset: 0B], tmp573, tmp353
	vmovd	%xmm0, %ecx	# tmp350, _281
	vmovq	%xmm2, 16(%rsp)	# tmp353, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:53:       array[i] = x[c];
	movslq	%ecx, %r13	# _281, _281
# quickosimd.h:53:       array[i] = x[c];
	movl	16(%rsp,%r13,4), %r13d	# MEM[(int[2] *)_163][_281], MEM[(int[2] *)_163][_281]
# quickosimd.h:32:   for (; j < high - 7;) {
	addq	$32, %rax	#, ivtmp.1799
# quickosimd.h:53:       array[i] = x[c];
	movl	%r13d, (%r12)	# MEM[(int[2] *)_163][_281], *_95
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	%edx, %r12d	# tmp359, tmp358
	subl	%ecx, %r12d	# _281, tmp358
# quickosimd.h:54:       array[j] = x[1 - c];
	movslq	%r12d, %r12	# tmp358, tmp360
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	16(%rsp,%r12,4), %r12d	# MEM[(int[2] *)_163][_105], MEM[(int[2] *)_163][_105]
	movl	%r12d, -32(%rax)	# MEM[(int[2] *)_163][_105], MEM[base: _502, offset: 0B]
# quickosimd.h:55:       i += c;
	leal	(%r10,%rcx), %r12d	#, i
# quickosimd.h:51:       x[0] = array[i];
	movslq	%r12d, %r10	# i, i
	leaq	(%rdi,%r10,4), %r10	#, _119
# quickosimd.h:51:       x[0] = array[i];
	vmovd	(%r10), %xmm6	# *_119, tmp575
	vpextrd	$1, %xmm0, %ecx	#, tmp350, _283
	vpinsrd	$1, -28(%rax), %xmm6, %xmm2	# MEM[base: _502, offset: 4B], tmp575, tmp365
# quickosimd.h:53:       array[i] = x[c];
	movslq	%ecx, %r13	# _283, _283
# quickosimd.h:51:       x[0] = array[i];
	vmovq	%xmm2, 16(%rsp)	# tmp365, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:53:       array[i] = x[c];
	movl	16(%rsp,%r13,4), %r13d	# MEM[(int[2] *)_163][_283], MEM[(int[2] *)_163][_283]
	movl	%r13d, (%r10)	# MEM[(int[2] *)_163][_283], *_119
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	%edx, %r10d	# tmp359, tmp370
	subl	%ecx, %r10d	# _283, tmp370
# quickosimd.h:54:       array[j] = x[1 - c];
	movslq	%r10d, %r10	# tmp370, tmp372
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	16(%rsp,%r10,4), %r10d	# MEM[(int[2] *)_163][_129], MEM[(int[2] *)_163][_129]
	movl	%r10d, -28(%rax)	# MEM[(int[2] *)_163][_129], MEM[base: _502, offset: 4B]
# quickosimd.h:55:       i += c;
	leal	(%r12,%rcx), %r10d	#, i
# quickosimd.h:51:       x[0] = array[i];
	movslq	%r10d, %rcx	# i, i
	leaq	(%rdi,%rcx,4), %rcx	#, _143
# quickosimd.h:51:       x[0] = array[i];
	vmovd	(%rcx), %xmm7	# *_143, tmp577
	vpextrd	$2, %xmm0, %r12d	#, tmp350, _285
	vpinsrd	$1, -24(%rax), %xmm7, %xmm2	# MEM[base: _502, offset: 8B], tmp577, tmp377
# quickosimd.h:53:       array[i] = x[c];
	movslq	%r12d, %r13	# _285, _285
# quickosimd.h:51:       x[0] = array[i];
	vmovq	%xmm2, 16(%rsp)	# tmp377, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:53:       array[i] = x[c];
	movl	16(%rsp,%r13,4), %r13d	# MEM[(int[2] *)_163][_285], MEM[(int[2] *)_163][_285]
# quickosimd.h:55:       i += c;
	addl	%r12d, %r10d	# _285, i
# quickosimd.h:53:       array[i] = x[c];
	movl	%r13d, (%rcx)	# MEM[(int[2] *)_163][_285], *_143
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	%edx, %ecx	# tmp359, tmp382
	subl	%r12d, %ecx	# _285, tmp382
# quickosimd.h:54:       array[j] = x[1 - c];
	movslq	%ecx, %rcx	# tmp382, tmp384
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	16(%rsp,%rcx,4), %ecx	# MEM[(int[2] *)_163][_153], MEM[(int[2] *)_163][_153]
	vpextrd	$3, %xmm0, %r12d	#, tmp350, _287
	movl	%ecx, -24(%rax)	# MEM[(int[2] *)_163][_153], MEM[base: _502, offset: 8B]
# quickosimd.h:51:       x[0] = array[i];
	movslq	%r10d, %rcx	# i, i
	leaq	(%rdi,%rcx,4), %rcx	#, _167
# quickosimd.h:51:       x[0] = array[i];
	vmovd	(%rcx), %xmm5	# *_167, tmp579
# quickosimd.h:53:       array[i] = x[c];
	movslq	%r12d, %r13	# _287, _287
# quickosimd.h:51:       x[0] = array[i];
	vpinsrd	$1, -20(%rax), %xmm5, %xmm1	# MEM[base: _502, offset: 12B], tmp579, tmp389
# quickosimd.h:55:       i += c;
	addl	%r12d, %r10d	# _287, i
# quickosimd.h:51:       x[0] = array[i];
	vmovq	%xmm1, 16(%rsp)	# tmp389, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:53:       array[i] = x[c];
	movl	16(%rsp,%r13,4), %r13d	# MEM[(int[2] *)_163][_287], MEM[(int[2] *)_163][_287]
	vextracti128	$0x1, %ymm0, %xmm0	# _80, tmp398
	movl	%r13d, (%rcx)	# MEM[(int[2] *)_163][_287], *_167
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	%edx, %ecx	# tmp359, tmp394
	subl	%r12d, %ecx	# _287, tmp394
# quickosimd.h:54:       array[j] = x[1 - c];
	movslq	%ecx, %rcx	# tmp394, tmp396
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	16(%rsp,%rcx,4), %ecx	# MEM[(int[2] *)_163][_177], MEM[(int[2] *)_163][_177]
	vmovd	%xmm0, %r12d	# tmp398, _289
	movl	%ecx, -20(%rax)	# MEM[(int[2] *)_163][_177], MEM[base: _502, offset: 12B]
# quickosimd.h:51:       x[0] = array[i];
	movslq	%r10d, %rcx	# i, i
	leaq	(%rdi,%rcx,4), %rcx	#, _191
# quickosimd.h:51:       x[0] = array[i];
	vmovd	(%rcx), %xmm6	# *_191, tmp581
# quickosimd.h:53:       array[i] = x[c];
	movslq	%r12d, %r13	# _289, _289
# quickosimd.h:51:       x[0] = array[i];
	vpinsrd	$1, -16(%rax), %xmm6, %xmm1	# MEM[base: _502, offset: 16B], tmp581, tmp401
# quickosimd.h:55:       i += c;
	addl	%r12d, %r10d	# _289, i
# quickosimd.h:51:       x[0] = array[i];
	vmovq	%xmm1, 16(%rsp)	# tmp401, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:53:       array[i] = x[c];
	movl	16(%rsp,%r13,4), %r13d	# MEM[(int[2] *)_163][_289], MEM[(int[2] *)_163][_289]
	movl	%r13d, (%rcx)	# MEM[(int[2] *)_163][_289], *_191
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	%edx, %ecx	# tmp359, tmp406
	subl	%r12d, %ecx	# _289, tmp406
# quickosimd.h:54:       array[j] = x[1 - c];
	movslq	%ecx, %rcx	# tmp406, tmp408
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	16(%rsp,%rcx,4), %ecx	# MEM[(int[2] *)_163][_201], MEM[(int[2] *)_163][_201]
	vpextrd	$1, %xmm0, %r12d	#, tmp398, _291
	movl	%ecx, -16(%rax)	# MEM[(int[2] *)_163][_201], MEM[base: _502, offset: 16B]
# quickosimd.h:51:       x[0] = array[i];
	movslq	%r10d, %rcx	# i, i
	leaq	(%rdi,%rcx,4), %rcx	#, _215
# quickosimd.h:51:       x[0] = array[i];
	vmovd	(%rcx), %xmm7	# *_215, tmp583
# quickosimd.h:53:       array[i] = x[c];
	movslq	%r12d, %r13	# _291, _291
# quickosimd.h:51:       x[0] = array[i];
	vpinsrd	$1, -12(%rax), %xmm7, %xmm1	# MEM[base: _502, offset: 20B], tmp583, tmp413
# quickosimd.h:55:       i += c;
	addl	%r12d, %r10d	# _291, i
# quickosimd.h:51:       x[0] = array[i];
	vmovq	%xmm1, 16(%rsp)	# tmp413, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:53:       array[i] = x[c];
	movl	16(%rsp,%r13,4), %r13d	# MEM[(int[2] *)_163][_291], MEM[(int[2] *)_163][_291]
	movl	%r13d, (%rcx)	# MEM[(int[2] *)_163][_291], *_215
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	%edx, %ecx	# tmp359, tmp418
	subl	%r12d, %ecx	# _291, tmp418
# quickosimd.h:54:       array[j] = x[1 - c];
	movslq	%ecx, %rcx	# tmp418, tmp420
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	16(%rsp,%rcx,4), %ecx	# MEM[(int[2] *)_163][_225], MEM[(int[2] *)_163][_225]
	vpextrd	$2, %xmm0, %r12d	#, tmp398, _293
	movl	%ecx, -12(%rax)	# MEM[(int[2] *)_163][_225], MEM[base: _502, offset: 20B]
# quickosimd.h:51:       x[0] = array[i];
	movslq	%r10d, %rcx	# i, i
	leaq	(%rdi,%rcx,4), %rcx	#, _239
# quickosimd.h:51:       x[0] = array[i];
	vmovd	(%rcx), %xmm5	# *_239, tmp585
# quickosimd.h:53:       array[i] = x[c];
	movslq	%r12d, %r13	# _293, _293
# quickosimd.h:51:       x[0] = array[i];
	vpinsrd	$1, -8(%rax), %xmm5, %xmm1	# MEM[base: _502, offset: 24B], tmp585, tmp425
# quickosimd.h:55:       i += c;
	addl	%r12d, %r10d	# _293, i
# quickosimd.h:51:       x[0] = array[i];
	vmovq	%xmm1, 16(%rsp)	# tmp425, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:53:       array[i] = x[c];
	movl	16(%rsp,%r13,4), %r13d	# MEM[(int[2] *)_163][_293], MEM[(int[2] *)_163][_293]
	movl	%r13d, (%rcx)	# MEM[(int[2] *)_163][_293], *_239
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	%edx, %ecx	# tmp359, tmp430
	subl	%r12d, %ecx	# _293, tmp430
# quickosimd.h:54:       array[j] = x[1 - c];
	movslq	%ecx, %rcx	# tmp430, tmp432
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	16(%rsp,%rcx,4), %ecx	# MEM[(int[2] *)_163][_249], MEM[(int[2] *)_163][_249]
	vpextrd	$3, %xmm0, %r12d	#, tmp398, _295
	movl	%ecx, -8(%rax)	# MEM[(int[2] *)_163][_249], MEM[base: _502, offset: 24B]
# quickosimd.h:51:       x[0] = array[i];
	movslq	%r10d, %rcx	# i, i
	leaq	(%rdi,%rcx,4), %rcx	#, _263
# quickosimd.h:51:       x[0] = array[i];
	vmovd	(%rcx), %xmm6	# *_263, tmp587
# quickosimd.h:53:       array[i] = x[c];
	movslq	%r12d, %r13	# _295, _295
# quickosimd.h:51:       x[0] = array[i];
	vpinsrd	$1, -4(%rax), %xmm6, %xmm0	# MEM[base: _502, offset: 28B], tmp587, tmp437
# quickosimd.h:55:       i += c;
	addl	%r12d, %r10d	# _295, <retval>
# quickosimd.h:51:       x[0] = array[i];
	vmovq	%xmm0, 16(%rsp)	# tmp437, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:53:       array[i] = x[c];
	movl	16(%rsp,%r13,4), %r13d	# MEM[(int[2] *)_163][_295], tmp588
	movl	%r13d, (%rcx)	# tmp588, *_263
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	%edx, %ecx	# tmp359, tmp442
	subl	%r12d, %ecx	# _295, tmp442
# quickosimd.h:54:       array[j] = x[1 - c];
	movslq	%ecx, %rcx	# tmp442, tmp444
# quickosimd.h:54:       array[j] = x[1 - c];
	movl	16(%rsp,%rcx,4), %ecx	# MEM[(int[2] *)_163][_273], MEM[(int[2] *)_163][_273]
	movl	%ecx, -4(%rax)	# MEM[(int[2] *)_163][_273], MEM[base: _502, offset: 28B]
# quickosimd.h:32:   for (; j < high - 7;) {
	cmpq	%rax, %r8	# ivtmp.1799, _469
	jne	.L1240	#,
# quickosimd.h:56:       j++;
	leal	8(%r11,%r9,8), %r11d	#, low
.L1239:
# quickosimd.h:59:   for (; j < high; j++) {
	cmpl	%ebx, %r11d	# high, low
	jge	.L1241	#,
# quickosimd.h:60:     int c = pivot > array[j];
	movslq	%r11d, %rax	# low, low
	leaq	(%rdi,%rax,4), %r8	#, _308
	movl	(%r8), %eax	# *_308, _307
# quickosimd.h:70:     x[0] = array[i];
	movslq	%r10d, %rdx	# <retval>, <retval>
# quickosimd.h:70:     x[0] = array[i];
	vmovd	(%rdi,%rdx,4), %xmm4	# *_302, tmp590
# quickosimd.h:60:     int c = pivot > array[j];
	xorl	%ecx, %ecx	# tmp450
	cmpl	%eax, %esi	# _307, pivot
# quickosimd.h:70:     x[0] = array[i];
	vpinsrd	$1, %eax, %xmm4, %xmm0	# _307, tmp590, tmp454
# quickosimd.h:72:     array[i] = x[c];
	setg	%al	#, c
# quickosimd.h:70:     x[0] = array[i];
	vmovq	%xmm0, 16(%rsp)	# tmp454, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:72:     array[i] = x[c];
	movzbl	%al, %eax	# c, c
# quickosimd.h:72:     array[i] = x[c];
	movl	16(%rsp,%rax,4), %eax	# MEM[(int[2] *)_163][c_305], MEM[(int[2] *)_163][c_305]
# quickosimd.h:60:     int c = pivot > array[j];
	setg	%cl	#, tmp450
# quickosimd.h:72:     array[i] = x[c];
	movl	%eax, (%rdi,%rdx,4)	# MEM[(int[2] *)_163][c_305], *_302
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	$1, %eax	#, tmp459
	movl	%eax, %edx	# tmp459, tmp458
	subl	%ecx, %edx	# tmp450, tmp458
# quickosimd.h:73:     array[j] = x[1 - c];
	movslq	%edx, %rdx	# tmp458, tmp460
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][_296], MEM[(int[2] *)_163][_296]
# quickosimd.h:74:     i += c;
	addl	%ecx, %r10d	# tmp450, <retval>
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%edx, (%r8)	# MEM[(int[2] *)_163][_296], *_308
# quickosimd.h:59:   for (; j < high; j++) {
	leal	1(%r11), %edx	#, j
# quickosimd.h:59:   for (; j < high; j++) {
	cmpl	%edx, %ebx	# j, high
	jle	.L1241	#,
# quickosimd.h:60:     int c = pivot > array[j];
	movslq	%edx, %rdx	# j, j
	leaq	(%rdi,%rdx,4), %r8	#, _258
	movl	(%r8), %edx	# *_258, _257
# quickosimd.h:70:     x[0] = array[i];
	movslq	%r10d, %r9	# <retval>, <retval>
# quickosimd.h:70:     x[0] = array[i];
	vmovd	(%rdi,%r9,4), %xmm3	# *_234, tmp592
# quickosimd.h:60:     int c = pivot > array[j];
	xorl	%ecx, %ecx	# tmp464
	cmpl	%edx, %esi	# _257, pivot
# quickosimd.h:70:     x[0] = array[i];
	vpinsrd	$1, %edx, %xmm3, %xmm0	# _257, tmp592, tmp468
# quickosimd.h:72:     array[i] = x[c];
	setg	%dl	#, c
# quickosimd.h:70:     x[0] = array[i];
	vmovq	%xmm0, 16(%rsp)	# tmp468, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:72:     array[i] = x[c];
	movzbl	%dl, %edx	# c, c
# quickosimd.h:72:     array[i] = x[c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][c_255], MEM[(int[2] *)_163][c_255]
# quickosimd.h:60:     int c = pivot > array[j];
	setg	%cl	#, tmp464
# quickosimd.h:72:     array[i] = x[c];
	movl	%edx, (%rdi,%r9,4)	# MEM[(int[2] *)_163][c_255], *_234
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%eax, %edx	# tmp459, tmp472
	subl	%ecx, %edx	# tmp464, tmp472
# quickosimd.h:73:     array[j] = x[1 - c];
	movslq	%edx, %rdx	# tmp472, tmp474
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][_209], MEM[(int[2] *)_163][_209]
# quickosimd.h:74:     i += c;
	addl	%ecx, %r10d	# tmp464, <retval>
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%edx, (%r8)	# MEM[(int[2] *)_163][_209], *_258
# quickosimd.h:59:   for (; j < high; j++) {
	leal	2(%r11), %edx	#, j
# quickosimd.h:59:   for (; j < high; j++) {
	cmpl	%edx, %ebx	# j, high
	jle	.L1241	#,
# quickosimd.h:60:     int c = pivot > array[j];
	movslq	%edx, %rdx	# j, j
	leaq	(%rdi,%rdx,4), %r8	#, _161
	movl	(%r8), %edx	# *_161, _160
# quickosimd.h:70:     x[0] = array[i];
	movslq	%r10d, %r9	# <retval>, <retval>
# quickosimd.h:70:     x[0] = array[i];
	vmovd	(%rdi,%r9,4), %xmm3	# *_136, tmp594
# quickosimd.h:60:     int c = pivot > array[j];
	xorl	%ecx, %ecx	# tmp478
	cmpl	%edx, %esi	# _160, pivot
# quickosimd.h:70:     x[0] = array[i];
	vpinsrd	$1, %edx, %xmm3, %xmm0	# _160, tmp594, tmp482
# quickosimd.h:72:     array[i] = x[c];
	setg	%dl	#, c
# quickosimd.h:70:     x[0] = array[i];
	vmovq	%xmm0, 16(%rsp)	# tmp482, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:72:     array[i] = x[c];
	movzbl	%dl, %edx	# c, c
# quickosimd.h:72:     array[i] = x[c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][c_140], MEM[(int[2] *)_163][c_140]
# quickosimd.h:60:     int c = pivot > array[j];
	setg	%cl	#, tmp478
# quickosimd.h:72:     array[i] = x[c];
	movl	%edx, (%rdi,%r9,4)	# MEM[(int[2] *)_163][c_140], *_136
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%eax, %edx	# tmp459, tmp486
	subl	%ecx, %edx	# tmp478, tmp486
# quickosimd.h:73:     array[j] = x[1 - c];
	movslq	%edx, %rdx	# tmp486, tmp488
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][_111], MEM[(int[2] *)_163][_111]
# quickosimd.h:74:     i += c;
	addl	%ecx, %r10d	# tmp478, <retval>
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%edx, (%r8)	# MEM[(int[2] *)_163][_111], *_161
# quickosimd.h:59:   for (; j < high; j++) {
	leal	3(%r11), %edx	#, j
# quickosimd.h:59:   for (; j < high; j++) {
	cmpl	%edx, %ebx	# j, high
	jle	.L1241	#,
# quickosimd.h:60:     int c = pivot > array[j];
	movslq	%edx, %rdx	# j, j
	leaq	(%rdi,%rdx,4), %r8	#, _74
	movl	(%r8), %edx	# *_74, _73
# quickosimd.h:70:     x[0] = array[i];
	movslq	%r10d, %r9	# <retval>, <retval>
# quickosimd.h:70:     x[0] = array[i];
	vmovd	(%rdi,%r9,4), %xmm4	# *_48, tmp596
# quickosimd.h:60:     int c = pivot > array[j];
	xorl	%ecx, %ecx	# tmp492
	cmpl	%edx, %esi	# _73, pivot
# quickosimd.h:70:     x[0] = array[i];
	vpinsrd	$1, %edx, %xmm4, %xmm0	# _73, tmp596, tmp496
# quickosimd.h:72:     array[i] = x[c];
	setg	%dl	#, c
# quickosimd.h:70:     x[0] = array[i];
	vmovq	%xmm0, 16(%rsp)	# tmp496, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:72:     array[i] = x[c];
	movzbl	%dl, %edx	# c, c
# quickosimd.h:72:     array[i] = x[c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][c_69], MEM[(int[2] *)_163][c_69]
# quickosimd.h:60:     int c = pivot > array[j];
	setg	%cl	#, tmp492
# quickosimd.h:72:     array[i] = x[c];
	movl	%edx, (%rdi,%r9,4)	# MEM[(int[2] *)_163][c_69], *_48
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%eax, %edx	# tmp459, tmp500
	subl	%ecx, %edx	# tmp492, tmp500
# quickosimd.h:73:     array[j] = x[1 - c];
	movslq	%edx, %rdx	# tmp500, tmp502
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][_40], MEM[(int[2] *)_163][_40]
# quickosimd.h:74:     i += c;
	addl	%ecx, %r10d	# tmp492, <retval>
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%edx, (%r8)	# MEM[(int[2] *)_163][_40], *_74
# quickosimd.h:59:   for (; j < high; j++) {
	leal	4(%r11), %edx	#, j
# quickosimd.h:59:   for (; j < high; j++) {
	cmpl	%ebx, %edx	# high, j
	jge	.L1241	#,
# quickosimd.h:60:     int c = pivot > array[j];
	movslq	%edx, %rdx	# j, j
	leaq	(%rdi,%rdx,4), %r8	#, _7
	movl	(%r8), %edx	# *_7, _6
# quickosimd.h:70:     x[0] = array[i];
	movslq	%r10d, %r9	# <retval>, <retval>
# quickosimd.h:70:     x[0] = array[i];
	vmovd	(%rdi,%r9,4), %xmm3	# *_329, tmp598
# quickosimd.h:60:     int c = pivot > array[j];
	xorl	%ecx, %ecx	# tmp506
	cmpl	%esi, %edx	# pivot, _6
# quickosimd.h:70:     x[0] = array[i];
	vpinsrd	$1, %edx, %xmm3, %xmm0	# _6, tmp598, tmp510
# quickosimd.h:72:     array[i] = x[c];
	setl	%dl	#, c
# quickosimd.h:70:     x[0] = array[i];
	vmovq	%xmm0, 16(%rsp)	# tmp510, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:72:     array[i] = x[c];
	movzbl	%dl, %edx	# c, c
# quickosimd.h:72:     array[i] = x[c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][c_326], MEM[(int[2] *)_163][c_326]
# quickosimd.h:60:     int c = pivot > array[j];
	setl	%cl	#, tmp506
# quickosimd.h:72:     array[i] = x[c];
	movl	%edx, (%rdi,%r9,4)	# MEM[(int[2] *)_163][c_326], *_329
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%eax, %edx	# tmp459, tmp514
	subl	%ecx, %edx	# tmp506, tmp514
# quickosimd.h:73:     array[j] = x[1 - c];
	movslq	%edx, %rdx	# tmp514, tmp516
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][_335], MEM[(int[2] *)_163][_335]
# quickosimd.h:74:     i += c;
	addl	%ecx, %r10d	# tmp506, <retval>
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%edx, (%r8)	# MEM[(int[2] *)_163][_335], *_7
# quickosimd.h:59:   for (; j < high; j++) {
	leal	5(%r11), %edx	#, j
# quickosimd.h:59:   for (; j < high; j++) {
	cmpl	%edx, %ebx	# j, high
	jle	.L1241	#,
# quickosimd.h:60:     int c = pivot > array[j];
	movslq	%edx, %rdx	# j, j
	leaq	(%rdi,%rdx,4), %r8	#, _346
	movl	(%r8), %edx	# *_346, _347
# quickosimd.h:70:     x[0] = array[i];
	movslq	%r10d, %r9	# <retval>, <retval>
# quickosimd.h:70:     x[0] = array[i];
	vmovd	(%rdi,%r9,4), %xmm4	# *_352, tmp600
# quickosimd.h:60:     int c = pivot > array[j];
	xorl	%ecx, %ecx	# tmp520
	cmpl	%edx, %esi	# _347, pivot
# quickosimd.h:70:     x[0] = array[i];
	vpinsrd	$1, %edx, %xmm4, %xmm0	# _347, tmp600, tmp524
# quickosimd.h:72:     array[i] = x[c];
	setg	%dl	#, c
# quickosimd.h:70:     x[0] = array[i];
	vmovq	%xmm0, 16(%rsp)	# tmp524, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:72:     array[i] = x[c];
	movzbl	%dl, %edx	# c, c
# quickosimd.h:72:     array[i] = x[c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][c_349], MEM[(int[2] *)_163][c_349]
# quickosimd.h:60:     int c = pivot > array[j];
	setg	%cl	#, tmp520
# quickosimd.h:72:     array[i] = x[c];
	movl	%edx, (%rdi,%r9,4)	# MEM[(int[2] *)_163][c_349], *_352
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%eax, %edx	# tmp459, tmp528
	subl	%ecx, %edx	# tmp520, tmp528
# quickosimd.h:73:     array[j] = x[1 - c];
	movslq	%edx, %rdx	# tmp528, tmp530
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][_358], MEM[(int[2] *)_163][_358]
# quickosimd.h:74:     i += c;
	addl	%ecx, %r10d	# tmp520, <retval>
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%edx, (%r8)	# MEM[(int[2] *)_163][_358], *_346
# quickosimd.h:59:   for (; j < high; j++) {
	leal	6(%r11), %edx	#, j
# quickosimd.h:59:   for (; j < high; j++) {
	cmpl	%edx, %ebx	# j, high
	jle	.L1241	#,
# quickosimd.h:60:     int c = pivot > array[j];
	movslq	%edx, %rdx	# j, j
	leaq	(%rdi,%rdx,4), %r8	#, _369
	movl	(%r8), %edx	# *_369, _370
# quickosimd.h:70:     x[0] = array[i];
	movslq	%r10d, %r9	# <retval>, <retval>
# quickosimd.h:70:     x[0] = array[i];
	vmovd	(%rdi,%r9,4), %xmm4	# *_375, tmp602
# quickosimd.h:60:     int c = pivot > array[j];
	xorl	%ecx, %ecx	# tmp534
	cmpl	%edx, %esi	# _370, pivot
# quickosimd.h:70:     x[0] = array[i];
	vpinsrd	$1, %edx, %xmm4, %xmm0	# _370, tmp602, tmp538
# quickosimd.h:72:     array[i] = x[c];
	setg	%dl	#, c
# quickosimd.h:70:     x[0] = array[i];
	vmovq	%xmm0, 16(%rsp)	# tmp538, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:72:     array[i] = x[c];
	movzbl	%dl, %edx	# c, c
# quickosimd.h:72:     array[i] = x[c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][c_372], MEM[(int[2] *)_163][c_372]
# quickosimd.h:60:     int c = pivot > array[j];
	setg	%cl	#, tmp534
# quickosimd.h:72:     array[i] = x[c];
	movl	%edx, (%rdi,%r9,4)	# MEM[(int[2] *)_163][c_372], *_375
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%eax, %edx	# tmp459, tmp542
	subl	%ecx, %edx	# tmp534, tmp542
# quickosimd.h:73:     array[j] = x[1 - c];
	movslq	%edx, %rdx	# tmp542, tmp544
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][_381], MEM[(int[2] *)_163][_381]
# quickosimd.h:59:   for (; j < high; j++) {
	addl	$7, %r11d	#, j
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%edx, (%r8)	# MEM[(int[2] *)_163][_381], *_369
# quickosimd.h:74:     i += c;
	addl	%ecx, %r10d	# tmp534, <retval>
# quickosimd.h:59:   for (; j < high; j++) {
	cmpl	%r11d, %ebx	# j, high
	jle	.L1241	#,
# quickosimd.h:60:     int c = pivot > array[j];
	movslq	%r11d, %r11	# j, j
	leaq	(%rdi,%r11,4), %r8	#, _20
	movl	(%r8), %edx	# *_20, _21
# quickosimd.h:60:     int c = pivot > array[j];
	xorl	%ecx, %ecx	# tmp548
	cmpl	%esi, %edx	# pivot, _21
# quickosimd.h:70:     x[0] = array[i];
	movslq	%r10d, %rsi	# <retval>, <retval>
# quickosimd.h:70:     x[0] = array[i];
	vmovd	(%rdi,%rsi,4), %xmm3	# *_25, tmp604
# quickosimd.h:60:     int c = pivot > array[j];
	setl	%cl	#, tmp548
# quickosimd.h:70:     x[0] = array[i];
	vpinsrd	$1, %edx, %xmm3, %xmm0	# _21, tmp604, tmp552
# quickosimd.h:72:     array[i] = x[c];
	setl	%dl	#, c
# quickosimd.h:73:     array[j] = x[1 - c];
	subl	%ecx, %eax	# tmp548, tmp556
# quickosimd.h:70:     x[0] = array[i];
	vmovq	%xmm0, 16(%rsp)	# tmp552, MEM <vector(2) int> [(int *)_163]
# quickosimd.h:72:     array[i] = x[c];
	movzbl	%dl, %edx	# c, c
# quickosimd.h:73:     array[j] = x[1 - c];
	cltq
# quickosimd.h:72:     array[i] = x[c];
	movl	16(%rsp,%rdx,4), %edx	# MEM[(int[2] *)_163][c_58], MEM[(int[2] *)_163][c_58]
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	16(%rsp,%rax,4), %eax	# MEM[(int[2] *)_163][_30], MEM[(int[2] *)_163][_30]
# quickosimd.h:72:     array[i] = x[c];
	movl	%edx, (%rdi,%rsi,4)	# MEM[(int[2] *)_163][c_58], *_25
# quickosimd.h:73:     array[j] = x[1 - c];
	movl	%eax, (%r8)	# MEM[(int[2] *)_163][_30], *_20
# quickosimd.h:74:     i += c;
	addl	%ecx, %r10d	# tmp548, <retval>
.L1241:
# quickosimd.h:76:   swap(&array[i], &array[high]);
	movslq	%r10d, %rdx	# <retval>, <retval>
# quickosimd.h:76:   swap(&array[i], &array[high]);
	leaq	(%rdi,%rbx,4), %rax	#, _34
	leaq	(%rdi,%rdx,4), %rdx	#, _37
# swap.h:2:   int t = *a;
	movl	(%rdx), %ecx	# *_37, t
# swap.h:3:   *a = *b;
	movl	(%rax), %esi	# *_34, _86
# swap.h:3:   *a = *b;
	movl	%esi, (%rdx)	# _86, *_37
# swap.h:4:   *b = t;
	movl	%ecx, (%rax)	# t, *_34
	vzeroupper
.L1236:
# quickosimd.h:78: }
	movq	24(%rsp), %rax	# D.41400, tmp571
	subq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], tmp571
	jne	.L1248	#,
	leaq	-24(%rbp), %rsp	#,
	popq	%rbx	#
	popq	%r12	#
	popq	%r13	#
	movl	%r10d, %eax	# <retval>,
	popq	%rbp	#
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret	
.L1247:
	.cfi_restore_state
# quickosimd.h:27:     return (low + high) / 2;
	addl	%ebx, %r11d	# high, tmp332
# quickosimd.h:27:     return (low + high) / 2;
	movl	%r11d, %r10d	# tmp332, tmp333
	shrl	$31, %r10d	#, tmp333
	addl	%r11d, %r10d	# tmp332, tmp334
	sarl	%r10d	# <retval>
	jmp	.L1236	#
.L1244:
# quickosimd.h:32:   for (; j < high - 7;) {
	movl	%r11d, %r10d	# low, <retval>
	jmp	.L1239	#
.L1248:
# quickosimd.h:78: }
	call	__stack_chk_fail@PLT	#
	.cfi_endproc
.LFE5418:
	.size	partition_quick_simd, .-partition_quick_simd
	.p2align 4
	.globl	sort_quick_simd
	.type	sort_quick_simd, @function
sort_quick_simd:
.LFB5419:
	.cfi_startproc
	endbr64	
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$72, %rsp	#,
	.cfi_def_cfa_offset 128
# quickosimd.h:80: void sort_quick_simd(int array[], int low, int high) {
	movl	%edx, 32(%rsp)	# high, %sfp
# quickosimd.h:82:   if (low < high) {
	cmpl	%esi, %edx	# low, high
	jle	.L1277	#,
	movl	%esi, %r13d	# tmp105, low
	movq	%rdi, %r14	# array, array
.L1267:
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	32(%rsp), %edx	# %sfp,
	movl	%r13d, %esi	# low,
	movq	%r14, %rdi	# array,
	call	partition_quick_simd	#
	movl	%eax, 36(%rsp)	# pi, %sfp
# quickosimd.h:85:     sort_quick_simd(array, low, pi - 1);
	decl	%eax	# _1
	movl	%eax, 20(%rsp)	# _1, %sfp
# quickosimd.h:82:   if (low < high) {
	cmpl	%r13d, %eax	# low, _1
	jle	.L1251	#,
.L1266:
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	20(%rsp), %edx	# %sfp,
	movl	%r13d, %esi	# low,
	movq	%r14, %rdi	# array,
	call	partition_quick_simd	#
	movl	%eax, 40(%rsp)	# pi, %sfp
# quickosimd.h:85:     sort_quick_simd(array, low, pi - 1);
	decl	%eax	# _15
	movl	%eax, 24(%rsp)	# _15, %sfp
# quickosimd.h:82:   if (low < high) {
	cmpl	%r13d, %eax	# low, _15
	jle	.L1252	#,
.L1265:
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	24(%rsp), %edx	# %sfp,
	movl	%r13d, %esi	# low,
	movq	%r14, %rdi	# array,
	call	partition_quick_simd	#
	movl	%eax, 44(%rsp)	# pi, %sfp
# quickosimd.h:85:     sort_quick_simd(array, low, pi - 1);
	decl	%eax	# _19
	movl	%eax, 28(%rsp)	# _19, %sfp
# quickosimd.h:82:   if (low < high) {
	cmpl	%r13d, %eax	# low, _19
	jle	.L1253	#,
	movl	%r13d, %r12d	# low, low
	movq	%r14, %r13	# array, array
.L1264:
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	28(%rsp), %edx	# %sfp,
	movl	%r12d, %esi	# low,
	movq	%r13, %rdi	# array,
	call	partition_quick_simd	#
# quickosimd.h:85:     sort_quick_simd(array, low, pi - 1);
	leal	-1(%rax), %r15d	#, _23
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	%eax, 48(%rsp)	# pi, %sfp
# quickosimd.h:82:   if (low < high) {
	cmpl	%r12d, %r15d	# low, _23
	jle	.L1254	#,
.L1263:
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	%r15d, %edx	# _23,
	movl	%r12d, %esi	# low,
	movq	%r13, %rdi	# array,
	call	partition_quick_simd	#
# quickosimd.h:85:     sort_quick_simd(array, low, pi - 1);
	leal	-1(%rax), %r14d	#, _27
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	%eax, %ebx	# tmp111, pi
# quickosimd.h:82:   if (low < high) {
	cmpl	%r12d, %r14d	# low, _27
	jle	.L1255	#,
.L1262:
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	%r14d, %edx	# _27,
	movl	%r12d, %esi	# low,
	movq	%r13, %rdi	# array,
	call	partition_quick_simd	#
	movl	%eax, 12(%rsp)	# pi, %sfp
# quickosimd.h:85:     sort_quick_simd(array, low, pi - 1);
	decl	%eax	# _31
	movl	%eax, 16(%rsp)	# _31, %sfp
# quickosimd.h:82:   if (low < high) {
	cmpl	%r12d, %eax	# low, _31
	jle	.L1256	#,
	movl	%ebx, 8(%rsp)	# pi, %sfp
	movq	%r13, %rbx	# array, array
.L1261:
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	16(%rsp), %edx	# %sfp,
	movl	%r12d, %esi	# low,
	movq	%rbx, %rdi	# array,
	call	partition_quick_simd	#
# quickosimd.h:85:     sort_quick_simd(array, low, pi - 1);
	leal	-1(%rax), %ebp	#, _35
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	%eax, 52(%rsp)	# pi, %sfp
# quickosimd.h:82:   if (low < high) {
	cmpl	%r12d, %ebp	# low, _35
	jle	.L1257	#,
	movl	%ebp, %r13d	# _35, _35
.L1260:
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	%r13d, %edx	# _35,
	movl	%r12d, %esi	# low,
	movq	%rbx, %rdi	# array,
	call	partition_quick_simd	#
# quickosimd.h:85:     sort_quick_simd(array, low, pi - 1);
	leal	-1(%rax), %ecx	#, _39
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	%eax, %ebp	# tmp114, pi
# quickosimd.h:82:   if (low < high) {
	cmpl	%r12d, %ecx	# low, _39
	jle	.L1258	#,
	movl	%r12d, %esi	# low, low
.L1259:
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	%ecx, %edx	# _39,
	movq	%rbx, %rdi	# array,
	movl	%ecx, 60(%rsp)	# _39, %sfp
	movl	%esi, 56(%rsp)	# low, %sfp
	call	partition_quick_simd	#
# quickosimd.h:85:     sort_quick_simd(array, low, pi - 1);
	movl	56(%rsp), %esi	# %sfp, low
	leal	-1(%rax), %edx	#, tmp103
	movq	%rbx, %rdi	# array,
# quickosimd.h:83:     int pi = partition_quick_simd(array, low, high);
	movl	%eax, %r12d	# tmp115, pi
# quickosimd.h:85:     sort_quick_simd(array, low, pi - 1);
	call	sort_quick_simd	#
# quickosimd.h:82:   if (low < high) {
	movl	60(%rsp), %ecx	# %sfp, _39
# quickosimd.h:86:     sort_quick_simd(array, pi + 1, high);
	leal	1(%r12), %esi	#, low
# quickosimd.h:82:   if (low < high) {
	cmpl	%esi, %ecx	# low, _39
	jg	.L1259	#,
.L1258:
# quickosimd.h:86:     sort_quick_simd(array, pi + 1, high);
	leal	1(%rbp), %r12d	#, low
# quickosimd.h:82:   if (low < high) {
	cmpl	%r12d, %r13d	# low, _35
	jg	.L1260	#,
.L1257:
# quickosimd.h:86:     sort_quick_simd(array, pi + 1, high);
	movl	52(%rsp), %r12d	# %sfp, pi
	incl	%r12d	# pi
# quickosimd.h:82:   if (low < high) {
	cmpl	%r12d, 16(%rsp)	# low, %sfp
	jg	.L1261	#,
	movq	%rbx, %r13	# array, array
	movl	8(%rsp), %ebx	# %sfp, pi
.L1256:
# quickosimd.h:86:     sort_quick_simd(array, pi + 1, high);
	movl	12(%rsp), %r12d	# %sfp, pi
	incl	%r12d	# pi
# quickosimd.h:82:   if (low < high) {
	cmpl	%r12d, %r14d	# low, _27
	jg	.L1262	#,
.L1255:
# quickosimd.h:86:     sort_quick_simd(array, pi + 1, high);
	leal	1(%rbx), %r12d	#, low
# quickosimd.h:82:   if (low < high) {
	cmpl	%r12d, %r15d	# low, _23
	jg	.L1263	#,
.L1254:
# quickosimd.h:86:     sort_quick_simd(array, pi + 1, high);
	movl	48(%rsp), %r12d	# %sfp, pi
	incl	%r12d	# pi
# quickosimd.h:82:   if (low < high) {
	cmpl	%r12d, 28(%rsp)	# low, %sfp
	jg	.L1264	#,
	movq	%r13, %r14	# array, array
.L1253:
# quickosimd.h:86:     sort_quick_simd(array, pi + 1, high);
	movl	44(%rsp), %r13d	# %sfp, pi
	incl	%r13d	# pi
# quickosimd.h:82:   if (low < high) {
	cmpl	%r13d, 24(%rsp)	# low, %sfp
	jg	.L1265	#,
.L1252:
# quickosimd.h:86:     sort_quick_simd(array, pi + 1, high);
	movl	40(%rsp), %r13d	# %sfp, pi
	incl	%r13d	# pi
# quickosimd.h:82:   if (low < high) {
	cmpl	%r13d, 20(%rsp)	# low, %sfp
	jg	.L1266	#,
.L1251:
# quickosimd.h:86:     sort_quick_simd(array, pi + 1, high);
	movl	36(%rsp), %r13d	# %sfp, pi
	incl	%r13d	# pi
# quickosimd.h:82:   if (low < high) {
	cmpl	32(%rsp), %r13d	# %sfp, low
	jl	.L1267	#,
.L1277:
# quickosimd.h:88: }
	addq	$72, %rsp	#,
	.cfi_def_cfa_offset 56
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE5419:
	.size	sort_quick_simd, .-sort_quick_simd
	.p2align 4
	.globl	partition_quick_optimized_simple
	.type	partition_quick_optimized_simple, @function
partition_quick_optimized_simple:
.LFB5420:
	.cfi_startproc
	endbr64	
	pushq	%r12	#
	.cfi_def_cfa_offset 16
	.cfi_offset 12, -16
	movl	%esi, %r12d	# tmp131, low
	pushq	%rbp	#
	.cfi_def_cfa_offset 24
	.cfi_offset 6, -24
	movslq	%edx, %rbp	# tmp132,
# quickosimple.h:14:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%ebp, %edx	# high,
# quickosimple.h:13: int partition_quick_optimized_simple(int array[], int low, int high) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 32
	.cfi_offset 3, -32
# quickosimple.h:13: int partition_quick_optimized_simple(int array[], int low, int high) {
	movq	%rdi, %rbx	# tmp130, array
# quickosimple.h:14:   int pivot = median_of_three_of_median_of_three(array, low, high);
	call	median_of_three_of_median_of_three	#
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	cmpl	%ebp, %r12d	# high, low
	jge	.L1285	#,
	leal	-1(%rbp), %edx	#, tmp116
	movslq	%r12d, %rsi	# low, _43
	subl	%r12d, %edx	# low, tmp118
	addq	%rsi, %rdx	# _43, tmp119
	movl	%eax, %r9d	# tmp133, pivot
	leaq	4(%rbx,%rdx,4), %r10	#, _30
	leaq	(%rbx,%rsi,4), %rax	#, ivtmp.1823
	.p2align 4,,10
	.p2align 3
.L1281:
# quickosimple.h:17:     int c = pivot > array[j];
	movl	(%rax), %ecx	# MEM[base: _2, offset: 0B], _48
# quickosimple.h:18:     int y = array[i];
	leaq	(%rbx,%rsi,4), %rdx	#, _40
# quickosimple.h:18:     int y = array[i];
	movl	(%rdx), %edi	# *_40, y
# quickosimple.h:20:     array[i] = c ? z : y;
	cmpl	%ecx, %r9d	# _48, pivot
	jg	.L1282	#,
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	addq	$4, %rax	#, ivtmp.1823
	cmpq	%rax, %r10	# ivtmp.1823, _30
	jne	.L1281	#,
.L1280:
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	(%rbx,%rbp,4), %rax	#, _12
	leaq	(%rbx,%rsi,4), %rdx	#, _15
# swap.h:2:   int t = *a;
	movl	(%rdx), %ecx	# *_15, t
# swap.h:3:   *a = *b;
	movl	(%rax), %esi	# *_12, _34
# swap.h:3:   *a = *b;
	movl	%esi, (%rdx)	# _34, *_15
# swap.h:4:   *b = t;
	movl	%ecx, (%rax)	# t, *_12
# quickosimple.h:26: }
	movl	%r12d, %eax	# <retval>,
	popq	%rbx	#
	.cfi_remember_state
	.cfi_def_cfa_offset 24
	popq	%rbp	#
	.cfi_def_cfa_offset 16
	popq	%r12	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1282:
	.cfi_restore_state
	movl	%ecx, (%rdx)	# _48, *_40
# quickosimple.h:22:     i += c;
	incl	%r12d	# <retval>
# quickosimple.h:21:     array[j] = c ? y : z;
	movl	%edi, (%rax)	# y, MEM[base: _2, offset: 0B]
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	addq	$4, %rax	#, ivtmp.1823
	movslq	%r12d, %rsi	# <retval>, <retval>
	cmpq	%rax, %r10	# ivtmp.1823, _30
	jne	.L1281	#,
	jmp	.L1280	#
	.p2align 4,,10
	.p2align 3
.L1285:
	movslq	%r12d, %rsi	# <retval>, <retval>
	jmp	.L1280	#
	.cfi_endproc
.LFE5420:
	.size	partition_quick_optimized_simple, .-partition_quick_optimized_simple
	.p2align 4
	.globl	sort_quick_optimized_simple
	.type	sort_quick_optimized_simple, @function
sort_quick_optimized_simple:
.LFB5421:
	.cfi_startproc
	endbr64	
# quickosimple.h:29:   if (low < high) {
	cmpl	%esi, %edx	# low, high
	jle	.L1385	#,
# quickosimple.h:28: void sort_quick_optimized_simple(int array[], int low, int high) {
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
# quickosimple.h:24:   swap(&array[i], &array[high]);
	movslq	%edx, %rax	# high, high
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	(%rdi,%rax,4), %rax	#, _33
# quickosimple.h:28: void sort_quick_optimized_simple(int array[], int low, int high) {
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
# quickosimple.h:24:   swap(&array[i], &array[high]);
	movl	%edx, %r12d	# high, high
# quickosimple.h:28: void sort_quick_optimized_simple(int array[], int low, int high) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
# quickosimple.h:24:   swap(&array[i], &array[high]);
	movl	%esi, %ebp	# low, low
# quickosimple.h:28: void sort_quick_optimized_simple(int array[], int low, int high) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	movq	%rdi, %rbx	# tmp315, array
	subq	$136, %rsp	#,
	.cfi_def_cfa_offset 192
# quickosimple.h:24:   swap(&array[i], &array[high]);
	movq	%rax, 56(%rsp)	# _33, %sfp
.L1342:
# quickosimple.h:14:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%r12d, %edx	# high,
	movl	%ebp, %esi	# low,
	movq	%rbx, %rdi	# array,
	call	median_of_three_of_median_of_three	#
	movslq	%ebp, %r13	# low, ivtmp.1850
	movl	%eax, %ecx	# tmp318, pivot
	movl	%ebp, %esi	# low, i
	movq	%r13, %rax	# ivtmp.1850, ivtmp.1906
	movq	%r13, %rdx	# ivtmp.1850, i
.L1293:
# quickosimple.h:17:     int c = pivot > array[j];
	movl	(%rbx,%rax,4), %r8d	# MEM[base: array_8(D), index: ivtmp.1906_312, step: 4, offset: 0B], _146
# quickosimple.h:18:     int y = array[i];
	leaq	(%rbx,%rdx,4), %rdi	#, _108
# quickosimple.h:18:     int y = array[i];
	movl	(%rdi), %r9d	# *_108, y
# quickosimple.h:20:     array[i] = c ? z : y;
	cmpl	%r8d, %ecx	# _146, pivot
	jg	.L1290	#,
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1906
	cmpl	%eax, %r12d	# ivtmp.1906, high
	jg	.L1293	#,
	movl	%esi, 16(%rsp)	# i, %sfp
.L1292:
# swap.h:3:   *a = *b;
	movq	56(%rsp), %rdi	# %sfp, _33
# quickosimple.h:24:   swap(&array[i], &array[high]);
	salq	$2, %rdx	#, _36
# swap.h:3:   *a = *b;
	movl	(%rdi), %esi	# *_33, _39
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	(%rbx,%rdx), %rax	#, _37
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# *_37, t
# swap.h:3:   *a = *b;
	movl	%esi, (%rax)	# _39, *_37
# quickosimple.h:31:     if (high - low > 2) {
	movl	%r12d, %eax	# high, tmp262
	subl	%ebp, %eax	# low, tmp262
# swap.h:4:   *b = t;
	movl	%ecx, (%rdi)	# t, *_33
# quickosimple.h:31:     if (high - low > 2) {
	cmpl	$2, %eax	#, tmp262
	jle	.L1383	#,
# quickosimple.h:32:         sort_quick_optimized_simple(array, low, pi - 1);
	movl	16(%rsp), %eax	# %sfp, i
	decl	%eax	# _2
	movl	%eax, (%rsp)	# _2, %sfp
# quickosimple.h:29:   if (low < high) {
	cmpl	%ebp, %eax	# low, _2
	jle	.L1294	#,
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	-4(%rbx,%rdx), %rax	#, _64
	movq	%rax, 64(%rsp)	# _64, %sfp
	movl	%r12d, 40(%rsp)	# high, %sfp
	movq	%rbx, %r14	# array, array
	movq	%r13, %rbx	# ivtmp.1850, ivtmp.1850
.L1341:
# quickosimple.h:14:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	(%rsp), %edx	# %sfp,
	movl	%ebp, %esi	# low,
	movq	%r14, %rdi	# array,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %ecx	# tmp319, pivot
	movl	%ebp, %esi	# low, i
	movq	%rbx, %rax	# ivtmp.1850, ivtmp.1899
	movq	%rbx, %rdx	# ivtmp.1850, i
.L1298:
# quickosimple.h:17:     int c = pivot > array[j];
	movl	(%r14,%rax,4), %r8d	# MEM[base: array_8(D), index: ivtmp.1899_272, step: 4, offset: 0B], _301
# quickosimple.h:18:     int y = array[i];
	leaq	(%r14,%rdx,4), %rdi	#, _294
# quickosimple.h:18:     int y = array[i];
	movl	(%rdi), %r9d	# *_294, y
# quickosimple.h:20:     array[i] = c ? z : y;
	cmpl	%r8d, %ecx	# _301, pivot
	jle	.L1295	#,
.L1389:
	movl	%r8d, (%rdi)	# _301, *_294
# quickosimple.h:21:     array[j] = c ? y : z;
	movl	%r9d, (%r14,%rax,4)	# y, MEM[base: array_8(D), index: ivtmp.1899_272, step: 4, offset: 0B]
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1899
# quickosimple.h:22:     i += c;
	incl	%esi	# i
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	cmpl	%eax, (%rsp)	# ivtmp.1899, %sfp
	jle	.L1388	#,
	movslq	%esi, %rdx	# i, i
# quickosimple.h:17:     int c = pivot > array[j];
	movl	(%r14,%rax,4), %r8d	# MEM[base: array_8(D), index: ivtmp.1899_272, step: 4, offset: 0B], _301
# quickosimple.h:18:     int y = array[i];
	leaq	(%r14,%rdx,4), %rdi	#, _294
# quickosimple.h:18:     int y = array[i];
	movl	(%rdi), %r9d	# *_294, y
# quickosimple.h:20:     array[i] = c ? z : y;
	cmpl	%r8d, %ecx	# _301, pivot
	jg	.L1389	#,
.L1295:
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1899
	cmpl	%eax, (%rsp)	# ivtmp.1899, %sfp
	jg	.L1298	#,
	movl	%esi, 28(%rsp)	# i, %sfp
	jmp	.L1297	#
.L1290:
	movl	%r8d, (%rdi)	# _146, *_108
# quickosimple.h:21:     array[j] = c ? y : z;
	movl	%r9d, (%rbx,%rax,4)	# y, MEM[base: array_8(D), index: ivtmp.1906_312, step: 4, offset: 0B]
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1906
# quickosimple.h:22:     i += c;
	incl	%esi	# i
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	cmpl	%eax, %r12d	# ivtmp.1906, high
	jle	.L1390	#,
	movslq	%esi, %rdx	# i, i
	jmp	.L1293	#
.L1390:
	movl	%esi, 16(%rsp)	# i, %sfp
	movslq	%esi, %rdx	# i, i
	jmp	.L1292	#
.L1388:
	movl	%esi, 28(%rsp)	# i, %sfp
	movslq	%esi, %rdx	# i, i
.L1297:
# swap.h:3:   *a = *b;
	movq	64(%rsp), %rdi	# %sfp, _64
# quickosimple.h:24:   swap(&array[i], &array[high]);
	salq	$2, %rdx	#, _67
# swap.h:3:   *a = *b;
	movl	(%rdi), %esi	# *_64, _70
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	(%r14,%rdx), %rax	#, _68
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# *_68, t
# swap.h:3:   *a = *b;
	movl	%esi, (%rax)	# _70, *_68
# quickosimple.h:31:     if (high - low > 2) {
	movl	(%rsp), %eax	# %sfp, tmp267
# swap.h:4:   *b = t;
	movl	%ecx, (%rdi)	# t, *_64
# quickosimple.h:31:     if (high - low > 2) {
	subl	%ebp, %eax	# low, tmp267
# quickosimple.h:31:     if (high - low > 2) {
	cmpl	$2, %eax	#, tmp267
	jle	.L1382	#,
# quickosimple.h:32:         sort_quick_optimized_simple(array, low, pi - 1);
	movl	28(%rsp), %eax	# %sfp, i
	decl	%eax	# _43
	movl	%eax, 4(%rsp)	# _43, %sfp
# quickosimple.h:29:   if (low < high) {
	cmpl	%ebp, %eax	# low, _43
	jle	.L1299	#,
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	-4(%r14,%rdx), %rax	#, _95
	movq	%rax, 72(%rsp)	# _95, %sfp
	movq	%r14, %r12	# array, array
	movl	%ebp, %r14d	# low, low
.L1340:
# quickosimple.h:14:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	4(%rsp), %edx	# %sfp,
	movl	%r14d, %esi	# low,
	movq	%r12, %rdi	# array,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %ecx	# tmp320, pivot
	movl	%r14d, %esi	# low, i
	movq	%rbx, %rax	# ivtmp.1850, ivtmp.1892
	movq	%rbx, %rdx	# ivtmp.1850, i
.L1303:
# quickosimple.h:17:     int c = pivot > array[j];
	movl	(%r12,%rax,4), %r8d	# MEM[base: array_8(D), index: ivtmp.1892_267, step: 4, offset: 0B], _387
# quickosimple.h:18:     int y = array[i];
	leaq	(%r12,%rdx,4), %rdi	#, _379
# quickosimple.h:18:     int y = array[i];
	movl	(%rdi), %r9d	# *_379, y
# quickosimple.h:20:     array[i] = c ? z : y;
	cmpl	%r8d, %ecx	# _387, pivot
	jg	.L1300	#,
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1892
	cmpl	%eax, 4(%rsp)	# ivtmp.1892, %sfp
	jg	.L1303	#,
	movl	%esi, 20(%rsp)	# i, %sfp
	jmp	.L1302	#
.L1300:
	movl	%r8d, (%rdi)	# _387, *_379
# quickosimple.h:21:     array[j] = c ? y : z;
	movl	%r9d, (%r12,%rax,4)	# y, MEM[base: array_8(D), index: ivtmp.1892_267, step: 4, offset: 0B]
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1892
# quickosimple.h:22:     i += c;
	incl	%esi	# i
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	cmpl	%eax, 4(%rsp)	# ivtmp.1892, %sfp
	jle	.L1391	#,
	movslq	%esi, %rdx	# i, i
	jmp	.L1303	#
.L1381:
	movq	%r12, %r14	# array, array
.L1299:
# quickosimple.h:33:         sort_quick_optimized_simple(array, pi + 1, high);
	movl	28(%rsp), %ebp	# %sfp, i
	incl	%ebp	# i
# quickosimple.h:29:   if (low < high) {
	cmpl	%ebp, (%rsp)	# low, %sfp
	jle	.L1382	#,
	movslq	%ebp, %rbx	# low, ivtmp.1850
	jmp	.L1341	#
.L1382:
	movl	40(%rsp), %r12d	# %sfp, high
	movq	%r14, %rbx	# array, array
.L1294:
# quickosimple.h:33:         sort_quick_optimized_simple(array, pi + 1, high);
	movl	16(%rsp), %ebp	# %sfp, i
	incl	%ebp	# i
# quickosimple.h:29:   if (low < high) {
	cmpl	%r12d, %ebp	# high, low
	jl	.L1342	#,
.L1383:
# quickosimple.h:36: }
	addq	$136, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
.L1391:
	.cfi_restore_state
	movl	%esi, 20(%rsp)	# i, %sfp
	movslq	%esi, %rdx	# i, i
.L1302:
# swap.h:3:   *a = *b;
	movq	72(%rsp), %rdi	# %sfp, _95
# quickosimple.h:24:   swap(&array[i], &array[high]);
	salq	$2, %rdx	#, _98
# swap.h:3:   *a = *b;
	movl	(%rdi), %esi	# *_95, _101
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	(%r12,%rdx), %rax	#, _99
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# *_99, t
# swap.h:3:   *a = *b;
	movl	%esi, (%rax)	# _101, *_99
# quickosimple.h:31:     if (high - low > 2) {
	movl	4(%rsp), %eax	# %sfp, tmp272
# swap.h:4:   *b = t;
	movl	%ecx, (%rdi)	# t, *_95
# quickosimple.h:31:     if (high - low > 2) {
	subl	%r14d, %eax	# low, tmp272
# quickosimple.h:31:     if (high - low > 2) {
	cmpl	$2, %eax	#, tmp272
	jle	.L1381	#,
# quickosimple.h:32:         sort_quick_optimized_simple(array, low, pi - 1);
	movl	20(%rsp), %eax	# %sfp, i
	decl	%eax	# _74
	movl	%eax, 8(%rsp)	# _74, %sfp
# quickosimple.h:29:   if (low < high) {
	cmpl	%r14d, %eax	# low, _74
	jle	.L1304	#,
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	-4(%r12,%rdx), %rax	#, _126
	movq	%rax, 80(%rsp)	# _126, %sfp
	movq	%rbx, %rax	# ivtmp.1850, ivtmp.1850
	movq	%r12, %rbx	# array, array
	movl	%r14d, %r12d	# low, low
	movq	%rax, %r14	# ivtmp.1850, ivtmp.1850
.L1339:
# quickosimple.h:14:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	8(%rsp), %edx	# %sfp,
	movl	%r12d, %esi	# low,
	movq	%rbx, %rdi	# array,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %ecx	# tmp321, pivot
	movl	%r12d, %esi	# low, i
	movq	%r14, %rax	# ivtmp.1850, ivtmp.1885
	movq	%r14, %rdx	# ivtmp.1850, i
.L1308:
# quickosimple.h:17:     int c = pivot > array[j];
	movl	(%rbx,%rax,4), %r8d	# MEM[base: array_8(D), index: ivtmp.1885_553, step: 4, offset: 0B], _409
# quickosimple.h:18:     int y = array[i];
	leaq	(%rbx,%rdx,4), %rdi	#, _404
# quickosimple.h:18:     int y = array[i];
	movl	(%rdi), %r9d	# *_404, y
# quickosimple.h:20:     array[i] = c ? z : y;
	cmpl	%r8d, %ecx	# _409, pivot
	jle	.L1305	#,
	movl	%r8d, (%rdi)	# _409, *_404
# quickosimple.h:21:     array[j] = c ? y : z;
	movl	%r9d, (%rbx,%rax,4)	# y, MEM[base: array_8(D), index: ivtmp.1885_553, step: 4, offset: 0B]
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1885
# quickosimple.h:22:     i += c;
	incl	%esi	# i
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	cmpl	%eax, 8(%rsp)	# ivtmp.1885, %sfp
	jg	.L1346	#,
	movl	%esi, 24(%rsp)	# i, %sfp
	movslq	%esi, %rdx	# i, i
.L1307:
# swap.h:3:   *a = *b;
	movq	80(%rsp), %rdi	# %sfp, _126
# quickosimple.h:24:   swap(&array[i], &array[high]);
	salq	$2, %rdx	#, _129
# swap.h:3:   *a = *b;
	movl	(%rdi), %esi	# *_126, _132
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	(%rbx,%rdx), %rax	#, _130
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# *_130, t
# swap.h:3:   *a = *b;
	movl	%esi, (%rax)	# _132, *_130
# quickosimple.h:31:     if (high - low > 2) {
	movl	8(%rsp), %eax	# %sfp, tmp277
# swap.h:4:   *b = t;
	movl	%ecx, (%rdi)	# t, *_126
# quickosimple.h:31:     if (high - low > 2) {
	subl	%r12d, %eax	# low, tmp277
# quickosimple.h:31:     if (high - low > 2) {
	cmpl	$2, %eax	#, tmp277
	jle	.L1380	#,
# quickosimple.h:32:         sort_quick_optimized_simple(array, low, pi - 1);
	movl	24(%rsp), %eax	# %sfp, i
	decl	%eax	# _105
	movl	%eax, 12(%rsp)	# _105, %sfp
# quickosimple.h:29:   if (low < high) {
	cmpl	%r12d, %eax	# low, _105
	jle	.L1309	#,
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	-4(%rbx,%rdx), %rax	#, _157
	movq	%rax, 88(%rsp)	# _157, %sfp
	movq	%r14, %rax	# ivtmp.1850, ivtmp.1850
	movl	%r12d, %r15d	# low, low
	movq	%rbx, %r14	# array, array
	movq	%rax, %rbx	# ivtmp.1850, ivtmp.1850
.L1338:
# quickosimple.h:14:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	12(%rsp), %edx	# %sfp,
	movl	%r15d, %esi	# low,
	movq	%r14, %rdi	# array,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %ecx	# tmp322, pivot
	movl	%r15d, %esi	# low, i
	movq	%rbx, %rax	# ivtmp.1850, ivtmp.1878
	movq	%rbx, %rdx	# ivtmp.1850, i
.L1313:
# quickosimple.h:17:     int c = pivot > array[j];
	movl	(%r14,%rax,4), %r8d	# MEM[base: array_8(D), index: ivtmp.1878_572, step: 4, offset: 0B], _430
# quickosimple.h:18:     int y = array[i];
	leaq	(%r14,%rdx,4), %rdi	#, _425
# quickosimple.h:18:     int y = array[i];
	movl	(%rdi), %r9d	# *_425, y
# quickosimple.h:20:     array[i] = c ? z : y;
	cmpl	%r8d, %ecx	# _430, pivot
	jle	.L1310	#,
	movl	%r8d, (%rdi)	# _430, *_425
# quickosimple.h:21:     array[j] = c ? y : z;
	movl	%r9d, (%r14,%rax,4)	# y, MEM[base: array_8(D), index: ivtmp.1878_572, step: 4, offset: 0B]
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1878
# quickosimple.h:22:     i += c;
	incl	%esi	# i
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	cmpl	%eax, 12(%rsp)	# ivtmp.1878, %sfp
	jg	.L1347	#,
	movl	%esi, 32(%rsp)	# i, %sfp
	movslq	%esi, %rdx	# i, i
.L1312:
# swap.h:3:   *a = *b;
	movq	88(%rsp), %rdi	# %sfp, _157
# quickosimple.h:24:   swap(&array[i], &array[high]);
	salq	$2, %rdx	#, _160
# swap.h:3:   *a = *b;
	movl	(%rdi), %esi	# *_157, _163
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	(%r14,%rdx), %rax	#, _161
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# *_161, t
# swap.h:3:   *a = *b;
	movl	%esi, (%rax)	# _163, *_161
# quickosimple.h:31:     if (high - low > 2) {
	movl	12(%rsp), %eax	# %sfp, tmp282
# swap.h:4:   *b = t;
	movl	%ecx, (%rdi)	# t, *_157
# quickosimple.h:31:     if (high - low > 2) {
	subl	%r15d, %eax	# low, tmp282
# quickosimple.h:31:     if (high - low > 2) {
	cmpl	$2, %eax	#, tmp282
	jle	.L1379	#,
# quickosimple.h:32:         sort_quick_optimized_simple(array, low, pi - 1);
	movl	32(%rsp), %eax	# %sfp, i
	leal	-1(%rax), %r12d	#, _136
# quickosimple.h:29:   if (low < high) {
	cmpl	%r15d, %r12d	# low, _136
	jle	.L1314	#,
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	-4(%r14,%rdx), %rax	#, _188
	movq	%rax, 96(%rsp)	# _188, %sfp
	movq	%rbx, %r13	# ivtmp.1850, ivtmp.1850
	movl	%r12d, %ebx	# _136, _136
.L1337:
# quickosimple.h:14:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%ebx, %edx	# _136,
	movl	%r15d, %esi	# low,
	movq	%r14, %rdi	# array,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %ecx	# tmp323, pivot
	movl	%r15d, %esi	# low, i
	movq	%r13, %rax	# ivtmp.1850, ivtmp.1871
	movq	%r13, %rdx	# ivtmp.1850, i
.L1318:
# quickosimple.h:17:     int c = pivot > array[j];
	movl	(%r14,%rax,4), %r8d	# MEM[base: array_8(D), index: ivtmp.1871_484, step: 4, offset: 0B], _451
# quickosimple.h:18:     int y = array[i];
	leaq	(%r14,%rdx,4), %rdi	#, _446
# quickosimple.h:18:     int y = array[i];
	movl	(%rdi), %r9d	# *_446, y
# quickosimple.h:20:     array[i] = c ? z : y;
	cmpl	%r8d, %ecx	# _451, pivot
	jg	.L1315	#,
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1871
	cmpl	%eax, %ebx	# ivtmp.1871, _136
	jg	.L1318	#,
	movl	%esi, 36(%rsp)	# i, %sfp
.L1317:
# swap.h:3:   *a = *b;
	movq	96(%rsp), %rdi	# %sfp, _188
# quickosimple.h:24:   swap(&array[i], &array[high]);
	salq	$2, %rdx	#, _191
# swap.h:3:   *a = *b;
	movl	(%rdi), %esi	# *_188, _194
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	(%r14,%rdx), %rax	#, _192
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# *_192, t
# swap.h:3:   *a = *b;
	movl	%esi, (%rax)	# _194, *_192
# quickosimple.h:31:     if (high - low > 2) {
	movl	%ebx, %eax	# _136, tmp287
	subl	%r15d, %eax	# low, tmp287
# swap.h:4:   *b = t;
	movl	%ecx, (%rdi)	# t, *_188
# quickosimple.h:31:     if (high - low > 2) {
	cmpl	$2, %eax	#, tmp287
	jle	.L1314	#,
# quickosimple.h:32:         sort_quick_optimized_simple(array, low, pi - 1);
	movl	36(%rsp), %eax	# %sfp, i
	leal	-1(%rax), %ebp	#, _167
# quickosimple.h:29:   if (low < high) {
	cmpl	%r15d, %ebp	# low, _167
	jle	.L1319	#,
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	-4(%r14,%rdx), %rax	#, _219
	movq	%rax, 104(%rsp)	# _219, %sfp
	movl	%ebx, 44(%rsp)	# _136, %sfp
.L1336:
# quickosimple.h:14:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%ebp, %edx	# _167,
	movl	%r15d, %esi	# low,
	movq	%r14, %rdi	# array,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %ecx	# tmp324, pivot
	movl	%r15d, %ebx	# low, i
	movq	%r13, %rax	# ivtmp.1850, ivtmp.1864
	movq	%r13, %rdx	# ivtmp.1850, i
.L1323:
# quickosimple.h:17:     int c = pivot > array[j];
	movl	(%r14,%rax,4), %edi	# MEM[base: array_8(D), index: ivtmp.1864_437, step: 4, offset: 0B], _472
# quickosimple.h:18:     int y = array[i];
	leaq	(%r14,%rdx,4), %rsi	#, _467
# quickosimple.h:18:     int y = array[i];
	movl	(%rsi), %r8d	# *_467, y
# quickosimple.h:20:     array[i] = c ? z : y;
	cmpl	%edi, %ecx	# _472, pivot
	jle	.L1320	#,
	movl	%edi, (%rsi)	# _472, *_467
# quickosimple.h:22:     i += c;
	incl	%ebx	# i
# quickosimple.h:21:     array[j] = c ? y : z;
	movl	%r8d, (%r14,%rax,4)	# y, MEM[base: array_8(D), index: ivtmp.1864_437, step: 4, offset: 0B]
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1864
	movslq	%ebx, %rdx	# i, i
	cmpl	%eax, %ebp	# ivtmp.1864, _167
	jg	.L1323	#,
.L1322:
# swap.h:3:   *a = *b;
	movq	104(%rsp), %rdi	# %sfp, _219
# quickosimple.h:24:   swap(&array[i], &array[high]);
	salq	$2, %rdx	#, _222
# swap.h:3:   *a = *b;
	movl	(%rdi), %esi	# *_219, _225
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	(%r14,%rdx), %rax	#, _223
# swap.h:2:   int t = *a;
	movl	(%rax), %ecx	# *_223, t
# swap.h:3:   *a = *b;
	movl	%esi, (%rax)	# _225, *_223
# quickosimple.h:31:     if (high - low > 2) {
	movl	%ebp, %eax	# _167, tmp292
	subl	%r15d, %eax	# low, tmp292
# swap.h:4:   *b = t;
	movl	%ecx, (%rdi)	# t, *_219
# quickosimple.h:31:     if (high - low > 2) {
	cmpl	$2, %eax	#, tmp292
	jle	.L1377	#,
# quickosimple.h:32:         sort_quick_optimized_simple(array, low, pi - 1);
	leal	-1(%rbx), %r12d	#, _198
# quickosimple.h:29:   if (low < high) {
	cmpl	%r15d, %r12d	# low, _198
	jle	.L1324	#,
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	-4(%r14,%rdx), %rax	#, _250
	movq	%rax, 112(%rsp)	# _250, %sfp
	movl	%ebx, 52(%rsp)	# i, %sfp
	movl	%ebp, 48(%rsp)	# _167, %sfp
	movq	%r13, %rbp	# ivtmp.1850, ivtmp.1850
.L1335:
# quickosimple.h:14:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%r12d, %edx	# _198,
	movl	%r15d, %esi	# low,
	movq	%r14, %rdi	# array,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %esi	# tmp325, pivot
	movl	%r15d, %r13d	# low, i
	movq	%rbp, %rax	# ivtmp.1850, ivtmp.1857
	movq	%rbp, %rdx	# ivtmp.1850, i
.L1328:
# quickosimple.h:17:     int c = pivot > array[j];
	movl	(%r14,%rax,4), %edi	# MEM[base: array_8(D), index: ivtmp.1857_395, step: 4, offset: 0B], _507
# quickosimple.h:18:     int y = array[i];
	leaq	(%r14,%rdx,4), %rcx	#, _497
# quickosimple.h:18:     int y = array[i];
	movl	(%rcx), %r8d	# *_497, y
# quickosimple.h:20:     array[i] = c ? z : y;
	cmpl	%edi, %esi	# _507, pivot
	jg	.L1325	#,
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1857
	cmpl	%eax, %r12d	# ivtmp.1857, _198
	jg	.L1328	#,
.L1327:
# swap.h:3:   *a = *b;
	movq	112(%rsp), %rcx	# %sfp, _250
# quickosimple.h:24:   swap(&array[i], &array[high]);
	salq	$2, %rdx	#, _253
# swap.h:3:   *a = *b;
	movl	(%rcx), %edi	# *_250, _256
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	(%r14,%rdx), %rax	#, _254
# swap.h:2:   int t = *a;
	movl	(%rax), %esi	# *_254, t
# swap.h:3:   *a = *b;
	movl	%edi, (%rax)	# _256, *_254
# quickosimple.h:31:     if (high - low > 2) {
	movl	%r12d, %eax	# _198, tmp297
	subl	%r15d, %eax	# low, tmp297
# swap.h:4:   *b = t;
	movl	%esi, (%rcx)	# t, *_250
# quickosimple.h:31:     if (high - low > 2) {
	cmpl	$2, %eax	#, tmp297
	jle	.L1376	#,
# quickosimple.h:32:         sort_quick_optimized_simple(array, low, pi - 1);
	leal	-1(%r13), %ebx	#, _229
# quickosimple.h:29:   if (low < high) {
	cmpl	%ebx, %r15d	# _229, low
	jge	.L1329	#,
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	-4(%r14,%rdx), %rax	#, _281
	movq	%rax, 120(%rsp)	# _281, %sfp
.L1334:
# quickosimple.h:14:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%ebx, %edx	# _229,
	movl	%r15d, %esi	# low,
	movq	%r14, %rdi	# array,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %ecx	# tmp326, pivot
	movq	%rbp, %rax	# ivtmp.1850, ivtmp.1850
	movq	%rax, %rdx	# ivtmp.1850, i
	movl	%r15d, %ebp	# low, i
.L1333:
# quickosimple.h:17:     int c = pivot > array[j];
	movl	(%r14,%rax,4), %edi	# MEM[base: array_8(D), index: ivtmp.1850_213, step: 4, offset: 0B], _565
# quickosimple.h:18:     int y = array[i];
	leaq	(%r14,%rdx,4), %rsi	#, _533
# quickosimple.h:18:     int y = array[i];
	movl	(%rsi), %r8d	# *_533, y
# quickosimple.h:20:     array[i] = c ? z : y;
	cmpl	%edi, %ecx	# _565, pivot
	jle	.L1330	#,
	movl	%edi, (%rsi)	# _565, *_533
# quickosimple.h:22:     i += c;
	incl	%ebp	# i
# quickosimple.h:21:     array[j] = c ? y : z;
	movl	%r8d, (%r14,%rax,4)	# y, MEM[base: array_8(D), index: ivtmp.1850_213, step: 4, offset: 0B]
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1850
	movslq	%ebp, %rdx	# i, i
	cmpl	%eax, %ebx	# ivtmp.1850, _229
	jg	.L1333	#,
.L1332:
# swap.h:3:   *a = *b;
	movq	120(%rsp), %rdi	# %sfp, _281
# quickosimple.h:24:   swap(&array[i], &array[high]);
	leaq	(%r14,%rdx,4), %rax	#, _285
# swap.h:3:   *a = *b;
	movl	(%rdi), %ecx	# *_281, _287
# swap.h:2:   int t = *a;
	movl	(%rax), %edx	# *_285, t
# swap.h:3:   *a = *b;
	movl	%ecx, (%rax)	# _287, *_285
# quickosimple.h:31:     if (high - low > 2) {
	movl	%ebx, %eax	# _229, tmp303
	subl	%r15d, %eax	# low, tmp303
# swap.h:4:   *b = t;
	movl	%edx, (%rdi)	# t, *_281
# quickosimple.h:31:     if (high - low > 2) {
	cmpl	$2, %eax	#, tmp303
	jle	.L1329	#,
# quickosimple.h:32:         sort_quick_optimized_simple(array, low, pi - 1);
	movl	%r15d, %esi	# low,
	leal	-1(%rbp), %edx	#, tmp304
	movq	%r14, %rdi	# array,
# quickosimple.h:33:         sort_quick_optimized_simple(array, pi + 1, high);
	leal	1(%rbp), %r15d	#, low
# quickosimple.h:32:         sort_quick_optimized_simple(array, low, pi - 1);
	call	sort_quick_optimized_simple	#
# quickosimple.h:29:   if (low < high) {
	cmpl	%r15d, %ebx	# low, _229
	jle	.L1329	#,
	movslq	%r15d, %rbp	# low, ivtmp.1850
	jmp	.L1334	#
.L1310:
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1878
	cmpl	%eax, 12(%rsp)	# ivtmp.1878, %sfp
	jg	.L1313	#,
	movl	%esi, 32(%rsp)	# i, %sfp
	jmp	.L1312	#
	.p2align 4,,10
	.p2align 3
.L1330:
	incq	%rax	# ivtmp.1850
	cmpl	%eax, %ebx	# ivtmp.1850, _229
	jle	.L1332	#,
	jmp	.L1333	#
.L1376:
	movl	48(%rsp), %ebp	# %sfp, _167
	movl	52(%rsp), %ebx	# %sfp, i
.L1324:
# quickosimple.h:33:         sort_quick_optimized_simple(array, pi + 1, high);
	leal	1(%rbx), %r15d	#, low
# quickosimple.h:29:   if (low < high) {
	cmpl	%r15d, %ebp	# low, _167
	jle	.L1377	#,
	movslq	%r15d, %r13	# low, ivtmp.1850
	jmp	.L1336	#
.L1377:
	movl	44(%rsp), %ebx	# %sfp, _136
.L1319:
# quickosimple.h:33:         sort_quick_optimized_simple(array, pi + 1, high);
	movl	36(%rsp), %r15d	# %sfp, i
	incl	%r15d	# i
# quickosimple.h:29:   if (low < high) {
	cmpl	%r15d, %ebx	# low, _136
	jle	.L1314	#,
	movslq	%r15d, %r13	# low, ivtmp.1850
	jmp	.L1337	#
.L1315:
	movl	%r8d, (%rdi)	# _451, *_446
# quickosimple.h:21:     array[j] = c ? y : z;
	movl	%r9d, (%r14,%rax,4)	# y, MEM[base: array_8(D), index: ivtmp.1871_484, step: 4, offset: 0B]
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1871
# quickosimple.h:22:     i += c;
	incl	%esi	# i
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	cmpl	%eax, %ebx	# ivtmp.1871, _136
	jg	.L1363	#,
	movl	%esi, 36(%rsp)	# i, %sfp
	movslq	%esi, %rdx	# i, i
	jmp	.L1317	#
.L1305:
	incq	%rax	# ivtmp.1885
	cmpl	%eax, 8(%rsp)	# ivtmp.1885, %sfp
	jg	.L1308	#,
	movl	%esi, 24(%rsp)	# i, %sfp
	jmp	.L1307	#
.L1314:
# quickosimple.h:33:         sort_quick_optimized_simple(array, pi + 1, high);
	movl	32(%rsp), %r15d	# %sfp, i
	incl	%r15d	# i
# quickosimple.h:29:   if (low < high) {
	cmpl	%r15d, 12(%rsp)	# low, %sfp
	jle	.L1379	#,
	movslq	%r15d, %rbx	# low, ivtmp.1850
	jmp	.L1338	#
.L1379:
	movq	%r14, %rbx	# array, array
.L1309:
# quickosimple.h:33:         sort_quick_optimized_simple(array, pi + 1, high);
	movl	24(%rsp), %r12d	# %sfp, i
	incl	%r12d	# i
# quickosimple.h:29:   if (low < high) {
	cmpl	%r12d, 8(%rsp)	# low, %sfp
	jle	.L1380	#,
	movslq	%r12d, %r14	# low, ivtmp.1850
	jmp	.L1339	#
.L1347:
	movslq	%esi, %rdx	# i, i
	jmp	.L1313	#
	.p2align 4,,10
	.p2align 3
.L1329:
# quickosimple.h:33:         sort_quick_optimized_simple(array, pi + 1, high);
	leal	1(%r13), %r15d	#, low
# quickosimple.h:29:   if (low < high) {
	cmpl	%r15d, %r12d	# low, _198
	jle	.L1376	#,
	movslq	%r15d, %rbp	# low, ivtmp.1850
	jmp	.L1335	#
.L1346:
	movslq	%esi, %rdx	# i, i
	jmp	.L1308	#
.L1363:
	movslq	%esi, %rdx	# i, i
	jmp	.L1318	#
.L1380:
	movq	%rbx, %r12	# array, array
.L1304:
# quickosimple.h:33:         sort_quick_optimized_simple(array, pi + 1, high);
	movl	20(%rsp), %r14d	# %sfp, i
	incl	%r14d	# i
# quickosimple.h:29:   if (low < high) {
	cmpl	%r14d, 4(%rsp)	# low, %sfp
	jle	.L1381	#,
	movslq	%r14d, %rbx	# low, ivtmp.1850
	jmp	.L1340	#
	.p2align 4,,10
	.p2align 3
.L1320:
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1864
	cmpl	%eax, %ebp	# ivtmp.1864, _167
	jle	.L1322	#,
	jmp	.L1323	#
	.p2align 4,,10
	.p2align 3
.L1325:
	movl	%edi, (%rcx)	# _507, *_497
# quickosimple.h:22:     i += c;
	incl	%r13d	# i
# quickosimple.h:21:     array[j] = c ? y : z;
	movl	%r8d, (%r14,%rax,4)	# y, MEM[base: array_8(D), index: ivtmp.1857_395, step: 4, offset: 0B]
# quickosimple.h:16:   for (int j = low; j < high; j++) {
	incq	%rax	# ivtmp.1857
	movslq	%r13d, %rdx	# i, i
	cmpl	%eax, %r12d	# ivtmp.1857, _198
	jle	.L1327	#,
	jmp	.L1328	#
.L1385:
	.cfi_def_cfa_offset 8
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	.cfi_restore 14
	.cfi_restore 15
	ret	
	.cfi_endproc
.LFE5421:
	.size	sort_quick_optimized_simple, .-sort_quick_optimized_simple
	.p2align 4
	.globl	partition_quick_stable
	.type	partition_quick_stable, @function
partition_quick_stable:
.LFB5422:
	.cfi_startproc
	endbr64	
	pushq	%rbp	#
	.cfi_def_cfa_offset 16
	.cfi_offset 6, -16
# quickostable.h:20:   int *from = reverse ? smaller_values : array;
	testl	%ecx, %ecx	# tmp299
	movq	%rdi, %rax	# array, iftmp.58_35
# quickostable.h:19: void partition_quick_stable(int array[], int smaller_values[], int equal_values[], int reverse, int low, int high, int low_target, int *smaller, int *larger, int *equal) {
	movq	%rsp, %rbp	#,
	.cfi_def_cfa_register 6
	pushq	%r15	#
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%r9d, %rcx	# high, high
# quickostable.h:19: void partition_quick_stable(int array[], int smaller_values[], int equal_values[], int reverse, int low, int high, int low_target, int *smaller, int *larger, int *equal) {
	movq	%rdi, %r11	# tmp296, array
	pushq	%r14	#
	pushq	%r13	#
	pushq	%r12	#
	.cfi_offset 15, -24
	.cfi_offset 14, -32
	.cfi_offset 13, -40
	.cfi_offset 12, -48
	movq	%rsi, %r12	# tmp297, smaller_values
# quickostable.h:20:   int *from = reverse ? smaller_values : array;
	cmovne	%r12, %rax	# smaller_values,, iftmp.58_35
# quickostable.h:19: void partition_quick_stable(int array[], int smaller_values[], int equal_values[], int reverse, int low, int high, int low_target, int *smaller, int *larger, int *equal) {
	pushq	%rbx	#
	.cfi_offset 3, -56
# quickostable.h:19: void partition_quick_stable(int array[], int smaller_values[], int equal_values[], int reverse, int low, int high, int low_target, int *smaller, int *larger, int *equal) {
	movq	%rdx, %rbx	# tmp298, equal_values
# median.h:70:   if (high - low > 2) {
	movl	%r9d, %edx	# high, _69
	subl	%r8d, %edx	# low, _69
# quickostable.h:19: void partition_quick_stable(int array[], int smaller_values[], int equal_values[], int reverse, int low, int high, int low_target, int *smaller, int *larger, int *equal) {
	movl	16(%rbp), %esi	# low_target, low_target
# median.h:7:   int c = array[*i1] <= array[*i2];
	leaq	(%rax,%rcx,4), %rcx	#, _235
# median.h:70:   if (high - low > 2) {
	cmpl	$2, %edx	#, _69
	jg	.L1428	#,
# median.h:88:   } if (high - low == 2) {
	je	.L1429	#,
# median.h:7:   int c = array[*i1] <= array[*i2];
	vmovd	(%rcx), %xmm0	# *_235, tmp309
	vmovd	%xmm0, %r10d	# tmp308, _119
# median.h:94:   } else if (high - low == 1) {
	cmpl	$1, %edx	#, _69
	je	.L1430	#,
.L1397:
# quickostable.h:69:   for (int j = low; j <= high; j++) {
	cmpl	%r9d, %r8d	# high, low
	jg	.L1399	#,
.L1432:
	movslq	%r8d, %r13	# low, ivtmp.1939
	subl	%r8d, %r9d	# low, tmp249
	leaq	1(%r13,%r9), %rcx	#, tmp251
	leaq	0(,%r13,4), %r14	#, _270
	leaq	(%rax,%rcx,4), %r9	#, _282
	leaq	(%rax,%r14), %rdx	#, ivtmp.1958
	movl	%r8d, %ecx	# low, h
	movl	%r8d, %edi	# low, k
	.p2align 4,,10
	.p2align 3
.L1400:
# quickostable.h:70:     int x = from[j];
	movl	(%rdx), %eax	# MEM[base: _272, offset: 0B], x
# quickostable.h:71:     array[i] = x;
	movslq	%esi, %r15	# low_target, low_target
# quickostable.h:71:     array[i] = x;
	movl	%eax, (%r11,%r15,4)	# x, *_6
# quickostable.h:72:     i += pivot > x;
	xorl	%r15d, %r15d	# tmp254
	cmpl	%r10d, %eax	# _119, x
	setl	%r15b	#, tmp254
# quickostable.h:72:     i += pivot > x;
	addl	%r15d, %esi	# tmp254, low_target
# quickostable.h:73:     smaller_values[k] = x;
	movslq	%edi, %r15	# k, k
# quickostable.h:73:     smaller_values[k] = x;
	movl	%eax, (%r12,%r15,4)	# x, *_11
# quickostable.h:74:     k += pivot < x;
	xorl	%r15d, %r15d	# tmp257
	cmpl	%r10d, %eax	# _119, x
	setg	%r15b	#, tmp257
# quickostable.h:74:     k += pivot < x;
	addl	%r15d, %edi	# tmp257, k
# quickostable.h:76:     h += pivot == x;
	cmpl	%r10d, %eax	# _119, x
# quickostable.h:75:     equal_values[h] = x;
	movslq	%ecx, %r15	# h, h
# quickostable.h:75:     equal_values[h] = x;
	movl	%eax, (%rbx,%r15,4)	# x, *_16
# quickostable.h:76:     h += pivot == x;
	sete	%al	#, tmp260
	movzbl	%al, %eax	# tmp260, tmp260
# quickostable.h:69:   for (int j = low; j <= high; j++) {
	addq	$4, %rdx	#, ivtmp.1958
# quickostable.h:76:     h += pivot == x;
	addl	%eax, %ecx	# tmp260, h
# quickostable.h:69:   for (int j = low; j <= high; j++) {
	cmpq	%r9, %rdx	# _282, ivtmp.1958
	jne	.L1400	#,
# quickostable.h:89:   *smaller = i - 1;
	movq	24(%rbp), %rdx	# smaller, tmp317
# quickostable.h:89:   *smaller = i - 1;
	leal	-1(%rsi), %eax	#, prephitmp_224
# quickostable.h:89:   *smaller = i - 1;
	movl	%eax, (%rdx)	# prephitmp_224, *smaller_51(D)
# quickostable.h:90:   *larger = k - 1;
	movq	32(%rbp), %rdx	# larger, tmp318
	decl	%edi	# tmp262
	movl	%edi, (%rdx)	# tmp262, *larger_53(D)
# quickostable.h:91:   for (int j = low; j < h; j++) {
	cmpl	%ecx, %r8d	# h, low
	jge	.L1401	#,
	movl	%r8d, %eax	# low, tmp263
	notl	%eax	# tmp263
	movslq	%esi, %r10	# low_target, _205
	leal	(%rax,%rcx), %edx	#, _207
	leaq	0(,%r10,4), %rax	#, _204
	leaq	(%r11,%rax), %r12	#, _191
	leaq	4(%rbx,%r14), %r9	#, tmp265
	movq	%r12, %rdi	# _191, tmp266
	subq	%r9, %rdi	# tmp265, tmp266
	cmpq	$24, %rdi	#, tmp266
	jbe	.L1402	#,
	cmpl	$2, %edx	#, _207
	jbe	.L1402	#,
	movl	%ecx, %r9d	# h, niters.1915
	subl	%r8d, %r9d	# low, niters.1915
	cmpl	$6, %edx	#, _207
	jbe	.L1413	#,
	movl	%r9d, %edi	# niters.1915, bnd.1916
	shrl	$3, %edi	#,
	addq	%rbx, %r14	# equal_values, vectp.1921
	salq	$5, %rdi	#, _217
	xorl	%eax, %eax	# ivtmp.1949
	.p2align 4,,10
	.p2align 3
.L1404:
# quickostable.h:92:     array[i++] = equal_values[j];
	vmovdqu	(%r14,%rax), %ymm3	# MEM[base: vectp.1921_227, index: ivtmp.1949_214, offset: 0B], tmp323
	vmovdqu	%ymm3, (%r12,%rax)	# tmp323, MEM[base: _191, index: ivtmp.1949_214, offset: 0B]
	addq	$32, %rax	#, ivtmp.1949
	cmpq	%rdi, %rax	# _217, ivtmp.1949
	jne	.L1404	#,
	movl	%r9d, %eax	# niters.1915, niters_vector_mult_vf.1917
	andl	$-8, %eax	#,
	leal	(%rsi,%rax), %edi	#, tmp.1928
	addl	%eax, %r8d	# niters_vector_mult_vf.1917, low
	cmpl	%eax, %r9d	# niters_vector_mult_vf.1917, niters.1915
	je	.L1424	#,
	movl	%edx, %r12d	# _207, tmp274
	subl	%eax, %r12d	# niters_vector_mult_vf.1917, tmp274
	subl	%eax, %r9d	# niters_vector_mult_vf.1917, niters.1915
	cmpl	$2, %r12d	#, tmp274
	jbe	.L1431	#,
	vzeroupper
.L1403:
# quickostable.h:92:     array[i++] = equal_values[j];
	addq	%rax, %r13	# _253, tmp275
	vmovdqu	(%rbx,%r13,4), %xmm0	# MEM <vector(4) int> [(int *)vectp.1931_251], MEM <vector(4) int> [(int *)vectp.1931_251]
# quickostable.h:92:     array[i++] = equal_values[j];
	addq	%r10, %rax	# _205, tmp277
	vmovdqu	%xmm0, (%r11,%rax,4)	# MEM <vector(4) int> [(int *)vectp.1931_251], MEM <vector(4) int> [(int *)vectp.1934_259]
	movl	%r9d, %eax	# niters.1915, niters_vector_mult_vf.1927
	andl	$-4, %eax	#, niters_vector_mult_vf.1927
	addl	%eax, %edi	# niters_vector_mult_vf.1927, tmp.1928
	addl	%eax, %r8d	# niters_vector_mult_vf.1927, low
	cmpl	%eax, %r9d	# niters_vector_mult_vf.1927, niters.1915
	je	.L1409	#,
.L1406:
# quickostable.h:92:     array[i++] = equal_values[j];
	movslq	%r8d, %rax	# low, low
	movl	(%rbx,%rax,4), %eax	# *_58, _60
# quickostable.h:92:     array[i++] = equal_values[j];
	leal	1(%rdi), %r9d	#, i
	movslq	%edi, %rdi	# tmp.1928, tmp.1928
# quickostable.h:92:     array[i++] = equal_values[j];
	movl	%eax, (%r11,%rdi,4)	# _60, *_27
# quickostable.h:91:   for (int j = low; j < h; j++) {
	leal	1(%r8), %eax	#, j
# quickostable.h:91:   for (int j = low; j < h; j++) {
	cmpl	%eax, %ecx	# j, h
	jle	.L1409	#,
# quickostable.h:92:     array[i++] = equal_values[j];
	cltq
	movl	(%rbx,%rax,4), %eax	# *_47, _28
# quickostable.h:92:     array[i++] = equal_values[j];
	movslq	%r9d, %rdi	# i, i
# quickostable.h:91:   for (int j = low; j < h; j++) {
	addl	$2, %r8d	#, j
# quickostable.h:92:     array[i++] = equal_values[j];
	movl	%eax, (%r11,%rdi,4)	# _28, *_34
# quickostable.h:92:     array[i++] = equal_values[j];
	leaq	0(,%rdi,4), %r9	#, _37
# quickostable.h:91:   for (int j = low; j < h; j++) {
	cmpl	%r8d, %ecx	# j, h
	jle	.L1409	#,
# quickostable.h:92:     array[i++] = equal_values[j];
	movslq	%r8d, %r8	# j, j
	movl	(%rbx,%r8,4), %eax	# *_95, _101
# quickostable.h:92:     array[i++] = equal_values[j];
	movl	%eax, 4(%r11,%r9)	# _101, *_100
.L1409:
	leal	(%rsi,%rdx), %eax	#, prephitmp_224
.L1401:
# quickostable.h:94:   *equal = i - 1;
	movq	40(%rbp), %rdx	# equal, equal
	movl	%eax, (%rdx)	# prephitmp_224, *equal_55(D)
# quickostable.h:95: }
	popq	%rbx	#
	popq	%r12	#
	popq	%r13	#
	popq	%r14	#
	popq	%r15	#
	popq	%rbp	#
	.cfi_remember_state
	.cfi_def_cfa 7, 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1428:
	.cfi_restore_state
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%r8d, %rdx	# low, low
# median.h:82:     int mid = (low + high) / 2;
	leal	(%r8,%r9), %edi	#, tmp232
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%rax,%rdx,4), %r10d	# *_74, _119
# median.h:82:     int mid = (low + high) / 2;
	movl	%edi, %edx	# tmp232, tmp234
	shrl	$31, %edx	#, tmp234
	addl	%edi, %edx	# tmp232, tmp235
	sarl	%edx	# tmp236
# median.h:7:   int c = array[*i1] <= array[*i2];
	movslq	%edx, %rdx	# tmp236, tmp237
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%rax,%rdx,4), %edx	# *_78, _79
# median.h:8:   *i1 = c ? x : y;
	cmpl	%edx, %r10d	# _79, _119
	jg	.L1396	#,
	movl	%r10d, %edi	# _119, _119
	movl	%edx, %r10d	# _79, _119
	movl	%edi, %edx	# _119, _79
.L1396:
# median.h:7:   int c = array[*i1] <= array[*i2];
	movl	(%rcx), %ecx	# *_235, _175
	cmpl	%ecx, %edx	# _175, _79
	cmovl	%ecx, %edx	# _79,, _175, tmp291
	cmpl	%r10d, %ecx	# _119, _175
	cmovl	%edx, %r10d	# tmp291,, _119
# quickostable.h:69:   for (int j = low; j <= high; j++) {
	cmpl	%r9d, %r8d	# high, low
	jle	.L1432	#,
.L1399:
# quickostable.h:89:   *smaller = i - 1;
	movq	24(%rbp), %rbx	# smaller, tmp328
# quickostable.h:89:   *smaller = i - 1;
	leal	-1(%rsi), %eax	#, prephitmp_224
# quickostable.h:89:   *smaller = i - 1;
	movl	%eax, (%rbx)	# prephitmp_224, *smaller_51(D)
# quickostable.h:90:   *larger = k - 1;
	movq	32(%rbp), %rbx	# larger, tmp329
	decl	%r8d	# tmp287
	movl	%r8d, (%rbx)	# tmp287, *larger_53(D)
	jmp	.L1401	#
	.p2align 4,,10
	.p2align 3
.L1430:
# median.h:95:     sort_pair(&array[low], &array[high]);
	movslq	%r8d, %rdx	# low, low
# median.h:95:     sort_pair(&array[low], &array[high]);
	leaq	(%rax,%rdx,4), %rdx	#, _110
# median.h:31:   int x = *i1;
	vmovd	(%rdx), %xmm1	# *_110, tmp310
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm0, %xmm1, %xmm2	# tmp308, x, tmp247
	vpmaxsd	%xmm1, %xmm0, %xmm0	# x, tmp308, tmp308
	vmovd	%xmm2, (%rdx)	# tmp247, *_110
	vmovd	%xmm0, %r10d	# tmp308, _119
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rcx)	# tmp308, *_235
# median.h:96:     return array[high];
	jmp	.L1397	#
.L1431:
	vzeroupper
	jmp	.L1406	#
	.p2align 4,,10
	.p2align 3
.L1402:
	movq	%r13, %rdi	# ivtmp.1939, tmp284
	negq	%rdi	# tmp284
	leaq	(%rax,%rdi,4), %rax	#, tmp286
	addq	%rax, %r11	# tmp286, _212
	.p2align 4,,10
	.p2align 3
.L1408:
# quickostable.h:92:     array[i++] = equal_values[j];
	movl	(%rbx,%r13,4), %eax	# MEM[base: equal_values_57(D), index: ivtmp.1939_211, step: 4, offset: 0B], _157
# quickostable.h:92:     array[i++] = equal_values[j];
	movl	%eax, (%r11,%r13,4)	# _157, MEM[base: _212, index: ivtmp.1939_211, step: 4, offset: 0B]
# quickostable.h:91:   for (int j = low; j < h; j++) {
	incq	%r13	# ivtmp.1939
	cmpl	%r13d, %ecx	# ivtmp.1939, h
	jg	.L1408	#,
	jmp	.L1409	#
	.p2align 4,,10
	.p2align 3
.L1429:
# median.h:89:     int mid = low + 1;
	leal	1(%r8), %edx	#, mid
# median.h:90:     sort_pair(&array[low], &array[mid]);
	movslq	%edx, %rdx	# mid, mid
	salq	$2, %rdx	#, _122
# median.h:90:     sort_pair(&array[low], &array[mid]);
	leaq	(%rax,%rdx), %rdi	#, _123
	leaq	-4(%rax,%rdx), %rdx	#, _126
# median.h:31:   int x = *i1;
	vmovd	(%rdx), %xmm0	# *_126, tmp302
	vmovdqa	%xmm0, %xmm1	# tmp302, x
# median.h:32:   int y = *i2;
	vmovd	(%rdi), %xmm0	# *_123, tmp303
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm0, %xmm1, %xmm2	# y, x, tmp241
	vpmaxsd	%xmm0, %xmm1, %xmm0	# y, x, iftmp.17_130
	vmovd	%xmm2, (%rdx)	# tmp241, *_126
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rdi)	# iftmp.17_130, *_123
# median.h:32:   int y = *i2;
	vmovd	(%rcx), %xmm1	# *_235, tmp304
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, iftmp.17_130, tmp242
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, iftmp.17_130, tmp243
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rdi)	# tmp242, *_123
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rcx)	# tmp243, *_235
# median.h:31:   int x = *i1;
	vmovd	(%rdx), %xmm0	# *_126, tmp306
	vmovdqa	%xmm0, %xmm1	# tmp306, x
# median.h:32:   int y = *i2;
	vmovd	(%rdi), %xmm0	# *_123, tmp307
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm0, %xmm1, %xmm2	# y, x, tmp244
	vpmaxsd	%xmm0, %xmm1, %xmm0	# y, x, tmp305
	vmovd	%xmm2, (%rdx)	# tmp244, *_126
	vmovd	%xmm0, %r10d	# tmp305, _119
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rdi)	# tmp305, *_123
	jmp	.L1397	#
.L1424:
	vzeroupper
	jmp	.L1409	#
.L1413:
# quickostable.h:72:     i += pivot > x;
	movl	%esi, %edi	# low_target, tmp.1928
# quickostable.h:91:   for (int j = low; j < h; j++) {
	xorl	%eax, %eax	#
	jmp	.L1403	#
	.cfi_endproc
.LFE5422:
	.size	partition_quick_stable, .-partition_quick_stable
	.p2align 4
	.globl	sort_quick_stable_h
	.type	sort_quick_stable_h, @function
sort_quick_stable_h:
.LFB5424:
	.cfi_startproc
	endbr64	
	pushq	%r14	#
	.cfi_def_cfa_offset 16
	.cfi_offset 14, -16
	pushq	%r13	#
	.cfi_def_cfa_offset 24
	.cfi_offset 13, -24
	pushq	%r12	#
	.cfi_def_cfa_offset 32
	.cfi_offset 12, -32
	movslq	%ecx, %r12	# tmp196,
	pushq	%rbp	#
	.cfi_def_cfa_offset 40
	.cfi_offset 6, -40
	movq	%rdi, %rbp	# tmp193, array
	subq	$40, %rsp	#,
	.cfi_def_cfa_offset 80
# quickostable.h:117:   if (high - low > 2) {
	movq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], _1
	movq	%rax, 24(%rsp)	# _1, D.41842
	movl	%r8d, %eax	# high, _1
	subl	%r12d, %eax	# low, _1
# quickostable.h:117:   if (high - low > 2) {
	cmpl	$2, %eax	#, _1
	jg	.L1445	#,
# quickostable.h:123:   } else if (low < high) {
	cmpl	%r12d, %r8d	# low, high
	jg	.L1446	#,
.L1433:
# quickostable.h:126: }
	movq	24(%rsp), %rax	# D.41842, tmp213
	subq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], tmp213
	jne	.L1447	#,
	addq	$40, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 40
	popq	%rbp	#
	.cfi_def_cfa_offset 32
	popq	%r12	#
	.cfi_def_cfa_offset 24
	popq	%r13	#
	.cfi_def_cfa_offset 16
	popq	%r14	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1445:
	.cfi_restore_state
# quickostable.h:119:     partition_quick_stable(array, smaller_values, equal_values, false, low, high, low, &smaller, &larger, &equal);
	leaq	20(%rsp), %rax	#, tmp154
	pushq	%rax	# tmp154
	.cfi_def_cfa_offset 88
	movl	%r8d, %r9d	# high,
	xorl	%ecx, %ecx	#
	leaq	24(%rsp), %rax	#, tmp155
	pushq	%rax	# tmp155
	.cfi_def_cfa_offset 96
	movl	%r12d, %r8d	# low,
	movq	%rsi, %r14	# tmp194, smaller_values
	leaq	28(%rsp), %rax	#, tmp156
	pushq	%rax	# tmp156
	.cfi_def_cfa_offset 104
	movq	%rdx, %r13	# tmp195, equal_values
	pushq	%r12	# low
	.cfi_def_cfa_offset 112
	call	partition_quick_stable	#
# quickostable.h:120:     sort_quick_stable_reverse_h(array, smaller_values, equal_values, low, larger, equal + 1);
	movl	52(%rsp), %eax	# equal, equal
	movl	48(%rsp), %r8d	# larger,
	addq	$32, %rsp	#,
	.cfi_def_cfa_offset 80
	leal	1(%rax), %r9d	#,
	movl	%r12d, %ecx	# low,
	movq	%r13, %rdx	# equal_values,
	movq	%r14, %rsi	# smaller_values,
	movq	%rbp, %rdi	# array,
	call	sort_quick_stable_reverse_h	#
# quickostable.h:121:     sort_quick_stable_h(array, smaller_values, equal_values, low, smaller);
	movslq	12(%rsp), %r8	# smaller,
# quickostable.h:117:   if (high - low > 2) {
	movl	%r8d, %eax	# smaller.65_14, _15
	subl	%r12d, %eax	# low, _15
# quickostable.h:117:   if (high - low > 2) {
	cmpl	$2, %eax	#, _15
	jg	.L1448	#,
# quickostable.h:123:   } else if (low < high) {
	cmpl	%r8d, %r12d	# smaller.65_14, low
	jge	.L1433	#,
# median.h:88:   } if (high - low == 2) {
	cmpl	$2, %eax	#, _15
	je	.L1449	#,
# median.h:94:   } else if (high - low == 1) {
	cmpl	$1, %eax	#, _15
	jne	.L1433	#,
# median.h:95:     sort_pair(&array[low], &array[high]);
	leaq	0(%rbp,%r8,4), %rax	#, _54
.L1444:
	leaq	0(%rbp,%r12,4), %rdx	#, _130
# median.h:31:   int x = *i1;
	vmovd	(%rdx), %xmm0	#* _130, tmp210
# median.h:32:   int y = *i2;
	vmovd	(%rax), %xmm1	#* _127, tmp211
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, x, tmp190
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, x, tmp191
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rdx)	# tmp190,* _130
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rax)	# tmp191,* _127
# quickostable.h:126: }
	jmp	.L1433	#
	.p2align 4,,10
	.p2align 3
.L1446:
# median.h:88:   } if (high - low == 2) {
	cmpl	$2, %eax	#, _1
	je	.L1450	#,
# median.h:94:   } else if (high - low == 1) {
	cmpl	$1, %eax	#, _1
	jne	.L1433	#,
# median.h:95:     sort_pair(&array[low], &array[high]);
	movslq	%r8d, %r9	# high, high
# median.h:95:     sort_pair(&array[low], &array[high]);
	leaq	(%rdi,%r9,4), %rax	#, _127
	jmp	.L1444	#
	.p2align 4,,10
	.p2align 3
.L1448:
	movl	%r12d, %ecx	# low,
	movq	%r13, %rdx	# equal_values,
	movq	%r14, %rsi	# smaller_values,
	movq	%rbp, %rdi	# array,
	call	sort_quick_stable_h.part.0	#
	jmp	.L1433	#
	.p2align 4,,10
	.p2align 3
.L1450:
# median.h:89:     int mid = low + 1;
	leal	1(%r12), %eax	#, mid
# median.h:90:     sort_pair(&array[low], &array[mid]);
	cltq
	salq	$2, %rax	#, _142
# median.h:90:     sort_pair(&array[low], &array[mid]);
	leaq	(%rdi,%rax), %rdx	#, _143
	leaq	-4(%rdi,%rax), %rax	#, _146
# median.h:31:   int x = *i1;
	vmovd	(%rax), %xmm0	# *_146, tmp205
	vmovdqa	%xmm0, %xmm1	# tmp205, x
# median.h:32:   int y = *i2;
	vmovd	(%rdx), %xmm0	# *_143, tmp206
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm0, %xmm1, %xmm2	# y, x, tmp179
# median.h:91:     sort_pair(&array[mid], &array[high]);
	movslq	%r8d, %r9	# high, high
	vpmaxsd	%xmm0, %xmm1, %xmm0	# y, x, iftmp.17_150
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rax)	# tmp179, *_146
# median.h:91:     sort_pair(&array[mid], &array[high]);
	leaq	(%rdi,%r9,4), %rcx	#, _153
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rdx)	# iftmp.17_150, *_143
.L1443:
# median.h:32:   int y = *i2;
	vmovd	(%rcx), %xmm1	#* _153, tmp207
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, iftmp.17_150, tmp182
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, iftmp.17_150, tmp183
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rdx)	# tmp182,* _143
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rcx)	# tmp183,* _153
# median.h:31:   int x = *i1;
	vmovd	(%rax), %xmm0	#* _146, tmp208
# median.h:32:   int y = *i2;
	vmovd	(%rdx), %xmm1	#* _143, tmp209
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, x, tmp184
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, x, tmp185
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rax)	# tmp184,* _146
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rdx)	# tmp185,* _143
	jmp	.L1433	#
	.p2align 4,,10
	.p2align 3
.L1449:
# median.h:89:     int mid = low + 1;
	leal	1(%r12), %eax	#, mid
# median.h:90:     sort_pair(&array[low], &array[mid]);
	cltq
	salq	$2, %rax	#, _69
# median.h:90:     sort_pair(&array[low], &array[mid]);
	leaq	0(%rbp,%rax), %rdx	#, _70
	leaq	-4(%rbp,%rax), %rax	#, _73
# median.h:31:   int x = *i1;
	vmovd	(%rax), %xmm0	# *_73, tmp198
	vmovdqa	%xmm0, %xmm1	# tmp198, x
# median.h:32:   int y = *i2;
	vmovd	(%rdx), %xmm0	# *_70, tmp199
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm0, %xmm1, %xmm2	# y, x, tmp163
	vpmaxsd	%xmm0, %xmm1, %xmm0	# y, x, iftmp.17_77
	vmovd	%xmm2, (%rax)	# tmp163, *_73
# median.h:91:     sort_pair(&array[mid], &array[high]);
	leaq	0(%rbp,%r8,4), %rcx	#, _80
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rdx)	# iftmp.17_77, *_70
	jmp	.L1443	#
.L1447:
# quickostable.h:126: }
	call	__stack_chk_fail@PLT	#
	.cfi_endproc
.LFE5424:
	.size	sort_quick_stable_h, .-sort_quick_stable_h
	.p2align 4
	.globl	sort_quick_stable_reverse_h
	.type	sort_quick_stable_reverse_h, @function
sort_quick_stable_reverse_h:
.LFB5423:
	.cfi_startproc
	endbr64	
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movq	%rdi, %r14	# tmp203, array
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	movl	%r9d, %r13d	# tmp208, low_target
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	movslq	%ecx, %r12	# tmp206,
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	movq	%rsi, %rbp	# tmp204, smaller_values
	subq	$32, %rsp	#,
	.cfi_def_cfa_offset 80
# quickostable.h:100:   if (high - low > 2) {
	movq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], _1
	movq	%rax, 24(%rsp)	# _1, D.41893
	movl	%r8d, %eax	# high, _1
	subl	%r12d, %eax	# low, _1
# quickostable.h:100:   if (high - low > 2) {
	cmpl	$2, %eax	#, _1
	jg	.L1464	#,
# quickostable.h:106:   } else if (low < high) {
	cmpl	%r12d, %r8d	# low, high
	jg	.L1465	#,
# quickostable.h:111:   } else if (low == high) {
	jne	.L1451	#,
# quickostable.h:112:     array[low_target] = smaller_values[low];
	movslq	%r8d, %r8	# high, low
	movl	(%rsi,%r8,4), %eax	# *_14, _18
# quickostable.h:112:     array[low_target] = smaller_values[low];
	movslq	%r9d, %r9	# low_target, low_target
# quickostable.h:112:     array[low_target] = smaller_values[low];
	movl	%eax, (%rdi,%r9,4)	# _18,* array
	.p2align 4,,10
	.p2align 3
.L1451:
# quickostable.h:114: }
	movq	24(%rsp), %rax	# D.41893, tmp217
	subq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], tmp217
	jne	.L1466	#,
	addq	$32, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1464:
	.cfi_restore_state
# quickostable.h:102:     partition_quick_stable(array, smaller_values, equal_values, true, low, high, low_target, &smaller, &larger, &equal);
	leaq	20(%rsp), %rax	#, tmp163
	pushq	%rax	# tmp163
	.cfi_def_cfa_offset 88
	movl	$1, %ecx	#,
	movq	%rdx, %r15	# tmp205, equal_values
	leaq	24(%rsp), %rax	#, tmp164
	pushq	%rax	# tmp164
	.cfi_def_cfa_offset 96
	leaq	28(%rsp), %rax	#, tmp165
	pushq	%rax	# tmp165
	.cfi_def_cfa_offset 104
	pushq	%r9	# low_target
	.cfi_def_cfa_offset 112
	movl	%r8d, %r9d	# high,
	movl	%r12d, %r8d	# low,
	call	partition_quick_stable	#
# quickostable.h:103:     sort_quick_stable_reverse_h(array, smaller_values, equal_values, low, larger, equal + 1);
	movl	52(%rsp), %eax	# equal, equal
	movl	48(%rsp), %r8d	# larger,
	addq	$32, %rsp	#,
	.cfi_def_cfa_offset 80
	movl	%r12d, %ecx	# low,
	movq	%r15, %rdx	# equal_values,
	movq	%rbp, %rsi	# smaller_values,
	movq	%r14, %rdi	# array,
	leal	1(%rax), %r9d	#,
	call	sort_quick_stable_reverse_h	#
# quickostable.h:104:     sort_quick_stable_h(array, smaller_values, equal_values, low_target, smaller);
	movl	12(%rsp), %r8d	# smaller,
	movl	%r13d, %ecx	# low_target,
	movq	%r15, %rdx	# equal_values,
	movq	%rbp, %rsi	# smaller_values,
	movq	%r14, %rdi	# array,
	call	sort_quick_stable_h	#
# quickostable.h:114: }
	jmp	.L1451	#
	.p2align 4,,10
	.p2align 3
.L1465:
# median.h:88:   } if (high - low == 2) {
	cmpl	$2, %eax	#, _1
	je	.L1467	#,
# median.h:94:   } else if (high - low == 1) {
	cmpl	$1, %eax	#, _1
	je	.L1468	#,
# quickostable.h:108:     for (int i = 0; i <= high - low; i++) {
	testl	%eax, %eax	# _1
	jne	.L1451	#,
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	0(%rbp,%r12,4), %eax	# *_41, _45
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movslq	%r13d, %r9	# low_target, low_target
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	%eax, (%r14,%r9,4)	# _45,* array
	jmp	.L1451	#
	.p2align 4,,10
	.p2align 3
.L1468:
# median.h:95:     sort_pair(&array[low], &array[high]);
	movslq	%r8d, %r8	# high, high
# median.h:95:     sort_pair(&array[low], &array[high]);
	movslq	%r12d, %rcx	# low, low
# median.h:95:     sort_pair(&array[low], &array[high]);
	leaq	(%rsi,%r8,4), %rdx	#, _75
	leaq	(%rsi,%rcx,4), %rsi	#, _78
# median.h:32:   int y = *i2;
	vmovd	(%rdx), %xmm1	# *_75, tmp215
# median.h:31:   int x = *i1;
	vmovd	(%rsi), %xmm0	# *_78, tmp214
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, x, tmp184
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, x, tmp185
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rsi)	# tmp184, *_78
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rdx)	# tmp185, *_75
	leal	1(%r12), %edx	#, tmp202
.L1456:
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	0(%rbp,%rcx,4), %esi	# *_51, _58
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movslq	%r13d, %rcx	# low_target, low_target
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	%esi, (%r14,%rcx,4)	# _58, *_55
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movslq	%edx, %rdx	# tmp202, tmp197
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	0(%rbp,%rdx,4), %ecx	# *_48, _69
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	leal	1(%r13), %edx	#, tmp198
	movslq	%edx, %rdx	# tmp198, tmp199
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	%ecx, (%r14,%rdx,4)	# _69, *_110
# quickostable.h:108:     for (int i = 0; i <= high - low; i++) {
	cmpl	$2, %eax	#, _1
	jne	.L1451	#,
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	addl	$2, %r12d	#, tmp186
	movslq	%r12d, %r12	# tmp186, tmp187
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	0(%rbp,%r12,4), %eax	# *_5, _10
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	leal	2(%r13), %r9d	#, tmp188
	movslq	%r9d, %r9	# tmp188, tmp189
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	%eax, (%r14,%r9,4)	# _10,* array
	jmp	.L1451	#
	.p2align 4,,10
	.p2align 3
.L1467:
# median.h:89:     int mid = low + 1;
	leal	1(%r12), %edx	#, tmp202
# median.h:90:     sort_pair(&array[low], &array[mid]);
	movslq	%edx, %rsi	# tmp202, mid
	salq	$2, %rsi	#, _90
# median.h:90:     sort_pair(&array[low], &array[mid]);
	leaq	0(%rbp,%rsi), %rcx	#, _91
	leaq	-4(%rbp,%rsi), %rsi	#, _94
# median.h:31:   int x = *i1;
	vmovd	(%rsi), %xmm0	# *_94, tmp209
	vmovdqa	%xmm0, %xmm1	# tmp209, x
# median.h:32:   int y = *i2;
	vmovd	(%rcx), %xmm0	# *_91, tmp210
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm0, %xmm1, %xmm2	# y, x, tmp173
# median.h:91:     sort_pair(&array[mid], &array[high]);
	movslq	%r8d, %r8	# high, high
	vpmaxsd	%xmm0, %xmm1, %xmm0	# y, x, iftmp.17_98
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rsi)	# tmp173, *_94
# median.h:91:     sort_pair(&array[mid], &array[high]);
	leaq	0(%rbp,%r8,4), %rdi	#, _101
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rcx)	# iftmp.17_98, *_91
# median.h:32:   int y = *i2;
	vmovd	(%rdi), %xmm1	# *_101, tmp211
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, iftmp.17_98, tmp176
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, iftmp.17_98, tmp177
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rcx)	# tmp176, *_91
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rdi)	# tmp177, *_101
# median.h:32:   int y = *i2;
	vmovd	(%rcx), %xmm1	# *_91, tmp213
# median.h:31:   int x = *i1;
	vmovd	(%rsi), %xmm0	# *_94, tmp212
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, x, tmp178
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, x, tmp179
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rsi)	# tmp178, *_94
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rcx)	# tmp179, *_91
	movslq	%r12d, %rcx	# low, low
	jmp	.L1456	#
.L1466:
# quickostable.h:114: }
	call	__stack_chk_fail@PLT	#
	.cfi_endproc
.LFE5423:
	.size	sort_quick_stable_reverse_h, .-sort_quick_stable_reverse_h
	.p2align 4
	.type	sort_quick_stable_h.part.0, @function
sort_quick_stable_h.part.0:
.LFB5714:
	.cfi_startproc
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
# quickostable.h:119:     partition_quick_stable(array, smaller_values, equal_values, false, low, high, low, &smaller, &larger, &equal);
	movl	%r8d, %r9d	# tmp260,
# quickostable.h:116: void sort_quick_stable_h(int array[], int smaller_values[], int equal_values[], int low, int high) {
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movq	%rdx, %r14	# tmp258, equal_values
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	movq	%rsi, %r13	# tmp257, smaller_values
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	movslq	%ecx, %r12	# tmp259,
# quickostable.h:119:     partition_quick_stable(array, smaller_values, equal_values, false, low, high, low, &smaller, &larger, &equal);
	movl	%r12d, %r8d	# low,
# quickostable.h:116: void sort_quick_stable_h(int array[], int smaller_values[], int equal_values[], int low, int high) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
# quickostable.h:119:     partition_quick_stable(array, smaller_values, equal_values, false, low, high, low, &smaller, &larger, &equal);
	xorl	%ecx, %ecx	#
# quickostable.h:116: void sort_quick_stable_h(int array[], int smaller_values[], int equal_values[], int low, int high) {
	movq	%rdi, %rbp	# tmp256, array
	subq	$32, %rsp	#,
	.cfi_def_cfa_offset 80
# quickostable.h:116: void sort_quick_stable_h(int array[], int smaller_values[], int equal_values[], int low, int high) {
	movq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], tmp275
	movq	%rax, 24(%rsp)	# tmp275, D.41983
	xorl	%eax, %eax	# tmp275
# quickostable.h:119:     partition_quick_stable(array, smaller_values, equal_values, false, low, high, low, &smaller, &larger, &equal);
	leaq	8(%rsp), %rax	#, tmp197
	pushq	%rax	# tmp197
	.cfi_def_cfa_offset 88
	leaq	12(%rsp), %rax	#, tmp198
	pushq	%rax	# tmp198
	.cfi_def_cfa_offset 96
	leaq	16(%rsp), %rax	#, tmp199
	pushq	%rax	# tmp199
	.cfi_def_cfa_offset 104
	pushq	%r12	# low
	.cfi_def_cfa_offset 112
	call	partition_quick_stable	#
# quickostable.h:120:     sort_quick_stable_reverse_h(array, smaller_values, equal_values, low, larger, equal + 1);
	movslq	36(%rsp), %r9	# larger,
	movl	40(%rsp), %edx	# equal, equal.63_6
# quickostable.h:100:   if (high - low > 2) {
	movl	%r9d, %eax	# larger.64_8, _18
	subl	%r12d, %eax	# low, _18
# quickostable.h:120:     sort_quick_stable_reverse_h(array, smaller_values, equal_values, low, larger, equal + 1);
	leal	1(%rdx), %r15d	#, _7
# quickostable.h:100:   if (high - low > 2) {
	addq	$32, %rsp	#,
	.cfi_def_cfa_offset 80
	cmpl	$2, %eax	#, _18
	jg	.L1486	#,
# quickostable.h:106:   } else if (low < high) {
	cmpl	%r9d, %r12d	# larger.64_8, low
	jl	.L1487	#,
# quickostable.h:111:   } else if (low == high) {
	je	.L1485	#,
.L1471:
# quickostable.h:121:     sort_quick_stable_h(array, smaller_values, equal_values, low, smaller);
	movslq	(%rsp), %r8	# smaller,
# quickostable.h:117:   if (high - low > 2) {
	movl	%r8d, %eax	# smaller.65_9, _17
	subl	%r12d, %eax	# low, _17
# quickostable.h:117:   if (high - low > 2) {
	cmpl	$2, %eax	#, _17
	jg	.L1488	#,
.L1478:
# quickostable.h:123:   } else if (low < high) {
	cmpl	%r8d, %r12d	# smaller.65_9, low
	jl	.L1489	#,
.L1469:
# quickostable.h:126: }
	movq	24(%rsp), %rax	# D.41983, tmp276
	subq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], tmp276
	jne	.L1490	#,
	addq	$32, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1486:
	.cfi_restore_state
# quickostable.h:102:     partition_quick_stable(array, smaller_values, equal_values, true, low, high, low_target, &smaller, &larger, &equal);
	leaq	20(%rsp), %rax	#, tmp200
	pushq	%rax	# tmp200
	.cfi_def_cfa_offset 88
	movl	%r12d, %r8d	# low,
	movl	$1, %ecx	#,
	leaq	24(%rsp), %rax	#, tmp201
	pushq	%rax	# tmp201
	.cfi_def_cfa_offset 96
	movq	%r14, %rdx	# equal_values,
	movq	%r13, %rsi	# smaller_values,
	leaq	28(%rsp), %rax	#, tmp202
	pushq	%rax	# tmp202
	.cfi_def_cfa_offset 104
	movq	%rbp, %rdi	# array,
	pushq	%r15	# _7
	.cfi_def_cfa_offset 112
	call	partition_quick_stable	#
# quickostable.h:103:     sort_quick_stable_reverse_h(array, smaller_values, equal_values, low, larger, equal + 1);
	movl	52(%rsp), %eax	# equal, equal
	movl	48(%rsp), %r8d	# larger,
	addq	$32, %rsp	#,
	.cfi_def_cfa_offset 80
	leal	1(%rax), %r9d	#,
	movl	%r12d, %ecx	# low,
	movq	%r14, %rdx	# equal_values,
	movq	%r13, %rsi	# smaller_values,
	movq	%rbp, %rdi	# array,
	call	sort_quick_stable_reverse_h	#
# quickostable.h:104:     sort_quick_stable_h(array, smaller_values, equal_values, low_target, smaller);
	movl	12(%rsp), %r8d	# smaller,
	movl	%r15d, %ecx	# _7,
	movq	%r14, %rdx	# equal_values,
	movq	%r13, %rsi	# smaller_values,
	movq	%rbp, %rdi	# array,
	call	sort_quick_stable_h	#
# quickostable.h:121:     sort_quick_stable_h(array, smaller_values, equal_values, low, smaller);
	movslq	(%rsp), %r8	# smaller,
# quickostable.h:117:   if (high - low > 2) {
	movl	%r8d, %eax	# smaller.65_9, _17
	subl	%r12d, %eax	# low, _17
# quickostable.h:117:   if (high - low > 2) {
	cmpl	$2, %eax	#, _17
	jle	.L1478	#,
.L1488:
	movl	%r12d, %ecx	# low,
	movq	%r14, %rdx	# equal_values,
	movq	%r13, %rsi	# smaller_values,
	movq	%rbp, %rdi	# array,
	call	sort_quick_stable_h.part.0	#
	jmp	.L1469	#
	.p2align 4,,10
	.p2align 3
.L1487:
# median.h:88:   } if (high - low == 2) {
	cmpl	$2, %eax	#, _18
	je	.L1491	#,
# median.h:94:   } else if (high - low == 1) {
	cmpl	$1, %eax	#, _18
	je	.L1492	#,
# quickostable.h:108:     for (int i = 0; i <= high - low; i++) {
	testl	%eax, %eax	# _18
	jne	.L1471	#,
.L1485:
# quickostable.h:112:     array[low_target] = smaller_values[low];
	movslq	%r12d, %rax	# low, larger.64_8
	movl	0(%r13,%rax,4), %eax	#* smaller_values, _36
# quickostable.h:112:     array[low_target] = smaller_values[low];
	movslq	%r15d, %r15	# _7, _7
# quickostable.h:112:     array[low_target] = smaller_values[low];
	movl	%eax, 0(%rbp,%r15,4)	# _36,* array
	jmp	.L1471	#
	.p2align 4,,10
	.p2align 3
.L1489:
# median.h:88:   } if (high - low == 2) {
	cmpl	$2, %eax	#, _17
	je	.L1493	#,
# median.h:94:   } else if (high - low == 1) {
	cmpl	$1, %eax	#, _17
	jne	.L1469	#,
# median.h:95:     sort_pair(&array[low], &array[high]);
	leaq	0(%rbp,%r8,4), %rax	#, _152
	leaq	0(%rbp,%r12,4), %rdx	#, _155
# median.h:31:   int x = *i1;
	vmovd	(%rdx), %xmm0	# *_155, tmp273
# median.h:32:   int y = *i2;
	vmovd	(%rax), %xmm1	# *_152, tmp274
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, x, tmp243
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, x, tmp244
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rdx)	# tmp243, *_155
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rax)	# tmp244, *_152
# quickostable.h:126: }
	jmp	.L1469	#
	.p2align 4,,10
	.p2align 3
.L1492:
# median.h:95:     sort_pair(&array[low], &array[high]);
	movslq	%r12d, %rsi	# low, low
# median.h:95:     sort_pair(&array[low], &array[high]);
	leaq	0(%r13,%r9,4), %rcx	#, _79
	leaq	0(%r13,%rsi,4), %rdi	#, _82
# median.h:32:   int y = *i2;
	vmovd	(%rcx), %xmm1	# *_79, tmp267
# median.h:31:   int x = *i1;
	vmovd	(%rdi), %xmm0	# *_82, tmp266
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, x, tmp221
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, x, tmp222
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rdi)	# tmp221, *_82
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rcx)	# tmp222, *_79
	leal	1(%r12), %ecx	#, tmp255
.L1474:
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	0(%r13,%rsi,4), %esi	# *_123, _140
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movslq	%r15d, %r15	# _7, _7
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	%esi, 0(%rbp,%r15,4)	# _140, *_129
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movslq	%ecx, %rcx	# tmp255, tmp250
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	0(%r13,%rcx,4), %esi	# *_119, _91
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	leal	2(%rdx), %ecx	#, tmp251
	movslq	%ecx, %rcx	# tmp251, tmp252
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	%esi, 0(%rbp,%rcx,4)	# _91, *_115
# quickostable.h:108:     for (int i = 0; i <= high - low; i++) {
	cmpl	$2, %eax	#, _18
	jne	.L1471	#,
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	leal	2(%r12), %eax	#, tmp223
	cltq
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	0(%r13,%rax,4), %eax	# *_23, _28
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	addl	$3, %edx	#, tmp225
	movslq	%edx, %rdx	# tmp225, tmp226
# quickostable.h:109:       array[low_target + i] = smaller_values[low + i];
	movl	%eax, 0(%rbp,%rdx,4)	# _28, *_27
	jmp	.L1471	#
	.p2align 4,,10
	.p2align 3
.L1493:
# median.h:89:     int mid = low + 1;
	leal	1(%r12), %eax	#, mid
# median.h:90:     sort_pair(&array[low], &array[mid]);
	cltq
	salq	$2, %rax	#, _167
# median.h:90:     sort_pair(&array[low], &array[mid]);
	leaq	0(%rbp,%rax), %rdx	#, _168
	leaq	-4(%rbp,%rax), %rax	#, _171
# median.h:31:   int x = *i1;
	vmovd	(%rax), %xmm0	# *_171, tmp268
	vmovdqa	%xmm0, %xmm1	# tmp268, x
# median.h:32:   int y = *i2;
	vmovd	(%rdx), %xmm0	# *_168, tmp269
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm0, %xmm1, %xmm2	# y, x, tmp232
	vpmaxsd	%xmm0, %xmm1, %xmm0	# y, x, iftmp.17_175
	vmovd	%xmm2, (%rax)	# tmp232, *_171
# median.h:91:     sort_pair(&array[mid], &array[high]);
	leaq	0(%rbp,%r8,4), %rcx	#, _178
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rdx)	# iftmp.17_175, *_168
# median.h:32:   int y = *i2;
	vmovd	(%rcx), %xmm1	# *_178, tmp270
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, iftmp.17_175, tmp235
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, iftmp.17_175, tmp236
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rdx)	# tmp235, *_168
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rcx)	# tmp236, *_178
# median.h:31:   int x = *i1;
	vmovd	(%rax), %xmm0	# *_171, tmp271
# median.h:32:   int y = *i2;
	vmovd	(%rdx), %xmm1	# *_168, tmp272
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, x, tmp237
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, x, tmp238
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rax)	# tmp237, *_171
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rdx)	# tmp238, *_168
	jmp	.L1469	#
	.p2align 4,,10
	.p2align 3
.L1491:
# median.h:89:     int mid = low + 1;
	leal	1(%r12), %ecx	#, tmp255
# median.h:90:     sort_pair(&array[low], &array[mid]);
	movslq	%ecx, %rdi	# tmp255, mid
	salq	$2, %rdi	#, _94
# median.h:90:     sort_pair(&array[low], &array[mid]);
	leaq	0(%r13,%rdi), %rsi	#, _95
	leaq	-4(%r13,%rdi), %rdi	#, _98
# median.h:31:   int x = *i1;
	vmovd	(%rdi), %xmm0	# *_98, tmp261
	vmovdqa	%xmm0, %xmm1	# tmp261, x
# median.h:32:   int y = *i2;
	vmovd	(%rsi), %xmm0	# *_95, tmp262
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm0, %xmm1, %xmm2	# y, x, tmp210
	vpmaxsd	%xmm0, %xmm1, %xmm0	# y, x, iftmp.17_102
	vmovd	%xmm2, (%rdi)	# tmp210, *_98
# median.h:91:     sort_pair(&array[mid], &array[high]);
	leaq	0(%r13,%r9,4), %r8	#, _105
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rsi)	# iftmp.17_102, *_95
# median.h:32:   int y = *i2;
	vmovd	(%r8), %xmm1	# *_105, tmp263
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, iftmp.17_102, tmp213
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, iftmp.17_102, tmp214
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rsi)	# tmp213, *_95
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%r8)	# tmp214, *_105
# median.h:32:   int y = *i2;
	vmovd	(%rsi), %xmm1	# *_95, tmp265
# median.h:31:   int x = *i1;
	vmovd	(%rdi), %xmm0	# *_98, tmp264
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, x, tmp215
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, x, tmp216
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rdi)	# tmp215, *_98
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rsi)	# tmp216, *_95
	movslq	%r12d, %rsi	# low, low
	jmp	.L1474	#
.L1490:
# quickostable.h:126: }
	call	__stack_chk_fail@PLT	#
	.cfi_endproc
.LFE5714:
	.size	sort_quick_stable_h.part.0, .-sort_quick_stable_h.part.0
	.p2align 4
	.globl	sort_quick_stable
	.type	sort_quick_stable, @function
sort_quick_stable:
.LFB5425:
	.cfi_startproc
	endbr64	
	pushq	%r14	#
	.cfi_def_cfa_offset 16
	.cfi_offset 14, -16
	pushq	%r13	#
	.cfi_def_cfa_offset 24
	.cfi_offset 13, -24
	pushq	%r12	#
	.cfi_def_cfa_offset 32
	.cfi_offset 12, -32
	movslq	%esi, %r12	# tmp208,
	pushq	%rbp	#
	.cfi_def_cfa_offset 40
	.cfi_offset 6, -40
	movq	%rdi, %rbp	# tmp207, array
	pushq	%rbx	#
	.cfi_def_cfa_offset 48
	.cfi_offset 3, -48
	movslq	%edx, %rbx	# tmp209,
# quickostable.h:129:   int *smaller_values = (int *) malloc(sizeof(int32_t) * (high - low + 1) * 2);
	movl	%ebx, %r13d	# high, _1
	subl	%r12d, %r13d	# low, _1
# quickostable.h:129:   int *smaller_values = (int *) malloc(sizeof(int32_t) * (high - low + 1) * 2);
	leal	1(%r13), %edi	#, tmp160
	movslq	%edi, %rdi	# tmp160, tmp161
# quickostable.h:128: void sort_quick_stable(int array[], int low, int high) {
	subq	$32, %rsp	#,
	.cfi_def_cfa_offset 80
# quickostable.h:129:   int *smaller_values = (int *) malloc(sizeof(int32_t) * (high - low + 1) * 2);
	salq	$3, %rdi	#, tmp162
# quickostable.h:128: void sort_quick_stable(int array[], int low, int high) {
	movq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], tmp225
	movq	%rax, 24(%rsp)	# tmp225, D.42059
	xorl	%eax, %eax	# tmp225
# quickostable.h:129:   int *smaller_values = (int *) malloc(sizeof(int32_t) * (high - low + 1) * 2);
	call	malloc@PLT	#
	movq	%rax, %r14	# tmp210, smaller_values
# quickostable.h:117:   if (high - low > 2) {
	cmpl	$2, %r13d	#, _1
	jg	.L1505	#,
# quickostable.h:123:   } else if (low < high) {
	cmpl	%r12d, %ebx	# low, high
	jg	.L1506	#,
.L1499:
# quickostable.h:132:   free(smaller_values);
	movq	24(%rsp), %rax	# D.42059, tmp226
	subq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], tmp226
	jne	.L1507	#,
# quickostable.h:133: }
	addq	$32, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 48
	popq	%rbx	#
	.cfi_def_cfa_offset 40
	popq	%rbp	#
	.cfi_def_cfa_offset 32
	popq	%r12	#
	.cfi_def_cfa_offset 24
	popq	%r13	#
	.cfi_def_cfa_offset 16
# quickostable.h:132:   free(smaller_values);
	movq	%r14, %rdi	# smaller_values,
# quickostable.h:133: }
	popq	%r14	#
	.cfi_def_cfa_offset 8
# quickostable.h:132:   free(smaller_values);
	jmp	free@PLT	#
	.p2align 4,,10
	.p2align 3
.L1505:
	.cfi_restore_state
# quickostable.h:130:   int *equal_values = &smaller_values[(high - low + 1)];
	movslq	%r13d, %r13	# _1, _1
# quickostable.h:130:   int *equal_values = &smaller_values[(high - low + 1)];
	leaq	4(%rax,%r13,4), %r13	#, equal_values
# quickostable.h:119:     partition_quick_stable(array, smaller_values, equal_values, false, low, high, low, &smaller, &larger, &equal);
	leaq	20(%rsp), %rax	#, tmp167
	pushq	%rax	# tmp167
	.cfi_def_cfa_offset 88
	movl	%ebx, %r9d	# high,
	movl	%r12d, %r8d	# low,
	leaq	24(%rsp), %rax	#, tmp168
	pushq	%rax	# tmp168
	.cfi_def_cfa_offset 96
	xorl	%ecx, %ecx	#
	movq	%r13, %rdx	# equal_values,
	leaq	28(%rsp), %rax	#, tmp169
	pushq	%rax	# tmp169
	.cfi_def_cfa_offset 104
	movq	%r14, %rsi	# smaller_values,
	movq	%rbp, %rdi	# array,
	pushq	%r12	# low
	.cfi_def_cfa_offset 112
	call	partition_quick_stable	#
# quickostable.h:120:     sort_quick_stable_reverse_h(array, smaller_values, equal_values, low, larger, equal + 1);
	movl	52(%rsp), %eax	# equal, equal
	movl	48(%rsp), %r8d	# larger,
	addq	$32, %rsp	#,
	.cfi_def_cfa_offset 80
	leal	1(%rax), %r9d	#,
	movl	%r12d, %ecx	# low,
	movq	%r13, %rdx	# equal_values,
	movq	%r14, %rsi	# smaller_values,
	movq	%rbp, %rdi	# array,
	call	sort_quick_stable_reverse_h	#
# quickostable.h:121:     sort_quick_stable_h(array, smaller_values, equal_values, low, smaller);
	movslq	12(%rsp), %r8	# smaller,
# quickostable.h:117:   if (high - low > 2) {
	movl	%r8d, %eax	# smaller.65_21, _22
	subl	%r12d, %eax	# low, _22
# quickostable.h:117:   if (high - low > 2) {
	cmpl	$2, %eax	#, _22
	jg	.L1508	#,
# quickostable.h:123:   } else if (low < high) {
	cmpl	%r8d, %r12d	# smaller.65_21, low
	jge	.L1499	#,
# median.h:88:   } if (high - low == 2) {
	cmpl	$2, %eax	#, _22
	je	.L1509	#,
# median.h:94:   } else if (high - low == 1) {
	cmpl	$1, %eax	#, _22
	jne	.L1499	#,
# median.h:95:     sort_pair(&array[low], &array[high]);
	leaq	0(%rbp,%r8,4), %rax	#, _61
.L1504:
	leaq	0(%rbp,%r12,4), %rdx	#, _137
# median.h:31:   int x = *i1;
	vmovd	(%rdx), %xmm0	#* _137, tmp223
# median.h:32:   int y = *i2;
	vmovd	(%rax), %xmm1	#* _134, tmp224
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, x, tmp203
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, x, tmp204
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rdx)	# tmp203,* _137
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rax)	# tmp204,* _134
# median.h:96:     return array[high];
	jmp	.L1499	#
	.p2align 4,,10
	.p2align 3
.L1506:
# median.h:88:   } if (high - low == 2) {
	cmpl	$2, %r13d	#, _1
	je	.L1510	#,
# median.h:94:   } else if (high - low == 1) {
	cmpl	$1, %r13d	#, _1
	jne	.L1499	#,
# median.h:95:     sort_pair(&array[low], &array[high]);
	leaq	0(%rbp,%rbx,4), %rax	#, _134
	jmp	.L1504	#
	.p2align 4,,10
	.p2align 3
.L1508:
	movl	%r12d, %ecx	# low,
	movq	%r13, %rdx	# equal_values,
	movq	%r14, %rsi	# smaller_values,
	movq	%rbp, %rdi	# array,
	call	sort_quick_stable_h.part.0	#
	jmp	.L1499	#
	.p2align 4,,10
	.p2align 3
.L1510:
# median.h:89:     int mid = low + 1;
	leal	1(%r12), %eax	#, mid
# median.h:90:     sort_pair(&array[low], &array[mid]);
	cltq
	salq	$2, %rax	#, _149
# median.h:90:     sort_pair(&array[low], &array[mid]);
	leaq	0(%rbp,%rax), %rcx	#, _150
	leaq	-4(%rbp,%rax), %rax	#, _153
# median.h:31:   int x = *i1;
	vmovd	(%rax), %xmm0	# *_153, tmp218
	vmovdqa	%xmm0, %xmm1	# tmp218, x
# median.h:32:   int y = *i2;
	vmovd	(%rcx), %xmm0	# *_150, tmp219
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm0, %xmm1, %xmm2	# y, x, tmp192
	vpmaxsd	%xmm0, %xmm1, %xmm0	# y, x, iftmp.17_157
	vmovd	%xmm2, (%rax)	# tmp192, *_153
# median.h:91:     sort_pair(&array[mid], &array[high]);
	leaq	0(%rbp,%rbx,4), %rdx	#, _160
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rcx)	# iftmp.17_157, *_150
# median.h:32:   int y = *i2;
	vmovd	(%rdx), %xmm1	# *_160, tmp220
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, iftmp.17_157, tmp195
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, iftmp.17_157, tmp196
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rcx)	# tmp195, *_150
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rdx)	# tmp196, *_160
# median.h:31:   int x = *i1;
	vmovd	(%rax), %xmm0	# *_153, tmp221
# median.h:32:   int y = *i2;
	vmovd	(%rcx), %xmm1	# *_150, tmp222
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, x, tmp197
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, x, tmp198
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rax)	# tmp197, *_153
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rcx)	# tmp198, *_150
	jmp	.L1499	#
	.p2align 4,,10
	.p2align 3
.L1509:
# median.h:89:     int mid = low + 1;
	leal	1(%r12), %eax	#, mid
# median.h:90:     sort_pair(&array[low], &array[mid]);
	cltq
	salq	$2, %rax	#, _76
# median.h:90:     sort_pair(&array[low], &array[mid]);
	leaq	0(%rbp,%rax), %rdx	#, _77
	leaq	-4(%rbp,%rax), %rax	#, _80
# median.h:31:   int x = *i1;
	vmovd	(%rax), %xmm0	# *_80, tmp211
	vmovdqa	%xmm0, %xmm1	# tmp211, x
# median.h:32:   int y = *i2;
	vmovd	(%rdx), %xmm0	# *_77, tmp212
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm0, %xmm1, %xmm2	# y, x, tmp176
	vpmaxsd	%xmm0, %xmm1, %xmm0	# y, x, iftmp.17_84
	vmovd	%xmm2, (%rax)	# tmp176, *_80
# median.h:91:     sort_pair(&array[mid], &array[high]);
	leaq	0(%rbp,%r8,4), %rcx	#, _87
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rdx)	# iftmp.17_84, *_77
# median.h:32:   int y = *i2;
	vmovd	(%rcx), %xmm1	# *_87, tmp213
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, iftmp.17_84, tmp179
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, iftmp.17_84, tmp180
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rdx)	# tmp179, *_77
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rcx)	# tmp180, *_87
# median.h:31:   int x = *i1;
	vmovd	(%rax), %xmm0	# *_80, tmp214
# median.h:32:   int y = *i2;
	vmovd	(%rdx), %xmm1	# *_77, tmp215
# median.h:34:   *i1 = c ? x : y;
	vpminsd	%xmm1, %xmm0, %xmm2	# y, x, tmp181
# median.h:35:   *i2 = c ? y : x;
	vpmaxsd	%xmm1, %xmm0, %xmm0	# y, x, tmp182
# median.h:34:   *i1 = c ? x : y;
	vmovd	%xmm2, (%rax)	# tmp181, *_80
# median.h:35:   *i2 = c ? y : x;
	vmovd	%xmm0, (%rdx)	# tmp182, *_77
	jmp	.L1499	#
.L1507:
# quickostable.h:132:   free(smaller_values);
	call	__stack_chk_fail@PLT	#
	.cfi_endproc
.LFE5425:
	.size	sort_quick_stable, .-sort_quick_stable
	.p2align 4
	.globl	partition_quick_optimized_swap_arith
	.type	partition_quick_optimized_swap_arith, @function
partition_quick_optimized_swap_arith:
.LFB5426:
	.cfi_startproc
	endbr64	
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movl	%esi, %r14d	# tmp93, low
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	movq	%rdi, %rbp	# tmp92, array
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
# quickoswaparith.h:21: int partition_quick_optimized_swap_arith(int array[], int low, int high) {
	movslq	%edx, %rbx	# tmp94,
# quickoswaparith.h:22:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%ebx, %edx	# high,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %r15d	#, tmp95
# quickoswaparith.h:36:   int64_t i = low;
	movslq	%r14d, %rax	# low, i
# quickoswaparith.h:38:   asm volatile("    movq    %[i], %%r12\n"
#APP
# 38 "quickoswaparith.h" 1
	    movq    %rax, %r12	# i
1:

    movl     (%rbp,%r12,4), %r8d	# array
    xorq     %r10, %r10
    cmp      %r15d, %r8d	# tmp95
    setl     %r10b
    movl     (%rbp,%rax,4), %r9d	# array, i
    movl     %r8d, %r11d
    movl     %r9d, %r13d
    imull    %r10d, %r11d
    imull    %r10d, %r13d
    xorl     $1, %r10d
    imull    %r10d, %r8d
    imull    %r10d, %r9d
    add      %r11d, %r9d
    add      %r13d, %r8d
    movl     %r8d, (%rbp,%r12,4)	# array
    movl     %r9d, (%rbp,%rax,4)	# array, i
    xorl     $1, %r10d
    addq     %r10, %rax	# i

    incq     %r12
    cmp      %r12, %rbx	# h
    jne      1b

    movl     (%rbp,%rax,4), %r9d	# array, i
    movl     (%rbp,%rbx,4), %r8d	# array, h
    movl     %r9d, (%rbp,%rbx,4)	# array, h
    movl     %r8d, (%rbp,%rax,4)	# array, i

# 0 "" 2
# quickoswaparith.h:79: }
#NO_APP
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	movl	%r14d, %eax	# low,
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE5426:
	.size	partition_quick_optimized_swap_arith, .-partition_quick_optimized_swap_arith
	.p2align 4
	.globl	sort_quick_optimized_swap_arith
	.type	sort_quick_optimized_swap_arith, @function
sort_quick_optimized_swap_arith:
.LFB5427:
	.cfi_startproc
	endbr64	
# quickoswaparith.h:82:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jge	.L1527	#,
# quickoswaparith.h:81: void sort_quick_optimized_swap_arith(int array[], int low, int high) {
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
# quickoswaparith.h:83:     if (high - low > INSERTION_SORT_THRESH) {
	movl	%edx, %eax	# high, _59
	subl	%esi, %eax	# low, _59
# quickoswaparith.h:81: void sort_quick_optimized_swap_arith(int array[], int low, int high) {
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	movl	%edx, %r15d	# tmp120, high
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	movq	%rdi, %rbp	# tmp118, array
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	movl	%esi, %ebx	# tmp119, low
	subq	$24, %rsp	#,
	.cfi_def_cfa_offset 80
# quickoswaparith.h:83:     if (high - low > INSERTION_SORT_THRESH) {
	cmpl	$20, %eax	#, _59
	jle	.L1515	#,
# quickoswaparith.h:37:   int64_t h = high;
	movslq	%edx, %rax	# high, _79
	movq	%rax, 8(%rsp)	# _79, %sfp
	movslq	%esi, %r14	# low, ivtmp.2008
.L1516:
# quickoswaparith.h:22:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%r15d, %edx	# high,
	movq	%rbp, %rdi	# array,
	movl	%ebx, %esi	# low,
	call	median_of_three_of_median_of_three	#
	movl	%eax, %edx	#, tmp121
# quickoswaparith.h:38:   asm volatile("    movq    %[i], %%r12\n"
	movq	8(%rsp), %rdi	# %sfp, _79
	movq	%r14, %rax	# ivtmp.2008, i
#APP
# 38 "quickoswaparith.h" 1
	    movq    %rax, %r12	# i
1:

    movl     (%rbp,%r12,4), %r8d	# array
    xorq     %r10, %r10
    cmp      %edx, %r8d	# tmp121
    setl     %r10b
    movl     (%rbp,%rax,4), %r9d	# array, i
    movl     %r8d, %r11d
    movl     %r9d, %r13d
    imull    %r10d, %r11d
    imull    %r10d, %r13d
    xorl     $1, %r10d
    imull    %r10d, %r8d
    imull    %r10d, %r9d
    add      %r11d, %r9d
    add      %r13d, %r8d
    movl     %r8d, (%rbp,%r12,4)	# array
    movl     %r9d, (%rbp,%rax,4)	# array, i
    xorl     $1, %r10d
    addq     %r10, %rax	# i

    incq     %r12
    cmp      %r12, %rdi	# _79
    jne      1b

    movl     (%rbp,%rax,4), %r9d	# array, i
    movl     (%rbp,%rdi,4), %r8d	# array, _79
    movl     %r9d, (%rbp,%rdi,4)	# array, _79
    movl     %r8d, (%rbp,%rax,4)	# array, i

# 0 "" 2
# quickoswaparith.h:85:       sort_quick_optimized_swap_arith(array, low, pi - 1);
#NO_APP
	leal	-1(%rbx), %edx	#, tmp112
	movl	%ebx, %esi	# low,
	movq	%rbp, %rdi	# array,
# quickoswaparith.h:86:       sort_quick_optimized_swap_arith(array, pi + 1, high);
	incl	%ebx	# low
# quickoswaparith.h:85:       sort_quick_optimized_swap_arith(array, low, pi - 1);
	call	sort_quick_optimized_swap_arith	#
# quickoswaparith.h:82:   if (low < high) {
	cmpl	%r15d, %ebx	# high, low
	je	.L1525	#,
	movl	%r15d, %eax	# high, _59
	subl	%ebx, %eax	# low, _59
# quickoswaparith.h:83:     if (high - low > INSERTION_SORT_THRESH) {
	incq	%r14	# ivtmp.2008
	cmpl	$20, %eax	#, _59
	jg	.L1516	#,
.L1515:
# quickoswaparith.h:88:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%ebx, %rbx	# low, low
# quickoswaparith.h:88:       insertionSortOptimized(array + low, high - low + 1);
	leaq	0(%rbp,%rbx,4), %r11	#, _8
	leaq	4(%r11), %r8	#, ivtmp.1998
	movslq	%eax, %r10	# _59, _34
	xorl	%r9d, %r9d	# ivtmp.1995
	.p2align 4,,10
	.p2align 3
.L1522:
	leaq	0(,%r9,4), %rax	#, tmp116
	leaq	-4(%r8), %rsi	#, tmp115
# insertionssort.h:6:     element = array[i];
	movl	(%r8), %edi	# MEM[base: _51, offset: 0B], element
	subq	%rax, %rsi	# tmp116, _69
	movq	%r8, %rax	# ivtmp.1998, ivtmp.1987
	.p2align 4,,10
	.p2align 3
.L1519:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %edx	# MEM[base: _80, offset: -4B], _33
	movq	%rax, %rcx	# ivtmp.1987, _80
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %edi	# _33, element
	jge	.L1520	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, (%rax)	# _33, MEM[base: _80, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	leaq	-4(%rcx), %rax	#, ivtmp.1987
	cmpq	%rsi, %rax	# _69, ivtmp.1987
	jne	.L1519	#,
	movq	%r11, %rcx	# _8, _80
.L1520:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incq	%r9	# ivtmp.1995
# insertionssort.h:13:     array[j + 1] = element;
	movl	%edi, (%rcx)	# element, *prephitmp_104
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	addq	$4, %r8	#, ivtmp.1998
	cmpq	%r9, %r10	# ivtmp.1995, _34
	jne	.L1522	#,
.L1525:
# quickoswaparith.h:91: }
	addq	$24, %rsp	#,
	.cfi_def_cfa_offset 56
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
.L1527:
	.cfi_restore 3
	.cfi_restore 6
	.cfi_restore 12
	.cfi_restore 13
	.cfi_restore 14
	.cfi_restore 15
	ret	
	.cfi_endproc
.LFE5427:
	.size	sort_quick_optimized_swap_arith, .-sort_quick_optimized_swap_arith
	.p2align 4
	.globl	partition_quick_optimized_swap_array
	.type	partition_quick_optimized_swap_array, @function
partition_quick_optimized_swap_array:
.LFB5428:
	.cfi_startproc
	endbr64	
	pushq	%r12	#
	.cfi_def_cfa_offset 16
	.cfi_offset 12, -16
	movl	%esi, %r12d	# tmp147, low
	pushq	%rbp	#
	.cfi_def_cfa_offset 24
	.cfi_offset 6, -24
	movslq	%edx, %rbp	# tmp148,
# quickoswaparray.h:22:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%ebp, %edx	# high,
# quickoswaparray.h:21: int partition_quick_optimized_swap_array(int array[], int low, int high) {
	pushq	%rbx	#
	.cfi_def_cfa_offset 32
	.cfi_offset 3, -32
# quickoswaparray.h:21: int partition_quick_optimized_swap_array(int array[], int low, int high) {
	movq	%rdi, %rbx	# tmp146, array
# quickoswaparray.h:22:   int pivot = median_of_three_of_median_of_three(array, low, high);
	call	median_of_three_of_median_of_three	#
# quickoswaparray.h:25:   for (int j = low; j < high; j++) {
	cmpl	%ebp, %r12d	# high, low
	jge	.L1531	#,
	leal	-1(%rbp), %edx	#, tmp122
	movslq	%r12d, %rcx	# low, _58
	subl	%r12d, %edx	# low, tmp124
	addq	%rcx, %rdx	# _58, tmp125
	movl	%eax, %r9d	# tmp149, pivot
	leaq	4(%rbx,%rdx,4), %r11	#, _23
	leaq	(%rbx,%rcx,4), %rax	#, ivtmp.2021
	leaq	x(%rip), %rsi	#, tmp145
# quickoswaparray.h:29:     array[j] = x[1 - c];
	movl	$1, %r10d	#, tmp136
	.p2align 4,,10
	.p2align 3
.L1532:
# quickoswaparray.h:27:     x[0] = array[i];
	movslq	%r12d, %rcx	# <retval>, <retval>
	leaq	(%rbx,%rcx,4), %rdi	#, _8
	movl	(%rdi), %ecx	# *_8, _9
# quickoswaparray.h:26:     int c = pivot > array[j];
	xorl	%edx, %edx	# tmp128
	cmpl	%r9d, (%rax)	# pivot, MEM[base: _61, offset: 0B]
# quickoswaparray.h:27:     x[0] = array[i];
	movl	%ecx, (%rsi)	# _9, x[0]
# quickoswaparray.h:26:     int c = pivot > array[j];
	setl	%dl	#, tmp128
# quickoswaparray.h:25:   for (int j = low; j < high; j++) {
	addq	$4, %rax	#, ivtmp.2021
# quickoswaparray.h:28:     x[1] = array[j];
	movl	-4(%rax), %ecx	# MEM[base: _61, offset: 0B], _11
# quickoswaparray.h:31:     i += c;
	addl	%edx, %r12d	# tmp128, <retval>
# quickoswaparray.h:28:     x[1] = array[j];
	movl	%ecx, 4+x(%rip)	# _11, x[1]
# quickoswaparray.h:29:     array[j] = x[1 - c];
	movl	%r10d, %ecx	# tmp136, tmp135
	subl	%edx, %ecx	# tmp128, tmp135
# quickoswaparray.h:29:     array[j] = x[1 - c];
	movslq	%ecx, %rcx	# tmp135, tmp137
	movl	(%rsi,%rcx,4), %ecx	# x[_12], _13
# quickoswaparray.h:29:     array[j] = x[1 - c];
	movl	%ecx, -4(%rax)	# _13, MEM[base: _61, offset: 0B]
# quickoswaparray.h:30:     array[i] = x[c];
	movslq	%edx, %rcx	# tmp128, c
	movl	(%rsi,%rcx,4), %ecx	# x[c_30], _14
# quickoswaparray.h:30:     array[i] = x[c];
	movl	%ecx, (%rdi)	# _14, *_8
# quickoswaparray.h:25:   for (int j = low; j < high; j++) {
	cmpq	%rax, %r11	# ivtmp.2021, _23
	jne	.L1532	#,
.L1531:
# quickoswaparray.h:33:   swap(&array[i], &array[high]);
	movslq	%r12d, %rdx	# <retval>, <retval>
# quickoswaparray.h:33:   swap(&array[i], &array[high]);
	leaq	(%rbx,%rbp,4), %rax	#, _17
	leaq	(%rbx,%rdx,4), %rdx	#, _20
# swap.h:3:   *a = *b;
	movl	(%rax), %esi	# *_17, _38
# swap.h:2:   int t = *a;
	movl	(%rdx), %ecx	# *_20, t
# swap.h:3:   *a = *b;
	movl	%esi, (%rdx)	# _38, *_20
# swap.h:4:   *b = t;
	movl	%ecx, (%rax)	# t, *_17
# quickoswaparray.h:35: }
	movl	%r12d, %eax	# <retval>,
	popq	%rbx	#
	.cfi_def_cfa_offset 24
	popq	%rbp	#
	.cfi_def_cfa_offset 16
	popq	%r12	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE5428:
	.size	partition_quick_optimized_swap_array, .-partition_quick_optimized_swap_array
	.p2align 4
	.globl	partition_quick_optimized_swap_asm
	.type	partition_quick_optimized_swap_asm, @function
partition_quick_optimized_swap_asm:
.LFB5430:
	.cfi_startproc
	endbr64	
	pushq	%r14	#
	.cfi_def_cfa_offset 16
	.cfi_offset 14, -16
	pushq	%r13	#
	.cfi_def_cfa_offset 24
	.cfi_offset 13, -24
	movq	%rdx, %r13	# tmp93, high
	pushq	%r12	#
	.cfi_def_cfa_offset 32
	.cfi_offset 12, -32
	pushq	%rbp	#
	.cfi_def_cfa_offset 40
	.cfi_offset 6, -40
	movq	%rdi, %rbp	# tmp91, array
	pushq	%rbx	#
	.cfi_def_cfa_offset 48
	.cfi_offset 3, -48
# quickoswapasm.h:21: int partition_quick_optimized_swap_asm(int array[], int64_t low, int64_t high) {
	movq	%rsi, %rbx	# tmp92, low
# quickoswapasm.h:22:   int pivot = median_of_three_of_median_of_three(array, low, high);
	call	median_of_three_of_median_of_three	#
	movl	%eax, %r14d	#, tmp94
# quickoswapasm.h:25:   asm volatile("    movq    %[i], %%r12\n"
	movq	%rbx, %rax	# low, low
#APP
# 25 "quickoswapasm.h" 1
	    movq    %rax, %r12	# low
1:

    movl     (%rbp,%r12,4), %r8d	# array
    movl     (%rbp,%rax,4), %r9d	# array, low
    xorq      %r10, %r10
    cmp      %r14d, %r8d	# tmp94
    setl     %r10b
    movl     %r9d, %r11d
    cmovll   %r8d, %r11d
    movl     %r11d, (%rbp,%rax,4)	# array, low
    cmovll   %r9d, %r8d
    movl     %r8d, (%rbp,%r12,4)	# array
    addq     %r10, %rax	# low

    incq     %r12
    cmp      %r12, %r13	# high
    jne      1b

    movl     (%rbp,%rax,4), %r9d	# array, low
    movl     (%rbp,%r13,4), %r8d	# array, high
    movl     %r9d, (%rbp,%r13,4)	# array, high
    movl     %r8d, (%rbp,%rax,4)	# array, low

# 0 "" 2
# quickoswapasm.h:52: }
#NO_APP
	popq	%rbx	#
	.cfi_def_cfa_offset 40
	popq	%rbp	#
	.cfi_def_cfa_offset 32
	popq	%r12	#
	.cfi_def_cfa_offset 24
	popq	%r13	#
	.cfi_def_cfa_offset 16
	popq	%r14	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE5430:
	.size	partition_quick_optimized_swap_asm, .-partition_quick_optimized_swap_asm
	.p2align 4
	.globl	partition_quick_optimized_swap_cmov
	.type	partition_quick_optimized_swap_cmov, @function
partition_quick_optimized_swap_cmov:
.LFB5723:
	.cfi_startproc
	endbr64	
	pushq	%r12	#
	.cfi_def_cfa_offset 16
	.cfi_offset 12, -16
	movl	%esi, %r12d	# tmp131, low
	pushq	%rbp	#
	.cfi_def_cfa_offset 24
	.cfi_offset 6, -24
	movslq	%edx, %rbp	# tmp132,
	movl	%ebp, %edx	# high,
	pushq	%rbx	#
	.cfi_def_cfa_offset 32
	.cfi_offset 3, -32
	movq	%rdi, %rbx	# tmp130, array
	call	median_of_three_of_median_of_three	#
	cmpl	%ebp, %r12d	# high, low
	jge	.L1544	#,
	leal	-1(%rbp), %edx	#, tmp116
	movslq	%r12d, %rsi	# low, _50
	subl	%r12d, %edx	# low, tmp118
	addq	%rsi, %rdx	# _50, tmp119
	movl	%eax, %r9d	# tmp133, pivot
	leaq	4(%rbx,%rdx,4), %r10	#, _39
	leaq	(%rbx,%rsi,4), %rax	#, ivtmp.2036
	.p2align 4,,10
	.p2align 3
.L1540:
	movl	(%rax), %ecx	# MEM[base: _10, offset: 0B], _46
	leaq	(%rbx,%rsi,4), %rdx	#, _41
	movl	(%rdx), %edi	# *_41, y
	cmpl	%ecx, %r9d	# _46, pivot
	jle	.L1541	#,
	movl	%ecx, (%rdx)	# _46, *_41
	incl	%r12d	# <retval>
	movl	%edi, (%rax)	# y, MEM[base: _10, offset: 0B]
	addq	$4, %rax	#, ivtmp.2036
	movslq	%r12d, %rsi	# <retval>, <retval>
	cmpq	%rax, %r10	# ivtmp.2036, _39
	jne	.L1540	#,
.L1539:
	leaq	(%rbx,%rbp,4), %rax	#, _26
	leaq	(%rbx,%rsi,4), %rdx	#, _30
	movl	(%rdx), %ecx	# *_30, t
	movl	(%rax), %esi	# *_26, _32
	movl	%esi, (%rdx)	# _32, *_30
	movl	%ecx, (%rax)	# t, *_26
	movl	%r12d, %eax	# <retval>,
	popq	%rbx	#
	.cfi_remember_state
	.cfi_def_cfa_offset 24
	popq	%rbp	#
	.cfi_def_cfa_offset 16
	popq	%r12	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1541:
	.cfi_restore_state
	addq	$4, %rax	#, ivtmp.2036
	cmpq	%rax, %r10	# ivtmp.2036, _39
	jne	.L1540	#,
	jmp	.L1539	#
	.p2align 4,,10
	.p2align 3
.L1544:
	movslq	%r12d, %rsi	# <retval>, <retval>
	jmp	.L1539	#
	.cfi_endproc
.LFE5723:
	.size	partition_quick_optimized_swap_cmov, .-partition_quick_optimized_swap_cmov
	.p2align 4
	.globl	partition_quick_tuned
	.type	partition_quick_tuned, @function
partition_quick_tuned:
.LFB5434:
	.cfi_startproc
	endbr64	
# quickotuned.h:22: int partition_quick_tuned(int array[], int low, int high) {
	pushq	%r12	#
	.cfi_def_cfa_offset 16
	.cfi_offset 12, -16
	movslq	%edx, %r12	# tmp132,
# quickotuned.h:23:   int pivot = median_of_three_of_median_of_three(array, low, high);
	movl	%r12d, %edx	# high,
# quickotuned.h:22: int partition_quick_tuned(int array[], int low, int high) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 24
	.cfi_offset 6, -24
	movq	%rdi, %rbp	# tmp130, array
	pushq	%rbx	#
	.cfi_def_cfa_offset 32
	.cfi_offset 3, -32
# quickotuned.h:22: int partition_quick_tuned(int array[], int low, int high) {
	movl	%esi, %ebx	# tmp131, low
# quickotuned.h:23:   int pivot = median_of_three_of_median_of_three(array, low, high);
	call	median_of_three_of_median_of_three	#
# quickotuned.h:27:   while(q < high){
	cmpl	%r12d, %ebx	# high, low
	jge	.L1550	#,
	movl	%eax, %r8d	# tmp133, pivot
	leal	-1(%rbx), %esi	#, p
	movslq	%ebx, %rax	# low, ivtmp.2046
# quickotuned.h:31:     int delta = smaller * (q - p);
	xorl	%r10d, %r10d	# tmp119
	.p2align 4,,10
	.p2align 3
.L1549:
# quickotuned.h:28:     int x = array[q];
	movl	0(%rbp,%rax,4), %edi	# MEM[base: array_27(D), index: ivtmp.2046_80, step: 4, offset: 0B], x
# quickotuned.h:29:     bool smaller = x < pivot;
	xorl	%edx, %edx	# smaller
	cmpl	%edi, %r8d	# x, pivot
	setg	%dl	#, smaller
# quickotuned.h:30:     p += smaller;
	addl	%edx, %esi	# smaller, p
# quickotuned.h:31:     int delta = smaller * (q - p);
	movl	%eax, %edx	# ivtmp.2046, tmp118
	subl	%esi, %edx	# p, tmp118
# quickotuned.h:31:     int delta = smaller * (q - p);
	cmpl	%edi, %r8d	# x, pivot
	cmovle	%r10d, %edx	# tmp118,, tmp119, tmp118
# quickotuned.h:34:     array[s] = array[p];
	movslq	%esi, %rcx	# p, p
	movl	0(%rbp,%rcx,4), %r9d	# *_9, _13
# quickotuned.h:32:     int s = p + delta;
	leal	(%rsi,%rdx), %ecx	#, s
# quickotuned.h:34:     array[s] = array[p];
	movslq	%ecx, %rcx	# s, s
# quickotuned.h:34:     array[s] = array[p];
	movl	%r9d, 0(%rbp,%rcx,4)	# _13, *_12
# quickotuned.h:33:     int t = q - delta;
	movl	%eax, %ecx	# ivtmp.2046, t
	subl	%edx, %ecx	# tmp118, t
# quickotuned.h:35:     array[t] = x;
	movslq	%ecx, %rdx	# t, t
# quickotuned.h:27:   while(q < high){
	incq	%rax	# ivtmp.2046
# quickotuned.h:35:     array[t] = x;
	movl	%edi, 0(%rbp,%rdx,4)	# x, *_16
# quickotuned.h:27:   while(q < high){
	cmpl	%eax, %r12d	# ivtmp.2046, high
	jg	.L1549	#,
# quickotuned.h:38:   p++;
	leal	1(%rsi), %eax	#, <retval>
.L1548:
# quickotuned.h:39:   swap(&array[p], &array[high]);
	movslq	%eax, %rcx	# <retval>, <retval>
# quickotuned.h:39:   swap(&array[p], &array[high]);
	leaq	0(%rbp,%r12,4), %rdx	#, _19
	leaq	0(%rbp,%rcx,4), %rcx	#, _22
# swap.h:2:   int t = *a;
	movl	(%rcx), %esi	# *_22, t
# swap.h:3:   *a = *b;
	movl	(%rdx), %edi	# *_19, _44
# swap.h:3:   *a = *b;
	movl	%edi, (%rcx)	# _44, *_22
# swap.h:4:   *b = t;
	movl	%esi, (%rdx)	# t, *_19
# quickotuned.h:41: }
	popq	%rbx	#
	.cfi_remember_state
	.cfi_def_cfa_offset 24
	popq	%rbp	#
	.cfi_def_cfa_offset 16
	popq	%r12	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1550:
	.cfi_restore_state
# quickotuned.h:27:   while(q < high){
	movl	%ebx, %eax	# low, <retval>
	jmp	.L1548	#
	.cfi_endproc
.LFE5434:
	.size	partition_quick_tuned, .-partition_quick_tuned
	.p2align 4
	.globl	sort_quick_tuned
	.type	sort_quick_tuned, @function
sort_quick_tuned:
.LFB5435:
	.cfi_startproc
	endbr64	
	pushq	%r15	#
	.cfi_def_cfa_offset 16
	.cfi_offset 15, -16
	pushq	%r14	#
	.cfi_def_cfa_offset 24
	.cfi_offset 14, -24
	pushq	%r13	#
	.cfi_def_cfa_offset 32
	.cfi_offset 13, -32
	pushq	%r12	#
	.cfi_def_cfa_offset 40
	.cfi_offset 12, -40
	pushq	%rbp	#
	.cfi_def_cfa_offset 48
	.cfi_offset 6, -48
	pushq	%rbx	#
	.cfi_def_cfa_offset 56
	.cfi_offset 3, -56
	subq	$72, %rsp	#,
	.cfi_def_cfa_offset 128
# quickotuned.h:43: void sort_quick_tuned(int array[], int low, int high) {
	movl	%edx, 16(%rsp)	# high, %sfp
# quickotuned.h:44:   if (low < high) {
	cmpl	%edx, %esi	# high, low
	jge	.L1926	#,
	movl	%edx, %eax	# tmp599, high
# quickotuned.h:45:     if (high - low > 16) {
	subl	%esi, %eax	# low, _232
	movq	%rdi, %rbx	# tmp597, array
	movl	%esi, %ebp	# tmp598, low
	movl	%esi, %r12d	# low, low
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _232
	jle	.L1556	#,
.L1555:
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	16(%rsp), %edx	# %sfp,
	movl	%r12d, %esi	# low,
	movq	%rbx, %rdi	# array,
	call	partition_quick_tuned	#
	movl	%eax, 40(%rsp)	# pi, %sfp
# quickotuned.h:47:       sort_quick_tuned(array, low, pi - 1);
	decl	%eax	# _2
	movl	%eax, 8(%rsp)	# _2, %sfp
# quickotuned.h:44:   if (low < high) {
	cmpl	%r12d, %eax	# low, _2
	jle	.L1564	#,
# quickotuned.h:45:     if (high - low > 16) {
	subl	%r12d, %eax	# low, _169
	movq	%rbx, %r15	# array, array
	movl	%r12d, %ebp	# low, low
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _169
	jle	.L1561	#,
.L1560:
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	8(%rsp), %edx	# %sfp,
	movl	%ebp, %esi	# low,
	movq	%r15, %rdi	# array,
	call	partition_quick_tuned	#
	movl	%eax, 44(%rsp)	# pi, %sfp
# quickotuned.h:47:       sort_quick_tuned(array, low, pi - 1);
	decl	%eax	# _22
	movl	%eax, 12(%rsp)	# _22, %sfp
# quickotuned.h:44:   if (low < high) {
	cmpl	%ebp, %eax	# low, _22
	jle	.L1569	#,
# quickotuned.h:45:     if (high - low > 16) {
	subl	%ebp, %eax	# low, _106
	movq	%r15, %r14	# array, array
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _106
	jle	.L1566	#,
.L1565:
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	12(%rsp), %edx	# %sfp,
	movl	%ebp, %esi	# low,
	movq	%r14, %rdi	# array,
	call	partition_quick_tuned	#
# quickotuned.h:47:       sort_quick_tuned(array, low, pi - 1);
	leal	-1(%rax), %r15d	#, _31
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	%eax, 48(%rsp)	# pi, %sfp
# quickotuned.h:44:   if (low < high) {
	cmpl	%ebp, %r15d	# low, _31
	jle	.L1574	#,
# quickotuned.h:45:     if (high - low > 16) {
	movl	%r15d, %eax	# _31, _69
	subl	%ebp, %eax	# low, _69
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _69
	jle	.L1571	#,
	movl	%r15d, 20(%rsp)	# _31, %sfp
	movl	%ebp, %r15d	# low, low
.L1570:
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	20(%rsp), %edx	# %sfp,
	movl	%r15d, %esi	# low,
	movq	%r14, %rdi	# array,
	call	partition_quick_tuned	#
# quickotuned.h:47:       sort_quick_tuned(array, low, pi - 1);
	leal	-1(%rax), %r13d	#, _40
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	%eax, 52(%rsp)	# pi, %sfp
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, %r13d	# low, _40
	jle	.L1579	#,
# quickotuned.h:45:     if (high - low > 16) {
	movl	%r13d, %eax	# _40, _42
	subl	%r15d, %eax	# low, _42
	movl	%r13d, %ebp	# _40, _40
	movq	%r14, %r12	# array, array
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _42
	jle	.L1576	#,
.L1575:
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	%ebp, %edx	# _40,
	movl	%r15d, %esi	# low,
	movq	%r12, %rdi	# array,
	call	partition_quick_tuned	#
# quickotuned.h:47:       sort_quick_tuned(array, low, pi - 1);
	leal	-1(%rax), %r14d	#, _49
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	%eax, 56(%rsp)	# pi, %sfp
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, %r14d	# low, _49
	jle	.L1584	#,
# quickotuned.h:45:     if (high - low > 16) {
	movl	%r14d, %edx	# _49, _56
	subl	%r15d, %edx	# low, _56
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %edx	#, _56
	jle	.L1581	#,
	movl	%ebp, 24(%rsp)	# _40, %sfp
.L1580:
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	%r14d, %edx	# _49,
	movl	%r15d, %esi	# low,
	movq	%r12, %rdi	# array,
	call	partition_quick_tuned	#
# quickotuned.h:47:       sort_quick_tuned(array, low, pi - 1);
	leal	-1(%rax), %ebx	#, _58
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	%eax, 60(%rsp)	# pi, %sfp
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, %ebx	# low, _58
	jle	.L1589	#,
# quickotuned.h:45:     if (high - low > 16) {
	movl	%ebx, %eax	# _58, _65
	subl	%r15d, %eax	# low, _65
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _65
	jle	.L1586	#,
	movl	%r14d, 28(%rsp)	# _49, %sfp
.L1585:
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	%ebx, %edx	# _58,
	movl	%r15d, %esi	# low,
	movq	%r12, %rdi	# array,
	call	partition_quick_tuned	#
# quickotuned.h:47:       sort_quick_tuned(array, low, pi - 1);
	leal	-1(%rax), %ebp	#, _67
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	%eax, %r14d	# tmp606, pi
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, %ebp	# low, _67
	jle	.L1594	#,
# quickotuned.h:45:     if (high - low > 16) {
	movl	%ebp, %eax	# _67, _170
	subl	%r15d, %eax	# low, _170
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _170
	jle	.L1591	#,
	movl	%ebx, 32(%rsp)	# _58, %sfp
	movq	%r12, %rbx	# array, array
	movl	%ebp, %r12d	# _67, _67
.L1590:
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	%r12d, %edx	# _67,
	movl	%r15d, %esi	# low,
	movq	%rbx, %rdi	# array,
	call	partition_quick_tuned	#
# quickotuned.h:47:       sort_quick_tuned(array, low, pi - 1);
	leal	-1(%rax), %r13d	#, _76
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	%eax, %ebp	# tmp607, pi
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, %r13d	# low, _76
	jle	.L1598	#,
# quickotuned.h:45:     if (high - low > 16) {
	movl	%r13d, %eax	# _76, _83
	subl	%r15d, %eax	# low, _83
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _83
	jle	.L1596	#,
	movl	%ebp, 36(%rsp)	# pi, %sfp
	movq	%rbx, %rbp	# array, array
.L1595:
# quickotuned.h:46:       int pi = partition_quick_tuned(array, low, high);
	movl	%r15d, %esi	# low,
	movl	%r13d, %edx	# _76,
	movq	%rbp, %rdi	# array,
	call	partition_quick_tuned	#
	movl	%eax, %ebx	# tmp608, pi
# quickotuned.h:47:       sort_quick_tuned(array, low, pi - 1);
	movl	%r15d, %esi	# low,
	leal	-1(%rax), %edx	#, tmp569
	movq	%rbp, %rdi	# array,
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	leal	1(%rbx), %r15d	#, low
# quickotuned.h:47:       sort_quick_tuned(array, low, pi - 1);
	call	sort_quick_tuned	#
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, %r13d	# low, _76
	jle	.L1929	#,
# quickotuned.h:45:     if (high - low > 16) {
	movl	%r13d, %eax	# _76, _83
	subl	%r15d, %eax	# low, _83
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _83
	jg	.L1595	#,
	movq	%rbp, %rbx	# array, array
	movl	36(%rsp), %ebp	# %sfp, pi
.L1596:
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%r15d, %r15	# low, low
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	leaq	(%rbx,%r15,4), %rdi	#, _90
	movq	%rdi, %r10	# _90, ivtmp.2387
	leal	-1(%rax), %r9d	#, _2215
	movl	$-1, %ecx	#, ivtmp.2405
.L1602:
	movq	%r10, %rax	# ivtmp.2387, ivtmp.2387
# insertionssort.h:6:     element = array[i];
	movl	4(%rax), %esi	# MEM[base: _2149, offset: 4B], element
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	(%rax), %r8d	# MEM[base: _2149, offset: 0B], _1889
	addq	$4, %r10	#, ivtmp.2387
	movq	%r10, %rdx	# ivtmp.2387, prephitmp_659
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _1889, element
	jge	.L1599	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, 4(%rax)	# _1889, MEM[base: _2149, offset: 4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$-1, %ecx	#, ivtmp.2405
	jne	.L1930	#,
.L1657:
	movq	%rdi, %rdx	# _90, prephitmp_659
.L1599:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incl	%ecx	# ivtmp.2405
# insertionssort.h:13:     array[j + 1] = element;
	movl	%esi, (%rdx)	# element, *prephitmp_659
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	cmpl	%r9d, %ecx	# _2215, ivtmp.2405
	jne	.L1602	#,
.L1598:
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	leal	1(%rbp), %r15d	#, low
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, %r12d	# low, _67
	jle	.L1931	#,
# quickotuned.h:45:     if (high - low > 16) {
	movl	%r12d, %eax	# _67, _170
	subl	%r15d, %eax	# low, _170
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _170
	jg	.L1590	#,
	movq	%rbx, %r12	# array, array
	movl	32(%rsp), %ebx	# %sfp, _58
.L1591:
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%r15d, %r15	# low, low
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	leaq	(%r12,%r15,4), %rdi	#, _81
	movq	%rdi, %r9	# _81, ivtmp.2348
	leal	-1(%rax), %r8d	#, _2110
	movl	$-1, %ecx	#, ivtmp.2366
.L1606:
	movq	%r9, %rax	# ivtmp.2348, ivtmp.2348
# insertionssort.h:6:     element = array[i];
	movl	4(%rax), %esi	# MEM[base: _2012, offset: 4B], element
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	(%rax), %r10d	# MEM[base: _2012, offset: 0B], _1697
	addq	$4, %r9	#, ivtmp.2348
	movq	%r9, %rdx	# ivtmp.2348, prephitmp_684
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1697, element
	jge	.L1603	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, 4(%rax)	# _1697, MEM[base: _2012, offset: 4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$-1, %ecx	#, ivtmp.2366
	jne	.L1932	#,
.L1680:
	movq	%rdi, %rdx	# _81, prephitmp_684
.L1603:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incl	%ecx	# ivtmp.2366
# insertionssort.h:13:     array[j + 1] = element;
	movl	%esi, (%rdx)	# element, *prephitmp_684
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	cmpl	%r8d, %ecx	# _2110, ivtmp.2366
	jne	.L1606	#,
.L1594:
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	leal	1(%r14), %r15d	#, low
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, %ebx	# low, _58
	jle	.L1933	#,
.L1588:
# quickotuned.h:45:     if (high - low > 16) {
	movl	%ebx, %eax	# _58, _65
	subl	%r15d, %eax	# low, _65
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _65
	jg	.L1585	#,
	movl	28(%rsp), %r14d	# %sfp, _49
.L1586:
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%r15d, %r15	# low, low
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	leaq	(%r12,%r15,4), %rdi	#, _72
	movq	%rdi, %r9	# _72, ivtmp.2309
	leal	-1(%rax), %r8d	#, _1917
	movl	$-1, %ecx	#, ivtmp.2327
.L1610:
	movq	%r9, %rax	# ivtmp.2309, ivtmp.2309
# insertionssort.h:6:     element = array[i];
	movl	4(%rax), %esi	# MEM[base: _1772, offset: 4B], element
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	(%rax), %r10d	# MEM[base: _1772, offset: 0B], _1505
	addq	$4, %r9	#, ivtmp.2309
	movq	%r9, %rdx	# ivtmp.2309, prephitmp_709
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1505, element
	jge	.L1607	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, 4(%rax)	# _1505, MEM[base: _1772, offset: 4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$-1, %ecx	#, ivtmp.2327
	jne	.L1934	#,
.L1703:
	movq	%rdi, %rdx	# _72, prephitmp_709
.L1607:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incl	%ecx	# ivtmp.2327
# insertionssort.h:13:     array[j + 1] = element;
	movl	%esi, (%rdx)	# element, *prephitmp_709
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	cmpl	%r8d, %ecx	# _1917, ivtmp.2327
	jne	.L1610	#,
.L1589:
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	movl	60(%rsp), %r15d	# %sfp, pi
	incl	%r15d	# pi
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, %r14d	# low, _49
	jle	.L1935	#,
.L1583:
# quickotuned.h:45:     if (high - low > 16) {
	movl	%r14d, %edx	# _49, _56
	subl	%r15d, %edx	# low, _56
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %edx	#, _56
	jg	.L1580	#,
	movl	24(%rsp), %ebp	# %sfp, _40
.L1581:
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%r15d, %r15	# low, low
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	leaq	(%r12,%r15,4), %rdi	#, _63
	movq	%rdi, %rax	# _63, ivtmp.2270
	leal	-1(%rdx), %r8d	#, _1689
	movl	$-1, %ecx	#, ivtmp.2288
.L1614:
# insertionssort.h:6:     element = array[i];
	movl	4(%rax), %esi	# MEM[base: _1532, offset: 4B], element
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	(%rax), %r10d	# MEM[base: _1532, offset: 0B], _1313
	leaq	4(%rax), %r9	#, _1616
	movq	%r9, %rdx	# _1616, prephitmp_734
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1313, element
	jge	.L1611	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, 4(%rax)	# _1313, MEM[base: _1532, offset: 4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$-1, %ecx	#, ivtmp.2288
	jne	.L1936	#,
.L1726:
	movq	%rdi, %rdx	# _63, prephitmp_734
.L1611:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incl	%ecx	# ivtmp.2288
# insertionssort.h:13:     array[j + 1] = element;
	movl	%esi, (%rdx)	# element, *prephitmp_734
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	cmpl	%r8d, %ecx	# _1689, ivtmp.2288
	jne	.L1937	#,
.L1584:
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	movl	56(%rsp), %r15d	# %sfp, pi
	incl	%r15d	# pi
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, %ebp	# low, _40
	jle	.L1938	#,
.L1578:
# quickotuned.h:45:     if (high - low > 16) {
	movl	%ebp, %eax	# _40, _42
	subl	%r15d, %eax	# low, _42
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _42
	jg	.L1575	#,
	movq	%r12, %r14	# array, array
.L1576:
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%r15d, %rsi	# low, low
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	leaq	(%r14,%rsi,4), %rdi	#, _54
	movq	%rdi, %r9	# _54, ivtmp.2231
	leal	-1(%rax), %r8d	#, _1449
	movl	$-1, %ecx	#, ivtmp.2249
.L1618:
	movq	%r9, %rax	# ivtmp.2231, ivtmp.2231
# insertionssort.h:6:     element = array[i];
	movl	4(%rax), %esi	# MEM[base: _1304, offset: 4B], element
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	(%rax), %r10d	# MEM[base: _1304, offset: 0B], _1121
	addq	$4, %r9	#, ivtmp.2231
	movq	%r9, %rdx	# ivtmp.2231, prephitmp_759
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1121, element
	jge	.L1615	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, 4(%rax)	# _1121, MEM[base: _1304, offset: 4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _54, prephitmp_759
	cmpl	$-1, %ecx	#, ivtmp.2249
	jne	.L1939	#,
.L1615:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incl	%ecx	# ivtmp.2249
# insertionssort.h:13:     array[j + 1] = element;
	movl	%esi, (%rdx)	# element, *prephitmp_759
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	cmpl	%r8d, %ecx	# _1449, ivtmp.2249
	jne	.L1618	#,
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	movl	52(%rsp), %r15d	# %sfp, pi
	incl	%r15d	# pi
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, 20(%rsp)	# low, %sfp
	jg	.L1573	#,
.L1574:
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	movl	48(%rsp), %ebp	# %sfp, pi
	incl	%ebp	# pi
# quickotuned.h:44:   if (low < high) {
	cmpl	%ebp, 12(%rsp)	# low, %sfp
	jle	.L1940	#,
# quickotuned.h:45:     if (high - low > 16) {
	movl	12(%rsp), %eax	# %sfp, _106
	subl	%ebp, %eax	# low, _106
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _106
	jg	.L1565	#,
	movq	%r14, %r15	# array, array
.L1566:
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%ebp, %rsi	# low, low
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	leaq	(%r15,%rsi,4), %rsi	#, _36
	movq	%rsi, %r9	# _36, ivtmp.2153
	leal	-1(%rax), %r8d	#, _969
	movl	$-1, %ecx	#, ivtmp.2171
.L1626:
	movq	%r9, %rax	# ivtmp.2153, ivtmp.2153
# insertionssort.h:6:     element = array[i];
	movl	4(%rax), %edi	# MEM[base: _706, offset: 4B], element
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	(%rax), %r10d	# MEM[base: _706, offset: 0B], _741
	addq	$4, %r9	#, ivtmp.2153
	movq	%r9, %rdx	# ivtmp.2153, prephitmp_809
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _741, element
	jge	.L1623	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, 4(%rax)	# _741, MEM[base: _706, offset: 4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$-1, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %r10d	# MEM[base: _706, offset: -4B], _713
	leaq	-4(%rax), %rdx	#, prephitmp_809
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _713, element
	jge	.L1775	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, (%rax)	# _713, MEM[base: _706, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	testl	%ecx, %ecx	# ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-8(%rax), %r10d	# MEM[base: _706, offset: -8B], _695
	leaq	-8(%rax), %r11	#, _920
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _695, element
	jge	.L1623	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -4(%rax)	# _695, MEM[base: _706, offset: -4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$1, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-12(%rax), %r10d	# MEM[base: _706, offset: -12B], _668
	leaq	-12(%rax), %rdx	#, prephitmp_809
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _668, element
	jge	.L1795	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -8(%rax)	# _668, MEM[base: _706, offset: -8B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$2, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-16(%rax), %r10d	# MEM[base: _706, offset: -16B], _657
	leaq	-16(%rax), %r11	#, _870
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _657, element
	jge	.L1623	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -12(%rax)	# _657, MEM[base: _706, offset: -12B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$3, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-20(%rax), %r10d	# MEM[base: _706, offset: -20B], _637
	leaq	-20(%rax), %rdx	#, prephitmp_809
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _637, element
	jge	.L1795	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -16(%rax)	# _637, MEM[base: _706, offset: -16B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$4, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-24(%rax), %r10d	# MEM[base: _706, offset: -24B], _110
	leaq	-24(%rax), %r11	#, _930
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edi, %r10d	# element, _110
	jle	.L1623	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -20(%rax)	# _110, MEM[base: _706, offset: -20B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$5, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-28(%rax), %r10d	# MEM[base: _706, offset: -28B], _131
	leaq	-28(%rax), %rdx	#, prephitmp_809
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edi, %r10d	# element, _131
	jle	.L1795	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -24(%rax)	# _131, MEM[base: _706, offset: -24B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$6, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-32(%rax), %r10d	# MEM[base: _706, offset: -32B], _152
	leaq	-32(%rax), %r11	#, _936
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edi, %r10d	# element, _152
	jle	.L1623	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -28(%rax)	# _152, MEM[base: _706, offset: -28B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$7, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-36(%rax), %r10d	# MEM[base: _706, offset: -36B], _173
	leaq	-36(%rax), %rdx	#, prephitmp_809
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edi, %r10d	# element, _173
	jle	.L1795	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -32(%rax)	# _173, MEM[base: _706, offset: -32B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$8, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-40(%rax), %r10d	# MEM[base: _706, offset: -40B], _194
	leaq	-40(%rax), %r11	#, _945
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edi, %r10d	# element, _194
	jle	.L1623	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -36(%rax)	# _194, MEM[base: _706, offset: -36B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$9, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-44(%rax), %r10d	# MEM[base: _706, offset: -44B], _215
	leaq	-44(%rax), %rdx	#, prephitmp_809
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edi, %r10d	# element, _215
	jle	.L1795	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -40(%rax)	# _215, MEM[base: _706, offset: -40B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$10, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-48(%rax), %r10d	# MEM[base: _706, offset: -48B], _236
	leaq	-48(%rax), %rbx	#, _956
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _236, element
	jge	.L1623	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -44(%rax)	# _236, MEM[base: _706, offset: -44B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$11, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-52(%rax), %edx	# MEM[base: _706, offset: -52B], _257
	leaq	-52(%rax), %r11	#, _960
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %edi	# _257, element
	jge	.L1793	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, -48(%rax)	# _257, MEM[base: _706, offset: -48B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$12, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-56(%rax), %r10d	# MEM[base: _706, offset: -56B], _278
	leaq	-56(%rax), %rdx	#, prephitmp_809
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _278, element
	jge	.L1795	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -52(%rax)	# _278, MEM[base: _706, offset: -52B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$13, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-60(%rax), %r10d	# MEM[base: _706, offset: -60B], _917
	leaq	-60(%rax), %r11	#, _907
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _917, element
	jge	.L1623	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -56(%rax)	# _917, MEM[base: _706, offset: -56B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$14, %ecx	#, ivtmp.2171
	je	.L1796	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-64(%rax), %edx	# MEM[base: _706, offset: -64B], _227
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %edi	# _227, element
	jge	.L1795	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, -60(%rax)	# _227, MEM[base: _706, offset: -60B]
	movq	%rsi, %rdx	# _36, prephitmp_809
.L1623:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incl	%ecx	# ivtmp.2171
# insertionssort.h:13:     array[j + 1] = element;
	movl	%edi, (%rdx)	# element, *prephitmp_809
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	cmpl	%r8d, %ecx	# _969, ivtmp.2171
	jne	.L1626	#,
.L1569:
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	movl	44(%rsp), %ebp	# %sfp, pi
	incl	%ebp	# pi
# quickotuned.h:44:   if (low < high) {
	cmpl	%ebp, 8(%rsp)	# low, %sfp
	jle	.L1941	#,
# quickotuned.h:45:     if (high - low > 16) {
	movl	8(%rsp), %eax	# %sfp, _169
	subl	%ebp, %eax	# low, _169
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _169
	jg	.L1560	#,
	movq	%r15, %rbx	# array, array
	movl	%ebp, %r12d	# low, low
.L1561:
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%r12d, %rsi	# low, low
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	leaq	(%rbx,%rsi,4), %rsi	#, _27
	movq	%rsi, %r9	# _27, ivtmp.2114
	leal	-1(%rax), %r8d	#, _868
	movl	$-1, %ecx	#, ivtmp.2132
.L1630:
	movq	%r9, %rax	# ivtmp.2114, ivtmp.2114
# insertionssort.h:6:     element = array[i];
	movl	4(%rax), %edi	# MEM[base: _381, offset: 4B], element
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	(%rax), %r10d	# MEM[base: _381, offset: 0B], _510
	addq	$4, %r9	#, ivtmp.2114
	movq	%r9, %rdx	# ivtmp.2114, _46
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _510, element
	jge	.L1627	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, 4(%rax)	# _510, MEM[base: _381, offset: 4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$-1, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %r10d	# MEM[base: _381, offset: -4B], _408
	leaq	-4(%rax), %rdx	#, _46
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _408, element
	jge	.L1798	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, (%rax)	# _408, MEM[base: _381, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	testl	%ecx, %ecx	# ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-8(%rax), %r10d	# MEM[base: _381, offset: -8B], _396
	leaq	-8(%rax), %r11	#, _840
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _396, element
	jge	.L1627	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -4(%rax)	# _396, MEM[base: _381, offset: -4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$1, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-12(%rax), %r10d	# MEM[base: _381, offset: -12B], _384
	leaq	-12(%rax), %rdx	#, _46
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _384, element
	jge	.L1819	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -8(%rax)	# _384, MEM[base: _381, offset: -8B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$2, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-16(%rax), %r10d	# MEM[base: _381, offset: -16B], _372
	leaq	-16(%rax), %r11	#, _820
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _372, element
	jge	.L1627	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -12(%rax)	# _372, MEM[base: _381, offset: -12B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$3, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-20(%rax), %r10d	# MEM[base: _381, offset: -20B], _360
	leaq	-20(%rax), %rdx	#, _46
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _360, element
	jge	.L1819	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -16(%rax)	# _360, MEM[base: _381, offset: -16B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$4, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-24(%rax), %r10d	# MEM[base: _381, offset: -24B], _348
	leaq	-24(%rax), %r11	#, _805
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _348, element
	jge	.L1627	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -20(%rax)	# _348, MEM[base: _381, offset: -20B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$5, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-28(%rax), %r10d	# MEM[base: _381, offset: -28B], _297
	leaq	-28(%rax), %rdx	#, _46
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _297, element
	jge	.L1819	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -24(%rax)	# _297, MEM[base: _381, offset: -24B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$6, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-32(%rax), %r10d	# MEM[base: _381, offset: -32B], _212
	leaq	-32(%rax), %r11	#, _790
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edi, %r10d	# element, _212
	jle	.L1627	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -28(%rax)	# _212, MEM[base: _381, offset: -28B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$7, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-36(%rax), %r10d	# MEM[base: _381, offset: -36B], _144
	leaq	-36(%rax), %rdx	#, _46
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edi, %r10d	# element, _144
	jle	.L1819	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -32(%rax)	# _144, MEM[base: _381, offset: -32B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$8, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-40(%rax), %r10d	# MEM[base: _381, offset: -40B], _64
	leaq	-40(%rax), %r11	#, _768
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edi, %r10d	# element, _64
	jle	.L1627	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -36(%rax)	# _64, MEM[base: _381, offset: -36B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$9, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-44(%rax), %r10d	# MEM[base: _381, offset: -44B], _845
	leaq	-44(%rax), %rdx	#, _46
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _845, element
	jge	.L1819	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -40(%rax)	# _845, MEM[base: _381, offset: -40B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$10, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-48(%rax), %r10d	# MEM[base: _381, offset: -48B], _818
	leaq	-48(%rax), %r11	#, _760
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _818, element
	jge	.L1627	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -44(%rax)	# _818, MEM[base: _381, offset: -44B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$11, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-52(%rax), %r10d	# MEM[base: _381, offset: -52B], _807
	leaq	-52(%rax), %rdx	#, _46
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _807, element
	jge	.L1819	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -48(%rax)	# _807, MEM[base: _381, offset: -48B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$12, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-56(%rax), %r10d	# MEM[base: _381, offset: -56B], _787
	leaq	-56(%rax), %r11	#, _866
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _787, element
	jge	.L1627	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -52(%rax)	# _787, MEM[base: _381, offset: -52B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$13, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-60(%rax), %r10d	# MEM[base: _381, offset: -60B], _764
	leaq	-60(%rax), %rdx	#, _46
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _764, element
	jge	.L1819	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -56(%rax)	# _764, MEM[base: _381, offset: -56B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$14, %ecx	#, ivtmp.2132
	je	.L1818	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-64(%rax), %r10d	# MEM[base: _381, offset: -64B], _248
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _248, element
	jge	.L1627	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -60(%rax)	# _248, MEM[base: _381, offset: -60B]
	movq	%rsi, %rdx	# _27, _46
.L1627:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incl	%ecx	# ivtmp.2132
# insertionssort.h:13:     array[j + 1] = element;
	movl	%edi, (%rdx)	# element, *prephitmp_834
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	cmpl	%r8d, %ecx	# _868, ivtmp.2132
	jne	.L1630	#,
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	movl	40(%rsp), %r12d	# %sfp, pi
	incl	%r12d	# pi
# quickotuned.h:44:   if (low < high) {
	cmpl	16(%rsp), %r12d	# %sfp, low
	jl	.L1558	#,
.L1926:
# quickotuned.h:53: }
	addq	$72, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1931:
	.cfi_restore_state
	movq	%rbx, %r12	# array, array
	movl	32(%rsp), %ebx	# %sfp, _58
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	leal	1(%r14), %r15d	#, low
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, %ebx	# low, _58
	jg	.L1588	#,
.L1933:
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	movl	60(%rsp), %r15d	# %sfp, pi
	movl	28(%rsp), %r14d	# %sfp, _49
	incl	%r15d	# pi
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, %r14d	# low, _49
	jg	.L1583	#,
.L1935:
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	movl	56(%rsp), %r15d	# %sfp, pi
	movl	24(%rsp), %ebp	# %sfp, _40
	incl	%r15d	# pi
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, %ebp	# low, _40
	jg	.L1578	#,
.L1938:
	movq	%r12, %r14	# array, array
.L1579:
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	movl	52(%rsp), %r15d	# %sfp, pi
	incl	%r15d	# pi
# quickotuned.h:44:   if (low < high) {
	cmpl	%r15d, 20(%rsp)	# low, %sfp
	jle	.L1574	#,
.L1573:
# quickotuned.h:45:     if (high - low > 16) {
	movl	20(%rsp), %eax	# %sfp, _69
	subl	%r15d, %eax	# low, _69
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _69
	jg	.L1570	#,
	movl	%r15d, %ebp	# low, low
.L1571:
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%ebp, %rsi	# low, low
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	leaq	(%r14,%rsi,4), %rdi	#, _45
	movq	%rdi, %r9	# _45, ivtmp.2192
	leal	-1(%rax), %r8d	#, _1209
	movl	$-1, %ecx	#, ivtmp.2210
	jmp	.L1622	#
.L1619:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incl	%ecx	# ivtmp.2210
# insertionssort.h:13:     array[j + 1] = element;
	movl	%esi, (%rdx)	# element, *prephitmp_784
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	cmpl	%r8d, %ecx	# _1209, ivtmp.2210
	je	.L1574	#,
.L1622:
	movq	%r9, %rax	# ivtmp.2192, ivtmp.2192
# insertionssort.h:6:     element = array[i];
	movl	4(%rax), %esi	# MEM[base: _1064, offset: 4B], element
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	(%rax), %r10d	# MEM[base: _1064, offset: 0B], _929
	addq	$4, %r9	#, ivtmp.2192
	movq	%r9, %rdx	# ivtmp.2192, prephitmp_784
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _929, element
	jge	.L1619	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, 4(%rax)	# _929, MEM[base: _1064, offset: 4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _45, prephitmp_784
	cmpl	$-1, %ecx	#, ivtmp.2210
	je	.L1619	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %r10d	# MEM[base: _1064, offset: -4B], _941
	leaq	-4(%rax), %rdx	#, prephitmp_784
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _941, element
	jge	.L1752	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, (%rax)	# _941, MEM[base: _1064, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	testl	%ecx, %ecx	# ivtmp.2210
	jne	.L1942	#,
.L1773:
	movq	%rdi, %rdx	# _45, prephitmp_784
	jmp	.L1619	#
.L1937:
	movq	%r9, %rax	# _1616, ivtmp.2270
	jmp	.L1614	#
	.p2align 4,,10
	.p2align 3
.L1929:
	movq	%rbp, %rbx	# array, array
	movl	36(%rsp), %ebp	# %sfp, pi
	jmp	.L1598	#
.L1819:
# insertionssort.h:10:       array[j + 1] = array[j];
	movq	%r11, %rdx	# _866, _46
	jmp	.L1627	#
.L1798:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rax, %rdx	# ivtmp.2114, _46
	jmp	.L1627	#
.L1818:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rsi, %rdx	# _27, _46
	jmp	.L1627	#
.L1941:
	movq	%r15, %rbx	# array, array
.L1564:
# quickotuned.h:48:       sort_quick_tuned(array, pi + 1, high);
	movl	40(%rsp), %r12d	# %sfp, pi
	incl	%r12d	# pi
# quickotuned.h:44:   if (low < high) {
	cmpl	16(%rsp), %r12d	# %sfp, low
	jge	.L1926	#,
.L1558:
# quickotuned.h:45:     if (high - low > 16) {
	movl	16(%rsp), %eax	# %sfp, _232
	subl	%r12d, %eax	# low, _232
# quickotuned.h:45:     if (high - low > 16) {
	cmpl	$16, %eax	#, _232
	jg	.L1555	#,
	movl	%r12d, %ebp	# low, low
.L1556:
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	movslq	%ebp, %rsi	# low, low
# quickotuned.h:50:       insertionSortOptimized(array + low, high - low + 1);
	leaq	(%rbx,%rsi,4), %rsi	#, _8
	movq	%rsi, %r9	# _8, ivtmp.2075
	leal	-1(%rax), %r8d	#, _554
	movl	$-1, %ecx	#, ivtmp.2093
.L1634:
	movq	%r9, %rax	# ivtmp.2075, ivtmp.2075
# insertionssort.h:6:     element = array[i];
	movl	4(%rax), %edi	# MEM[base: _1693, offset: 4B], element
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	(%rax), %r10d	# MEM[base: _1693, offset: 0B], _342
	addq	$4, %r9	#, ivtmp.2075
	movq	%r9, %rdx	# ivtmp.2075, _626
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _342, element
	jge	.L1631	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, 4(%rax)	# _342, MEM[base: _1693, offset: 4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$-1, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %r10d	# MEM[base: _1693, offset: -4B], _9
	leaq	-4(%rax), %rdx	#, _626
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edi, %r10d	# element, _9
	jle	.L1821	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, (%rax)	# _9, MEM[base: _1693, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	testl	%ecx, %ecx	# ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-8(%rax), %r10d	# MEM[base: _1693, offset: -8B], _822
	leaq	-8(%rax), %r11	#, _615
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _822, element
	jge	.L1631	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -4(%rax)	# _822, MEM[base: _1693, offset: -4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$1, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-12(%rax), %r10d	# MEM[base: _1693, offset: -12B], _772
	leaq	-12(%rax), %rdx	#, _626
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _772, element
	jge	.L1842	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -8(%rax)	# _772, MEM[base: _1693, offset: -8B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$2, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-16(%rax), %r10d	# MEM[base: _1693, offset: -16B], _722
	leaq	-16(%rax), %r11	#, _604
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _722, element
	jge	.L1631	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -12(%rax)	# _722, MEM[base: _1693, offset: -12B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$3, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-20(%rax), %r10d	# MEM[base: _1693, offset: -20B], _672
	leaq	-20(%rax), %rdx	#, _626
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _672, element
	jge	.L1842	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -16(%rax)	# _672, MEM[base: _1693, offset: -16B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$4, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-24(%rax), %r10d	# MEM[base: _1693, offset: -24B], _630
	leaq	-24(%rax), %r11	#, _593
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _630, element
	jge	.L1631	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -20(%rax)	# _630, MEM[base: _1693, offset: -20B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$5, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-28(%rax), %r10d	# MEM[base: _1693, offset: -28B], _618
	leaq	-28(%rax), %rdx	#, _626
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _618, element
	jge	.L1842	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -24(%rax)	# _618, MEM[base: _1693, offset: -24B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$6, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-32(%rax), %r10d	# MEM[base: _1693, offset: -32B], _606
	leaq	-32(%rax), %r11	#, _587
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _606, element
	jge	.L1631	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -28(%rax)	# _606, MEM[base: _1693, offset: -28B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$7, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-36(%rax), %r10d	# MEM[base: _1693, offset: -36B], _594
	leaq	-36(%rax), %rdx	#, _626
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _594, element
	jge	.L1842	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -32(%rax)	# _594, MEM[base: _1693, offset: -32B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$8, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-40(%rax), %r10d	# MEM[base: _1693, offset: -40B], _582
	leaq	-40(%rax), %r11	#, _578
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _582, element
	jge	.L1631	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -36(%rax)	# _582, MEM[base: _1693, offset: -36B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$9, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-44(%rax), %r10d	# MEM[base: _1693, offset: -44B], _570
	leaq	-44(%rax), %rdx	#, _626
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _570, element
	jge	.L1842	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -40(%rax)	# _570, MEM[base: _1693, offset: -40B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$10, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-48(%rax), %r10d	# MEM[base: _1693, offset: -48B], _558
	leaq	-48(%rax), %r11	#, _567
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _558, element
	jge	.L1631	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -44(%rax)	# _558, MEM[base: _1693, offset: -44B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$11, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-52(%rax), %r10d	# MEM[base: _1693, offset: -52B], _546
	leaq	-52(%rax), %rdx	#, _626
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _546, element
	jge	.L1842	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -48(%rax)	# _546, MEM[base: _1693, offset: -48B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$12, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-56(%rax), %r10d	# MEM[base: _1693, offset: -56B], _534
	leaq	-56(%rax), %r11	#, _556
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _534, element
	jge	.L1631	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -52(%rax)	# _534, MEM[base: _1693, offset: -52B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$13, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-60(%rax), %r10d	# MEM[base: _1693, offset: -60B], _522
	leaq	-60(%rax), %rdx	#, _626
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _522, element
	jge	.L1842	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -56(%rax)	# _522, MEM[base: _1693, offset: -56B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$14, %ecx	#, ivtmp.2093
	je	.L1841	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-64(%rax), %r10d	# MEM[base: _1693, offset: -64B], _269
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %edi	# _269, element
	jge	.L1631	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -60(%rax)	# _269, MEM[base: _1693, offset: -60B]
	movq	%rsi, %rdx	# _8, _626
.L1631:
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	incl	%ecx	# ivtmp.2093
# insertionssort.h:13:     array[j + 1] = element;
	movl	%edi, (%rdx)	# element, *prephitmp_859
# insertionssort.h:5:   for (i = 1; i < n; i++) {
	cmpl	%ecx, %r8d	# ivtmp.2093, _554
	jne	.L1634	#,
# quickotuned.h:53: }
	addq	$72, %rsp	#,
	.cfi_remember_state
	.cfi_def_cfa_offset 56
	popq	%rbx	#
	.cfi_def_cfa_offset 48
	popq	%rbp	#
	.cfi_def_cfa_offset 40
	popq	%r12	#
	.cfi_def_cfa_offset 32
	popq	%r13	#
	.cfi_def_cfa_offset 24
	popq	%r14	#
	.cfi_def_cfa_offset 16
	popq	%r15	#
	.cfi_def_cfa_offset 8
	ret	
.L1793:
	.cfi_restore_state
# insertionssort.h:10:       array[j + 1] = array[j];
	movq	%rbx, %rdx	# _956, prephitmp_809
	jmp	.L1623	#
.L1795:
	movq	%r11, %rdx	# _960, prephitmp_809
	jmp	.L1623	#
.L1775:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rax, %rdx	# ivtmp.2153, prephitmp_809
	jmp	.L1623	#
.L1796:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rsi, %rdx	# _36, prephitmp_809
	jmp	.L1623	#
.L1940:
	movq	%r14, %r15	# array, array
	jmp	.L1569	#
.L1934:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %r10d	# MEM[base: _1772, offset: -4B], _1517
	leaq	-4(%rax), %rdx	#, prephitmp_709
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1517, element
	jge	.L1682	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, (%rax)	# _1517, MEM[base: _1772, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	testl	%ecx, %ecx	# ivtmp.2327
	je	.L1703	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-8(%rax), %r10d	# MEM[base: _1772, offset: -8B], _1529
	leaq	-8(%rax), %r11	#, _1868
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1529, element
	jge	.L1607	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -4(%rax)	# _1529, MEM[base: _1772, offset: -4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$1, %ecx	#, ivtmp.2327
	je	.L1703	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-12(%rax), %r10d	# MEM[base: _1772, offset: -12B], _1541
	leaq	-12(%rax), %rdx	#, prephitmp_709
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1541, element
	jge	.L1702	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -8(%rax)	# _1541, MEM[base: _1772, offset: -8B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$2, %ecx	#, ivtmp.2327
	je	.L1703	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-16(%rax), %r10d	# MEM[base: _1772, offset: -16B], _1553
	leaq	-16(%rax), %r11	#, _1879
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1553, element
	jge	.L1607	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -12(%rax)	# _1553, MEM[base: _1772, offset: -12B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _72, prephitmp_709
	cmpl	$3, %ecx	#, ivtmp.2327
	je	.L1607	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-20(%rax), %r10d	# MEM[base: _1772, offset: -20B], _1565
	leaq	-20(%rax), %rdx	#, prephitmp_709
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1565, element
	jge	.L1702	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -16(%rax)	# _1565, MEM[base: _1772, offset: -16B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$4, %ecx	#, ivtmp.2327
	je	.L1703	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-24(%rax), %r10d	# MEM[base: _1772, offset: -24B], _1577
	leaq	-24(%rax), %r11	#, _889
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1577, element
	jge	.L1607	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -20(%rax)	# _1577, MEM[base: _1772, offset: -20B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _72, prephitmp_709
	cmpl	$5, %ecx	#, ivtmp.2327
	je	.L1607	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-28(%rax), %r10d	# MEM[base: _1772, offset: -28B], _1589
	leaq	-28(%rax), %rdx	#, prephitmp_709
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1589, element
	jge	.L1702	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -24(%rax)	# _1589, MEM[base: _1772, offset: -24B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$6, %ecx	#, ivtmp.2327
	je	.L1703	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-32(%rax), %r10d	# MEM[base: _1772, offset: -32B], _1601
	leaq	-32(%rax), %r11	#, _1884
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1601, element
	jge	.L1607	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -28(%rax)	# _1601, MEM[base: _1772, offset: -28B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _72, prephitmp_709
	cmpl	$7, %ecx	#, ivtmp.2327
	je	.L1607	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-36(%rax), %r10d	# MEM[base: _1772, offset: -36B], _1613
	leaq	-36(%rax), %rdx	#, prephitmp_709
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1613, element
	jge	.L1702	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -32(%rax)	# _1613, MEM[base: _1772, offset: -32B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$8, %ecx	#, ivtmp.2327
	je	.L1703	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-40(%rax), %r10d	# MEM[base: _1772, offset: -40B], _1625
	leaq	-40(%rax), %r11	#, _1893
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1625, element
	jge	.L1607	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -36(%rax)	# _1625, MEM[base: _1772, offset: -36B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _72, prephitmp_709
	cmpl	$9, %ecx	#, ivtmp.2327
	je	.L1607	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-44(%rax), %r10d	# MEM[base: _1772, offset: -44B], _1637
	leaq	-44(%rax), %rdx	#, prephitmp_709
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1637, element
	jge	.L1702	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -40(%rax)	# _1637, MEM[base: _1772, offset: -40B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$10, %ecx	#, ivtmp.2327
	je	.L1703	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-48(%rax), %r10d	# MEM[base: _1772, offset: -48B], _1649
	leaq	-48(%rax), %rbx	#, _1904
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1649, element
	jge	.L1607	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -44(%rax)	# _1649, MEM[base: _1772, offset: -44B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _72, prephitmp_709
	cmpl	$11, %ecx	#, ivtmp.2327
	je	.L1607	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-52(%rax), %r10d	# MEM[base: _1772, offset: -52B], _1661
	leaq	-52(%rax), %r11	#, _1908
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1661, element
	jge	.L1700	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -48(%rax)	# _1661, MEM[base: _1772, offset: -48B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$12, %ecx	#, ivtmp.2327
	je	.L1607	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-56(%rax), %r10d	# MEM[base: _1772, offset: -56B], _1673
	leaq	-56(%rax), %rdx	#, prephitmp_709
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1673, element
	jge	.L1702	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -52(%rax)	# _1673, MEM[base: _1772, offset: -52B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$13, %ecx	#, ivtmp.2327
	je	.L1703	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-60(%rax), %r10d	# MEM[base: _1772, offset: -60B], _1685
	leaq	-60(%rax), %r11	#, _1855
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1685, element
	jge	.L1607	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -56(%rax)	# _1685, MEM[base: _1772, offset: -56B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$14, %ecx	#, ivtmp.2327
	je	.L1703	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-64(%rax), %edx	# MEM[base: _1772, offset: -64B], _143
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %esi	# _143, element
	jge	.L1702	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, -60(%rax)	# _143, MEM[base: _1772, offset: -60B]
	movq	%rdi, %rdx	# _72, prephitmp_709
	jmp	.L1607	#
	.p2align 4,,10
	.p2align 3
.L1939:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %r10d	# MEM[base: _1304, offset: -4B], _1133
	leaq	-4(%rax), %rdx	#, prephitmp_759
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1133, element
	jge	.L1729	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, (%rax)	# _1133, MEM[base: _1304, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	testl	%ecx, %ecx	# ivtmp.2249
	jne	.L1943	#,
.L1750:
	movq	%rdi, %rdx	# _54, prephitmp_759
	jmp	.L1615	#
.L1752:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rax, %rdx	# ivtmp.2192, prephitmp_784
	jmp	.L1619	#
.L1942:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-8(%rax), %r10d	# MEM[base: _1064, offset: -8B], _953
	leaq	-8(%rax), %r11	#, _1148
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _953, element
	jge	.L1619	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -4(%rax)	# _953, MEM[base: _1064, offset: -4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _45, prephitmp_784
	cmpl	$1, %ecx	#, ivtmp.2210
	je	.L1619	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-12(%rax), %r10d	# MEM[base: _1064, offset: -12B], _965
	leaq	-12(%rax), %rdx	#, prephitmp_784
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _965, element
	jge	.L1772	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -8(%rax)	# _965, MEM[base: _1064, offset: -8B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$2, %ecx	#, ivtmp.2210
	je	.L1773	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-16(%rax), %r10d	# MEM[base: _1064, offset: -16B], _977
	leaq	-16(%rax), %r11	#, _1159
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _977, element
	jge	.L1619	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -12(%rax)	# _977, MEM[base: _1064, offset: -12B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _45, prephitmp_784
	cmpl	$3, %ecx	#, ivtmp.2210
	je	.L1619	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-20(%rax), %r10d	# MEM[base: _1064, offset: -20B], _989
	leaq	-20(%rax), %rdx	#, prephitmp_784
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _989, element
	jge	.L1772	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -16(%rax)	# _989, MEM[base: _1064, offset: -16B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$4, %ecx	#, ivtmp.2210
	je	.L1773	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-24(%rax), %r10d	# MEM[base: _1064, offset: -24B], _1001
	leaq	-24(%rax), %r11	#, _1170
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1001, element
	jge	.L1619	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -20(%rax)	# _1001, MEM[base: _1064, offset: -20B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _45, prephitmp_784
	cmpl	$5, %ecx	#, ivtmp.2210
	je	.L1619	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-28(%rax), %r10d	# MEM[base: _1064, offset: -28B], _1013
	leaq	-28(%rax), %rdx	#, prephitmp_784
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1013, element
	jge	.L1772	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -24(%rax)	# _1013, MEM[base: _1064, offset: -24B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$6, %ecx	#, ivtmp.2210
	je	.L1773	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-32(%rax), %r10d	# MEM[base: _1064, offset: -32B], _1025
	leaq	-32(%rax), %r11	#, _1176
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1025, element
	jge	.L1619	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -28(%rax)	# _1025, MEM[base: _1064, offset: -28B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _45, prephitmp_784
	cmpl	$7, %ecx	#, ivtmp.2210
	je	.L1619	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-36(%rax), %r10d	# MEM[base: _1064, offset: -36B], _1037
	leaq	-36(%rax), %rdx	#, prephitmp_784
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1037, element
	jge	.L1772	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -32(%rax)	# _1037, MEM[base: _1064, offset: -32B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$8, %ecx	#, ivtmp.2210
	je	.L1773	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-40(%rax), %r10d	# MEM[base: _1064, offset: -40B], _1049
	leaq	-40(%rax), %r11	#, _1185
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1049, element
	jge	.L1619	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -36(%rax)	# _1049, MEM[base: _1064, offset: -36B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _45, prephitmp_784
	cmpl	$9, %ecx	#, ivtmp.2210
	je	.L1619	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-44(%rax), %r10d	# MEM[base: _1064, offset: -44B], _1061
	leaq	-44(%rax), %rdx	#, prephitmp_784
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1061, element
	jge	.L1772	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -40(%rax)	# _1061, MEM[base: _1064, offset: -40B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$10, %ecx	#, ivtmp.2210
	je	.L1773	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-48(%rax), %r10d	# MEM[base: _1064, offset: -48B], _1073
	leaq	-48(%rax), %rbx	#, _1196
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1073, element
	jge	.L1619	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -44(%rax)	# _1073, MEM[base: _1064, offset: -44B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _45, prephitmp_784
	cmpl	$11, %ecx	#, ivtmp.2210
	je	.L1619	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-52(%rax), %r10d	# MEM[base: _1064, offset: -52B], _1085
	leaq	-52(%rax), %r11	#, _1200
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1085, element
	jge	.L1770	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -48(%rax)	# _1085, MEM[base: _1064, offset: -48B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$12, %ecx	#, ivtmp.2210
	je	.L1619	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-56(%rax), %r10d	# MEM[base: _1064, offset: -56B], _1097
	leaq	-56(%rax), %rdx	#, prephitmp_784
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1097, element
	jge	.L1772	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -52(%rax)	# _1097, MEM[base: _1064, offset: -52B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$13, %ecx	#, ivtmp.2210
	je	.L1773	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-60(%rax), %r10d	# MEM[base: _1064, offset: -60B], _1109
	leaq	-60(%rax), %r11	#, _1135
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1109, element
	jge	.L1619	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -56(%rax)	# _1109, MEM[base: _1064, offset: -56B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$14, %ecx	#, ivtmp.2210
	je	.L1773	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-64(%rax), %edx	# MEM[base: _1064, offset: -64B], _206
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %esi	# _206, element
	jge	.L1772	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, -60(%rax)	# _206, MEM[base: _1064, offset: -60B]
	movq	%rdi, %rdx	# _45, prephitmp_784
	jmp	.L1619	#
	.p2align 4,,10
	.p2align 3
.L1842:
# insertionssort.h:10:       array[j + 1] = array[j];
	movq	%r11, %rdx	# _556, _626
	jmp	.L1631	#
.L1841:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rsi, %rdx	# _8, _626
	jmp	.L1631	#
.L1729:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rax, %rdx	# ivtmp.2231, prephitmp_759
	jmp	.L1615	#
.L1936:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %r10d	# MEM[base: _1532, offset: -4B], _1325
	leaq	-4(%rax), %rdx	#, prephitmp_734
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1325, element
	jge	.L1705	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, (%rax)	# _1325, MEM[base: _1532, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	testl	%ecx, %ecx	# ivtmp.2288
	je	.L1726	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-8(%rax), %r10d	# MEM[base: _1532, offset: -8B], _1337
	leaq	-8(%rax), %r11	#, _1628
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1337, element
	jge	.L1611	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -4(%rax)	# _1337, MEM[base: _1532, offset: -4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _63, prephitmp_734
	cmpl	$1, %ecx	#, ivtmp.2288
	je	.L1611	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-12(%rax), %r10d	# MEM[base: _1532, offset: -12B], _1349
	leaq	-12(%rax), %rdx	#, prephitmp_734
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1349, element
	jge	.L1725	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -8(%rax)	# _1349, MEM[base: _1532, offset: -8B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$2, %ecx	#, ivtmp.2288
	je	.L1726	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-16(%rax), %r10d	# MEM[base: _1532, offset: -16B], _1361
	leaq	-16(%rax), %r11	#, _1639
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1361, element
	jge	.L1611	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -12(%rax)	# _1361, MEM[base: _1532, offset: -12B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _63, prephitmp_734
	cmpl	$3, %ecx	#, ivtmp.2288
	je	.L1611	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-20(%rax), %r10d	# MEM[base: _1532, offset: -20B], _1373
	leaq	-20(%rax), %rdx	#, prephitmp_734
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1373, element
	jge	.L1725	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -16(%rax)	# _1373, MEM[base: _1532, offset: -16B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$4, %ecx	#, ivtmp.2288
	je	.L1726	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-24(%rax), %r10d	# MEM[base: _1532, offset: -24B], _1385
	leaq	-24(%rax), %r11	#, _1650
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1385, element
	jge	.L1611	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -20(%rax)	# _1385, MEM[base: _1532, offset: -20B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _63, prephitmp_734
	cmpl	$5, %ecx	#, ivtmp.2288
	je	.L1611	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-28(%rax), %r10d	# MEM[base: _1532, offset: -28B], _1397
	leaq	-28(%rax), %rdx	#, prephitmp_734
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1397, element
	jge	.L1725	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -24(%rax)	# _1397, MEM[base: _1532, offset: -24B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$6, %ecx	#, ivtmp.2288
	je	.L1726	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-32(%rax), %r10d	# MEM[base: _1532, offset: -32B], _1409
	leaq	-32(%rax), %r11	#, _1656
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1409, element
	jge	.L1611	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -28(%rax)	# _1409, MEM[base: _1532, offset: -28B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _63, prephitmp_734
	cmpl	$7, %ecx	#, ivtmp.2288
	je	.L1611	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-36(%rax), %r10d	# MEM[base: _1532, offset: -36B], _1421
	leaq	-36(%rax), %rdx	#, prephitmp_734
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1421, element
	jge	.L1725	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -32(%rax)	# _1421, MEM[base: _1532, offset: -32B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$8, %ecx	#, ivtmp.2288
	je	.L1726	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-40(%rax), %r10d	# MEM[base: _1532, offset: -40B], _1433
	leaq	-40(%rax), %r11	#, _1665
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1433, element
	jge	.L1611	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -36(%rax)	# _1433, MEM[base: _1532, offset: -36B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _63, prephitmp_734
	cmpl	$9, %ecx	#, ivtmp.2288
	je	.L1611	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-44(%rax), %r10d	# MEM[base: _1532, offset: -44B], _1445
	leaq	-44(%rax), %rdx	#, prephitmp_734
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1445, element
	jge	.L1725	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -40(%rax)	# _1445, MEM[base: _1532, offset: -40B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$10, %ecx	#, ivtmp.2288
	je	.L1726	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-48(%rax), %r10d	# MEM[base: _1532, offset: -48B], _1457
	leaq	-48(%rax), %rbx	#, _1676
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1457, element
	jge	.L1611	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -44(%rax)	# _1457, MEM[base: _1532, offset: -44B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _63, prephitmp_734
	cmpl	$11, %ecx	#, ivtmp.2288
	je	.L1611	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-52(%rax), %r10d	# MEM[base: _1532, offset: -52B], _1469
	leaq	-52(%rax), %r11	#, _1680
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1469, element
	jge	.L1723	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -48(%rax)	# _1469, MEM[base: _1532, offset: -48B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$12, %ecx	#, ivtmp.2288
	je	.L1611	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-56(%rax), %r10d	# MEM[base: _1532, offset: -56B], _1481
	leaq	-56(%rax), %rdx	#, prephitmp_734
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1481, element
	jge	.L1725	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -52(%rax)	# _1481, MEM[base: _1532, offset: -52B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$13, %ecx	#, ivtmp.2288
	je	.L1726	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-60(%rax), %r10d	# MEM[base: _1532, offset: -60B], _1493
	leaq	-60(%rax), %r11	#, _1615
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1493, element
	jge	.L1611	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -56(%rax)	# _1493, MEM[base: _1532, offset: -56B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$14, %ecx	#, ivtmp.2288
	je	.L1726	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-64(%rax), %edx	# MEM[base: _1532, offset: -64B], _164
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %esi	# _164, element
	jge	.L1725	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, -60(%rax)	# _164, MEM[base: _1532, offset: -60B]
	movq	%rdi, %rdx	# _63, prephitmp_734
	jmp	.L1611	#
	.p2align 4,,10
	.p2align 3
.L1821:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rax, %rdx	# ivtmp.2075, _626
	jmp	.L1631	#
.L1930:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %r8d	# MEM[base: _2149, offset: -4B], _1901
	leaq	-4(%rax), %rdx	#, prephitmp_659
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _1901, element
	jge	.L1636	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, (%rax)	# _1901, MEM[base: _2149, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	testl	%ecx, %ecx	# ivtmp.2405
	je	.L1657	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-8(%rax), %r8d	# MEM[base: _2149, offset: -8B], _1913
	leaq	-8(%rax), %r11	#, _2189
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _1913, element
	jge	.L1599	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -4(%rax)	# _1913, MEM[base: _2149, offset: -4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _90, prephitmp_659
	cmpl	$1, %ecx	#, ivtmp.2405
	je	.L1599	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-12(%rax), %r8d	# MEM[base: _2149, offset: -12B], _1925
	leaq	-12(%rax), %rdx	#, prephitmp_659
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _1925, element
	jge	.L1656	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -8(%rax)	# _1925, MEM[base: _2149, offset: -8B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$2, %ecx	#, ivtmp.2405
	je	.L1657	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-16(%rax), %r8d	# MEM[base: _2149, offset: -16B], _1937
	leaq	-16(%rax), %r11	#, _2193
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _1937, element
	jge	.L1599	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -12(%rax)	# _1937, MEM[base: _2149, offset: -12B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _90, prephitmp_659
	cmpl	$3, %ecx	#, ivtmp.2405
	je	.L1599	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-20(%rax), %r8d	# MEM[base: _2149, offset: -20B], _1949
	leaq	-20(%rax), %rdx	#, prephitmp_659
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _1949, element
	jge	.L1656	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -16(%rax)	# _1949, MEM[base: _2149, offset: -16B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$4, %ecx	#, ivtmp.2405
	je	.L1657	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-24(%rax), %r8d	# MEM[base: _2149, offset: -24B], _1961
	leaq	-24(%rax), %r11	#, _2197
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _1961, element
	jge	.L1599	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -20(%rax)	# _1961, MEM[base: _2149, offset: -20B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _90, prephitmp_659
	cmpl	$5, %ecx	#, ivtmp.2405
	je	.L1599	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-28(%rax), %r8d	# MEM[base: _2149, offset: -28B], _1973
	leaq	-28(%rax), %rdx	#, prephitmp_659
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _1973, element
	jge	.L1656	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -24(%rax)	# _1973, MEM[base: _2149, offset: -24B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$6, %ecx	#, ivtmp.2405
	je	.L1657	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-32(%rax), %r8d	# MEM[base: _2149, offset: -32B], _1985
	leaq	-32(%rax), %r11	#, _2201
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _1985, element
	jge	.L1599	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -28(%rax)	# _1985, MEM[base: _2149, offset: -28B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _90, prephitmp_659
	cmpl	$7, %ecx	#, ivtmp.2405
	je	.L1599	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-36(%rax), %r8d	# MEM[base: _2149, offset: -36B], _1997
	leaq	-36(%rax), %rdx	#, prephitmp_659
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _1997, element
	jge	.L1656	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -32(%rax)	# _1997, MEM[base: _2149, offset: -32B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$8, %ecx	#, ivtmp.2405
	je	.L1657	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-40(%rax), %r8d	# MEM[base: _2149, offset: -40B], _2009
	leaq	-40(%rax), %r11	#, _2205
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _2009, element
	jge	.L1599	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -36(%rax)	# _2009, MEM[base: _2149, offset: -36B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _90, prephitmp_659
	cmpl	$9, %ecx	#, ivtmp.2405
	je	.L1599	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-44(%rax), %r8d	# MEM[base: _2149, offset: -44B], _2021
	leaq	-44(%rax), %rdx	#, prephitmp_659
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _2021, element
	jge	.L1656	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -40(%rax)	# _2021, MEM[base: _2149, offset: -40B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$10, %ecx	#, ivtmp.2405
	je	.L1657	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-48(%rax), %r8d	# MEM[base: _2149, offset: -48B], _2033
	leaq	-48(%rax), %r13	#, _2209
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _2033, element
	jge	.L1599	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -44(%rax)	# _2033, MEM[base: _2149, offset: -44B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _90, prephitmp_659
	cmpl	$11, %ecx	#, ivtmp.2405
	je	.L1599	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-52(%rax), %r8d	# MEM[base: _2149, offset: -52B], _2045
	leaq	-52(%rax), %r11	#, _2211
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _2045, element
	jge	.L1654	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -48(%rax)	# _2045, MEM[base: _2149, offset: -48B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$12, %ecx	#, ivtmp.2405
	je	.L1599	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-56(%rax), %r8d	# MEM[base: _2149, offset: -56B], _2057
	leaq	-56(%rax), %rdx	#, prephitmp_659
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _2057, element
	jge	.L1656	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -52(%rax)	# _2057, MEM[base: _2149, offset: -52B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$13, %ecx	#, ivtmp.2405
	je	.L1657	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-60(%rax), %r8d	# MEM[base: _2149, offset: -60B], _2069
	leaq	-60(%rax), %r11	#, _2183
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r8d, %esi	# _2069, element
	jge	.L1599	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r8d, -56(%rax)	# _2069, MEM[base: _2149, offset: -56B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$14, %ecx	#, ivtmp.2405
	je	.L1657	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-64(%rax), %edx	# MEM[base: _2149, offset: -64B], _101
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %esi	# _101, element
	jge	.L1656	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, -60(%rax)	# _101, MEM[base: _2149, offset: -60B]
	movq	%rdi, %rdx	# _90, prephitmp_659
	jmp	.L1599	#
	.p2align 4,,10
	.p2align 3
.L1932:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-4(%rax), %r10d	# MEM[base: _2012, offset: -4B], _1709
	leaq	-4(%rax), %rdx	#, prephitmp_684
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1709, element
	jge	.L1659	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, (%rax)	# _1709, MEM[base: _2012, offset: 0B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	testl	%ecx, %ecx	# ivtmp.2366
	je	.L1680	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-8(%rax), %r10d	# MEM[base: _2012, offset: -8B], _1721
	leaq	-8(%rax), %r11	#, _2084
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1721, element
	jge	.L1603	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -4(%rax)	# _1721, MEM[base: _2012, offset: -4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _81, prephitmp_684
	cmpl	$1, %ecx	#, ivtmp.2366
	je	.L1603	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-12(%rax), %r10d	# MEM[base: _2012, offset: -12B], _1733
	leaq	-12(%rax), %rdx	#, prephitmp_684
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1733, element
	jge	.L1679	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -8(%rax)	# _1733, MEM[base: _2012, offset: -8B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$2, %ecx	#, ivtmp.2366
	je	.L1680	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-16(%rax), %r10d	# MEM[base: _2012, offset: -16B], _1745
	leaq	-16(%rax), %r11	#, _2088
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1745, element
	jge	.L1603	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -12(%rax)	# _1745, MEM[base: _2012, offset: -12B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _81, prephitmp_684
	cmpl	$3, %ecx	#, ivtmp.2366
	je	.L1603	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-20(%rax), %r10d	# MEM[base: _2012, offset: -20B], _1757
	leaq	-20(%rax), %rdx	#, prephitmp_684
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1757, element
	jge	.L1679	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -16(%rax)	# _1757, MEM[base: _2012, offset: -16B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$4, %ecx	#, ivtmp.2366
	je	.L1680	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-24(%rax), %r10d	# MEM[base: _2012, offset: -24B], _1769
	leaq	-24(%rax), %r11	#, _2092
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1769, element
	jge	.L1603	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -20(%rax)	# _1769, MEM[base: _2012, offset: -20B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _81, prephitmp_684
	cmpl	$5, %ecx	#, ivtmp.2366
	je	.L1603	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-28(%rax), %r10d	# MEM[base: _2012, offset: -28B], _1781
	leaq	-28(%rax), %rdx	#, prephitmp_684
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1781, element
	jge	.L1679	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -24(%rax)	# _1781, MEM[base: _2012, offset: -24B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$6, %ecx	#, ivtmp.2366
	je	.L1680	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-32(%rax), %r10d	# MEM[base: _2012, offset: -32B], _1793
	leaq	-32(%rax), %r11	#, _2096
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1793, element
	jge	.L1603	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -28(%rax)	# _1793, MEM[base: _2012, offset: -28B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _81, prephitmp_684
	cmpl	$7, %ecx	#, ivtmp.2366
	je	.L1603	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-36(%rax), %r10d	# MEM[base: _2012, offset: -36B], _1805
	leaq	-36(%rax), %rdx	#, prephitmp_684
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1805, element
	jge	.L1679	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -32(%rax)	# _1805, MEM[base: _2012, offset: -32B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$8, %ecx	#, ivtmp.2366
	je	.L1680	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-40(%rax), %r10d	# MEM[base: _2012, offset: -40B], _1817
	leaq	-40(%rax), %r11	#, _2100
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1817, element
	jge	.L1603	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -36(%rax)	# _1817, MEM[base: _2012, offset: -36B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _81, prephitmp_684
	cmpl	$9, %ecx	#, ivtmp.2366
	je	.L1603	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-44(%rax), %r10d	# MEM[base: _2012, offset: -44B], _1829
	leaq	-44(%rax), %rdx	#, prephitmp_684
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1829, element
	jge	.L1679	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -40(%rax)	# _1829, MEM[base: _2012, offset: -40B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$10, %ecx	#, ivtmp.2366
	je	.L1680	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-48(%rax), %r10d	# MEM[base: _2012, offset: -48B], _1841
	leaq	-48(%rax), %rbp	#, _2104
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1841, element
	jge	.L1603	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -44(%rax)	# _1841, MEM[base: _2012, offset: -44B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _81, prephitmp_684
	cmpl	$11, %ecx	#, ivtmp.2366
	je	.L1603	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-52(%rax), %r10d	# MEM[base: _2012, offset: -52B], _1853
	leaq	-52(%rax), %r11	#, _2106
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1853, element
	jge	.L1677	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -48(%rax)	# _1853, MEM[base: _2012, offset: -48B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$12, %ecx	#, ivtmp.2366
	je	.L1603	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-56(%rax), %r10d	# MEM[base: _2012, offset: -56B], _1865
	leaq	-56(%rax), %rdx	#, prephitmp_684
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1865, element
	jge	.L1679	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -52(%rax)	# _1865, MEM[base: _2012, offset: -52B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$13, %ecx	#, ivtmp.2366
	je	.L1680	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-60(%rax), %r10d	# MEM[base: _2012, offset: -60B], _1877
	leaq	-60(%rax), %r11	#, _2078
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1877, element
	jge	.L1603	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -56(%rax)	# _1877, MEM[base: _2012, offset: -56B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$14, %ecx	#, ivtmp.2366
	je	.L1680	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-64(%rax), %edx	# MEM[base: _2012, offset: -64B], _122
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %esi	# _122, element
	jge	.L1679	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, -60(%rax)	# _122, MEM[base: _2012, offset: -60B]
	movq	%rdi, %rdx	# _81, prephitmp_684
	jmp	.L1603	#
	.p2align 4,,10
	.p2align 3
.L1682:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rax, %rdx	# ivtmp.2309, prephitmp_709
	jmp	.L1607	#
.L1943:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-8(%rax), %r10d	# MEM[base: _1304, offset: -8B], _1145
	leaq	-8(%rax), %r11	#, _1388
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1145, element
	jge	.L1615	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -4(%rax)	# _1145, MEM[base: _1304, offset: -4B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _54, prephitmp_759
	cmpl	$1, %ecx	#, ivtmp.2249
	je	.L1615	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-12(%rax), %r10d	# MEM[base: _1304, offset: -12B], _1157
	leaq	-12(%rax), %rdx	#, prephitmp_759
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1157, element
	jge	.L1749	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -8(%rax)	# _1157, MEM[base: _1304, offset: -8B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$2, %ecx	#, ivtmp.2249
	je	.L1750	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-16(%rax), %r10d	# MEM[base: _1304, offset: -16B], _1169
	leaq	-16(%rax), %r11	#, _1399
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1169, element
	jge	.L1615	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -12(%rax)	# _1169, MEM[base: _1304, offset: -12B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _54, prephitmp_759
	cmpl	$3, %ecx	#, ivtmp.2249
	je	.L1615	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-20(%rax), %r10d	# MEM[base: _1304, offset: -20B], _1181
	leaq	-20(%rax), %rdx	#, prephitmp_759
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1181, element
	jge	.L1749	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -16(%rax)	# _1181, MEM[base: _1304, offset: -16B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$4, %ecx	#, ivtmp.2249
	je	.L1750	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-24(%rax), %r10d	# MEM[base: _1304, offset: -24B], _1193
	leaq	-24(%rax), %r11	#, _1410
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1193, element
	jge	.L1615	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -20(%rax)	# _1193, MEM[base: _1304, offset: -20B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _54, prephitmp_759
	cmpl	$5, %ecx	#, ivtmp.2249
	je	.L1615	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-28(%rax), %r10d	# MEM[base: _1304, offset: -28B], _1205
	leaq	-28(%rax), %rdx	#, prephitmp_759
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1205, element
	jge	.L1749	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -24(%rax)	# _1205, MEM[base: _1304, offset: -24B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$6, %ecx	#, ivtmp.2249
	je	.L1750	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-32(%rax), %r10d	# MEM[base: _1304, offset: -32B], _1217
	leaq	-32(%rax), %r11	#, _1416
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1217, element
	jge	.L1615	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -28(%rax)	# _1217, MEM[base: _1304, offset: -28B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _54, prephitmp_759
	cmpl	$7, %ecx	#, ivtmp.2249
	je	.L1615	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-36(%rax), %r10d	# MEM[base: _1304, offset: -36B], _1229
	leaq	-36(%rax), %rdx	#, prephitmp_759
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1229, element
	jge	.L1749	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -32(%rax)	# _1229, MEM[base: _1304, offset: -32B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$8, %ecx	#, ivtmp.2249
	je	.L1750	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-40(%rax), %r10d	# MEM[base: _1304, offset: -40B], _1241
	leaq	-40(%rax), %r11	#, _1425
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1241, element
	jge	.L1615	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -36(%rax)	# _1241, MEM[base: _1304, offset: -36B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _54, prephitmp_759
	cmpl	$9, %ecx	#, ivtmp.2249
	je	.L1615	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-44(%rax), %r10d	# MEM[base: _1304, offset: -44B], _1253
	leaq	-44(%rax), %rdx	#, prephitmp_759
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1253, element
	jge	.L1749	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -40(%rax)	# _1253, MEM[base: _1304, offset: -40B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$10, %ecx	#, ivtmp.2249
	je	.L1750	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-48(%rax), %r10d	# MEM[base: _1304, offset: -48B], _1265
	leaq	-48(%rax), %rbx	#, _1436
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1265, element
	jge	.L1615	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -44(%rax)	# _1265, MEM[base: _1304, offset: -44B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rdi, %rdx	# _54, prephitmp_759
	cmpl	$11, %ecx	#, ivtmp.2249
	je	.L1615	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-52(%rax), %r10d	# MEM[base: _1304, offset: -52B], _1277
	leaq	-52(%rax), %r11	#, _1440
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1277, element
	jge	.L1747	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -48(%rax)	# _1277, MEM[base: _1304, offset: -48B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$12, %ecx	#, ivtmp.2249
	je	.L1615	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-56(%rax), %r10d	# MEM[base: _1304, offset: -56B], _1289
	leaq	-56(%rax), %rdx	#, prephitmp_759
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1289, element
	jge	.L1749	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -52(%rax)	# _1289, MEM[base: _1304, offset: -52B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$13, %ecx	#, ivtmp.2249
	je	.L1750	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-60(%rax), %r10d	# MEM[base: _1304, offset: -60B], _1301
	leaq	-60(%rax), %r11	#, _1375
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%r10d, %esi	# _1301, element
	jge	.L1615	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%r10d, -56(%rax)	# _1301, MEM[base: _1304, offset: -56B]
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	$14, %ecx	#, ivtmp.2249
	je	.L1750	#,
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movl	-64(%rax), %edx	# MEM[base: _1304, offset: -64B], _185
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	cmpl	%edx, %esi	# _185, element
	jge	.L1749	#,
# insertionssort.h:10:       array[j + 1] = array[j];
	movl	%edx, -60(%rax)	# _185, MEM[base: _1304, offset: -60B]
	movq	%rdi, %rdx	# _54, prephitmp_759
	jmp	.L1615	#
	.p2align 4,,10
	.p2align 3
.L1772:
# insertionssort.h:10:       array[j + 1] = array[j];
	movq	%r11, %rdx	# _1200, prephitmp_784
	jmp	.L1619	#
.L1636:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rax, %rdx	# ivtmp.2387, prephitmp_659
	jmp	.L1599	#
.L1770:
# insertionssort.h:10:       array[j + 1] = array[j];
	movq	%rbx, %rdx	# _1196, prephitmp_784
	jmp	.L1619	#
.L1747:
	movq	%rbx, %rdx	# _1436, prephitmp_759
	jmp	.L1615	#
.L1749:
	movq	%r11, %rdx	# _1440, prephitmp_759
	jmp	.L1615	#
	.p2align 4,,10
	.p2align 3
.L1705:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rax, %rdx	# ivtmp.2270, prephitmp_734
	jmp	.L1611	#
.L1700:
# insertionssort.h:10:       array[j + 1] = array[j];
	movq	%rbx, %rdx	# _1904, prephitmp_709
	jmp	.L1607	#
.L1702:
	movq	%r11, %rdx	# _1908, prephitmp_709
	jmp	.L1607	#
.L1723:
	movq	%rbx, %rdx	# _1676, prephitmp_734
	jmp	.L1611	#
.L1725:
	movq	%r11, %rdx	# _1680, prephitmp_734
	jmp	.L1611	#
	.p2align 4,,10
	.p2align 3
.L1659:
# insertionssort.h:9:     while (j >= 0 && array[j] > element) {
	movq	%rax, %rdx	# ivtmp.2348, prephitmp_684
	jmp	.L1603	#
.L1677:
# insertionssort.h:10:       array[j + 1] = array[j];
	movq	%rbp, %rdx	# _2104, prephitmp_684
	jmp	.L1603	#
.L1679:
	movq	%r11, %rdx	# _2106, prephitmp_684
	jmp	.L1603	#
.L1654:
	movq	%r13, %rdx	# _2209, prephitmp_659
	jmp	.L1599	#
.L1656:
	movq	%r11, %rdx	# _2211, prephitmp_659
	jmp	.L1599	#
	.cfi_endproc
.LFE5435:
	.size	sort_quick_tuned, .-sort_quick_tuned
	.p2align 4
	.globl	partition_quick_hoare
	.type	partition_quick_hoare, @function
partition_quick_hoare:
.LFB5436:
	.cfi_startproc
	endbr64	
	pushq	%r12	#
	.cfi_def_cfa_offset 16
	.cfi_offset 12, -16
	movq	%rdi, %r12	# tmp102, array
	pushq	%rbp	#
	.cfi_def_cfa_offset 24
	.cfi_offset 6, -24
	movl	%esi, %ebp	# tmp103, low
	pushq	%rbx	#
	.cfi_def_cfa_offset 32
	.cfi_offset 3, -32
# quickuhoare.h:11: int partition_quick_hoare(int array[], int low, int high) {
	movl	%edx, %ebx	# tmp104, high
# quickuhoare.h:12:   int pivot = median_of_three_of_median_of_three(array, low, high);
	call	median_of_three_of_median_of_three	#
	movl	%eax, %ecx	# tmp105, pivot
# quickuhoare.h:15:   int j = high + 1;
	leal	1(%rbx), %r8d	#, <retval>
	movslq	%ebp, %rdi	# low, ivtmp.2440
	.p2align 4,,10
	.p2align 3
.L1945:
# quickuhoare.h:17:     do {i++;} while (array[i] < pivot);
	movl	(%r12,%rdi,4), %r9d	# MEM[base: array_20(D), index: ivtmp.2440_44, step: 4, offset: 0B], _4
# quickuhoare.h:17:     do {i++;} while (array[i] < pivot);
	cmpl	%ecx, %r9d	# pivot, _4
	jl	.L1946	#,
	movslq	%r8d, %rax	# <retval>, <retval>
	leaq	-4(%r12,%rax,4), %rax	#, ivtmp.2431
	.p2align 4,,10
	.p2align 3
.L1947:
# quickuhoare.h:18:     do {j--;} while (array[j] > pivot);
	movq	%rax, %rsi	# ivtmp.2431, _7
	movl	(%rax), %edx	# MEM[base: _45, offset: 4B], _8
# quickuhoare.h:18:     do {j--;} while (array[j] > pivot);
	subq	$4, %rax	#, ivtmp.2431
# quickuhoare.h:18:     do {j--;} while (array[j] > pivot);
	decl	%r8d	# <retval>
# quickuhoare.h:18:     do {j--;} while (array[j] > pivot);
	cmpl	%ecx, %edx	# pivot, _8
	jg	.L1947	#,
# quickuhoare.h:19:     if (i >= j) {
	cmpl	%edi, %r8d	# ivtmp.2440, <retval>
	jle	.L1950	#,
# swap.h:3:   *a = *b;
	movl	%edx, (%r12,%rdi,4)	# _8, MEM[base: array_20(D), index: ivtmp.2440_44, step: 4, offset: 0B]
# swap.h:4:   *b = t;
	movl	%r9d, (%rsi)	# _4, *_7
.L1946:
	incq	%rdi	# ivtmp.2440
	jmp	.L1945	#
	.p2align 4,,10
	.p2align 3
.L1950:
# quickuhoare.h:24: }
	popq	%rbx	#
	.cfi_def_cfa_offset 24
	popq	%rbp	#
	.cfi_def_cfa_offset 16
	movl	%r8d, %eax	# <retval>,
	popq	%r12	#
	.cfi_def_cfa_offset 8
	ret	
	.cfi_endproc
.LFE5436:
	.size	partition_quick_hoare, .-partition_quick_hoare
	.p2align 4
	.globl	partition_quick_lomuto
	.type	partition_quick_lomuto, @function
partition_quick_lomuto:
.LFB5438:
	.cfi_startproc
	endbr64	
	pushq	%r12	#
	.cfi_def_cfa_offset 16
	.cfi_offset 12, -16
	movslq	%edx, %r12	# tmp134,
# quickulomuto.h:12:   int pivot = median_of_three_of_median_of_three(array, low, high); //
	movl	%r12d, %edx	# high,
# quickulomuto.h:11: int partition_quick_lomuto(int array[], int low, int high) {
	pushq	%rbp	#
	.cfi_def_cfa_offset 24
	.cfi_offset 6, -24
	movl	%esi, %ebp	# tmp133, low
	pushq	%rbx	#
	.cfi_def_cfa_offset 32
	.cfi_offset 3, -32
# quickulomuto.h:11: int partition_quick_lomuto(int array[], int low, int high) {
	movq	%rdi, %rbx	# tmp132, array
# quickulomuto.h:12:   int pivot = median_of_three_of_median_of_three(array, low, high); //
	call	median_of_three_of_median_of_three	#
# quickulomuto.h:14:   int i = (low - 1);
	leal	-1(%rbp), %ecx	#, i
# quickulomuto.h:15:   for (int j = low; j < high; j++) {
	cmpl	%r12d, %ebp	# high, low
	jge	.L1957	#,
	leal	-1(%r12), %edx	#, tmp118
	movslq	%ebp, %rsi	# low, _39
	subl	%ebp, %edx	# low, tmp120
	addq	%rsi, %rdx	# _39, tmp121
	movl	%eax, %edi	# tmp135, pivot
	leaq	4(%rbx,%rdx,4), %r8	#, _30
	leaq	(%rbx,%rsi,4), %rax	#, ivtmp.2453
	.p2align 4,,10
	.p2align 3
.L1954:
# quickulomuto.h:16:     if (array[j] <= pivot) {
	movl	(%rax), %edx	# MEM[base: _2, offset: 0B], _53
# quickulomuto.h:16:     if (array[j] <= pivot) {
	cmpl	%edx, %edi	# _53, pivot
	jl	.L1955	#,
# quickulomuto.h:17:       i++;
	incl	%ecx	# i
# quickulomuto.h:18:       swap(&array[i], &array[j]);
	movslq	%ecx, %rsi	# i, i
# quickulomuto.h:18:       swap(&array[i], &array[j]);
	leaq	(%rbx,%rsi,4), %rsi	#, _49
# swap.h:2:   int t = *a;
	movl	(%rsi), %r9d	# *_49, t
# swap.h:3:   *a = *b;
	movl	%edx, (%rsi)	# _53, *_49
# swap.h:4:   *b = t;
	movl	%r9d, (%rax)	# t, MEM[base: _2, offset: 0B]
.L1955:
# quickulomuto.h:15:   for (int j = low; j < high; j++) {
	addq	$4, %rax	#, ivtmp.2453
	cmpq	%r8, %rax	# _30, ivtmp.2453
	jne	.L1954	#,
# quickulomuto.h:22:   return (i + 1);
	leal	1(%rcx), %eax	#, <retval>
.L1953:
# quickulomuto.h:21:   swap(&array[i + 1], &array[high]);
	movslq	%ecx, %rcx	# i, i
# quickulomuto.h:21:   swap(&array[i + 1], &array[high]);
	leaq	(%rbx,%r12,4), %rdx	#, _11
	leaq	4(%rbx,%rcx,4), %rcx	#, _15
# swap.h:2:   int t = *a;
	movl	(%rcx), %esi	# *_15, t
# swap.h:3:   *a = *b;
	movl	(%rdx), %edi	# *_11, _33
# swap.h:3:   *a = *b;
	movl	%edi, (%rcx)	# _33, *_15
# swap.h:4:   *b = t;
	movl	%esi, (%rdx)	# t, *_11
# quickulomuto.h:23: }
	popq	%rbx	#
	.cfi_remember_state
	.cfi_def_cfa_offset 24
	popq	%rbp	#
	.cfi_def_cfa_offset 16
	popq	%r12	#
	.cfi_def_cfa_offset 8
	ret	
	.p2align 4,,10
	.p2align 3
.L1957:
	.cfi_restore_state
# quickulomuto.h:15:   for (int j = low; j < high; j++) {
	movl	%ebp, %eax	# low, <retval>
	jmp	.L1953	#
	.cfi_endproc
.LFE5438:
	.size	partition_quick_lomuto, .-partition_quick_lomuto
	.p2align 4
	.globl	hsum_epi32_avx
	.type	hsum_epi32_avx, @function
hsum_epi32_avx:
.LFB5440:
	.cfi_startproc
	endbr64	
# /usr/lib/gcc/x86_64-linux-gnu/10/include/emmintrin.h:1000:   return (__m128i)__builtin_ia32_punpckhqdq128 ((__v2di)__A, (__v2di)__B);
	vpunpckhqdq	%xmm0, %xmm0, %xmm1	# x, x, tmp94
# /usr/lib/gcc/x86_64-linux-gnu/10/include/emmintrin.h:1042:   return (__m128i) ((__v4su)__A + (__v4su)__B);
	vpaddd	%xmm0, %xmm1, %xmm1	# x, tmp94, _12
# /usr/lib/gcc/x86_64-linux-gnu/10/include/emmintrin.h:1434:   return (__m128i)__builtin_ia32_pshufd ((__v4si)__A, __mask);
	vpshufd	$177, %xmm1, %xmm0	#, _12, tmp95
# /usr/lib/gcc/x86_64-linux-gnu/10/include/emmintrin.h:1042:   return (__m128i) ((__v4su)__A + (__v4su)__B);
	vpaddd	%xmm1, %xmm0, %xmm0	# _12, tmp95, tmp97
# /usr/lib/gcc/x86_64-linux-gnu/10/include/emmintrin.h:226:   return __builtin_ia32_vec_ext_v4si ((__v4si)__A, 0);
	vmovd	%xmm0, %eax	# tmp97, tmp98
# simd.h:14: }
	ret	
	.cfi_endproc
.LFE5440:
	.size	hsum_epi32_avx, .-hsum_epi32_avx
	.p2align 4
	.globl	hsum_8x32
	.type	hsum_8x32, @function
hsum_8x32:
.LFB5441:
	.cfi_startproc
	endbr64	
# /usr/lib/gcc/x86_64-linux-gnu/10/include/avx2intrin.h:1095:   return (__m128i) __builtin_ia32_extract128i256 ((__v4di)__X, __M);
	vextracti128	$0x1, %ymm0, %xmm1	# v, tmp100
# /usr/lib/gcc/x86_64-linux-gnu/10/include/emmintrin.h:1042:   return (__m128i) ((__v4su)__A + (__v4su)__B);
	vpaddd	%xmm1, %xmm0, %xmm0	# tmp100, tmp102, _4
# /usr/lib/gcc/x86_64-linux-gnu/10/include/emmintrin.h:1000:   return (__m128i)__builtin_ia32_punpckhqdq128 ((__v2di)__A, (__v2di)__B);
	vpunpckhqdq	%xmm0, %xmm0, %xmm1	# _4, _4, tmp104
# /usr/lib/gcc/x86_64-linux-gnu/10/include/emmintrin.h:1042:   return (__m128i) ((__v4su)__A + (__v4su)__B);
	vpaddd	%xmm1, %xmm0, %xmm0	# tmp104, _4, _12
# /usr/lib/gcc/x86_64-linux-gnu/10/include/emmintrin.h:1434:   return (__m128i)__builtin_ia32_pshufd ((__v4si)__A, __mask);
	vpshufd	$177, %xmm0, %xmm1	#, _12, tmp105
# /usr/lib/gcc/x86_64-linux-gnu/10/include/emmintrin.h:1042:   return (__m128i) ((__v4su)__A + (__v4su)__B);
	vpaddd	%xmm0, %xmm1, %xmm0	# _12, tmp105, tmp107
# /usr/lib/gcc/x86_64-linux-gnu/10/include/emmintrin.h:226:   return __builtin_ia32_vec_ext_v4si ((__v4si)__A, 0);
	vmovd	%xmm0, %eax	# tmp107, tmp108
# simd.h:20: }
	ret	
	.cfi_endproc
.LFE5441:
	.size	hsum_8x32, .-hsum_8x32
	.p2align 4
	.globl	swap
	.type	swap, @function
swap:
.LFB5442:
	.cfi_startproc
	endbr64	
# swap.h:2:   int t = *a;
	movl	(%rdi), %eax	# *a_3(D), t
# swap.h:3:   *a = *b;
	movl	(%rsi), %edx	# *b_5(D), _1
# swap.h:3:   *a = *b;
	movl	%edx, (%rdi)	# _1, *a_3(D)
# swap.h:4:   *b = t;
	movl	%eax, (%rsi)	# t, *b_5(D)
# swap.h:5: }
	ret	
	.cfi_endproc
.LFE5442:
	.size	swap, .-swap
	.p2align 4
	.globl	handle_error
	.type	handle_error, @function
handle_error:
.LFB5708:
	.cfi_startproc
	endbr64	
# benchy.c:77:   if (retval != PAPI_OK) {
	testl	%edi, %edi	# retval
	jne	.L1970	#,
	ret	
.L1970:
# benchy.c:76: void handle_error(int retval) {
	pushq	%rax	#
	.cfi_def_cfa_offset 16
	call	handle_error.part.0	#
	.cfi_endproc
.LFE5708:
	.size	handle_error, .-handle_error
	.section	.rodata.str1.1
.LC11:
	.string	"Starting"
.LC18:
	.string	"w"
.LC19:
	.string	"output-gcc-c.csv"
	.section	.rodata.str1.8,"aMS",@progbits,1
	.align 8
.LC20:
	.string	"Algorithm,Array size,Pre bench action,Randomnes,Average Cycles,Cycles per Element,Std Dev"
	.section	.rodata.str1.1
.LC21:
	.string	",%s"
.LC22:
	.string	",Seed %d"
.LC23:
	.string	"*"
.LC24:
	.string	"Insertionsort"
	.section	.rodata.str1.8
	.align 8
.LC36:
	.string	"Benching %s with size %d, action %s, randomnes %f and seed %d"
	.section	.rodata.str1.1
.LC37:
	.string	"\nIntegrity violation!"
.LC38:
	.string	"%d:%d "
	.section	.rodata.str1.8
	.align 8
.LC39:
	.string	"\nIntegrity violation! Wrqng value at %d\n"
	.align 8
.LC40:
	.string	"  Abort %s as it takes too long! "
	.section	.rodata.str1.1
.LC42:
	.string	"%s,%d,%s,%f"
.LC43:
	.string	",%f"
.LC44:
	.string	"  Average: %.3f\n"
	.data
	.align 32
.LC0:
# name:
	.string	"Quicksort Std Lomuto "
	.zero	28
# sorting_function:
	.zero	6
	.quad	sort_quick_lomuto
# name:
	.string	"Quicksort Std Hoare  "
	.zero	28
# sorting_function:
	.zero	6
	.quad	sort_quick_hoare
# name:
	.string	"Quicksort Swap CMOV  "
	.zero	28
# sorting_function:
	.zero	6
	.quad	sort_quick_optimized_swap_cmov
# name:
	.string	"Quicksort Swap Array "
	.zero	28
# sorting_function:
	.zero	6
	.quad	sort_quick_optimized_swap_array
# name:
	.string	"Quicksort Swap ASM   "
	.zero	28
# sorting_function:
	.zero	6
	.quad	sort_quick_optimized_swap_asm
# name:
	.string	"Quicksort Optimized  "
	.zero	28
# sorting_function:
	.zero	6
	.quad	peqsort
# name:
	.string	"Quicksort Stable     "
	.zero	28
# sorting_function:
	.zero	6
	.quad	sort_quick_stable
# name:
	.string	"BlockQuicksort       "
	.zero	28
# sorting_function:
	.zero	6
	.quad	sort_quick_block
# name:
	.string	"Mergesort Standard   "
	.zero	28
# sorting_function:
	.zero	6
	.quad	sort_merge_standard
# name:
	.string	"Mergesort Optimized  "
	.zero	28
# sorting_function:
	.zero	6
	.quad	sort_merge_optimized
# name:
	.string	"Quicksort tuned      "
	.zero	28
# sorting_function:
	.zero	6
	.quad	sort_quick_tuned
# name:
	.string	"Quicksort libc       "
	.zero	28
# sorting_function:
	.zero	6
	.quad	qsort_h
	.section	.rodata
	.align 32
.LC1:
# name:
	.string	"NOTHING"
	.zero	42
# action:
	.zero	2
	.long	0
# name:
	.string	"PRESORTED"
	.zero	40
# action:
	.zero	2
	.long	1
# name:
	.string	"SORT_REVERSE"
	.zero	37
# action:
	.zero	2
	.long	2
# name:
	.string	"END_RANDOM"
	.zero	39
# action:
	.zero	2
	.long	3
# name:
	.string	"LIMIT_VALUES_1000"
	.zero	32
# action:
	.zero	2
	.long	4
# name:
	.string	"LIMIT_VALUES_10000"
	.zero	31
# action:
	.zero	2
	.long	5
	.section	.text.startup,"ax",@progbits
	.p2align 4
	.globl	main
	.type	main, @function
main:
.LFB5709:
	.cfi_startproc
	endbr64	
# benchy.c:88: int main(int argc, char *argv[]) {
	leaq	8(%rsp), %r10	#,
	.cfi_def_cfa 10, 0
	andq	$-32, %rsp	#,
	pushq	-8(%r10)	#
	pushq	%rbp	#
	movq	%rsp, %rbp	#,
	.cfi_escape 0x10,0x6,0x2,0x76,0
	pushq	%r15	#
	pushq	%r14	#
	pushq	%r13	#
	pushq	%r12	#
	pushq	%r10	#
	.cfi_escape 0xf,0x3,0x76,0x58,0x6
	.cfi_escape 0x10,0xf,0x2,0x76,0x78
	.cfi_escape 0x10,0xe,0x2,0x76,0x70
	.cfi_escape 0x10,0xd,0x2,0x76,0x68
	.cfi_escape 0x10,0xc,0x2,0x76,0x60
	pushq	%rbx	#
	subq	$4096, %rsp	#,
	orq	$0, (%rsp)	#,
	subq	$4096, %rsp	#,
	orq	$0, (%rsp)	#,
	subq	$192, %rsp	#,
	.cfi_escape 0x10,0x3,0x2,0x76,0x50
# benchy.c:88: int main(int argc, char *argv[]) {
	movl	%edi, -8248(%rbp)	# tmp1073, %sfp
	movq	%rsi, -8304(%rbp)	# tmp1074, %sfp
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	leaq	.LC11(%rip), %rdi	#,
# benchy.c:97:   struct Algorithm algorithms[] = {
	leaq	-7504(%rbp), %r14	#, ivtmp.2737
# benchy.c:88: int main(int argc, char *argv[]) {
	movq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], tmp1226
	movq	%rax, -56(%rbp)	# tmp1226, D.42982
	xorl	%eax, %eax	# tmp1226
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	call	puts@PLT	#
# benchy.c:93:     seeds[i] = i;
	vmovdqa	.LC12(%rip), %ymm0	#, tmp519
	movabsq	$38654705672, %rax	#, tmp1228
	vmovdqa	%ymm0, -8112(%rbp)	# tmp519, MEM <vector(8) int> [(int *)&seeds]
# benchy.c:96:   int array_sizes[] = {3, 5, 7, 10, 15, 20, 25, 30, 40, 50, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000};
	vmovdqa	.LC13(%rip), %ymm0	#, tmp521
# benchy.c:97:   struct Algorithm algorithms[] = {
	movl	$768, %edx	#,
# benchy.c:96:   int array_sizes[] = {3, 5, 7, 10, 15, 20, 25, 30, 40, 50, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000};
	vmovdqa	%ymm0, -7920(%rbp)	# tmp521, MEM <vector(8) int> [(int *)&array_sizes]
	vmovdqa	.LC14(%rip), %ymm0	#, tmp522
# benchy.c:97:   struct Algorithm algorithms[] = {
	leaq	.LC0(%rip), %rsi	#,
	movq	%r14, %rdi	# ivtmp.2737,
# benchy.c:93:     seeds[i] = i;
	movq	%rax, -8080(%rbp)	# tmp1228, MEM <unsigned long> [(int *)&seeds + 32B]
# benchy.c:96:   int array_sizes[] = {3, 5, 7, 10, 15, 20, 25, 30, 40, 50, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000};
	movl	$100000000, -7856(%rbp)	#, array_sizes[16]
	vmovdqa	%ymm0, -7888(%rbp)	# tmp522, MEM <vector(8) int> [(int *)&array_sizes + 32B]
# benchy.c:97:   struct Algorithm algorithms[] = {
	vzeroupper
	call	memcpy@PLT	#
# benchy.c:125:   struct BeforeSortAction before_sort_actions[] = {
	leaq	-7840(%rbp), %rax	#, ivtmp.2730
	movq	%rax, -8384(%rbp)	# ivtmp.2730, %sfp
	leaq	.LC1(%rip), %rcx	#, tmp919
	xorl	%edx, %edx	# tmp530
.L1972:
	movl	%edx, %eax	# tmp530, tmp533
	movq	(%rcx,%rax), %r9	#, tmp535
	movq	8(%rcx,%rax), %r8	#, tmp536
	movq	16(%rcx,%rax), %rdi	#, tmp537
	movq	24(%rcx,%rax), %rsi	#, tmp538
	addl	$32, %edx	#,
	movq	%r9, -7840(%rbp,%rax)	# tmp535, before_sort_actions
	movq	%r8, -7832(%rbp,%rax)	# tmp536, before_sort_actions
	movq	%rdi, -7824(%rbp,%rax)	# tmp537, before_sort_actions
	movq	%rsi, -7816(%rbp,%rax)	# tmp538, before_sort_actions
	cmpl	$320, %edx	#, tmp530
	jb	.L1972	#,
# benchy.c:134:   float randomnes[] = {0.0, 0.00001, 0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9};
	vmovaps	.LC15(%rip), %ymm0	#, tmp541
# benchy.c:125:   struct BeforeSortAction before_sort_actions[] = {
	vmovdqa	(%rcx,%rdx), %xmm4	#, tmp540
# benchy.c:134:   float randomnes[] = {0.0, 0.00001, 0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9};
	vmovaps	%ymm0, -7984(%rbp)	# tmp541, MEM <vector(8) float> [(float *)&randomnes]
	vmovaps	.LC16(%rip), %ymm0	#, tmp542
# benchy.c:125:   struct BeforeSortAction before_sort_actions[] = {
	movq	-8384(%rbp), %rax	# %sfp, ivtmp.2730
# benchy.c:134:   float randomnes[] = {0.0, 0.00001, 0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9};
	vmovaps	%ymm0, -7952(%rbp)	# tmp542, MEM <vector(8) float> [(float *)&randomnes + 32B]
# benchy.c:136:   int cpu_counters[] = {
	vmovdqa	.LC17(%rip), %xmm0	#, tmp543
# benchy.c:146:   int version = PAPI_library_init(PAPI_VER_CURRENT);
	movl	$100663296, %edi	#,
# benchy.c:136:   int cpu_counters[] = {
	movl	$-2147483648, -8128(%rbp)	#, cpu_counters[4]
# benchy.c:145:   int event_set = PAPI_NULL;
	movl	$-1, -8148(%rbp)	#, event_set
# benchy.c:125:   struct BeforeSortAction before_sort_actions[] = {
	vmovdqa	%xmm4, -8176(%rbp)	# tmp540, %sfp
	vmovdqa	%xmm4, (%rax,%rdx)	# tmp540, before_sort_actions
# benchy.c:136:   int cpu_counters[] = {
	vmovdqa	%xmm0, -8144(%rbp)	# tmp543, MEM <vector(4) int> [(int *)&cpu_counters]
# benchy.c:146:   int version = PAPI_library_init(PAPI_VER_CURRENT);
	vzeroupper
	call	PAPI_library_init@PLT	#
# benchy.c:147:   handle_error(PAPI_create_eventset(&event_set));
	leaq	-8148(%rbp), %rdi	#, tmp544
	call	PAPI_create_eventset@PLT	#
	movl	%eax, %edi	# tmp1075, _1
# benchy.c:77:   if (retval != PAPI_OK) {
	testl	%eax, %eax	# _1
	jne	.L2148	#,
	leaq	-8144(%rbp), %rbx	#, ivtmp.2750
	leaq	-8124(%rbp), %r12	#, _585
	movq	%rbx, %r13	# ivtmp.2750, ivtmp.2757
.L1976:
# benchy.c:149:     handle_error(PAPI_add_event(event_set, cpu_counters[i]));
	movl	0(%r13), %esi	# MEM[base: _449, offset: 0B],
	movl	-8148(%rbp), %edi	# event_set,
	call	PAPI_add_event@PLT	#
# benchy.c:77:   if (retval != PAPI_OK) {
	testl	%eax, %eax	# _4
	jne	.L2149	#,
# benchy.c:148:   for (int i = 0; i < CPU_COUNTER_COUNT; i++) {
	addq	$4, %r13	#, ivtmp.2757
	cmpq	%r12, %r13	# _585, ivtmp.2757
	jne	.L1976	#,
# benchy.c:151:   handle_error(PAPI_start(event_set));
	movl	-8148(%rbp), %edi	# event_set,
	call	PAPI_start@PLT	#
	movl	%eax, %edi	# tmp1077, _6
# benchy.c:77:   if (retval != PAPI_OK) {
	testl	%eax, %eax	# _6
	jne	.L2148	#,
# benchy.c:158:   file = fopen("output-gcc-c.csv", "w");
	leaq	.LC18(%rip), %rsi	#,
	leaq	.LC19(%rip), %rdi	#,
	call	fopen@PLT	#
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	movq	%rax, %rcx	# file,
	movl	$89, %edx	#,
	movl	$1, %esi	#,
	leaq	.LC20(%rip), %rdi	#,
	leaq	-6736(%rbp), %r15	#, tmp914
	movq	%rax, -8256(%rbp)	# file, %sfp
	call	fwrite@PLT	#
	movq	%r15, -8192(%rbp)	# tmp914, %sfp
	movq	%r14, -8176(%rbp)	# ivtmp.2737, %sfp
	movq	-8256(%rbp), %r14	# %sfp, file
	leaq	-5644(%rbp), %r13	#, tmp1072
.L1979:
# benchy.c:165:     handle_error(PAPI_get_event_info(cpu_counters[i], &info));
	movl	(%rbx), %edi	# MEM[base: _463, offset: 0B],
	movq	%r15, %rsi	# tmp914,
	call	PAPI_get_event_info@PLT	#
# benchy.c:77:   if (retval != PAPI_OK) {
	testl	%eax, %eax	# _8
	jne	.L2149	#,
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	movq	%r13, %rcx	# tmp1072,
	leaq	.LC21(%rip), %rdx	#,
	movl	$1, %esi	#,
	movq	%r14, %rdi	# file,
	xorl	%eax, %eax	#
# benchy.c:163:   for (int i = 0; i < CPU_COUNTER_COUNT; i++) {
	addq	$4, %rbx	#, ivtmp.2750
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	call	__fprintf_chk@PLT	#
# benchy.c:163:   for (int i = 0; i < CPU_COUNTER_COUNT; i++) {
	cmpq	%r12, %rbx	# _585, ivtmp.2750
	jne	.L1979	#,
# benchy.c:168:   for (int i = 0; i < SEEDS_AMOUNT; i++) {
	movq	-8176(%rbp), %r14	# %sfp, ivtmp.2737
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	movq	-8256(%rbp), %r13	# %sfp, file
# benchy.c:168:   for (int i = 0; i < SEEDS_AMOUNT; i++) {
	xorl	%r12d, %r12d	# i
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	leaq	.LC22(%rip), %rbx	#, tmp1071
.L1980:
	movl	%r12d, %ecx	# i,
	movq	%rbx, %rdx	# tmp1071,
	movl	$1, %esi	#,
	movq	%r13, %rdi	# file,
	xorl	%eax, %eax	#
# benchy.c:168:   for (int i = 0; i < SEEDS_AMOUNT; i++) {
	incl	%r12d	# i
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	call	__fprintf_chk@PLT	#
# benchy.c:168:   for (int i = 0; i < SEEDS_AMOUNT; i++) {
	cmpl	$10, %r12d	#, i
	jne	.L1980	#,
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	movq	-8256(%rbp), %rsi	# %sfp,
	movl	$10, %edi	#,
	call	fputc@PLT	#
	movq	%r14, -8320(%rbp)	# ivtmp.2737, %sfp
.L1982:
# benchy.c:178:     struct Algorithm algorithm = algorithms[algo_index];
	movq	-8320(%rbp), %rax	# %sfp, ivtmp.2737
# benchy.c:179:     if (argc > 1) {
	cmpl	$1, -8248(%rbp)	#, %sfp
# benchy.c:178:     struct Algorithm algorithm = algorithms[algo_index];
	vmovdqu	(%rax), %xmm4	# MEM[base: _69, offset: 0B], MEM[base: _69, offset: 0B]
	vmovdqu	48(%rax), %xmm5	# MEM[base: _69, offset: 0B], MEM[base: _69, offset: 0B]
	vmovdqu	32(%rax), %xmm6	# MEM[base: _69, offset: 0B], MEM[base: _69, offset: 0B]
	vmovdqa	%xmm4, -6736(%rbp)	# MEM[base: _69, offset: 0B], MEM[(struct Algorithm *)_944]
	vmovdqu	16(%rax), %xmm4	# MEM[base: _69, offset: 0B], MEM[base: _69, offset: 0B]
	vmovdqa	%xmm6, -6704(%rbp)	# MEM[base: _69, offset: 0B], MEM[(struct Algorithm *)_944]
	vmovdqa	%xmm4, -6720(%rbp)	# MEM[base: _69, offset: 0B], MEM[(struct Algorithm *)_944]
	vmovdqa	%xmm5, -8176(%rbp)	# MEM[base: _69, offset: 0B], %sfp
	vmovdqa	%xmm5, -6688(%rbp)	# MEM[base: _69, offset: 0B], MEM[(struct Algorithm *)_944]
# benchy.c:179:     if (argc > 1) {
	jle	.L1981	#,
# benchy.c:180:       if (!strstr(algorithm.name, argv[1]) && !strstr("*", argv[1])) {
	movq	-8304(%rbp), %rax	# %sfp, argv
	movq	-8192(%rbp), %rdi	# %sfp,
	movq	8(%rax), %r12	# MEM[(char * *)argv_292(D) + 8B], _9
	movq	%r12, %rsi	# _9,
	call	strstr@PLT	#
# benchy.c:180:       if (!strstr(algorithm.name, argv[1]) && !strstr("*", argv[1])) {
	testq	%rax, %rax	# tmp1080
	jne	.L1981	#,
# benchy.c:180:       if (!strstr(algorithm.name, argv[1]) && !strstr("*", argv[1])) {
	movq	%r12, %rsi	# _9,
	leaq	.LC23(%rip), %rdi	#,
	call	strstr@PLT	#
# benchy.c:180:       if (!strstr(algorithm.name, argv[1]) && !strstr("*", argv[1])) {
	testq	%rax, %rax	# tmp1081
	je	.L2074	#,
.L1981:
	movq	-8384(%rbp), %rax	# %sfp, ivtmp.2730
# benchy.c:168:   for (int i = 0; i < SEEDS_AMOUNT; i++) {
	movl	$0, -8296(%rbp)	#, %sfp
	movq	%rax, -8368(%rbp)	# ivtmp.2730, %sfp
	xorl	%ebx, %ebx	# runs_of_size
	xorl	%r14d, %r14d	# last_mean
.L2073:
# benchy.c:186:       struct BeforeSortAction before_sort_action_struct = before_sort_actions[action_index];
	movq	-8368(%rbp), %rax	# %sfp, ivtmp.2730
# benchy.c:187:       if (argc > 2) {
	cmpl	$2, -8248(%rbp)	#, %sfp
# benchy.c:186:       struct BeforeSortAction before_sort_action_struct = before_sort_actions[action_index];
	vmovdqu	(%rax), %xmm4	# MEM[base: _45, offset: 0B], MEM[base: _45, offset: 0B]
	vmovdqu	16(%rax), %xmm7	# MEM[base: _45, offset: 0B], MEM[base: _45, offset: 0B]
	vmovdqa	%xmm4, -8048(%rbp)	# MEM[base: _45, offset: 0B], before_sort_action_struct
	vmovdqu	32(%rax), %xmm4	# MEM[base: _45, offset: 0B], MEM[base: _45, offset: 0B]
	movq	48(%rax), %rax	# MEM[base: _45, offset: 0B], MEM[base: _45, offset: 0B]
	vmovdqa	%xmm7, -8032(%rbp)	# MEM[base: _45, offset: 0B], before_sort_action_struct
	movq	%rax, -8000(%rbp)	# MEM[base: _45, offset: 0B], before_sort_action_struct
	vmovdqa	%xmm4, -8176(%rbp)	# MEM[base: _45, offset: 0B], %sfp
	vmovdqa	%xmm4, -8016(%rbp)	# MEM[base: _45, offset: 0B], before_sort_action_struct
# benchy.c:187:       if (argc > 2) {
	jle	.L1984	#,
# benchy.c:188:         if (!strstr("*", argv[2])) {
	movq	-8304(%rbp), %rax	# %sfp, argv
	leaq	.LC23(%rip), %rdi	#,
	movq	16(%rax), %r12	# MEM[(char * *)argv_292(D) + 16B], _13
	movq	%r12, %rsi	# _13,
	call	strstr@PLT	#
# benchy.c:188:         if (!strstr("*", argv[2])) {
	testq	%rax, %rax	# tmp1082
	jne	.L1984	#,
# benchy.c:189:           if (action_index != 0) {
	cmpl	$0, -8296(%rbp)	#, %sfp
	je	.L2151	#,
.L1986:
# benchy.c:185:     for (int action_index = 0; action_index < sizeof(before_sort_actions) / sizeof(before_sort_actions[0]); action_index++) {          
	incl	-8296(%rbp)	# %sfp
# benchy.c:185:     for (int action_index = 0; action_index < sizeof(before_sort_actions) / sizeof(before_sort_actions[0]); action_index++) {          
	addq	$56, -8368(%rbp)	#, %sfp
# benchy.c:185:     for (int action_index = 0; action_index < sizeof(before_sort_actions) / sizeof(before_sort_actions[0]); action_index++) {          
	movl	-8296(%rbp), %eax	# %sfp, action_index
# benchy.c:185:     for (int action_index = 0; action_index < sizeof(before_sort_actions) / sizeof(before_sort_actions[0]); action_index++) {          
	cmpl	$6, %eax	#, action_index
	jne	.L2073	#,
.L2074:
# benchy.c:174:   for (int algo_index = 0; algo_index < sizeof(algorithms) / sizeof(algorithms[0]); algo_index++) {
	addq	$64, -8320(%rbp)	#, %sfp
	movq	-8320(%rbp), %rax	# %sfp, ivtmp.2737
	cmpq	%rax, -8192(%rbp)	# ivtmp.2737, %sfp
	jne	.L1982	#,
# benchy.c:393: }
	movq	-56(%rbp), %rax	# D.42982, tmp1227
	subq	%fs:40, %rax	# MEM[(<address-space-1> long unsigned int *)40B], tmp1227
	jne	.L2152	#,
	addq	$8384, %rsp	#,
	popq	%rbx	#
	popq	%r10	#
	.cfi_remember_state
	.cfi_def_cfa 10, 0
	popq	%r12	#
	popq	%r13	#
	popq	%r14	#
	popq	%r15	#
	xorl	%eax, %eax	#
	popq	%rbp	#
	leaq	-8(%r10), %rsp	#,
	.cfi_def_cfa 7, 8
	ret	
.L2151:
	.cfi_restore_state
# /usr/include/stdlib.h:363:   return (int) strtol (__nptr, (char **) NULL, 10);
	xorl	%esi, %esi	#
	movq	%r12, %rdi	# _13,
	movl	$10, %edx	#,
	call	strtol@PLT	#
# benchy.c:192:           before_sort_action_struct = before_sort_actions[atoi(argv[2])];
	cltq
	imulq	$56, %rax, %rax	#, _377, tmp560
	movl	$14, %ecx	#, tmp565
	leaq	-7840(%rbp,%rax), %rsi	#, tmp562
	leaq	-8048(%rbp), %rax	#, tmp930
	movq	%rax, %rdi	# tmp930, tmp930
	rep movsl
.L1984:
# benchy.c:195:       int before_sort_action = before_sort_action_struct.action;
	movl	-7996(%rbp), %eax	# before_sort_action_struct.action, before_sort_action
# benchy.c:198:         if (before_sort_action != PRESORTED && before_sort_action != END_RANDOM && randomnes_index != 0) {
	movq	$0, -8288(%rbp)	#, %sfp
# benchy.c:195:       int before_sort_action = before_sort_action_struct.action;
	movl	%eax, -8244(%rbp)	# before_sort_action, %sfp
# benchy.c:213:             (before_sort_action == 1 && randomnes_index != 0 && array_size > 10000000)
	andl	$-3, %eax	#, _235
	movl	%eax, -8332(%rbp)	# _235, %sfp
# benchy.c:198:         if (before_sort_action != PRESORTED && before_sort_action != END_RANDOM && randomnes_index != 0) {
	cmpl	$1, %eax	#, _235
	setne	-8290(%rbp)	#, %sfp
.L2072:
# benchy.c:198:         if (before_sort_action != PRESORTED && before_sort_action != END_RANDOM && randomnes_index != 0) {
	movl	-8288(%rbp), %edi	# %sfp,
	testl	%edi, %edi	#
	setne	-8289(%rbp)	#, %sfp
	je	.L2084	#,
	cmpb	$0, -8290(%rbp)	#, %sfp
	je	.L2084	#,
.L1987:
# benchy.c:197:       for (int randomnes_index = 0; randomnes_index < sizeof(randomnes) / sizeof(randomnes[0]); randomnes_index++) {
	incq	-8288(%rbp)	# %sfp
	movq	-8288(%rbp), %rax	# %sfp, ivtmp.2718
	cmpq	$16, %rax	#, ivtmp.2718
	jne	.L2072	#,
	jmp	.L1986	#
	.p2align 4,,10
	.p2align 3
.L2084:
# benchy.c:201:         float randomnes_value = randomnes[randomnes_index];
	movq	-8288(%rbp), %rax	# %sfp, ivtmp.2718
	movq	$0, -8240(%rbp)	#, %sfp
	vmovss	-7984(%rbp,%rax,4), %xmm7	# MEM[symbol: randomnes, index: ivtmp.2718_814, step: 4, offset: 0B], randomnes_value
	movl	%r14d, %r13d	# last_mean, last_mean
	vmovss	%xmm7, -8264(%rbp)	# randomnes_value, %sfp
	jmp	.L2070	#
.L2153:
# benchy.c:206:             if (size_index != 0) {
	cmpq	$0, -8240(%rbp)	#, %sfp
	jne	.L1990	#,
# /usr/include/stdlib.h:363:   return (int) strtol (__nptr, (char **) NULL, 10);
	movq	-8304(%rbp), %rax	# %sfp, argv
	xorl	%esi, %esi	#
	movq	24(%rax), %rdi	# MEM[(char * *)argv_292(D) + 24B], MEM[(char * *)argv_292(D) + 24B]
	movl	$10, %edx	#,
	call	strtol@PLT	#
# benchy.c:212:           if ((before_sort_action > 2 && array_size > 10000000) ||
	cmpl	$10000000, %eax	#, _379
# /usr/include/stdlib.h:363:   return (int) strtol (__nptr, (char **) NULL, 10);
	movl	%eax, %r14d	# _379, array_size
# benchy.c:212:           if ((before_sort_action > 2 && array_size > 10000000) ||
	setg	%al	#, _21
# benchy.c:212:           if ((before_sort_action > 2 && array_size > 10000000) ||
	cmpl	$2, -8244(%rbp)	#, %sfp
	jle	.L1993	#,
	testb	%al, %al	# _21
	jne	.L1991	#,
.L1993:
# benchy.c:213:             (before_sort_action == 1 && randomnes_index != 0 && array_size > 10000000)
	cmpl	$1, -8244(%rbp)	#, %sfp
	sete	%dl	#, tmp578
# benchy.c:213:             (before_sort_action == 1 && randomnes_index != 0 && array_size > 10000000)
	testb	%dl, -8289(%rbp)	# tmp578, %sfp
	je	.L2085	#,
	testb	%al, %al	# _21
	jne	.L1990	#,
.L2085:
# benchy.c:219:           if (strstr(algorithm.name, "Insertionsort") && array_size >= 100000) {
	movq	-8192(%rbp), %rdi	# %sfp,
	leaq	.LC24(%rip), %rsi	#,
	call	strstr@PLT	#
# benchy.c:219:           if (strstr(algorithm.name, "Insertionsort") && array_size >= 100000) {
	testq	%rax, %rax	# tmp1085
	je	.L2086	#,
	cmpl	$99999, %r14d	#, array_size
	jle	.L2086	#,
.L1990:
# benchy.c:203:         for (int size_index = 0; size_index < sizeof(array_sizes) / sizeof(array_sizes[0]); size_index++) {
	cmpl	$16, -8240(%rbp)	#, %sfp
	je	.L2069	#,
.L1991:
	incq	-8240(%rbp)	# %sfp
.L2070:
# benchy.c:205:           if (argc > 3) {
	cmpl	$3, -8248(%rbp)	#, %sfp
	jg	.L2153	#,
# benchy.c:204:           int array_size = array_sizes[size_index];
	movq	-8240(%rbp), %rax	# %sfp, ivtmp.2714
	movl	-7920(%rbp,%rax,4), %r14d	# MEM[symbol: array_sizes, index: ivtmp.2714_812, step: 4, offset: 0B], array_size
# benchy.c:212:           if ((before_sort_action > 2 && array_size > 10000000) ||
	cmpl	$10000000, %r14d	#, array_size
	setg	%al	#, _21
# benchy.c:212:           if ((before_sort_action > 2 && array_size > 10000000) ||
	cmpl	$2, -8244(%rbp)	#, %sfp
	jle	.L1993	#,
	testb	%al, %al	# _21
	je	.L1993	#,
# benchy.c:203:         for (int size_index = 0; size_index < sizeof(array_sizes) / sizeof(array_sizes[0]); size_index++) {
	cmpl	$16, -8240(%rbp)	#, %sfp
	jne	.L1991	#,
.L2069:
# benchy.c:387:         if (runs_of_size != 0) {
	vmovd	%ebx, %xmm6	# runs_of_size, runs_of_size
	vxorps	%xmm3, %xmm3, %xmm3	# tmp1442
	vucomiss	%xmm3, %xmm6	# tmp1442, runs_of_size
	movl	%r13d, %r14d	# last_mean, last_mean
	jp	.L2068	#,
	vcomiss	%xmm3, %xmm6	# tmp1444, runs_of_size
	je	.L1987	#,
.L2068:
# benchy.c:388:           printf("  Average: %.3f\n", last_mean / runs_of_size);
	vmovd	%r14d, %xmm7	# last_mean, last_mean
	vmovd	%ebx, %xmm6	# runs_of_size, runs_of_size
	vdivss	%xmm6, %xmm7, %xmm0	# runs_of_size, last_mean, tmp900
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	leaq	.LC44(%rip), %rsi	#,
	movl	$1, %edi	#,
	movl	$1, %eax	#,
# benchy.c:388:           printf("  Average: %.3f\n", last_mean / runs_of_size);
	vcvtss2sd	%xmm0, %xmm0, %xmm0	# tmp900, tmp901
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	call	__printf_chk@PLT	#
	jmp	.L1987	#
.L2086:
# benchy.c:226:           double *seed_times = (double *) calloc(SEEDS_AMOUNT, sizeof(double));
	movl	$8, %esi	#,
	movl	$10, %edi	#,
	call	calloc@PLT	#
# benchy.c:227:           double *event_values_of_row = (double *) calloc(sizeof(cpu_counters) / sizeof(*cpu_counters), sizeof(double));
	movl	$8, %esi	#,
	movl	$5, %edi	#,
# benchy.c:226:           double *seed_times = (double *) calloc(SEEDS_AMOUNT, sizeof(double));
	movq	%rax, -8280(%rbp)	# tmp1086, %sfp
# benchy.c:227:           double *event_values_of_row = (double *) calloc(sizeof(cpu_counters) / sizeof(*cpu_counters), sizeof(double));
	call	calloc@PLT	#
	movq	%rax, -8328(%rbp)	# tmp1087, %sfp
# benchy.c:243:             int *dataset = (int *) malloc(sizeof(int) * array_size);
	movslq	%r14d, %rax	# array_size, _28
	leaq	0(,%rax,4), %r10	#, _29
	movq	%rax, -8312(%rbp)	# _28, %sfp
# benchy.c:254:               for (int i = 0; i < array_size / 2; i++) {
	movl	%r14d, %eax	# array_size, tmp587
	shrl	$31, %eax	#, tmp587
	addl	%r14d, %eax	# array_size, tmp588
	movl	%eax, %edi	# tmp588, tmp588
	movl	%r14d, %eax	# array_size, bnd.2582
	shrl	$3, %eax	#,
	salq	$5, %rax	#, bnd.2582
	movq	%rax, -8360(%rbp)	# bnd.2582, %sfp
	movl	%r14d, %eax	# array_size, niters_vector_mult_vf.2583
	sarl	%edi	# tmp588
	leal	-1(%r14), %r13d	#, _739
	andl	$-8, %eax	#, niters_vector_mult_vf.2583
	movslq	%r13d, %rdx	# _739, _649
	movl	%eax, -8372(%rbp)	# niters_vector_mult_vf.2583, %sfp
	movl	%edi, %eax	# tmp589, _684
	leaq	0(,%rdx,4), %rbx	#, _689
	cmpl	$1, %r14d	#, array_size
	leaq	0(,%rax,4), %rcx	#, tmp593
	movl	$4, %edx	#, tmp594
	cmovle	%rdx, %rcx	# tmp593,, tmp594, tmp593
	negq	%rax	# tmp597
	movl	$0, %esi	#, tmp596
	cmpl	$1, %r14d	#, array_size
	leaq	4(,%rax,4), %rax	#, tmp595
	cmovle	%rsi, %rax	# tmp595,, tmp596, tmp595
# benchy.c:243:             int *dataset = (int *) malloc(sizeof(int) * array_size);
	movq	%r10, -8272(%rbp)	# _29, %sfp
	addq	%rbx, %rax	# _689, tmp600
	cmpq	%rax, %rcx	# tmp600, tmp593
	setle	%al	#, tmp602
	testq	%r10, %r10	# _29
	setle	%cl	#, tmp604
	orl	%ecx, %eax	# tmp604, tmp605
	cmpl	$7, %r14d	#, array_size
	setg	%cl	#, tmp607
	andl	%ecx, %eax	# tmp607, tmp605
	movb	%al, -8291(%rbp)	# tmp605, %sfp
	movl	$1, %eax	#, tmp609
	cmpl	$1, %r14d	#, array_size
	movl	%eax, %esi	# tmp609, tmp609
	cmovg	%edi, %esi	# tmp589,, tmp609
	leaq	-28(%rbx), %rax	#, _746
	movq	%rax, -8400(%rbp)	# _746, %sfp
	movl	%esi, %eax	# niters.2519, bnd.2520
	shrl	$3, %eax	#,
	salq	$5, %rax	#, bnd.2520
	movq	%rax, -8408(%rbp)	# bnd.2520, %sfp
# benchy.c:270:               sorted_dataset[i] = dataset[i];
	movl	%r13d, %eax	# _739, _739
	leaq	4(,%rax,4), %rax	#, _536
	movl	%esi, -8336(%rbp)	# niters.2519, %sfp
	andl	$-8, %esi	#, niters_vector_mult_vf.2521
	testl	%r14d, %r14d	# array_size
	cmovg	%rax, %rdx	# _536,, tmp594
	movq	%rax, -8224(%rbp)	# _536, %sfp
	leaq	-8048(%rbp), %rax	#, tmp930
# benchy.c:254:               for (int i = 0; i < array_size / 2; i++) {
	movl	%edi, -8376(%rbp)	# tmp589, %sfp
	movq	%rbx, -8352(%rbp)	# _689, %sfp
	movl	%esi, -8388(%rbp)	# niters_vector_mult_vf.2521, %sfp
# benchy.c:270:               sorted_dataset[i] = dataset[i];
	movq	%rdx, -8344(%rbp)	# tmp594, %sfp
# benchy.c:229:           int seeds_performed = 0;
	movl	$0, -8260(%rbp)	#, %sfp
# benchy.c:270:               sorted_dataset[i] = dataset[i];
	movq	$0, -8232(%rbp)	#, %sfp
	movq	%rax, -8216(%rbp)	# tmp930, %sfp
	movl	%r14d, -8176(%rbp)	# array_size, %sfp
# benchy.c:230:           double seeds_total = 0;
	vxorpd	%xmm8, %xmm8, %xmm8	# seeds_total
	movl	%r13d, %r14d	# _739, _739
.L2052:
# benchy.c:234:             if (argc > 4) {
	cmpl	$4, -8248(%rbp)	#, %sfp
	jle	.L2154	#,
# benchy.c:235:               if (seed_index != 0) {
	cmpq	$0, -8232(%rbp)	#, %sfp
	je	.L2155	#,
.L1999:
# benchy.c:232:           for (int seed_index = 0; seed_index < SEEDS_AMOUNT; seed_index++) {
	incq	-8232(%rbp)	# %sfp
	movq	-8232(%rbp), %rax	# %sfp, ivtmp.2706
	cmpq	$10, %rax	#, ivtmp.2706
	jne	.L2052	#,
# benchy.c:354:           fprintf(file, "%s,%d,%s,%f", algorithm.name, array_size, before_sort_action_struct.name, before_sort_action == PRESORTED || before_sort_action == END_RANDOM ? randomnes_value : -1);
	cmpl	$1, -8332(%rbp)	#, %sfp
	movl	-8176(%rbp), %r14d	# %sfp, array_size
	je	.L2156	#,
	movq	.LC9(%rip), %rax	#, tmp1410
	vmovq	%rax, %xmm0	# tmp1410, iftmp.73_204
	movq	.LC41(%rip), %rax	#, tmp1411
	movq	%rax, -8184(%rbp)	# tmp1411, %sfp
.L2053:
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	movq	-8216(%rbp), %r9	# %sfp,
	movq	-8192(%rbp), %rcx	# %sfp,
	movq	-8256(%rbp), %rdi	# %sfp,
	movl	%r14d, %r8d	# array_size,
	leaq	.LC42(%rip), %rdx	#,
	movl	$1, %esi	#,
	movl	$1, %eax	#,
	vmovsd	%xmm8, -8200(%rbp)	# seeds_total, %sfp
	call	__fprintf_chk@PLT	#
# benchy.c:356:           float mean = seeds_total / seeds_performed;
	movl	-8260(%rbp), %eax	# %sfp, seeds_performed
	vxorpd	%xmm5, %xmm5, %xmm5	# tmp1412
	vcvtsi2sdl	%eax, %xmm5, %xmm0	# seeds_performed, tmp1412, tmp1111
	vmovsd	-8200(%rbp), %xmm8	# %sfp, seeds_total
# benchy.c:358:           last_mean += mean;
	vxorps	%xmm6, %xmm6, %xmm6	# tmp1416
# benchy.c:356:           float mean = seeds_total / seeds_performed;
	vdivsd	%xmm0, %xmm8, %xmm4	# _124, seeds_total, tmp842
	vmovsd	%xmm0, -8176(%rbp)	# _124, %sfp
# benchy.c:356:           float mean = seeds_total / seeds_performed;
	vcvtsd2ss	%xmm4, %xmm4, %xmm4	# tmp842, mean
# benchy.c:358:           last_mean += mean;
	vaddss	%xmm6, %xmm4, %xmm7	# tmp1416, mean, last_mean
	vmovd	%xmm7, %r13d	# last_mean, last_mean
# benchy.c:361:           for (int index = 0; index < seeds_performed; index++) {
	testl	%eax, %eax	# seeds_performed
	je	.L2082	#,
.L2075:
	movl	-8260(%rbp), %eax	# %sfp, seeds_performed
	movl	$1, %edx	#, tmp845
	testl	%eax, %eax	# seeds_performed
	cmovg	%eax, %edx	# seeds_performed,, niters.2487
# benchy.c:362:             float diff = mean - seed_times[index];
	vcvtss2sd	%xmm4, %xmm4, %xmm5	# mean, tmp924
	cmpl	$7, %eax	#, seeds_performed
	jle	.L2083	#,
	movl	%edx, %ecx	# niters.2487, bnd.2488
	movq	-8280(%rbp), %rsi	# %sfp, seed_times
	shrl	$3, %ecx	#,
	salq	$6, %rcx	#, tmp849
	vbroadcastsd	%xmm5, %ymm6	# tmp924, vect_cst__452
	movq	%rsi, %rax	# seed_times, ivtmp.2652
	addq	%rsi, %rcx	# seed_times, _620
# benchy.c:362:             float diff = mean - seed_times[index];
	vxorps	%xmm0, %xmm0, %xmm0	# sum
.L2056:
# benchy.c:362:             float diff = mean - seed_times[index];
	vsubpd	(%rax), %ymm6, %ymm1	# MEM[base: _257, offset: 0B], vect_cst__452, vect__131.2495
	vsubpd	32(%rax), %ymm6, %ymm2	# MEM[base: _257, offset: 32B], vect_cst__452, vect__131.2495
	addq	$64, %rax	#, ivtmp.2652
# benchy.c:362:             float diff = mean - seed_times[index];
	vcvtpd2psy	%ymm1, %xmm1	# vect__131.2495, tmp854
	vcvtpd2psy	%ymm2, %xmm2	# vect__131.2495, tmp855
	vinsertf128	$0x1, %xmm2, %ymm1, %ymm1	# tmp855, tmp854, vect_diff_360.2496
# benchy.c:363:             float square = powf(diff, 2);
	vmulps	%ymm1, %ymm1, %ymm1	# vect_diff_360.2496, vect_diff_360.2496, vect_powmult_18.2497
	vaddss	%xmm0, %xmm1, %xmm3	# sum, stmp_sum_363.2498, stmp_sum_363.2498
	vshufps	$85, %xmm1, %xmm1, %xmm0	#, tmp856, tmp856, stmp_sum_363.2498
	vshufps	$255, %xmm1, %xmm1, %xmm2	#, tmp856, tmp856, stmp_sum_363.2498
	vaddss	%xmm3, %xmm0, %xmm3	# stmp_sum_363.2498, stmp_sum_363.2498, stmp_sum_363.2498
	vunpckhps	%xmm1, %xmm1, %xmm0	# tmp856, tmp856, stmp_sum_363.2498
	vextractf128	$0x1, %ymm1, %xmm1	# vect_powmult_18.2497, tmp860
	vaddss	%xmm3, %xmm0, %xmm0	# stmp_sum_363.2498, stmp_sum_363.2498, stmp_sum_363.2498
	vaddss	%xmm0, %xmm2, %xmm2	# stmp_sum_363.2498, stmp_sum_363.2498, stmp_sum_363.2498
	vshufps	$85, %xmm1, %xmm1, %xmm0	#, tmp860, tmp860, stmp_sum_363.2498
	vaddss	%xmm2, %xmm1, %xmm2	# stmp_sum_363.2498, stmp_sum_363.2498, stmp_sum_363.2498
	vaddss	%xmm2, %xmm0, %xmm2	# stmp_sum_363.2498, stmp_sum_363.2498, stmp_sum_363.2498
	vunpckhps	%xmm1, %xmm1, %xmm0	# tmp860, tmp860, stmp_sum_363.2498
# benchy.c:364:             sum += square; 
	vshufps	$255, %xmm1, %xmm1, %xmm1	#, tmp860, tmp860, stmp_sum_363.2498
	vaddss	%xmm2, %xmm0, %xmm0	# stmp_sum_363.2498, stmp_sum_363.2498, stmp_sum_363.2498
	vaddss	%xmm1, %xmm0, %xmm0	# stmp_sum_363.2498, stmp_sum_363.2498, sum
	cmpq	%rcx, %rax	# _620, ivtmp.2652
	jne	.L2056	#,
	movl	%edx, %ecx	# niters.2487, niters_vector_mult_vf.2489
	andl	$-8, %ecx	#,
	movl	%ecx, %eax	# niters_vector_mult_vf.2489, tmp.2490
	cmpl	%edx, %ecx	# niters.2487, niters_vector_mult_vf.2489
	je	.L2145	#,
.L2055:
	subl	%ecx, %edx	# niters_vector_mult_vf.2489, niters.2499
	leal	-1(%rdx), %esi	#, tmp866
	cmpl	$2, %esi	#, tmp866
	jbe	.L2058	#,
	movq	-8280(%rbp), %rsi	# %sfp, seed_times
	vmovddup	%xmm5, %xmm3	# tmp924, tmp869
	leaq	(%rsi,%rcx,8), %rcx	#, vectp_seed_times.2504
# benchy.c:362:             float diff = mean - seed_times[index];
	vsubpd	(%rcx), %xmm3, %xmm2	# MEM <vector(2) double> [(double *)vectp_seed_times.2504_638], tmp869, vect__335.2507
	vsubpd	16(%rcx), %xmm3, %xmm3	# MEM <vector(2) double> [(double *)vectp_seed_times.2504_638 + 16B], tmp869, vect__335.2507
	movl	%edx, %ecx	# niters.2499, niters_vector_mult_vf.2501
	andl	$-4, %ecx	#, niters_vector_mult_vf.2501
# benchy.c:362:             float diff = mean - seed_times[index];
	vinsertf128	$0x1, %xmm3, %ymm2, %ymm2	# vect__335.2507, vect__335.2507, tmp874
	vcvtpd2psy	%ymm2, %xmm2	# tmp874, vect_diff_51.2508
# benchy.c:363:             float square = powf(diff, 2);
	vmulps	%xmm2, %xmm2, %xmm2	# vect_diff_51.2508, vect_diff_51.2508, vect_powmult_489.2509
	addl	%ecx, %eax	# niters_vector_mult_vf.2501, tmp.2490
	vaddss	%xmm2, %xmm0, %xmm3	# stmp_sum_66.2510, sum, stmp_sum_66.2510
	vshufps	$85, %xmm2, %xmm2, %xmm0	#, vect_powmult_489.2509, vect_powmult_489.2509, stmp_sum_66.2510
	vaddss	%xmm3, %xmm0, %xmm0	# stmp_sum_66.2510, stmp_sum_66.2510, stmp_sum_66.2510
	vunpckhps	%xmm2, %xmm2, %xmm3	# vect_powmult_489.2509, vect_powmult_489.2509, stmp_sum_66.2510
# benchy.c:364:             sum += square; 
	vshufps	$255, %xmm2, %xmm2, %xmm2	#, vect_powmult_489.2509, vect_powmult_489.2509, stmp_sum_66.2510
	vaddss	%xmm3, %xmm0, %xmm0	# stmp_sum_66.2510, stmp_sum_66.2510, stmp_sum_66.2510
	vaddss	%xmm2, %xmm0, %xmm0	# stmp_sum_66.2510, stmp_sum_66.2510, sum
	cmpl	%ecx, %edx	# niters_vector_mult_vf.2501, niters.2499
	je	.L2145	#,
.L2058:
# benchy.c:362:             float diff = mean - seed_times[index];
	movq	-8280(%rbp), %rsi	# %sfp, seed_times
# benchy.c:362:             float diff = mean - seed_times[index];
	movslq	%eax, %rcx	# tmp.2490, tmp.2490
# benchy.c:362:             float diff = mean - seed_times[index];
	vsubsd	(%rsi,%rcx,8), %xmm5, %xmm2	# *_1028, tmp924, tmp878
# benchy.c:361:           for (int index = 0; index < seeds_performed; index++) {
	movl	-8260(%rbp), %edi	# %sfp, seeds_performed
# benchy.c:362:             float diff = mean - seed_times[index];
	leaq	0(,%rcx,8), %rdx	#, _1035
# benchy.c:361:           for (int index = 0; index < seeds_performed; index++) {
	leal	1(%rax), %ecx	#, index
# benchy.c:362:             float diff = mean - seed_times[index];
	vcvtsd2ss	%xmm2, %xmm2, %xmm2	# tmp878, diff
# benchy.c:364:             sum += square; 
	vfmadd231ss	%xmm2, %xmm2, %xmm0	# diff, diff, sum
# benchy.c:361:           for (int index = 0; index < seeds_performed; index++) {
	cmpl	%edi, %ecx	# seeds_performed, index
	jge	.L2145	#,
# benchy.c:362:             float diff = mean - seed_times[index];
	vsubsd	8(%rsi,%rdx), %xmm5, %xmm2	# *_80, tmp924, tmp880
# benchy.c:361:           for (int index = 0; index < seeds_performed; index++) {
	addl	$2, %eax	#, index
# benchy.c:362:             float diff = mean - seed_times[index];
	vcvtsd2ss	%xmm2, %xmm2, %xmm2	# tmp880, diff
# benchy.c:364:             sum += square; 
	vfmadd231ss	%xmm2, %xmm2, %xmm0	# diff, diff, sum
# benchy.c:361:           for (int index = 0; index < seeds_performed; index++) {
	cmpl	%edi, %eax	# seeds_performed, index
	jge	.L2145	#,
# benchy.c:362:             float diff = mean - seed_times[index];
	vsubsd	16(%rsi,%rdx), %xmm5, %xmm2	# *_175, tmp924, tmp882
# benchy.c:362:             float diff = mean - seed_times[index];
	vcvtsd2ss	%xmm2, %xmm2, %xmm2	# tmp882, diff
# benchy.c:364:             sum += square; 
	vfmadd231ss	%xmm2, %xmm2, %xmm0	# diff, diff, sum
	vzeroupper
.L2054:
# benchy.c:366:           float std_dev = sqrtf(sum / (float)seeds_performed);
	vxorps	%xmm3, %xmm3, %xmm3	# tmp1430
	vcvtsi2ssl	-8260(%rbp), %xmm3, %xmm2	# %sfp, tmp1430, tmp1112
	vxorps	%xmm7, %xmm7, %xmm7	# tmp1432
# benchy.c:366:           float std_dev = sqrtf(sum / (float)seeds_performed);
	vdivss	%xmm2, %xmm0, %xmm0	# tmp883, sum, _133
	vucomiss	%xmm0, %xmm7	# _133, tmp1432
	ja	.L2135	#,
	vsqrtss	%xmm0, %xmm0, %xmm2	# _133, std_dev
.L2062:
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	movq	-8256(%rbp), %rbx	# %sfp, file
	vmovsd	%xmm5, %xmm5, %xmm0	# tmp924,
	movq	%rbx, %rdi	# file,
	leaq	.LC43(%rip), %rdx	#,
	movl	$1, %esi	#,
	movl	$1, %eax	#,
	vmovsd	%xmm8, -8200(%rbp)	# seeds_total, %sfp
	vmovss	%xmm2, -8216(%rbp)	# std_dev, %sfp
	vmovss	%xmm4, -8208(%rbp)	# mean, %sfp
	call	__fprintf_chk@PLT	#
# benchy.c:368:           fprintf(file, ",%f", mean / array_size);
	vxorps	%xmm4, %xmm4, %xmm4	# tmp1433
	vcvtsi2ssl	%r14d, %xmm4, %xmm0	# array_size, tmp1433, tmp1113
	vmovss	-8208(%rbp), %xmm4	# %sfp, mean
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	movq	%rbx, %rdi	# file,
	leaq	.LC43(%rip), %rdx	#,
# benchy.c:368:           fprintf(file, ",%f", mean / array_size);
	vdivss	%xmm0, %xmm4, %xmm0	# tmp886, mean, tmp887
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	movl	$1, %esi	#,
	movl	$1, %eax	#,
# benchy.c:368:           fprintf(file, ",%f", mean / array_size);
	vcvtss2sd	%xmm0, %xmm0, %xmm0	# tmp887, tmp888
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	call	__fprintf_chk@PLT	#
# benchy.c:369:           fprintf(file, ",%f", std_dev);
	vmovss	-8216(%rbp), %xmm2	# %sfp, std_dev
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	movq	%rbx, %rdi	# file,
	leaq	.LC43(%rip), %rdx	#,
	movl	$1, %esi	#,
	movl	$1, %eax	#,
# benchy.c:369:           fprintf(file, ",%f", std_dev);
	vcvtss2sd	%xmm2, %xmm2, %xmm0	# std_dev, tmp889
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	call	__fprintf_chk@PLT	#
	movq	-8328(%rbp), %rax	# %sfp, event_values_of_row
	vmovsd	-8200(%rbp), %xmm8	# %sfp, seeds_total
	movq	%rax, %r15	# event_values_of_row, ivtmp.2646
	leaq	40(%rax), %r12	#, _261
	leaq	.LC43(%rip), %rbx	#, tmp933
	vmovq	%xmm8, %r14	# seeds_total, seeds_total
.L2063:
# benchy.c:371:             fprintf(file, ",%f", event_values_of_row[index] / seeds_performed);
	vmovsd	(%r15), %xmm0	# MEM[base: _263, offset: 0B], MEM[base: _263, offset: 0B]
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	movq	-8256(%rbp), %rdi	# %sfp,
	movq	%rbx, %rdx	# tmp933,
	movl	$1, %esi	#,
	movl	$1, %eax	#,
# benchy.c:370:           for (int index = 0; index < CPU_COUNTER_COUNT; index++) {
	addq	$8, %r15	#, ivtmp.2646
# benchy.c:371:             fprintf(file, ",%f", event_values_of_row[index] / seeds_performed);
	vdivsd	-8176(%rbp), %xmm0, %xmm0	# %sfp, MEM[base: _263, offset: 0B], tmp890
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	call	__fprintf_chk@PLT	#
# benchy.c:370:           for (int index = 0; index < CPU_COUNTER_COUNT; index++) {
	cmpq	%r15, %r12	# ivtmp.2646, _261
	jne	.L2063	#,
# benchy.c:373:           for (int index = 0; index < seeds_performed; index++) {
	movl	-8260(%rbp), %eax	# %sfp,
	vmovq	%r14, %xmm8	# seeds_total, seeds_total
	testl	%eax, %eax	#
	je	.L2067	#,
	movl	-8260(%rbp), %eax	# %sfp, seeds_performed
	movq	-8280(%rbp), %rsi	# %sfp, seed_times
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	movq	%r14, -8200(%rbp)	# seeds_total, %sfp
	decl	%eax	# tmp894
	movq	-8256(%rbp), %r14	# %sfp, file
	movl	%r13d, -8176(%rbp)	# last_mean, %sfp
	leaq	8(%rsi,%rax,8), %r12	#, _267
	leaq	.LC43(%rip), %rbx	#, tmp932
	movq	%rsi, %r13	# ivtmp.2638, ivtmp.2638
.L2066:
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	vmovsd	0(%r13), %xmm0	# MEM[base: _274, offset: 0B],
	movq	%rbx, %rdx	# tmp932,
	movl	$1, %esi	#,
	movq	%r14, %rdi	# file,
	movl	$1, %eax	#,
# benchy.c:373:           for (int index = 0; index < seeds_performed; index++) {
	addq	$8, %r13	#, ivtmp.2638
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	call	__fprintf_chk@PLT	#
# benchy.c:373:           for (int index = 0; index < seeds_performed; index++) {
	cmpq	%r13, %r12	# ivtmp.2638, _267
	jne	.L2066	#,
	movl	-8176(%rbp), %r13d	# %sfp, last_mean
	vmovsd	-8200(%rbp), %xmm8	# %sfp, seeds_total
.L2067:
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	movq	-8256(%rbp), %rbx	# %sfp, file
	movl	$10, %edi	#,
	movq	%rbx, %rsi	# file,
	vmovsd	%xmm8, -8176(%rbp)	# seeds_total, %sfp
	call	fputc@PLT	#
# benchy.c:377:           free(seed_times);
	movq	-8280(%rbp), %rdi	# %sfp,
	call	free@PLT	#
# benchy.c:378:           free(event_values_of_row);
	movq	-8328(%rbp), %rdi	# %sfp,
	call	free@PLT	#
# benchy.c:379:           fflush(file);
	movq	%rbx, %rdi	# file,
	call	fflush@PLT	#
# benchy.c:381:           if (seeds_total > 750000000000) {
	vmovsd	-8176(%rbp), %xmm8	# %sfp, seeds_total
	vcomisd	-8184(%rbp), %xmm8	# %sfp, seeds_total
	ja	.L2065	#,
# benchy.c:359:           runs_of_size++;
	movl	$0x3f800000, %ebx	#, runs_of_size
	jmp	.L1990	#
.L2155:
# /usr/include/stdlib.h:363:   return (int) strtol (__nptr, (char **) NULL, 10);
	movq	-8304(%rbp), %rax	# %sfp, argv
	movl	$10, %edx	#,
	movq	32(%rax), %rdi	# MEM[(char * *)argv_292(D) + 32B], MEM[(char * *)argv_292(D) + 32B]
	xorl	%esi, %esi	#
	call	strtol@PLT	#
# /usr/include/stdlib.h:363:   return (int) strtol (__nptr, (char **) NULL, 10);
	movl	%eax, -8200(%rbp)	# tmp1088, %sfp
.L1998:
# benchy.c:243:             int *dataset = (int *) malloc(sizeof(int) * array_size);
	movq	-8272(%rbp), %rdi	# %sfp,
	call	malloc@PLT	#
# data-random.h:12:   srand(seed);
	movl	-8200(%rbp), %edi	# %sfp,
# benchy.c:243:             int *dataset = (int *) malloc(sizeof(int) * array_size);
	movq	%rax, %rbx	# tmp1089, dataset
	movq	%rax, -8184(%rbp)	# dataset, %sfp
	movq	%rbx, %r12	# dataset, ivtmp.2703
# data-random.h:12:   srand(seed);
	call	srand@PLT	#
	movq	%rbx, %rax	# dataset, dataset
# data-random.h:13:   for (int i = 0; i < amount; i++) {
	movl	-8176(%rbp), %esi	# %sfp,
	movq	-8224(%rbp), %rbx	# %sfp, _785
	addq	%rax, %rbx	# dataset, _785
	testl	%esi, %esi	#
	jle	.L2004	#,
	.p2align 4,,10
	.p2align 3
.L2003:
# data-random.h:14:     array[i] = rand();
	call	rand@PLT	#
# data-random.h:14:     array[i] = rand();
	movl	%eax, (%r12)	# tmp1090, MEM[base: _757, offset: 0B]
# data-random.h:13:   for (int i = 0; i < amount; i++) {
	addq	$4, %r12	#, ivtmp.2703
	cmpq	%rbx, %r12	# _785, ivtmp.2703
	jne	.L2003	#,
.L2004:
# benchy.c:247:             if (before_sort_action == PRESORTED) {
	cmpl	$1, -8244(%rbp)	#, %sfp
	je	.L2157	#,
# benchy.c:250:             } else if (before_sort_action == END_RANDOM) {
	cmpl	$3, -8244(%rbp)	#, %sfp
	je	.L2158	#,
# benchy.c:252:             } else if (before_sort_action == SORT_REVERSE) {
	cmpl	$2, -8244(%rbp)	#, %sfp
	je	.L2159	#,
# benchy.c:257:             } else if (before_sort_action == LIMIT_VALUES_1000) {
	cmpl	$4, -8244(%rbp)	#, %sfp
	je	.L2160	#,
# benchy.c:261:             } else if (before_sort_action == LIMIT_VALUES_10000) {
	cmpl	$5, -8244(%rbp)	#, %sfp
	je	.L2161	#,
.L2005:
# benchy.c:266:             int *sorted_dataset = (int *) malloc(sizeof(int) * array_size);
	movq	-8272(%rbp), %rbx	# %sfp, _29
	movq	%rbx, %rdi	# _29,
	call	malloc@PLT	#
# benchy.c:267:             int *data_to_sort = (int *) malloc(sizeof(int) * array_size);
	movq	%rbx, %rdi	# _29,
# benchy.c:266:             int *sorted_dataset = (int *) malloc(sizeof(int) * array_size);
	movq	%rax, %r13	# tmp1093, sorted_dataset
# benchy.c:267:             int *data_to_sort = (int *) malloc(sizeof(int) * array_size);
	call	malloc@PLT	#
# benchy.c:269:             for (int i = 0; i < array_size; i++) {
	movl	-8176(%rbp), %ecx	# %sfp,
# benchy.c:267:             int *data_to_sort = (int *) malloc(sizeof(int) * array_size);
	movq	%rax, %r15	# tmp1094, data_to_sort
# benchy.c:269:             for (int i = 0; i < array_size; i++) {
	testl	%ecx, %ecx	#
	jle	.L2032	#,
.L2031:
# benchy.c:270:               sorted_dataset[i] = dataset[i];
	movq	-8344(%rbp), %rdx	# %sfp,
	movq	-8184(%rbp), %rsi	# %sfp,
	movq	%r13, %rdi	# sorted_dataset,
	call	memcpy@PLT	#
.L2032:
# benchy.c:73:   qsort(&array[low], high - low + 1, sizeof (int), compare_ints);
	movq	-8312(%rbp), %rsi	# %sfp,
	leaq	compare_ints(%rip), %rcx	#,
	movl	$4, %edx	#,
	movq	%r13, %rdi	# sorted_dataset,
	call	qsort@PLT	#
# benchy.c:284:             long long int *event_values_of_seed = (long long int *) malloc(sizeof(long long int) * sizeof(cpu_counters) / sizeof(*cpu_counters));
	movl	$40, %edi	#,
	call	malloc@PLT	#
# benchy.c:286:               event_values_of_seed[i] = 0;
	vpxor	%xmm0, %xmm0, %xmm0	# tmp795
# benchy.c:284:             long long int *event_values_of_seed = (long long int *) malloc(sizeof(long long int) * sizeof(cpu_counters) / sizeof(*cpu_counters));
	movq	%rax, %r12	# tmp1095, event_values_of_seed
# benchy.c:286:               event_values_of_seed[i] = 0;
	movq	$0, 32(%rax)	#, MEM[(long long int *)event_values_of_seed_322 + 32B]
	vmovdqu	%ymm0, (%rax)	# tmp795, MEM <vector(4) long long int> [(long long int *)event_values_of_seed_322]
	movl	%r14d, %eax	# _739, _739
# benchy.c:283:             int runs = 0;
	xorl	%ebx, %ebx	# runs
	movq	%r13, %r14	# sorted_dataset, sorted_dataset
	movq	%r12, %r13	# event_values_of_seed, event_values_of_seed
	movl	%eax, %r12d	# _739, _739
	vcvtss2sd	-8264(%rbp), %xmm5, %xmm5	# %sfp, iftmp.73_204
	vmovsd	%xmm5, -8208(%rbp)	# iftmp.73_204, %sfp
	vzeroupper
	.p2align 4,,10
	.p2align 3
.L2044:
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	movl	$13, %edi	#,
	call	putchar@PLT	#
	movq	-8192(%rbp), %rdx	# %sfp,
	movl	-8200(%rbp), %r9d	# %sfp,
	vmovsd	-8208(%rbp), %xmm0	# %sfp,
	movq	-8216(%rbp), %r8	# %sfp,
	movl	-8176(%rbp), %ecx	# %sfp,
	leaq	.LC36(%rip), %rsi	#,
	movl	$1, %edi	#,
	movl	$1, %eax	#,
	call	__printf_chk@PLT	#
# benchy.c:292:               fflush(stdout);
	movq	stdout(%rip), %rdi	# stdout,
	call	fflush@PLT	#
# benchy.c:294:               for (int i = 0; i < array_size; i++) {
	movl	-8176(%rbp), %edx	# %sfp,
	testl	%edx, %edx	#
	jle	.L2036	#,
# benchy.c:295:                 data_to_sort[i] = dataset[i];
	movq	-8224(%rbp), %rdx	# %sfp,
	movq	-8184(%rbp), %rsi	# %sfp,
	movq	%r15, %rdi	# data_to_sort,
	call	memcpy@PLT	#
.L2036:
# benchy.c:298:               handle_error(PAPI_reset(event_set));
	movl	-8148(%rbp), %edi	# event_set,
	call	PAPI_reset@PLT	#
# benchy.c:77:   if (retval != PAPI_OK) {
	testl	%eax, %eax	# _83
	jne	.L2149	#,
# benchy.c:300:               algorithm.sorting_function(data_to_sort, 0, array_size - 1);
	movl	%r12d, %edx	# _739,
	xorl	%esi, %esi	#
	movq	%r15, %rdi	# data_to_sort,
	call	*-6680(%rbp)	# MEM[(struct Algorithm *)_944].sorting_function
# benchy.c:303:               handle_error(PAPI_accum(event_set, event_values_of_seed));
	movl	-8148(%rbp), %edi	# event_set,
	movq	%r13, %rsi	# event_values_of_seed,
	call	PAPI_accum@PLT	#
	movl	%eax, %r9d	# tmp1097, tmp.2514
# benchy.c:77:   if (retval != PAPI_OK) {
	testl	%eax, %eax	# tmp.2514
	jne	.L2162	#,
# benchy.c:304:               total = event_values_of_seed[2];
	movq	16(%r13), %rcx	# MEM[(long long int *)event_values_of_seed_322 + 16B], total
# benchy.c:307:               for (int i = 0; i < array_size - 1; i++) {
	xorl	%eax, %eax	# ivtmp.2661
	jmp	.L2038	#
	.p2align 4,,10
	.p2align 3
.L2041:
# benchy.c:308:                 if (data_to_sort[i] > data_to_sort[i + 1]) {
	movl	(%r15,%rax,4), %edx	# MEM[base: data_to_sort_519, index: ivtmp.2661_246, step: 4, offset: 0B], _90
# benchy.c:308:                 if (data_to_sort[i] > data_to_sort[i + 1]) {
	cmpl	4(%r15,%rax,4), %edx	# MEM[base: data_to_sort_519, index: ivtmp.2661_246, step: 4, offset: 4B], _90
	jg	.L2163	#,
# benchy.c:316:                 if (data_to_sort[i] != sorted_dataset[i]) {
	incq	%rax	# ivtmp.2661
	cmpl	-4(%r14,%rax,4), %edx	# MEM[base: sorted_dataset_530, index: ivtmp.2661_245, step: 4, offset: -4B], _90
	jne	.L2164	#,
.L2038:
	movl	%eax, %r8d	# ivtmp.2661, i
# benchy.c:307:               for (int i = 0; i < array_size - 1; i++) {
	cmpl	%eax, %r12d	# ivtmp.2661, _739
	jg	.L2041	#,
# benchy.c:323:               if (total > 75000000000)
	movabsq	$75000000000, %rax	#, tmp1379
# benchy.c:321:               runs++;
	incl	%ebx	# runs
# benchy.c:323:               if (total > 75000000000)
	cmpq	%rax, %rcx	# tmp1379, total
	jg	.L2042	#,
# benchy.c:289:             while ((total < 10000000 || runs < MIN_RUNS_PER_BENCH) && runs < MAX_RUNS_PER_BENCH) {
	cmpq	$9999999, %rcx	#, total
	jle	.L2087	#,
	cmpl	$2, %ebx	#, runs
	jg	.L2042	#,
.L2087:
# benchy.c:289:             while ((total < 10000000 || runs < MIN_RUNS_PER_BENCH) && runs < MAX_RUNS_PER_BENCH) {
	cmpl	$500, %ebx	#, runs
	jne	.L2044	#,
.L2042:
# benchy.c:327:             free(dataset);
	movq	-8184(%rbp), %rdi	# %sfp,
	movl	%r12d, %eax	# _739, _739
	movl	%r9d, -8392(%rbp)	# tmp.2514, %sfp
	movq	%r13, %r12	# event_values_of_seed, event_values_of_seed
	movq	%rcx, -8200(%rbp)	# total, %sfp
	movq	%r14, %r13	# sorted_dataset, sorted_dataset
	movl	%eax, %r14d	# _739, _739
	call	free@PLT	#
# benchy.c:328:             free(data_to_sort);
	movq	%r15, %rdi	# data_to_sort,
	call	free@PLT	#
# benchy.c:329:             free(sorted_dataset);
	movq	%r13, %rdi	# sorted_dataset,
	call	free@PLT	#
# benchy.c:331:             seed_times[seed_index] = (double)(total) / runs;
	movq	-8200(%rbp), %rcx	# %sfp, total
# benchy.c:331:             seed_times[seed_index] = (double)(total) / runs;
	vxorpd	%xmm7, %xmm7, %xmm7	# tmp1380
	vcvtsi2sdl	%ebx, %xmm7, %xmm1	# runs, tmp1380, tmp1105
# benchy.c:331:             seed_times[seed_index] = (double)(total) / runs;
	vcvtsi2sdq	%rcx, %xmm7, %xmm2	# total, tmp1381, tmp1106
# benchy.c:333:               event_values_of_row[i] = ((double) event_values_of_seed[i]) / (double) runs;
	vcvtsi2sdq	8(%r12), %xmm7, %xmm3	# MEM[(long long int *)event_values_of_seed_322 + 8B], tmp1385, tmp1108
	vcvtsi2sdq	(%r12), %xmm7, %xmm0	# *event_values_of_seed_322, tmp1384, tmp1107
# benchy.c:331:             seed_times[seed_index] = (double)(total) / runs;
	movq	-8232(%rbp), %rax	# %sfp, ivtmp.2706
# benchy.c:331:             seed_times[seed_index] = (double)(total) / runs;
	vdivsd	%xmm1, %xmm2, %xmm2	# _106, tmp816, _110
# benchy.c:331:             seed_times[seed_index] = (double)(total) / runs;
	movq	-8280(%rbp), %r15	# %sfp, seed_times
# benchy.c:333:               event_values_of_row[i] = ((double) event_values_of_seed[i]) / (double) runs;
	vunpcklpd	%xmm3, %xmm0, %xmm0	# tmp819, tmp818, tmp817
	vmovddup	%xmm1, %xmm3	# _106, tmp820
# benchy.c:335:             free(event_values_of_seed);
	movq	%r12, %rdi	# event_values_of_seed,
# benchy.c:331:             seed_times[seed_index] = (double)(total) / runs;
	movq	%rcx, -8184(%rbp)	# total, %sfp
# benchy.c:333:               event_values_of_row[i] = ((double) event_values_of_seed[i]) / (double) runs;
	vdivpd	%xmm3, %xmm0, %xmm0	# tmp820, tmp817, vect__413.2625
# benchy.c:331:             seed_times[seed_index] = (double)(total) / runs;
	vmovsd	%xmm2, (%r15,%rax,8)	# _110, MEM[base: seed_times_303, index: ivtmp.2706_801, step: 8, offset: 0B]
# benchy.c:333:               event_values_of_row[i] = ((double) event_values_of_seed[i]) / (double) runs;
	movq	-8328(%rbp), %rax	# %sfp, event_values_of_row
	vmovsd	%xmm2, 16(%rax)	# _110, MEM[(double *)event_values_of_row_305 + 16B]
	vmovupd	%xmm0, (%rax)	# vect__413.2625, MEM <vector(2) double> [(double *)event_values_of_row_305]
# benchy.c:333:               event_values_of_row[i] = ((double) event_values_of_seed[i]) / (double) runs;
	vcvtsi2sdq	24(%r12), %xmm7, %xmm0	# MEM[(long long int *)event_values_of_seed_322 + 24B], tmp1388, tmp1109
# benchy.c:333:               event_values_of_row[i] = ((double) event_values_of_seed[i]) / (double) runs;
	vdivsd	%xmm1, %xmm0, %xmm0	# _106, tmp822, tmp823
# benchy.c:333:               event_values_of_row[i] = ((double) event_values_of_seed[i]) / (double) runs;
	vmovsd	%xmm0, 24(%rax)	# tmp823, MEM[(double *)event_values_of_row_305 + 24B]
# benchy.c:333:               event_values_of_row[i] = ((double) event_values_of_seed[i]) / (double) runs;
	vcvtsi2sdq	32(%r12), %xmm7, %xmm0	# MEM[(long long int *)event_values_of_seed_322 + 32B], tmp1390, tmp1110
# benchy.c:333:               event_values_of_row[i] = ((double) event_values_of_seed[i]) / (double) runs;
	vdivsd	%xmm1, %xmm0, %xmm1	# _106, tmp824, tmp825
# benchy.c:333:               event_values_of_row[i] = ((double) event_values_of_seed[i]) / (double) runs;
	vmovsd	%xmm1, 32(%rax)	# tmp825, MEM[(double *)event_values_of_row_305 + 32B]
# benchy.c:335:             free(event_values_of_seed);
	call	free@PLT	#
	movl	-8260(%rbp), %eax	# %sfp, seeds_performed
	movq	-8184(%rbp), %rcx	# %sfp, total
	cmpl	$2, %eax	#, seeds_performed
	movl	-8392(%rbp), %r9d	# %sfp, tmp.2514
	leal	1(%rax), %ebx	#, seeds_performed
	jle	.L2080	#,
	movl	%ebx, %edx	# seeds_performed, bnd.2512
	shrl	$2, %edx	#,
	salq	$5, %rdx	#, tmp828
	movq	%r15, %rax	# seed_times, ivtmp.2656
	addq	%r15, %rdx	# seed_times, _247
# benchy.c:338:             seeds_total = 0;
	vxorpd	%xmm8, %xmm8, %xmm8	# seeds_total
	.p2align 4,,10
	.p2align 3
.L2046:
# benchy.c:340:               seeds_total += seed_times[index];
	vmovupd	(%rax), %ymm0	# MEM[base: _251, offset: 0B], MEM[base: _251, offset: 0B]
	addq	$32, %rax	#, ivtmp.2656
	vaddsd	%xmm0, %xmm8, %xmm8	# stmp_seeds_total_341.2518, seeds_total, stmp_seeds_total_341.2518
	vunpckhpd	%xmm0, %xmm0, %xmm1	# tmp830, stmp_seeds_total_341.2518
	vextractf128	$0x1, %ymm0, %xmm0	# MEM[base: _251, offset: 0B], tmp832
	vaddsd	%xmm1, %xmm8, %xmm8	# stmp_seeds_total_341.2518, stmp_seeds_total_341.2518, stmp_seeds_total_341.2518
# benchy.c:340:               seeds_total += seed_times[index];
	vaddsd	%xmm0, %xmm8, %xmm8	# stmp_seeds_total_341.2518, stmp_seeds_total_341.2518, stmp_seeds_total_341.2518
	vunpckhpd	%xmm0, %xmm0, %xmm0	# tmp832, stmp_seeds_total_341.2518
	vaddsd	%xmm0, %xmm8, %xmm8	# stmp_seeds_total_341.2518, stmp_seeds_total_341.2518, seeds_total
	cmpq	%rax, %rdx	# ivtmp.2656, _247
	jne	.L2046	#,
	movl	%ebx, %r9d	# seeds_performed, tmp.2514
	andl	$-4, %r9d	#, tmp.2514
	testb	$3, %bl	#, seeds_performed
	je	.L2165	#,
	vzeroupper
.L2045:
# benchy.c:340:               seeds_total += seed_times[index];
	movq	-8280(%rbp), %rsi	# %sfp, seed_times
# benchy.c:339:             for (int index = 0; index < seeds_performed; index++) {
	movl	-8260(%rbp), %edi	# %sfp, seeds_performed
# benchy.c:340:               seeds_total += seed_times[index];
	movslq	%r9d, %rdx	# tmp.2514, tmp.2514
# benchy.c:340:               seeds_total += seed_times[index];
	vaddsd	(%rsi,%rdx,8), %xmm8, %xmm8	# *_48, seeds_total, seeds_total
# benchy.c:340:               seeds_total += seed_times[index];
	leaq	0(,%rdx,8), %rax	#, _47
# benchy.c:339:             for (int index = 0; index < seeds_performed; index++) {
	leal	1(%r9), %edx	#, index
# benchy.c:339:             for (int index = 0; index < seeds_performed; index++) {
	cmpl	%edi, %r9d	# seeds_performed, tmp.2514
	jge	.L2047	#,
# benchy.c:340:               seeds_total += seed_times[index];
	vaddsd	8(%rsi,%rax), %xmm8, %xmm8	# *_41, seeds_total, seeds_total
# benchy.c:339:             for (int index = 0; index < seeds_performed; index++) {
	cmpl	%edi, %edx	# seeds_performed, index
	jge	.L2047	#,
# benchy.c:340:               seeds_total += seed_times[index];
	vaddsd	16(%rsi,%rax), %xmm8, %xmm8	# *_231, seeds_total, seeds_total
.L2047:
# benchy.c:343:             if (total > 75000000000) {
	movabsq	$75000000000, %rax	#, tmp1401
# benchy.c:240:             seeds_performed++;
	movl	%ebx, -8260(%rbp)	# seeds_performed, %sfp
# benchy.c:343:             if (total > 75000000000) {
	cmpq	%rax, %rcx	# tmp1401, total
	jg	.L2166	#,
# benchy.c:348:             if (seeds_total > 750000000000) {
	vcomisd	.LC41(%rip), %xmm8	#, seeds_total
	movq	.LC41(%rip), %rax	#, tmp1404
	movq	%rax, -8184(%rbp)	# tmp1404, %sfp
	jbe	.L1999	#,
	movl	-8176(%rbp), %r14d	# %sfp, array_size
.L2051:
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	movq	-8192(%rbp), %rdx	# %sfp,
	xorl	%eax, %eax	#
	leaq	.LC40(%rip), %rsi	#,
	movl	$1, %edi	#,
	vmovsd	%xmm8, -8176(%rbp)	# seeds_total, %sfp
	call	__printf_chk@PLT	#
# benchy.c:354:           fprintf(file, "%s,%d,%s,%f", algorithm.name, array_size, before_sort_action_struct.name, before_sort_action == PRESORTED || before_sort_action == END_RANDOM ? randomnes_value : -1);
	cmpl	$1, -8332(%rbp)	#, %sfp
	vmovsd	-8176(%rbp), %xmm8	# %sfp, seeds_total
	je	.L2049	#,
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:100:   return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
	movq	.LC9(%rip), %rax	#, tmp1452
	movq	-8216(%rbp), %r9	# %sfp,
	movq	-8192(%rbp), %rcx	# %sfp,
	movq	-8256(%rbp), %rdi	# %sfp,
	vmovq	%rax, %xmm0	# tmp1452,
	movl	%r14d, %r8d	# array_size,
	leaq	.LC42(%rip), %rdx	#,
	movl	$1, %esi	#,
	movl	$1, %eax	#,
	vmovsd	%xmm8, -8200(%rbp)	# seeds_total, %sfp
	call	__fprintf_chk@PLT	#
# benchy.c:356:           float mean = seeds_total / seeds_performed;
	vxorpd	%xmm3, %xmm3, %xmm3	# tmp1453
	vcvtsi2sdl	%ebx, %xmm3, %xmm0	# seeds_performed, tmp1453, tmp1114
	vmovsd	-8200(%rbp), %xmm8	# %sfp, seeds_total
# benchy.c:358:           last_mean += mean;
	vxorps	%xmm7, %xmm7, %xmm7	# tmp1456
# benchy.c:356:           float mean = seeds_total / seeds_performed;
	vdivsd	%xmm0, %xmm8, %xmm4	# _124, seeds_total, tmp906
	vmovsd	%xmm0, -8176(%rbp)	# _124, %sfp
# benchy.c:356:           float mean = seeds_total / seeds_performed;
	vcvtsd2ss	%xmm4, %xmm4, %xmm4	# tmp906, mean
# benchy.c:358:           last_mean += mean;
	vaddss	%xmm7, %xmm4, %xmm5	# tmp1456, mean, last_mean
	vmovd	%xmm5, %r13d	# last_mean, last_mean
	jmp	.L2075	#
	.p2align 4,,10
	.p2align 3
.L2154:
# benchy.c:233:             int seed = seeds[seed_index];
	movq	-8232(%rbp), %rax	# %sfp, ivtmp.2706
	movl	-8112(%rbp,%rax,4), %eax	# MEM[symbol: seeds, index: ivtmp.2706_801, step: 4, offset: 0B], seed
	movl	%eax, -8200(%rbp)	# seed, %sfp
	jmp	.L1998	#
.L2157:
# benchy.c:73:   qsort(&array[low], high - low + 1, sizeof (int), compare_ints);
	movq	-8184(%rbp), %rbx	# %sfp, dataset
	movq	-8312(%rbp), %rsi	# %sfp,
	movq	%rbx, %rdi	# dataset,
	leaq	compare_ints(%rip), %rcx	#,
	movl	$4, %edx	#,
	call	qsort@PLT	#
# benchy.c:249:               randomise(dataset, 0, array_size - 1, randomnes_value, seed);
	movl	-8200(%rbp), %ecx	# %sfp,
	vmovss	-8264(%rbp), %xmm0	# %sfp,
	movl	%r14d, %edx	# _739,
	xorl	%esi, %esi	#
	movq	%rbx, %rdi	# dataset,
	call	randomise	#
	jmp	.L2005	#
.L2156:
	movq	.LC41(%rip), %rax	#, tmp1409
	vcvtss2sd	-8264(%rbp), %xmm4, %xmm4	# %sfp, iftmp.73_204
	movq	%rax, -8184(%rbp)	# tmp1409, %sfp
	vmovsd	%xmm4, -8208(%rbp)	# iftmp.73_204, %sfp
.L2049:
# benchy.c:354:           fprintf(file, "%s,%d,%s,%f", algorithm.name, array_size, before_sort_action_struct.name, before_sort_action == PRESORTED || before_sort_action == END_RANDOM ? randomnes_value : -1);
	vmovsd	-8208(%rbp), %xmm0	# %sfp, iftmp.73_204
	jmp	.L2053	#
.L2145:
	vzeroupper
	jmp	.L2054	#
.L2165:
	vzeroupper
	jmp	.L2047	#
.L2164:
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	movl	$1, %edi	#,
	movl	%r8d, %edx	# i,
	leaq	.LC39(%rip), %rsi	#,
	xorl	%eax, %eax	#
	call	__printf_chk@PLT	#
# benchy.c:318:                   exit(1);
	movl	$1, %edi	#,
	call	exit@PLT	#
.L2163:
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	leaq	.LC37(%rip), %rdi	#,
	movl	%r8d, -8176(%rbp)	# i, %sfp
	call	puts@PLT	#
# benchy.c:310:                   for (int index = i - 1; index < i + 2; index++) {
	movl	-8176(%rbp), %r8d	# %sfp, i
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	leaq	.LC38(%rip), %r12	#, tmp931
# benchy.c:310:                   for (int index = i - 1; index < i + 2; index++) {
	leal	-1(%r8), %ebx	#, index
	movslq	%ebx, %rbx	# index, ivtmp.2631
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	movl	%r8d, %r13d	# i, i
.L2040:
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	movl	(%r15,%rbx,4), %ecx	# MEM[base: data_to_sort_519, index: ivtmp.2631_997, step: 4, offset: 0B], MEM[base: data_to_sort_519, index: ivtmp.2631_997, step: 4, offset: 0B]
	movl	%ebx, %edx	# ivtmp.2631,
	movq	%r12, %rsi	# tmp931,
	movl	$1, %edi	#,
	xorl	%eax, %eax	#
# benchy.c:310:                   for (int index = i - 1; index < i + 2; index++) {
	incq	%rbx	# ivtmp.2631
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	call	__printf_chk@PLT	#
# benchy.c:310:                   for (int index = i - 1; index < i + 2; index++) {
	leal	-1(%rbx), %eax	#, index
	cmpl	%eax, %r13d	# index, i
	jge	.L2040	#,
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	movl	$10, %edi	#,
	call	putchar@PLT	#
# benchy.c:314:                   exit(1);
	movl	$1, %edi	#,
	call	exit@PLT	#
.L2158:
# benchy.c:251:               qsort_h(dataset, 0, (array_size - 1) * (1 - randomnes_value));
	vmovss	.LC10(%rip), %xmm4	#, tmp1315
# benchy.c:251:               qsort_h(dataset, 0, (array_size - 1) * (1 - randomnes_value));
	vxorps	%xmm6, %xmm6, %xmm6	# tmp1314
	vcvtsi2ssl	%r14d, %xmm6, %xmm0	# _739, tmp1314, tmp1104
# benchy.c:251:               qsort_h(dataset, 0, (array_size - 1) * (1 - randomnes_value));
	vsubss	-8264(%rbp), %xmm4, %xmm1	# %sfp, tmp1315, tmp620
# benchy.c:73:   qsort(&array[low], high - low + 1, sizeof (int), compare_ints);
	movq	-8184(%rbp), %rdi	# %sfp,
	leaq	compare_ints(%rip), %rcx	#,
# benchy.c:251:               qsort_h(dataset, 0, (array_size - 1) * (1 - randomnes_value));
	vmulss	%xmm1, %xmm0, %xmm0	# tmp620, tmp619, tmp622
# benchy.c:73:   qsort(&array[low], high - low + 1, sizeof (int), compare_ints);
	movl	$4, %edx	#,
# benchy.c:251:               qsort_h(dataset, 0, (array_size - 1) * (1 - randomnes_value));
	vcvttss2sil	%xmm0, %esi	# tmp622, tmp623
# benchy.c:73:   qsort(&array[low], high - low + 1, sizeof (int), compare_ints);
	incl	%esi	# tmp624
# benchy.c:73:   qsort(&array[low], high - low + 1, sizeof (int), compare_ints);
	movslq	%esi, %rsi	# tmp624, tmp625
	call	qsort@PLT	#
# benchy.c:74: }
	jmp	.L2005	#
.L2080:
# benchy.c:338:             seeds_total = 0;
	vxorpd	%xmm8, %xmm8, %xmm8	# seeds_total
	jmp	.L2045	#
.L2161:
# benchy.c:262:               for (int i = 0; i < array_size; i++) {
	cmpl	$0, -8176(%rbp)	#, %sfp
	jle	.L2018	#,
	cmpl	$6, %r14d	#, _739
	jbe	.L2079	#,
	movq	-8184(%rbp), %rdx	# %sfp, dataset
	movq	%rdx, %rax	# dataset, ivtmp.2696
	addq	-8360(%rbp), %rdx	# %sfp, _744
.L2025:
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	vmovdqu	(%rax), %ymm1	# MEM[base: _680, offset: 0B], MEM[base: _680, offset: 0B]
	addq	$32, %rax	#, ivtmp.2696
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	vpsrlq	$32, %ymm1, %ymm2	#, MEM[base: _680, offset: 0B], tmp726
	vpmuldq	.LC32(%rip), %ymm1, %ymm0	#, MEM[base: _680, offset: 0B], tmp722
	vpmuldq	.LC32(%rip), %ymm2, %ymm2	#, tmp726, tmp724
	vpshufb	.LC26(%rip), %ymm0, %ymm0	#, tmp722, tmp733
	vpshufb	.LC27(%rip), %ymm2, %ymm2	#, tmp724, tmp735
	vpor	%ymm2, %ymm0, %ymm0	# tmp735, tmp733, tmp730
	vpsrad	$12, %ymm0, %ymm0	#, tmp730, vect_patt_932.2589
	vpsrad	$31, %ymm1, %ymm2	#, MEM[base: _680, offset: 0B], vect_patt_933.2590
	vpsubd	%ymm2, %ymm0, %ymm0	# vect_patt_933.2590, vect_patt_932.2589, vect_patt_934.2591
	vpmulld	.LC33(%rip), %ymm0, %ymm0	#, vect_patt_934.2591, vect_patt_935.2592
	vpsubd	%ymm0, %ymm1, %ymm0	# vect_patt_935.2592, MEM[base: _680, offset: 0B], vect_patt_936.2593
	vmovdqu	%ymm0, -32(%rax)	# vect_patt_936.2593, MEM[base: _680, offset: 0B]
	cmpq	%rax, %rdx	# ivtmp.2696, _744
	jne	.L2025	#,
	movl	-8372(%rbp), %ecx	# %sfp, niters_vector_mult_vf.2583
	movl	%ecx, %eax	# niters_vector_mult_vf.2583,
	cmpl	%eax, -8176(%rbp)	# niters_vector_mult_vf.2583, %sfp
	je	.L2141	#,
	vzeroupper
.L2024:
	movl	-8176(%rbp), %edx	# %sfp, niters.2596
	subl	%eax, %edx	# _965, niters.2596
	leal	-1(%rdx), %esi	#, tmp742
	cmpl	$2, %esi	#, tmp742
	jbe	.L2029	#,
	movq	-8184(%rbp), %rsi	# %sfp, dataset
	leaq	(%rsi,%rax,4), %rax	#, vectp_dataset.2601
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	vmovdqu	(%rax), %xmm1	# MEM <vector(4) int> [(int *)vectp_dataset.2601_1006], MEM <vector(4) int> [(int *)vectp_dataset.2601_1006]
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	vpsrlq	$32, %xmm1, %xmm2	#, MEM <vector(4) int> [(int *)vectp_dataset.2601_1006], tmp750
	vpmuldq	.LC34(%rip), %xmm1, %xmm0	#, MEM <vector(4) int> [(int *)vectp_dataset.2601_1006], tmp746
	vpmuldq	.LC34(%rip), %xmm2, %xmm2	#, tmp750, tmp748
	vpshufb	.LC29(%rip), %xmm0, %xmm0	#, tmp746, tmp755
	vpshufb	.LC30(%rip), %xmm2, %xmm2	#, tmp748, tmp757
	vpor	%xmm2, %xmm0, %xmm0	# tmp757, tmp755, tmp758
	vpsrad	$12, %xmm0, %xmm0	#, tmp758, vect_patt_940.2604
	vpsrad	$31, %xmm1, %xmm2	#, MEM <vector(4) int> [(int *)vectp_dataset.2601_1006], vect_patt_941.2605
	vpsubd	%xmm2, %xmm0, %xmm0	# vect_patt_941.2605, vect_patt_940.2604, vect_patt_942.2606
	vpmulld	.LC35(%rip), %xmm0, %xmm0	#, vect_patt_942.2606, vect_patt_943.2607
	vpsubd	%xmm0, %xmm1, %xmm0	# vect_patt_943.2607, MEM <vector(4) int> [(int *)vectp_dataset.2601_1006], vect_patt_944.2608
	vmovdqu	%xmm0, (%rax)	# vect_patt_944.2608, MEM <vector(4) int> [(int *)vectp_dataset.2601_1006]
	movl	%edx, %eax	# niters.2596, niters_vector_mult_vf.2598
	andl	$-4, %eax	#, niters_vector_mult_vf.2598
	addl	%eax, %ecx	# niters_vector_mult_vf.2598, tmp.2599
	cmpl	%eax, %edx	# niters_vector_mult_vf.2598, niters.2596
	je	.L2027	#,
.L2029:
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	movq	-8184(%rbp), %rbx	# %sfp, dataset
	movslq	%ecx, %rdi	# tmp.2599, tmp.2599
	salq	$2, %rdi	#, _945
	leaq	(%rbx,%rdi), %r8	#, _884
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	movl	(%r8), %eax	# *_884, *_884
	movl	$10000, %esi	#, tmp770
	cltd
	idivl	%esi	# tmp770
# benchy.c:262:               for (int i = 0; i < array_size; i++) {
	movl	-8176(%rbp), %r11d	# %sfp, array_size
# benchy.c:262:               for (int i = 0; i < array_size; i++) {
	leal	1(%rcx), %eax	#, i
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	movl	%edx, (%r8)	# tmp768, *_884
# benchy.c:262:               for (int i = 0; i < array_size; i++) {
	cmpl	%eax, %r11d	# i, array_size
	jle	.L2027	#,
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	leaq	4(%rbx,%rdi), %r8	#, _202
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	movl	(%r8), %eax	# *_202, *_202
# benchy.c:262:               for (int i = 0; i < array_size; i++) {
	addl	$2, %ecx	#, i
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	cltd
	idivl	%esi	# tmp770
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	movl	%edx, (%r8)	# tmp775, *_202
# benchy.c:262:               for (int i = 0; i < array_size; i++) {
	cmpl	%ecx, %r11d	# i, array_size
	jg	.L2147	#,
	jmp	.L2027	#
.L2160:
# benchy.c:258:               for (int i = 0; i < array_size; i++) {
	cmpl	$0, -8176(%rbp)	#, %sfp
	jle	.L2018	#,
	cmpl	$6, %r14d	#, _739
	jbe	.L2078	#,
	movq	-8184(%rbp), %rsi	# %sfp, dataset
	movq	-8360(%rbp), %rdx	# %sfp, _727
	movq	%rsi, %rax	# dataset, ivtmp.2690
	addq	%rsi, %rdx	# dataset, _727
.L2020:
# benchy.c:259:                 dataset[i] = dataset[i] % 1000;
	vmovdqu	(%rax), %ymm2	# MEM[base: _910, offset: 0B], MEM[base: _910, offset: 0B]
	addq	$32, %rax	#, ivtmp.2690
# benchy.c:259:                 dataset[i] = dataset[i] % 1000;
	vpsrlq	$32, %ymm2, %ymm1	#, MEM[base: _910, offset: 0B], tmp658
	vpmuldq	.LC25(%rip), %ymm2, %ymm0	#, MEM[base: _910, offset: 0B], tmp654
	vpmuldq	.LC25(%rip), %ymm1, %ymm1	#, tmp658, tmp656
	vpshufb	.LC26(%rip), %ymm0, %ymm0	#, tmp654, tmp665
	vpshufb	.LC27(%rip), %ymm1, %ymm1	#, tmp656, tmp667
	vpor	%ymm1, %ymm0, %ymm0	# tmp667, tmp665, tmp662
	vpsrad	$6, %ymm0, %ymm0	#, tmp662, vect_patt_833.2559
	vpsrad	$31, %ymm2, %ymm1	#, MEM[base: _910, offset: 0B], vect_patt_834.2560
	vpsubd	%ymm1, %ymm0, %ymm0	# vect_patt_834.2560, vect_patt_833.2559, vect_patt_835.2561
	vpslld	$5, %ymm0, %ymm1	#, vect_patt_835.2561, tmp672
	vpsubd	%ymm0, %ymm1, %ymm1	# vect_patt_835.2561, tmp672, tmp673
	vpslld	$2, %ymm1, %ymm1	#, tmp673, tmp674
	vpaddd	%ymm0, %ymm1, %ymm0	# vect_patt_835.2561, tmp674, vect_patt_836.2562
	vpslld	$3, %ymm0, %ymm0	#, vect_patt_836.2562, tmp676
	vpsubd	%ymm0, %ymm2, %ymm0	# tmp676, MEM[base: _910, offset: 0B], vect_patt_837.2563
	vmovdqu	%ymm0, -32(%rax)	# vect_patt_837.2563, MEM[base: _910, offset: 0B]
	cmpq	%rax, %rdx	# ivtmp.2690, _727
	jne	.L2020	#,
	movl	-8372(%rbp), %ecx	# %sfp, niters_vector_mult_vf.2583
	movl	%ecx, %eax	# niters_vector_mult_vf.2583,
	cmpl	%eax, -8176(%rbp)	# niters_vector_mult_vf.2583, %sfp
	je	.L2141	#,
	vzeroupper
.L2019:
	movl	-8176(%rbp), %edx	# %sfp, niters.2566
	subl	%eax, %edx	# _866, niters.2566
	leal	-1(%rdx), %esi	#, tmp678
	cmpl	$2, %esi	#, tmp678
	jbe	.L2022	#,
	movq	-8184(%rbp), %rsi	# %sfp, dataset
	leaq	(%rsi,%rax,4), %rax	#, vectp_dataset.2571
# benchy.c:259:                 dataset[i] = dataset[i] % 1000;
	vmovdqu	(%rax), %xmm1	# MEM <vector(4) int> [(int *)vectp_dataset.2571_907], MEM <vector(4) int> [(int *)vectp_dataset.2571_907]
# benchy.c:259:                 dataset[i] = dataset[i] % 1000;
	vpsrlq	$32, %xmm1, %xmm2	#, MEM <vector(4) int> [(int *)vectp_dataset.2571_907], tmp686
	vpmuldq	.LC28(%rip), %xmm1, %xmm0	#, MEM <vector(4) int> [(int *)vectp_dataset.2571_907], tmp682
	vpmuldq	.LC28(%rip), %xmm2, %xmm2	#, tmp686, tmp684
	vpshufb	.LC29(%rip), %xmm0, %xmm0	#, tmp682, tmp691
	vpshufb	.LC30(%rip), %xmm2, %xmm2	#, tmp684, tmp693
	vpor	%xmm2, %xmm0, %xmm0	# tmp693, tmp691, tmp694
	vpsrad	$6, %xmm0, %xmm0	#, tmp694, vect_patt_841.2574
	vpsrad	$31, %xmm1, %xmm2	#, MEM <vector(4) int> [(int *)vectp_dataset.2571_907], vect_patt_842.2575
	vpsubd	%xmm2, %xmm0, %xmm0	# vect_patt_842.2575, vect_patt_841.2574, vect_patt_843.2576
	vpmulld	.LC31(%rip), %xmm0, %xmm0	#, vect_patt_843.2576, vect_patt_844.2577
	vpsubd	%xmm0, %xmm1, %xmm0	# vect_patt_844.2577, MEM <vector(4) int> [(int *)vectp_dataset.2571_907], vect_patt_845.2578
	vmovdqu	%xmm0, (%rax)	# vect_patt_845.2578, MEM <vector(4) int> [(int *)vectp_dataset.2571_907]
	movl	%edx, %eax	# niters.2566, niters_vector_mult_vf.2568
	andl	$-4, %eax	#, niters_vector_mult_vf.2568
	addl	%eax, %ecx	# niters_vector_mult_vf.2568, tmp.2569
	cmpl	%eax, %edx	# niters_vector_mult_vf.2568, niters.2566
	je	.L2027	#,
.L2022:
# benchy.c:259:                 dataset[i] = dataset[i] % 1000;
	movq	-8184(%rbp), %rbx	# %sfp, dataset
	movslq	%ecx, %rdi	# tmp.2569, tmp.2569
	salq	$2, %rdi	#, _947
	leaq	(%rbx,%rdi), %r8	#, _949
# benchy.c:259:                 dataset[i] = dataset[i] % 1000;
	movl	(%r8), %eax	# *_949, *_949
	movl	$1000, %esi	#, tmp706
	cltd
	idivl	%esi	# tmp706
# benchy.c:258:               for (int i = 0; i < array_size; i++) {
	movl	-8176(%rbp), %r10d	# %sfp, array_size
# benchy.c:258:               for (int i = 0; i < array_size; i++) {
	leal	1(%rcx), %eax	#, i
# benchy.c:259:                 dataset[i] = dataset[i] % 1000;
	movl	%edx, (%r8)	# tmp704, *_949
# benchy.c:258:               for (int i = 0; i < array_size; i++) {
	cmpl	%eax, %r10d	# i, array_size
	jle	.L2027	#,
# benchy.c:259:                 dataset[i] = dataset[i] % 1000;
	leaq	4(%rbx,%rdi), %r8	#, _995
# benchy.c:259:                 dataset[i] = dataset[i] % 1000;
	movl	(%r8), %eax	# *_995, *_995
# benchy.c:258:               for (int i = 0; i < array_size; i++) {
	addl	$2, %ecx	#, i
# benchy.c:259:                 dataset[i] = dataset[i] % 1000;
	cltd
	idivl	%esi	# tmp706
# benchy.c:259:                 dataset[i] = dataset[i] % 1000;
	movl	%edx, (%r8)	# tmp711, *_995
# benchy.c:258:               for (int i = 0; i < array_size; i++) {
	cmpl	%r10d, %ecx	# array_size, i
	jge	.L2027	#,
.L2147:
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	leaq	8(%rbx,%rdi), %rcx	#, _990
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	movl	(%rcx), %eax	#* _990, *_990
	cltd
	idivl	%esi	# tmp770
# benchy.c:263:                 dataset[i] = dataset[i] % 10000;
	movl	%edx, (%rcx)	# tmp782,* _990
.L2027:
# benchy.c:266:             int *sorted_dataset = (int *) malloc(sizeof(int) * array_size);
	movq	-8272(%rbp), %rbx	# %sfp, _29
	movq	%rbx, %rdi	# _29,
	call	malloc@PLT	#
# benchy.c:267:             int *data_to_sort = (int *) malloc(sizeof(int) * array_size);
	movq	%rbx, %rdi	# _29,
# benchy.c:266:             int *sorted_dataset = (int *) malloc(sizeof(int) * array_size);
	movq	%rax, %r13	# tmp1099, sorted_dataset
# benchy.c:267:             int *data_to_sort = (int *) malloc(sizeof(int) * array_size);
	call	malloc@PLT	#
	movq	%rax, %r15	# tmp1100, data_to_sort
	jmp	.L2031	#
.L2018:
# benchy.c:266:             int *sorted_dataset = (int *) malloc(sizeof(int) * array_size);
	movq	-8272(%rbp), %rbx	# %sfp, _29
	movq	%rbx, %rdi	# _29,
	call	malloc@PLT	#
# benchy.c:267:             int *data_to_sort = (int *) malloc(sizeof(int) * array_size);
	movq	%rbx, %rdi	# _29,
# benchy.c:266:             int *sorted_dataset = (int *) malloc(sizeof(int) * array_size);
	movq	%rax, %r13	# tmp1101, sorted_dataset
# benchy.c:267:             int *data_to_sort = (int *) malloc(sizeof(int) * array_size);
	call	malloc@PLT	#
	movq	%rax, %r15	# tmp1102, data_to_sort
	jmp	.L2032	#
.L2083:
# benchy.c:362:             float diff = mean - seed_times[index];
	xorl	%eax, %eax	# tmp.2490
	xorl	%ecx, %ecx	#
	vxorps	%xmm0, %xmm0, %xmm0	# sum
	jmp	.L2055	#
.L2082:
# benchy.c:360:           float sum = 0;
	vxorps	%xmm0, %xmm0, %xmm0	# sum
	vcvtss2sd	%xmm4, %xmm4, %xmm5	# mean, tmp924
	jmp	.L2054	#
.L2159:
# benchy.c:73:   qsort(&array[low], high - low + 1, sizeof (int), compare_ints);
	movq	-8184(%rbp), %rbx	# %sfp, dataset
	movq	-8312(%rbp), %rsi	# %sfp,
	leaq	compare_ints(%rip), %rcx	#,
	movl	$4, %edx	#,
	movq	%rbx, %rdi	# dataset,
	call	qsort@PLT	#
# benchy.c:254:               for (int i = 0; i < array_size / 2; i++) {
	movl	-8176(%rbp), %eax	# %sfp, array_size
	cmpl	$1, %eax	#, array_size
	jle	.L2005	#,
	cmpb	$0, -8291(%rbp)	#, %sfp
	je	.L2009	#,
	cmpl	$15, %eax	#, array_size
	jle	.L2077	#,
	addq	-8400(%rbp), %rbx	# %sfp, ivtmp.2684
	movq	%rbx, %rdx	# ivtmp.2684, ivtmp.2684
	xorl	%eax, %eax	# ivtmp.2682
.L2011:
# swap.h:2:   int t = *a;
	movq	-8184(%rbp), %rsi	# %sfp, dataset
# swap.h:3:   *a = *b;
	vmovdqa	.LC6(%rip), %ymm7	#, tmp1323
# swap.h:2:   int t = *a;
	vmovdqu	(%rsi,%rax), %ymm0	# MEM[base: dataset_309, index: ivtmp.2682_858, offset: 0B], MEM[base: dataset_309, index: ivtmp.2682_858, offset: 0B]
# swap.h:3:   *a = *b;
	vpermd	(%rdx), %ymm7, %ymm1	# MEM[base: _897, offset: 0B], tmp1323, vect__391.2529
# swap.h:4:   *b = t;
	vpermd	%ymm0, %ymm7, %ymm0	# MEM[base: dataset_309, index: ivtmp.2682_858, offset: 0B], tmp1325, vect_t_390.2534
# swap.h:3:   *a = *b;
	vmovdqu	%ymm1, (%rsi,%rax)	# vect__391.2529, MEM[base: dataset_309, index: ivtmp.2682_858, offset: 0B]
	addq	$32, %rax	#, ivtmp.2682
# swap.h:4:   *b = t;
	vmovdqu	%ymm0, (%rdx)	# vect_t_390.2534, MEM[base: _897, offset: 0B]
	subq	$32, %rdx	#, ivtmp.2684
	cmpq	-8408(%rbp), %rax	# %sfp, ivtmp.2682
	jne	.L2011	#,
	movl	-8388(%rbp), %eax	# %sfp, niters_vector_mult_vf.2521
	cmpl	%eax, -8336(%rbp)	# niters_vector_mult_vf.2521, %sfp
	je	.L2141	#,
# swap.h:4:   *b = t;
	movl	%eax, %edx	# niters_vector_mult_vf.2521,
	vzeroupper
.L2010:
	movl	-8336(%rbp), %ecx	# %sfp, niters.2535
	subl	%edx, %ecx	# _738, niters.2535
	leal	-1(%rcx), %esi	#, tmp632
	cmpl	$2, %esi	#, tmp632
	jbe	.L2013	#,
	movq	-8184(%rbp), %rdi	# %sfp, dataset
	movq	-8352(%rbp), %rbx	# %sfp, _689
	leaq	(%rdi,%rdx,4), %rsi	#, vectp_dataset.2540
	imulq	$-4, %rdx, %rdx	#, _795, tmp635
# swap.h:2:   int t = *a;
	vmovdqu	(%rsi), %xmm0	# MEM <vector(4) int> [(int *)vectp_dataset.2540_794], MEM <vector(4) int> [(int *)vectp_dataset.2540_794]
	leaq	-12(%rbx,%rdx), %rdx	#, tmp636
# swap.h:4:   *b = t;
	vpshufd	$27, %xmm0, %xmm0	#, MEM <vector(4) int> [(int *)vectp_dataset.2540_794], vect_t_726.2550
# swap.h:3:   *a = *b;
	vpshufd	$27, (%rdi,%rdx), %xmm1	#, MEM <vector(4) int> [(int *)vectp.2543_800], vect__727.2545
# swap.h:3:   *a = *b;
	vmovdqu	%xmm1, (%rsi)	# vect__727.2545, MEM <vector(4) int> [(int *)vectp_dataset.2540_794]
# swap.h:4:   *b = t;
	vmovdqu	%xmm0, (%rdi,%rdx)	# vect_t_726.2550, MEM <vector(4) int> [(int *)vectp.2543_800]
	movl	%ecx, %edx	# niters.2535, niters_vector_mult_vf.2537
	andl	$-4, %edx	#, niters_vector_mult_vf.2537
	addl	%edx, %eax	# niters_vector_mult_vf.2537, tmp.2538
	cmpl	%edx, %ecx	# niters_vector_mult_vf.2537, niters.2535
	je	.L2027	#,
.L2013:
# benchy.c:255:                 swap(&dataset[i], &dataset[array_size - 1 - i]);
	movl	%r14d, %edx	# _739, tmp641
# benchy.c:255:                 swap(&dataset[i], &dataset[array_size - 1 - i]);
	movq	-8184(%rbp), %rbx	# %sfp, dataset
# benchy.c:255:                 swap(&dataset[i], &dataset[array_size - 1 - i]);
	subl	%eax, %edx	# tmp.2538, tmp641
	movslq	%edx, %rdx	# tmp641, tmp642
# benchy.c:255:                 swap(&dataset[i], &dataset[array_size - 1 - i]);
	leaq	(%rbx,%rdx,4), %rcx	#, _55
# benchy.c:255:                 swap(&dataset[i], &dataset[array_size - 1 - i]);
	movslq	%eax, %rdx	# tmp.2538, tmp.2538
	salq	$2, %rdx	#, _57
# benchy.c:255:                 swap(&dataset[i], &dataset[array_size - 1 - i]);
	leaq	(%rbx,%rdx), %rsi	#, _58
# swap.h:3:   *a = *b;
	movl	(%rcx), %r8d	# *_55, _312
# swap.h:2:   int t = *a;
	movl	(%rsi), %edi	# *_58, t
# benchy.c:254:               for (int i = 0; i < array_size / 2; i++) {
	movl	-8376(%rbp), %r11d	# %sfp, tmp589
# swap.h:3:   *a = *b;
	movl	%r8d, (%rsi)	# _312, *_58
# benchy.c:254:               for (int i = 0; i < array_size / 2; i++) {
	leal	1(%rax), %esi	#, i
# swap.h:4:   *b = t;
	movl	%edi, (%rcx)	# t, *_55
# benchy.c:254:               for (int i = 0; i < array_size / 2; i++) {
	cmpl	%esi, %r11d	# i, tmp589
	jle	.L2027	#,
# benchy.c:255:                 swap(&dataset[i], &dataset[array_size - 1 - i]);
	movl	%r14d, %ecx	# _739, tmp645
	subl	%esi, %ecx	# i, tmp645
	movslq	%ecx, %rcx	# tmp645, tmp646
# benchy.c:255:                 swap(&dataset[i], &dataset[array_size - 1 - i]);
	leaq	(%rbx,%rcx,4), %rcx	#, _717
	leaq	4(%rbx,%rdx), %rsi	#, _721
# swap.h:2:   int t = *a;
	movl	(%rsi), %edi	# *_721, t
# swap.h:3:   *a = *b;
	movl	(%rcx), %r8d	# *_717, _723
# benchy.c:254:               for (int i = 0; i < array_size / 2; i++) {
	addl	$2, %eax	#, i
# swap.h:3:   *a = *b;
	movl	%r8d, (%rsi)	# _723, *_721
# swap.h:4:   *b = t;
	movl	%edi, (%rcx)	# t, *_717
# benchy.c:254:               for (int i = 0; i < array_size / 2; i++) {
	cmpl	%eax, %r11d	# i, tmp589
	jle	.L2027	#,
# benchy.c:255:                 swap(&dataset[i], &dataset[array_size - 1 - i]);
	movl	%r14d, %ecx	# _739, tmp649
	subl	%eax, %ecx	# i, tmp649
	movslq	%ecx, %rax	# tmp649, tmp650
# benchy.c:255:                 swap(&dataset[i], &dataset[array_size - 1 - i]);
	leaq	(%rbx,%rax,4), %rax	#, _773
	leaq	8(%rbx,%rdx), %rdx	#, _776
# swap.h:2:   int t = *a;
	movl	(%rdx), %ecx	# *_776, t
# swap.h:3:   *a = *b;
	movl	(%rax), %esi	# *_773, _778
# swap.h:3:   *a = *b;
	movl	%esi, (%rdx)	# _778, *_776
# swap.h:4:   *b = t;
	movl	%ecx, (%rax)	# t, *_773
	jmp	.L2027	#
.L2141:
	vzeroupper
	jmp	.L2027	#
.L2152:
# benchy.c:393: }
	call	__stack_chk_fail@PLT	#
.L2079:
# benchy.c:262:               for (int i = 0; i < array_size; i++) {
	xorl	%ecx, %ecx	# tmp.2599
# benchy.c:262:               for (int i = 0; i < array_size; i++) {
	xorl	%eax, %eax	#
	jmp	.L2024	#
.L2078:
# benchy.c:258:               for (int i = 0; i < array_size; i++) {
	xorl	%ecx, %ecx	# tmp.2569
# benchy.c:258:               for (int i = 0; i < array_size; i++) {
	xorl	%eax, %eax	#
	jmp	.L2019	#
.L2135:
	vmovsd	%xmm5, -8216(%rbp)	# tmp924, %sfp
	vmovss	%xmm4, -8208(%rbp)	# mean, %sfp
	vmovsd	%xmm8, -8200(%rbp)	# seeds_total, %sfp
# benchy.c:366:           float std_dev = sqrtf(sum / (float)seeds_performed);
	call	sqrtf@PLT	#
	vmovaps	%xmm0, %xmm2	# tmp1098, std_dev
	vmovsd	-8216(%rbp), %xmm5	# %sfp, tmp924
	vmovss	-8208(%rbp), %xmm4	# %sfp, mean
	vmovsd	-8200(%rbp), %xmm8	# %sfp, seeds_total
	jmp	.L2062	#
.L2065:
# /usr/include/x86_64-linux-gnu/bits/stdio2.h:107:   return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
	movq	-8192(%rbp), %rdx	# %sfp,
	leaq	.LC40(%rip), %rsi	#,
	movl	$1, %edi	#,
	xorl	%eax, %eax	#
	movl	%r13d, %r14d	# last_mean, last_mean
	call	__printf_chk@PLT	#
# benchy.c:359:           runs_of_size++;
	movl	$0x3f800000, %ebx	#, runs_of_size
	jmp	.L2068	#
.L2162:
	movl	%eax, %edi	# tmp.2514,
	call	handle_error.part.0	#
.L2166:
	movq	.LC41(%rip), %rax	#, tmp1402
	movl	-8176(%rbp), %r14d	# %sfp, array_size
	movq	%rax, -8184(%rbp)	# tmp1402, %sfp
	jmp	.L2051	#
.L2149:
	movl	%eax, %edi	# _4,
.L2148:
	call	handle_error.part.0	#
.L2077:
# benchy.c:254:               for (int i = 0; i < array_size / 2; i++) {
	xorl	%eax, %eax	# tmp.2538
# benchy.c:254:               for (int i = 0; i < array_size / 2; i++) {
	xorl	%edx, %edx	#
	jmp	.L2010	#
.L2009:
	movq	-8184(%rbp), %rdx	# %sfp, ivtmp.2677
	xorl	%eax, %eax	# ivtmp.2674
	addq	-8352(%rbp), %rdx	# %sfp, ivtmp.2677
.L2015:
# swap.h:2:   int t = *a;
	movq	-8184(%rbp), %rdi	# %sfp, dataset
# swap.h:3:   *a = *b;
	movl	(%rdx), %esi	# MEM[base: _121, offset: 0B], _710
# swap.h:2:   int t = *a;
	movl	(%rdi,%rax,4), %ecx	# MEM[base: dataset_309, index: ivtmp.2674_242, step: 4, offset: 0B], t
# swap.h:3:   *a = *b;
	movl	%esi, (%rdi,%rax,4)	# _710, MEM[base: dataset_309, index: ivtmp.2674_242, step: 4, offset: 0B]
# benchy.c:254:               for (int i = 0; i < array_size / 2; i++) {
	incq	%rax	# ivtmp.2674
# swap.h:4:   *b = t;
	movl	%ecx, (%rdx)	# t, MEM[base: _121, offset: 0B]
# benchy.c:254:               for (int i = 0; i < array_size / 2; i++) {
	subq	$4, %rdx	#, ivtmp.2677
	cmpl	%eax, -8376(%rbp)	# ivtmp.2674, %sfp
	jg	.L2015	#,
	jmp	.L2027	#
	.cfi_endproc
.LFE5709:
	.size	main, .-main
	.globl	x
	.bss
	.align 8
	.type	x, @object
	.size	x, 8
x:
	.zero	8
	.globl	count
	.align 4
	.type	count, @object
	.size	count, 4
count:
	.zero	4
	.globl	blocksize
	.section	.rodata
	.align 4
	.type	blocksize, @object
	.size	blocksize, 4
blocksize:
	.long	128
	.globl	INSERTION_SORT_THRESH_BLOCK
	.align 4
	.type	INSERTION_SORT_THRESH_BLOCK, @object
	.size	INSERTION_SORT_THRESH_BLOCK, 4
INSERTION_SORT_THRESH_BLOCK:
	.long	20
	.section	.rodata.cst4,"aM",@progbits,4
	.align 4
.LC3:
	.long	1325400064
	.section	.rodata.cst16,"aM",@progbits,16
	.align 16
.LC4:
	.long	1
	.long	1
	.long	1
	.long	1
	.section	.rodata.cst8,"aM",@progbits,8
	.align 8
.LC5:
	.long	858993459
	.long	1069757235
	.section	.rodata.cst32,"aM",@progbits,32
	.align 32
.LC6:
	.long	7
	.long	6
	.long	5
	.long	4
	.long	3
	.long	2
	.long	1
	.long	0
	.section	.rodata.cst8
	.align 8
.LC9:
	.long	0
	.long	-1074790400
	.section	.rodata.cst4
	.align 4
.LC10:
	.long	1065353216
	.section	.rodata.cst32
	.align 32
.LC12:
	.long	0
	.long	1
	.long	2
	.long	3
	.long	4
	.long	5
	.long	6
	.long	7
	.align 32
.LC13:
	.long	3
	.long	5
	.long	7
	.long	10
	.long	15
	.long	20
	.long	25
	.long	30
	.align 32
.LC14:
	.long	40
	.long	50
	.long	100
	.long	1000
	.long	10000
	.long	100000
	.long	1000000
	.long	10000000
	.align 32
.LC15:
	.long	0
	.long	925353388
	.long	953267991
	.long	981668463
	.long	1000593162
	.long	1008981770
	.long	1028443341
	.long	1036831949
	.align 32
.LC16:
	.long	1045220557
	.long	1050253722
	.long	1053609165
	.long	1056964608
	.long	1058642330
	.long	1060320051
	.long	1061997773
	.long	1063675494
	.section	.rodata.cst16
	.align 16
.LC17:
	.long	-2147483605
	.long	-2147483602
	.long	-2147483589
	.long	-2147483541
	.section	.rodata.cst32
	.align 32
.LC25:
	.long	274877907
	.long	274877907
	.long	274877907
	.long	274877907
	.long	274877907
	.long	274877907
	.long	274877907
	.long	274877907
	.align 32
.LC26:
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 32
.LC27:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.section	.rodata.cst16
	.align 16
.LC28:
	.long	274877907
	.long	274877907
	.long	274877907
	.long	274877907
	.align 16
.LC29:
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.align 16
.LC30:
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	4
	.byte	5
	.byte	6
	.byte	7
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	-128
	.byte	12
	.byte	13
	.byte	14
	.byte	15
	.align 16
.LC31:
	.long	1000
	.long	1000
	.long	1000
	.long	1000
	.section	.rodata.cst32
	.align 32
.LC32:
	.long	1759218605
	.long	1759218605
	.long	1759218605
	.long	1759218605
	.long	1759218605
	.long	1759218605
	.long	1759218605
	.long	1759218605
	.align 32
.LC33:
	.long	10000
	.long	10000
	.long	10000
	.long	10000
	.long	10000
	.long	10000
	.long	10000
	.long	10000
	.section	.rodata.cst16
	.align 16
.LC34:
	.long	1759218605
	.long	1759218605
	.long	1759218605
	.long	1759218605
	.align 16
.LC35:
	.long	10000
	.long	10000
	.long	10000
	.long	10000
	.section	.rodata.cst8
	.align 8
.LC41:
	.long	2038431744
	.long	1113969647
	.ident	"GCC: (Ubuntu 10.3.0-1ubuntu1~20.04) 10.3.0"
	.section	.note.GNU-stack,"",@progbits
	.section	.note.gnu.property,"a"
	.align 8
	.long	 1f - 0f
	.long	 4f - 1f
	.long	 5
0:
	.string	 "GNU"
1:
	.align 8
	.long	 0xc0000002
	.long	 3f - 2f
2:
	.long	 0x3
3:
	.align 8
4:
