	.section	__TEXT,__text,regular,pure_instructions
	.build_version macos, 11, 3	sdk_version 11, 3
	.globl	_partition_quick_block          ## -- Begin function partition_quick_block
	.p2align	4, 0x90
_partition_quick_block:                 ## @partition_quick_block
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$1128, %rsp                     ## imm = 0x468
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movq	%rdi, %r13
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	movq	%rax, -48(%rbp)
	movl	%edx, %eax
	subl	%esi, %eax
	movslq	%edx, %r11
	cmpl	$3, %eax
	jl	LBB0_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%r13,%r8,4), %edi
	movslq	%ecx, %r9
	movl	(%r13,%r9,4), %r10d
	movl	(%r13,%r11,4), %ecx
	cmpl	%r10d, %edi
	movl	%r10d, %ebx
	cmovll	%edi, %ebx
	movl	%r10d, %eax
	cmovgl	%edi, %eax
	cmpl	%ecx, %ebx
	cmovgel	%ecx, %ebx
	cmpl	%ecx, %eax
	cmovlel	%ecx, %eax
	addl	%edi, %r10d
	addl	%ecx, %r10d
	subl	%ebx, %r10d
	subl	%eax, %r10d
	movl	%ebx, (%r13,%r8,4)
	movl	%r10d, (%r13,%r11,4)
	movl	%eax, (%r13,%r9,4)
	jmp	LBB0_3
LBB0_2:
	movl	(%r13,%r11,4), %r10d
LBB0_3:
	movq	%r11, -1112(%rbp)               ## 8-byte Spill
	decl	%edx
	movq	%rdx, %r9
	movl	%edx, %ebx
	subl	%esi, %ebx
	cmpl	$256, %ebx                      ## imm = 0x100
	movq	%r13, -1080(%rbp)               ## 8-byte Spill
	movq	%rsi, %rdi
	jl	LBB0_4
## %bb.12:
	leaq	12(%r13), %rax
	movq	%rax, -1136(%rbp)               ## 8-byte Spill
	xorl	%ecx, %ecx
	xorl	%r11d, %r11d
	xorl	%r12d, %r12d
	xorl	%r8d, %r8d
	movq	%r9, %rsi
	jmp	LBB0_13
	.p2align	4, 0x90
LBB0_25:                                ##   in Loop: Header=BB0_13 Depth=1
	addl	%ebx, %r8d
	addl	%ebx, %r12d
	leal	128(%rdi), %eax
	subl	%ebx, %r11d
	cmovel	%eax, %edi
	leal	-128(%rsi), %eax
	subl	%ebx, %ecx
	cmovel	%eax, %esi
	movl	%esi, %ebx
	subl	%edi, %ebx
	cmpl	$255, %ebx
	jle	LBB0_26
LBB0_13:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_15 Depth 2
                                        ##     Child Loop BB0_19 Depth 2
                                        ##     Child Loop BB0_36 Depth 2
	testl	%r11d, %r11d
	je	LBB0_14
## %bb.17:                              ##   in Loop: Header=BB0_13 Depth=1
	testl	%ecx, %ecx
	jne	LBB0_20
	jmp	LBB0_18
	.p2align	4, 0x90
LBB0_14:                                ##   in Loop: Header=BB0_13 Depth=1
	movq	%rsi, %r14
	movslq	%edi, %rax
	movq	-1136(%rbp), %rdx               ## 8-byte Reload
	leaq	(%rdx,%rax,4), %rax
	xorl	%r8d, %r8d
	xorl	%ebx, %ebx
	xorl	%r11d, %r11d
	.p2align	4, 0x90
LBB0_15:                                ##   Parent Loop BB0_13 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	%r11d, %edx
	movl	%ebx, -560(%rbp,%rdx,4)
	xorl	%edx, %edx
	cmpl	-12(%rax,%rbx,4), %r10d
	setle	%dl
	addl	%r11d, %edx
	leal	1(%rbx), %esi
	movl	%esi, -560(%rbp,%rdx,4)
	xorl	%esi, %esi
	cmpl	-8(%rax,%rbx,4), %r10d
	setle	%sil
	addl	%edx, %esi
	leal	2(%rbx), %edx
	movl	%edx, -560(%rbp,%rsi,4)
	xorl	%edx, %edx
	cmpl	-4(%rax,%rbx,4), %r10d
	setle	%dl
	addl	%esi, %edx
	leal	3(%rbx), %esi
	movl	%esi, -560(%rbp,%rdx,4)
	xorl	%r11d, %r11d
	cmpl	(%rax,%rbx,4), %r10d
	setle	%r11b
	addl	%edx, %r11d
	addq	$4, %rbx
	cmpq	$128, %rbx
	jne	LBB0_15
## %bb.16:                              ##   in Loop: Header=BB0_13 Depth=1
	movq	%r14, %rsi
	testl	%ecx, %ecx
	jne	LBB0_20
LBB0_18:                                ##   in Loop: Header=BB0_13 Depth=1
	movslq	%esi, %rax
	leaq	(,%rax,4), %rax
	addq	%r13, %rax
	xorl	%r12d, %r12d
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_19:                                ##   Parent Loop BB0_13 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	%ecx, %edx
	movl	%ebx, -1072(%rbp,%rdx,4)
	xorl	%edx, %edx
	cmpl	(%rax), %r10d
	setge	%dl
	addl	%ecx, %edx
	movl	%ebx, %ecx
	orl	$1, %ecx
	movl	%ecx, -1072(%rbp,%rdx,4)
	xorl	%ecx, %ecx
	cmpl	-4(%rax), %r10d
	setge	%cl
	addl	%edx, %ecx
	movl	%ebx, %edx
	orl	$2, %edx
	movl	%edx, -1072(%rbp,%rcx,4)
	xorl	%edx, %edx
	cmpl	-8(%rax), %r10d
	setge	%dl
	addl	%ecx, %edx
	movl	%ebx, %ecx
	orl	$3, %ecx
	movl	%ecx, -1072(%rbp,%rdx,4)
	xorl	%ecx, %ecx
	cmpl	-12(%rax), %r10d
	setge	%cl
	addl	%edx, %ecx
	addq	$4, %rbx
	addq	$-16, %rax
	cmpq	$128, %rbx
	jne	LBB0_19
LBB0_20:                                ##   in Loop: Header=BB0_13 Depth=1
	cmpl	%ecx, %r11d
	movl	%ecx, %ebx
	cmovll	%r11d, %ebx
	testl	%ebx, %ebx
	jle	LBB0_25
## %bb.21:                              ##   in Loop: Header=BB0_13 Depth=1
	movq	%r8, -1128(%rbp)                ## 8-byte Spill
	movq	%rsi, %rax
	movslq	%r8d, %rsi
	movq	%r12, -1104(%rbp)               ## 8-byte Spill
	movslq	%r12d, %rdx
	movl	%ebx, %r8d
	movq	%rdi, -1160(%rbp)               ## 8-byte Spill
	movslq	%edi, %r15
	movq	%rax, -1120(%rbp)               ## 8-byte Spill
	movslq	%eax, %r14
	movl	%ebx, -1084(%rbp)               ## 4-byte Spill
	cmpl	$1, %ebx
	movq	%rdx, -1152(%rbp)               ## 8-byte Spill
	movq	%rsi, -1144(%rbp)               ## 8-byte Spill
	movq	%r8, -1096(%rbp)                ## 8-byte Spill
	jne	LBB0_35
## %bb.22:                              ##   in Loop: Header=BB0_13 Depth=1
	xorl	%r9d, %r9d
	jmp	LBB0_23
	.p2align	4, 0x90
LBB0_35:                                ##   in Loop: Header=BB0_13 Depth=1
                                        ## kill: def $r8d killed $r8d killed $r8 def $r8
	andl	$-2, %r8d
	leaq	-556(%rbp), %rax
	leaq	(%rax,%rsi,4), %rsi
	leaq	-1068(%rbp), %rax
	leaq	(%rax,%rdx,4), %r12
	xorl	%r9d, %r9d
	.p2align	4, 0x90
LBB0_36:                                ##   Parent Loop BB0_13 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movslq	-4(%rsi,%r9,4), %rdx
	addq	%r15, %rdx
	movslq	-4(%r12,%r9,4), %r13
	movq	%r14, %rax
	subq	%r13, %rax
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	movl	(%r13,%rdx,4), %ebx
	movl	(%r13,%rax,4), %edi
	movl	%edi, (%r13,%rdx,4)
	movl	%ebx, (%r13,%rax,4)
	movslq	(%rsi,%r9,4), %rax
	addq	%r15, %rax
	movslq	(%r12,%r9,4), %rdx
	movq	%r14, %rdi
	subq	%rdx, %rdi
	movl	(%r13,%rax,4), %edx
	movl	(%r13,%rdi,4), %ebx
	movl	%ebx, (%r13,%rax,4)
	movl	%edx, (%r13,%rdi,4)
	addq	$2, %r9
	cmpq	%r9, %r8
	jne	LBB0_36
LBB0_23:                                ##   in Loop: Header=BB0_13 Depth=1
	testb	$1, -1096(%rbp)                 ## 1-byte Folded Reload
	movq	-1120(%rbp), %rsi               ## 8-byte Reload
	movq	-1160(%rbp), %rdi               ## 8-byte Reload
	movq	-1128(%rbp), %r8                ## 8-byte Reload
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	-1084(%rbp), %ebx               ## 4-byte Reload
	je	LBB0_25
## %bb.24:                              ##   in Loop: Header=BB0_13 Depth=1
	movq	-1144(%rbp), %rax               ## 8-byte Reload
	addq	%r9, %rax
	movslq	-560(%rbp,%rax,4), %rdx
	addq	%r15, %rdx
	movq	-1152(%rbp), %rax               ## 8-byte Reload
	addq	%r9, %rax
	movq	%rsi, %r9
	movslq	-1072(%rbp,%rax,4), %rsi
	subq	%rsi, %r14
	movl	(%r13,%rdx,4), %r8d
	movl	(%r13,%r14,4), %esi
	movl	%esi, (%r13,%rdx,4)
	movq	%r9, %rsi
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	%r8d, (%r13,%r14,4)
	movq	-1128(%rbp), %r8                ## 8-byte Reload
	jmp	LBB0_25
LBB0_4:
	movq	%r9, %rsi
	jmp	LBB0_5
LBB0_26:
	movl	%ecx, %eax
	orl	%r11d, %eax
	je	LBB0_5
## %bb.27:
	leal	-127(%rbx), %r9d
	testl	%ecx, %ecx
	movq	%rsi, -1120(%rbp)               ## 8-byte Spill
	je	LBB0_43
## %bb.28:
	xorl	%r8d, %r8d
	cmpl	$128, %ebx
	jl	LBB0_34
## %bb.29:
	movslq	%edi, %r14
	movl	%r9d, %r13d
	leaq	-1(%r13), %rax
	movl	%r13d, %r15d
	andl	$3, %r15d
	xorl	%r8d, %r8d
	cmpq	$3, %rax
	jae	LBB0_40
## %bb.30:
	xorl	%ebx, %ebx
	jmp	LBB0_31
LBB0_5:
	leal	1(%rbx), %r14d
	movl	%r14d, %eax
	shrl	$31, %eax
	leal	(%rbx,%rax), %edx
	incl	%edx
	sarl	%edx
	subl	%edx, %r14d
	xorl	%r8d, %r8d
	movl	$0, %r11d
	movl	$0, %ecx
	testl	%ebx, %ebx
	movq	%rsi, -1120(%rbp)               ## 8-byte Spill
	jle	LBB0_10
## %bb.6:
	movq	%rsi, %r9
	movq	%rdi, %rsi
	movslq	%edi, %r15
	movslq	%r9d, %rcx
	testl	%edx, %edx
	movl	$1, %r8d
	movl	%edx, -1084(%rbp)               ## 4-byte Spill
	cmovgl	%edx, %r8d
	cmpl	$3, %ebx
	movq	%rcx, -1104(%rbp)               ## 8-byte Spill
	jge	LBB0_37
## %bb.7:
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	xorl	%r11d, %r11d
	jmp	LBB0_8
LBB0_37:
	movq	%r13, %rax
	movl	%r8d, %r13d
	andl	$2147483646, %r13d              ## imm = 0x7FFFFFFE
	movq	%r15, %rdi
	leaq	(%rax,%r15,4), %r15
	addq	$4, %r15
	leaq	(%rax,%rcx,4), %r12
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	xorl	%r11d, %r11d
	.p2align	4, 0x90
LBB0_38:                                ## =>This Inner Loop Header: Depth=1
	movl	%r11d, %eax
	movl	%ebx, -560(%rbp,%rax,4)
	xorl	%eax, %eax
	cmpl	-4(%r15,%rbx,4), %r10d
	setle	%al
	addl	%r11d, %eax
	movl	%ecx, %edx
	movl	%ebx, -1072(%rbp,%rdx,4)
	xorl	%edx, %edx
	cmpl	(%r12), %r10d
	setge	%dl
	addl	%ecx, %edx
	leal	1(%rbx), %ecx
	movl	%ecx, -560(%rbp,%rax,4)
	xorl	%r11d, %r11d
	cmpl	(%r15,%rbx,4), %r10d
	setle	%r11b
	addl	%eax, %r11d
	movl	%ecx, -1072(%rbp,%rdx,4)
	xorl	%ecx, %ecx
	cmpl	-4(%r12), %r10d
	setge	%cl
	addl	%edx, %ecx
	addq	$2, %rbx
	addq	$-8, %r12
	cmpq	%rbx, %r13
	jne	LBB0_38
## %bb.39:
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	movq	-1120(%rbp), %r9                ## 8-byte Reload
	movq	%rdi, %r15
LBB0_8:
	testb	$1, %r8b
	movl	$0, %r8d
	movq	%rsi, %rdi
	movq	%r9, %rsi
	movl	-1084(%rbp), %edx               ## 4-byte Reload
	je	LBB0_10
## %bb.9:
	movl	%r11d, %eax
	movl	%ebx, -560(%rbp,%rax,4)
	addq	%rbx, %r15
	movl	%ecx, %eax
	movq	-1104(%rbp), %rsi               ## 8-byte Reload
	subq	%rbx, %rsi
	xorl	%r12d, %r12d
	cmpl	(%r13,%r15,4), %r10d
	movl	%ebx, -1072(%rbp,%rax,4)
	setle	%r12b
	xorl	%eax, %eax
	cmpl	(%r13,%rsi,4), %r10d
	movq	%r9, %rsi
	setge	%al
	addl	%ecx, %eax
	addl	%r11d, %r12d
	movl	%r12d, %r11d
	movl	%eax, %ecx
LBB0_10:
	cmpl	%r14d, %edx
	movl	%edx, %ebx
	movq	%r14, -1096(%rbp)               ## 8-byte Spill
	jge	LBB0_55
## %bb.11:
	leal	-1(%r14), %eax
	movl	%ecx, %edx
	movl	%eax, -1072(%rbp,%rdx,4)
	movl	%esi, %eax
	subl	%r14d, %eax
	incl	%eax
	cltq
	xorl	%edx, %edx
	cmpl	(%r13,%rax,4), %r10d
	setge	%dl
	addl	%ecx, %edx
	xorl	%r12d, %r12d
	movl	%edx, %ecx
	jmp	LBB0_56
LBB0_43:
	xorl	%r12d, %r12d
	cmpl	$128, %ebx
	jl	LBB0_44
## %bb.45:
	movq	%rdi, %rdx
	movq	%r8, %rdi
	movslq	%esi, %r13
	movl	%r9d, %r8d
	leaq	-1(%r8), %rax
	movl	%r8d, %r14d
	andl	$3, %r14d
	xorl	%r12d, %r12d
	cmpq	$3, %rax
	jae	LBB0_47
## %bb.46:
	movl	%r9d, %ebx
	xorl	%r15d, %r15d
	xorl	%ecx, %ecx
	testq	%r14, %r14
	movq	%rdi, %r8
	movq	%rdx, %rdi
	je	LBB0_51
LBB0_52:
	leaq	(,%r15,4), %rax
	movq	-1080(%rbp), %rdx               ## 8-byte Reload
	subq	%rax, %rdx
	leaq	(%rdx,%r13,4), %rax
	negq	%r14
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB0_53:                                ## =>This Inner Loop Header: Depth=1
	movl	%ecx, %esi
	movl	%ecx, %ecx
	movl	%r15d, -1072(%rbp,%rcx,4)
	xorl	%ecx, %ecx
	cmpl	(%rax,%rdx,4), %r10d
	setge	%cl
	addl	%esi, %ecx
	decq	%rdx
	incl	%r15d
	cmpq	%rdx, %r14
	jne	LBB0_53
## %bb.54:
	movl	%ebx, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	$128, %ebx
	movq	-1080(%rbp), %r13               ## 8-byte Reload
LBB0_55:
	xorl	%r12d, %r12d
	jmp	LBB0_56
LBB0_44:
	xorl	%ecx, %ecx
	movl	%r9d, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	$128, %ebx
	jmp	LBB0_56
LBB0_40:
	andl	$-4, %r13d
	movq	-1080(%rbp), %rax               ## 8-byte Reload
	leaq	(%rax,%r14,4), %r8
	addq	$12, %r8
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB0_41:                                ## =>This Inner Loop Header: Depth=1
	movslq	%r11d, %rax
	movl	%ebx, -560(%rbp,%rax,4)
	xorl	%edx, %edx
	cmpl	-12(%r8,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %eax
	cltq
	leal	1(%rbx), %edx
	movl	%edx, -560(%rbp,%rax,4)
	xorl	%edx, %edx
	cmpl	-8(%r8,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %eax
	cltq
	leal	2(%rbx), %edx
	movl	%edx, -560(%rbp,%rax,4)
	xorl	%edx, %edx
	cmpl	-4(%r8,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %eax
	movslq	%eax, %r11
	leal	3(%rbx), %eax
	movl	%eax, -560(%rbp,%r11,4)
	xorl	%eax, %eax
	cmpl	(%r8,%rbx,4), %r10d
	setle	%al
	addl	%eax, %r11d
	addq	$4, %rbx
	cmpq	%rbx, %r13
	jne	LBB0_41
## %bb.42:
	xorl	%r8d, %r8d
LBB0_31:
	testq	%r15, %r15
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	je	LBB0_34
## %bb.32:
	leaq	(,%r14,4), %rax
	addq	%r13, %rax
	.p2align	4, 0x90
LBB0_33:                                ## =>This Inner Loop Header: Depth=1
	movslq	%r11d, %r11
	movl	%ebx, -560(%rbp,%r11,4)
	xorl	%edx, %edx
	cmpl	(%rax,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %r11d
	incq	%rbx
	decq	%r15
	jne	LBB0_33
LBB0_34:
	movl	$128, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	%r9d, %ebx
LBB0_56:
	cmpl	%ecx, %r11d
	movl	%ecx, %r10d
	cmovll	%r11d, %r10d
	testl	%r10d, %r10d
	jle	LBB0_61
## %bb.57:
	movl	%ebx, -1084(%rbp)               ## 4-byte Spill
	movq	%r8, -1128(%rbp)                ## 8-byte Spill
	movslq	%r8d, %rdx
	movq	%r12, -1104(%rbp)               ## 8-byte Spill
	movslq	%r12d, %rax
	movl	%r10d, %r12d
	movq	%rdi, -1160(%rbp)               ## 8-byte Spill
	movslq	%edi, %r9
	movslq	-1120(%rbp), %r14               ## 4-byte Folded Reload
	movq	%r10, -1152(%rbp)               ## 8-byte Spill
	cmpl	$1, %r10d
	movq	%rax, -1136(%rbp)               ## 8-byte Spill
	movq	%rdx, -1168(%rbp)               ## 8-byte Spill
	movq	%r12, -1144(%rbp)               ## 8-byte Spill
	jne	LBB0_64
## %bb.58:
	xorl	%eax, %eax
	jmp	LBB0_59
LBB0_64:
                                        ## kill: def $r12d killed $r12d killed $r12 def $r12
	andl	$-2, %r12d
	leaq	-556(,%rdx,4), %r15
	addq	%rbp, %r15
	leaq	-1068(,%rax,4), %r10
	addq	%rbp, %r10
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB0_65:                                ## =>This Inner Loop Header: Depth=1
	movslq	-4(%r15,%rax,4), %rdx
	addq	%r9, %rdx
	movslq	-4(%r10,%rax,4), %rdi
	movq	%r14, %r13
	subq	%rdi, %r13
	movq	-1080(%rbp), %rsi               ## 8-byte Reload
	movl	(%rsi,%rdx,4), %edi
	movq	-1080(%rbp), %rsi               ## 8-byte Reload
	movl	(%rsi,%r13,4), %r8d
	movq	-1080(%rbp), %rsi               ## 8-byte Reload
	movl	%r8d, (%rsi,%rdx,4)
	movq	-1080(%rbp), %rdx               ## 8-byte Reload
	movl	%edi, (%rdx,%r13,4)
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	movslq	(%r15,%rax,4), %rdx
	addq	%r9, %rdx
	movslq	(%r10,%rax,4), %rdi
	movq	%r14, %rsi
	subq	%rdi, %rsi
	movl	(%r13,%rdx,4), %edi
	movl	(%r13,%rsi,4), %ebx
	movl	%ebx, (%r13,%rdx,4)
	movl	%edi, (%r13,%rsi,4)
	addq	$2, %rax
	cmpq	%rax, %r12
	jne	LBB0_65
LBB0_59:
	testb	$1, -1144(%rbp)                 ## 1-byte Folded Reload
	movq	-1160(%rbp), %rdi               ## 8-byte Reload
	movq	-1128(%rbp), %r8                ## 8-byte Reload
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	-1084(%rbp), %ebx               ## 4-byte Reload
	movq	-1152(%rbp), %r10               ## 8-byte Reload
	je	LBB0_61
## %bb.60:
	movq	-1168(%rbp), %rdx               ## 8-byte Reload
	addq	%rax, %rdx
	movslq	-560(%rbp,%rdx,4), %rdx
	addq	%r9, %rdx
	movq	-1136(%rbp), %rsi               ## 8-byte Reload
	addq	%rax, %rsi
	movslq	-1072(%rbp,%rsi,4), %rax
	subq	%rax, %r14
	movl	(%r13,%rdx,4), %eax
	movl	(%r13,%r14,4), %esi
	movl	%esi, (%r13,%rdx,4)
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	%eax, (%r13,%r14,4)
LBB0_61:
	leal	(%r10,%r12), %r9d
	addl	%edi, %ebx
	xorl	%eax, %eax
	cmpl	%ecx, %r11d
	movq	-1096(%rbp), %rdx               ## 8-byte Reload
	cmovll	%eax, %edx
	movq	-1120(%rbp), %r15               ## 8-byte Reload
	subl	%edx, %r15d
	cmpl	%ecx, %r11d
	cmovlel	%ebx, %edi
	jle	LBB0_79
## %bb.62:
	addl	%r8d, %r10d
	leal	(%r11,%r8), %eax
	subl	%edi, %r15d
	movslq	%r10d, %r14
	cmpl	%r10d, %eax
	jle	LBB0_63
## %bb.66:
	movslq	%eax, %rcx
	leal	-1(%r10), %eax
	leal	(%r11,%r8), %ebx
	decl	%ebx
	movq	-1112(%rbp), %rdx               ## 8-byte Reload
	.p2align	4, 0x90
LBB0_67:                                ## =>This Inner Loop Header: Depth=1
	cmpl	-564(%rbp,%rcx,4), %r15d
	jne	LBB0_70
## %bb.68:                              ##   in Loop: Header=BB0_67 Depth=1
	decq	%rcx
	decl	%r15d
	decl	%ebx
	cmpq	%r14, %rcx
	jg	LBB0_67
## %bb.69:
	movl	%eax, %ebx
	jmp	LBB0_70
LBB0_79:
	jge	LBB0_95
## %bb.80:
	leal	(%rcx,%r12), %edx
	movl	%r15d, %eax
	subl	%edi, %eax
	movslq	%r9d, %r10
	cmpl	%r9d, %edx
	movq	-1112(%rbp), %r11               ## 8-byte Reload
	jle	LBB0_81
## %bb.82:
	movslq	%edx, %rsi
	leal	-1(%r9), %edx
	addl	%r12d, %ecx
	decl	%ecx
	.p2align	4, 0x90
LBB0_83:                                ## =>This Inner Loop Header: Depth=1
	cmpl	-1076(%rbp,%rsi,4), %eax
	jne	LBB0_86
## %bb.84:                              ##   in Loop: Header=BB0_83 Depth=1
	decq	%rsi
	decl	%eax
	decl	%ecx
	cmpq	%r10, %rsi
	jg	LBB0_83
## %bb.85:
	movl	%edx, %ecx
	jmp	LBB0_86
LBB0_63:
	leal	(%r11,%r8), %ebx
	decl	%ebx
	movq	-1112(%rbp), %rdx               ## 8-byte Reload
LBB0_70:
	movl	%ebx, %ecx
	subl	%r10d, %ecx
	jl	LBB0_78
## %bb.71:
	movslq	%r15d, %rax
	movq	%rdi, %r12
	movslq	%edi, %r9
	movslq	%ebx, %rbx
	incl	%ecx
	movq	%rbx, %r8
	subq	%r14, %r8
	andq	$3, %rcx
	je	LBB0_74
## %bb.72:
	leaq	(,%r9,4), %r10
	addq	%r13, %r10
	negq	%rcx
	movq	%rax, %rsi
	.p2align	4, 0x90
LBB0_73:                                ## =>This Inner Loop Header: Depth=1
	leaq	-1(%rsi), %rax
	movslq	-560(%rbp,%rbx,4), %rdi
	decq	%rbx
	addq	%r9, %rdi
	movl	(%r10,%rsi,4), %r11d
	movl	(%r13,%rdi,4), %edx
	movl	%edx, (%r10,%rsi,4)
	movl	%r11d, (%r13,%rdi,4)
	movq	%rax, %rsi
	incq	%rcx
	jne	LBB0_73
LBB0_74:
	movq	%rax, %r15
	cmpq	$3, %r8
	jb	LBB0_77
## %bb.75:
	incq	%rbx
	leaq	(,%r9,4), %rcx
	addq	%r13, %rcx
	.p2align	4, 0x90
LBB0_76:                                ## =>This Inner Loop Header: Depth=1
	movslq	-564(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, (%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	movslq	-568(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	-4(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, -4(%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	movslq	-572(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	-8(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, -8(%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	leaq	-4(%rax), %r15
	movslq	-576(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	-12(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, -12(%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	addq	$-4, %rbx
	movq	%r15, %rax
	cmpq	%r14, %rbx
	jg	LBB0_76
LBB0_77:
	movq	-1112(%rbp), %rdx               ## 8-byte Reload
	movq	%r12, %rdi
LBB0_78:
	leaq	(,%rdx,4), %rcx
	addq	%r13, %rcx
	addl	%r15d, %edi
	incl	%edi
	movl	%edi, %ebx
	jmp	LBB0_96
LBB0_95:
	movq	-1112(%rbp), %rax               ## 8-byte Reload
	leaq	(,%rax,4), %rcx
	addq	%r13, %rcx
	jmp	LBB0_96
LBB0_81:
	addl	%r12d, %ecx
	decl	%ecx
LBB0_86:
	movl	%ecx, %edx
	subl	%r9d, %edx
	jl	LBB0_94
## %bb.87:
	movq	%r9, %rsi
	movl	%eax, %r9d
	movslq	%ecx, %rbx
	incl	%edx
	movslq	%r15d, %r14
	testb	$1, %dl
	je	LBB0_89
## %bb.88:
	decq	%r9
	movl	%r15d, %edx
	subl	%eax, %edx
	decl	%eax
	movslq	%edx, %r11
	movslq	-1072(%rbp,%rbx,4), %r8
	decq	%rbx
	movq	%r14, %rdi
	subq	%r8, %rdi
	movl	(%r13,%r11,4), %r8d
	movl	(%r13,%rdi,4), %edx
	movl	%edx, (%r13,%r11,4)
	movq	-1112(%rbp), %r11               ## 8-byte Reload
	movl	%r8d, (%r13,%rdi,4)
LBB0_89:
	cmpl	%esi, %ecx
	je	LBB0_93
## %bb.90:
	incq	%rbx
	cltq
	movq	%r14, %rcx
	subq	%rax, %rcx
	leaq	4(,%rcx,4), %rcx
	addq	%r13, %rcx
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB0_91:                                ## =>This Inner Loop Header: Depth=1
	movslq	-1076(%rbp,%rbx,4), %rdx
	movq	%r14, %rdi
	subq	%rdx, %rdi
	movl	-4(%rcx,%rax,4), %edx
	movl	(%r13,%rdi,4), %esi
	movl	%esi, -4(%rcx,%rax,4)
	movl	%edx, (%r13,%rdi,4)
	movslq	-1080(%rbp,%rbx,4), %rdx
	movq	%r14, %rsi
	subq	%rdx, %rsi
	movl	(%rcx,%rax,4), %edx
	movl	(%r13,%rsi,4), %edi
	movl	%edi, (%rcx,%rax,4)
	movl	%edx, (%r13,%rsi,4)
	addq	$-2, %rbx
	addq	$2, %rax
	cmpq	%r10, %rbx
	jg	LBB0_91
## %bb.92:
	subq	%rax, %r9
LBB0_93:
	movl	%r9d, %eax
LBB0_94:
	leaq	(,%r11,4), %rcx
	addq	%r13, %rcx
	subl	%eax, %r15d
	movl	%r15d, %edi
	movl	%r15d, %ebx
LBB0_96:
	movslq	%edi, %rax
	movl	(%rcx), %edx
	movl	(%r13,%rax,4), %esi
	movl	%esi, (%rcx)
	movl	%edx, (%r13,%rax,4)
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB0_98
## %bb.97:
	movl	%ebx, %eax
	addq	$1128, %rsp                     ## imm = 0x468
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB0_47:
	andl	$-4, %r8d
	movq	-1080(%rbp), %rax               ## 8-byte Reload
	leaq	(%rax,%r13,4), %rbx
	xorl	%r15d, %r15d
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_48:                                ## =>This Inner Loop Header: Depth=1
	movl	%ecx, %eax
	movl	%r15d, -1072(%rbp,%rax,4)
	xorl	%eax, %eax
	cmpl	(%rbx), %r10d
	setge	%al
	addl	%ecx, %eax
	leal	1(%r15), %ecx
	movl	%ecx, -1072(%rbp,%rax,4)
	xorl	%ecx, %ecx
	cmpl	-4(%rbx), %r10d
	setge	%cl
	addl	%eax, %ecx
	leal	2(%r15), %eax
	movl	%eax, -1072(%rbp,%rcx,4)
	xorl	%eax, %eax
	cmpl	-8(%rbx), %r10d
	setge	%al
	addl	%ecx, %eax
	leal	3(%r15), %ecx
	movl	%ecx, -1072(%rbp,%rax,4)
	xorl	%ecx, %ecx
	cmpl	-12(%rbx), %r10d
	setge	%cl
	addl	%eax, %ecx
	addq	$4, %r15
	addq	$-16, %rbx
	cmpq	%r15, %r8
	jne	LBB0_48
## %bb.49:
	movl	%r9d, %ebx
	testq	%r14, %r14
	movq	%rdi, %r8
	movq	%rdx, %rdi
	jne	LBB0_52
LBB0_51:
	movl	%ebx, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	$128, %ebx
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	jmp	LBB0_56
LBB0_98:
	callq	___stack_chk_fail
	.cfi_endproc
                                        ## -- End function
	.globl	_median_of_three                ## -- Begin function median_of_three
	.p2align	4, 0x90
_median_of_three:                       ## @median_of_three
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%rdi,%r8,4), %r11d
	movslq	%ecx, %r9
	movl	(%rdi,%r9,4), %eax
	movslq	%edx, %r10
	movl	(%rdi,%r10,4), %ecx
	cmpl	%eax, %r11d
	movl	%eax, %edx
	cmovll	%r11d, %edx
	movl	%eax, %esi
	cmovgl	%r11d, %esi
	cmpl	%ecx, %edx
	cmovgel	%ecx, %edx
	cmpl	%ecx, %esi
	cmovlel	%ecx, %esi
	addl	%r11d, %eax
	addl	%ecx, %eax
	subl	%edx, %eax
	subl	%esi, %eax
	movl	%edx, (%rdi,%r8,4)
	movl	%eax, (%rdi,%r10,4)
	movl	%esi, (%rdi,%r9,4)
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_min                            ## -- Begin function min
	.p2align	4, 0x90
_min:                                   ## @min
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	%esi, %eax
	cmpl	%esi, %edi
	cmovll	%edi, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_swap                           ## -- Begin function swap
	.p2align	4, 0x90
_swap:                                  ## @swap
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	(%rdi), %eax
	movl	(%rsi), %ecx
	movl	%ecx, (%rdi)
	movl	%eax, (%rsi)
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_block               ## -- Begin function sort_quick_block
	.p2align	4, 0x90
_sort_quick_block:                      ## @sort_quick_block
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	%esi, %edx
	jle	LBB4_22
## %bb.1:
	movl	%edx, %r15d
	movl	%esi, %r12d
	movq	%rdi, %r14
	.p2align	4, 0x90
LBB4_2:                                 ## =>This Inner Loop Header: Depth=1
	movl	%r15d, %esi
	subl	%r12d, %esi
	cmpl	$21, %esi
	jl	LBB4_4
## %bb.3:                               ##   in Loop: Header=BB4_2 Depth=1
	movq	%r14, %rdi
	movl	%r12d, %esi
	movl	%r15d, %edx
	callq	_partition_quick_block
	movl	%eax, %ebx
	leal	-1(%rbx), %edx
	movq	%r14, %rdi
	movl	%r12d, %esi
	callq	_sort_quick_block
	incl	%ebx
	movl	%ebx, %r12d
	cmpl	%r15d, %ebx
	jl	LBB4_2
	jmp	LBB4_22
LBB4_4:
	testl	%esi, %esi
	jle	LBB4_22
## %bb.5:
	movslq	%r12d, %rax
	leaq	(%r14,%rax,4), %rax
	movabsq	$-4294967296, %rcx              ## imm = 0xFFFFFFFF00000000
	movl	%esi, %r8d
	movl	$1, %r15d
	cmpl	$1, %esi
	jne	LBB4_6
LBB4_16:
	testb	$1, %r8b
	je	LBB4_22
## %bb.17:
	movl	(%rax,%r15,4), %esi
	movq	%r15, %rdi
	shlq	$32, %rdi
	addq	%rcx, %rdi
	.p2align	4, 0x90
LBB4_18:                                ## =>This Inner Loop Header: Depth=1
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB4_21
## %bb.19:                              ##   in Loop: Header=BB4_18 Depth=1
	movl	%edx, (%rax,%r15,4)
	leaq	-1(%r15), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %r15
	movq	%rdx, %r15
	jg	LBB4_18
## %bb.20:
	xorl	%r15d, %r15d
LBB4_21:
	movslq	%r15d, %rcx
	movl	%esi, (%rax,%rcx,4)
LBB4_22:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB4_6:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movl	%r8d, %r10d
	andl	$-2, %r10d
	movl	$1, %r15d
	movabsq	$4294967296, %r11               ## imm = 0x100000000
	xorl	%r14d, %r14d
	jmp	LBB4_7
	.p2align	4, 0x90
LBB4_15:                                ##   in Loop: Header=BB4_7 Depth=1
	movslq	%ebx, %rdx
	movl	%esi, (%rax,%rdx,4)
	addq	$2, %r15
	addq	%r9, %r14
	addq	%r9, %r11
	addq	$-2, %r10
	je	LBB4_16
LBB4_7:                                 ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB4_8 Depth 2
                                        ##     Child Loop BB4_12 Depth 2
	movl	(%rax,%r15,4), %esi
	movq	%r14, %rdi
	movq	%r15, %rbx
	.p2align	4, 0x90
LBB4_8:                                 ##   Parent Loop BB4_7 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB4_11
## %bb.9:                               ##   in Loop: Header=BB4_8 Depth=2
	movl	%edx, (%rax,%rbx,4)
	leaq	-1(%rbx), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %rbx
	movq	%rdx, %rbx
	jg	LBB4_8
## %bb.10:                              ##   in Loop: Header=BB4_7 Depth=1
	xorl	%ebx, %ebx
LBB4_11:                                ##   in Loop: Header=BB4_7 Depth=1
	movslq	%ebx, %rdx
	movl	%esi, (%rax,%rdx,4)
	leaq	1(%r15), %rbx
	movl	4(%rax,%r15,4), %esi
	movq	%r11, %rdi
	.p2align	4, 0x90
LBB4_12:                                ##   Parent Loop BB4_7 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB4_15
## %bb.13:                              ##   in Loop: Header=BB4_12 Depth=2
	movl	%edx, (%rax,%rbx,4)
	leaq	-1(%rbx), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %rbx
	movq	%rdx, %rbx
	jg	LBB4_12
## %bb.14:                              ##   in Loop: Header=BB4_7 Depth=1
	xorl	%ebx, %ebx
	jmp	LBB4_15
	.cfi_endproc
                                        ## -- End function
	.globl	_insertionSort                  ## -- Begin function insertionSort
	.p2align	4, 0x90
_insertionSort:                         ## @insertionSort
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	$2, %esi
	jl	LBB5_18
## %bb.1:
	movabsq	$-4294967296, %rax              ## imm = 0xFFFFFFFF00000000
	movl	%esi, %r8d
	decq	%r8
	movl	$1, %r15d
	cmpl	$2, %esi
	jne	LBB5_2
LBB5_12:
	testb	$1, %r8b
	je	LBB5_18
## %bb.13:
	movl	(%rdi,%r15,4), %edx
	movq	%r15, %rsi
	shlq	$32, %rsi
	addq	%rax, %rsi
	.p2align	4, 0x90
LBB5_14:                                ## =>This Inner Loop Header: Depth=1
	movq	%rsi, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%edx, %ecx
	jle	LBB5_17
## %bb.15:                              ##   in Loop: Header=BB5_14 Depth=1
	movl	%ecx, (%rdi,%r15,4)
	leaq	-1(%r15), %rcx
	addq	%rax, %rsi
	cmpq	$1, %r15
	movq	%rcx, %r15
	jg	LBB5_14
## %bb.16:
	xorl	%r15d, %r15d
LBB5_17:
	movslq	%r15d, %rax
	movl	%edx, (%rdi,%rax,4)
LBB5_18:
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB5_2:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movq	%r8, %r10
	andq	$-2, %r10
	movl	$1, %r15d
	movabsq	$4294967296, %r11               ## imm = 0x100000000
	xorl	%r14d, %r14d
	jmp	LBB5_3
	.p2align	4, 0x90
LBB5_11:                                ##   in Loop: Header=BB5_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	addq	$2, %r15
	addq	%r9, %r14
	addq	%r9, %r11
	addq	$-2, %r10
	je	LBB5_12
LBB5_3:                                 ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB5_4 Depth 2
                                        ##     Child Loop BB5_8 Depth 2
	movl	(%rdi,%r15,4), %esi
	movq	%r14, %rdx
	movq	%r15, %rbx
	.p2align	4, 0x90
LBB5_4:                                 ##   Parent Loop BB5_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB5_7
## %bb.5:                               ##   in Loop: Header=BB5_4 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB5_4
## %bb.6:                               ##   in Loop: Header=BB5_3 Depth=1
	xorl	%ebx, %ebx
LBB5_7:                                 ##   in Loop: Header=BB5_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	leaq	1(%r15), %rbx
	movl	4(%rdi,%r15,4), %esi
	movq	%r11, %rdx
	.p2align	4, 0x90
LBB5_8:                                 ##   Parent Loop BB5_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB5_11
## %bb.9:                               ##   in Loop: Header=BB5_8 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB5_8
## %bb.10:                              ##   in Loop: Header=BB5_3 Depth=1
	xorl	%ebx, %ebx
	jmp	LBB5_11
	.cfi_endproc
                                        ## -- End function
	.globl	_random_data                    ## -- Begin function random_data
	.p2align	4, 0x90
_random_data:                           ## @random_data
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movl	%esi, %r14d
	movq	%rdi, %r15
	callq	_clock
	movl	%eax, %edi
	callq	_srand
	testl	%r14d, %r14d
	jle	LBB6_3
## %bb.1:
	movl	%r14d, %r14d
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB6_2:                                 ## =>This Inner Loop Header: Depth=1
	callq	_rand
	movl	%eax, (%r15,%rbx,4)
	incq	%rbx
	cmpq	%rbx, %r14
	jne	LBB6_2
LBB6_3:
	addq	$8, %rsp
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_insertionSortOptimized         ## -- Begin function insertionSortOptimized
	.p2align	4, 0x90
_insertionSortOptimized:                ## @insertionSortOptimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	$2, %esi
	jl	LBB7_18
## %bb.1:
	movabsq	$-4294967296, %rax              ## imm = 0xFFFFFFFF00000000
	movl	%esi, %r8d
	decq	%r8
	movl	$1, %r15d
	cmpl	$2, %esi
	jne	LBB7_2
LBB7_12:
	testb	$1, %r8b
	je	LBB7_18
## %bb.13:
	movl	(%rdi,%r15,4), %edx
	movq	%r15, %rsi
	shlq	$32, %rsi
	addq	%rax, %rsi
	.p2align	4, 0x90
LBB7_14:                                ## =>This Inner Loop Header: Depth=1
	movq	%rsi, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%edx, %ecx
	jle	LBB7_17
## %bb.15:                              ##   in Loop: Header=BB7_14 Depth=1
	movl	%ecx, (%rdi,%r15,4)
	leaq	-1(%r15), %rcx
	addq	%rax, %rsi
	cmpq	$1, %r15
	movq	%rcx, %r15
	jg	LBB7_14
## %bb.16:
	xorl	%r15d, %r15d
LBB7_17:
	movslq	%r15d, %rax
	movl	%edx, (%rdi,%rax,4)
LBB7_18:
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB7_2:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movq	%r8, %r10
	andq	$-2, %r10
	movl	$1, %r15d
	movabsq	$4294967296, %r11               ## imm = 0x100000000
	xorl	%r14d, %r14d
	jmp	LBB7_3
	.p2align	4, 0x90
LBB7_11:                                ##   in Loop: Header=BB7_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	addq	$2, %r15
	addq	%r9, %r14
	addq	%r9, %r11
	addq	$-2, %r10
	je	LBB7_12
LBB7_3:                                 ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB7_4 Depth 2
                                        ##     Child Loop BB7_8 Depth 2
	movl	(%rdi,%r15,4), %esi
	movq	%r14, %rdx
	movq	%r15, %rbx
	.p2align	4, 0x90
LBB7_4:                                 ##   Parent Loop BB7_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB7_7
## %bb.5:                               ##   in Loop: Header=BB7_4 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB7_4
## %bb.6:                               ##   in Loop: Header=BB7_3 Depth=1
	xorl	%ebx, %ebx
LBB7_7:                                 ##   in Loop: Header=BB7_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	leaq	1(%r15), %rbx
	movl	4(%rdi,%r15,4), %esi
	movq	%r11, %rdx
	.p2align	4, 0x90
LBB7_8:                                 ##   Parent Loop BB7_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB7_11
## %bb.9:                               ##   in Loop: Header=BB7_8 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB7_8
## %bb.10:                              ##   in Loop: Header=BB7_3 Depth=1
	xorl	%ebx, %ebx
	jmp	LBB7_11
	.cfi_endproc
                                        ## -- End function
	.globl	_sign                           ## -- Begin function sign
	.p2align	4, 0x90
_sign:                                  ## @sign
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	%edi, %ecx
	sarl	$31, %ecx
	xorl	%eax, %eax
	testl	%edi, %edi
	setne	%al
	orl	%ecx, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_merging_optimzed               ## -- Begin function merging_optimzed
	.p2align	4, 0x90
_merging_optimzed:                      ## @merging_optimzed
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$24, %rsp
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $ecx killed $ecx def $rcx
                                        ## kill: def $edx killed $edx def $rdx
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	movq	%rax, -48(%rbp)
	leal	1(%rdx), %r9d
	movslq	%esi, %r8
	movl	(%rdi,%r8,4), %r10d
	movl	%r10d, -56(%rbp)
	movslq	%r9d, %rax
	movl	(%rdi,%rax,4), %r11d
	movl	%r11d, -52(%rbp)
	cmpl	%ecx, %edx
	jge	LBB9_1
## %bb.8:
	cmpl	%edx, %esi
	jg	LBB9_1
## %bb.9:
	leaq	(,%r8,4), %r12
	addq	_b@GOTPCREL(%rip), %r12
	movl	%esi, %r14d
	movl	%esi, %ebx
	.p2align	4, 0x90
LBB9_10:                                ## =>This Inner Loop Header: Depth=1
	movl	%ebx, %r15d
	xorl	%ebx, %ebx
	xorl	%eax, %eax
	cmpl	%r11d, %r10d
	setle	%bl
	setg	%al
	addl	%r15d, %ebx
	addl	%eax, %r9d
	movl	-56(%rbp,%rax,4), %eax
	movl	%eax, (%r12)
	movslq	%ebx, %rax
	movl	(%rdi,%rax,4), %r10d
	movl	%r10d, -56(%rbp)
	movslq	%r9d, %rax
	movl	(%rdi,%rax,4), %r11d
	movl	%r11d, -52(%rbp)
	incl	%r14d
	cmpl	%ecx, %eax
	jg	LBB9_2
## %bb.11:                              ##   in Loop: Header=BB9_10 Depth=1
	addq	$4, %r12
	cmpl	%edx, %ebx
	jle	LBB9_10
	jmp	LBB9_2
LBB9_1:
	movl	%esi, %r14d
	movl	%esi, %ebx
LBB9_2:
	cmpl	%edx, %ebx
	jg	LBB9_26
## %bb.3:
	movslq	%ebx, %r10
	movslq	%r14d, %r14
	movl	%edx, %r11d
	subl	%ebx, %r11d
	cmpl	$31, %r11d
	jb	LBB9_19
## %bb.4:
	movq	_b@GOTPCREL(%rip), %r15
	leaq	(%r15,%r14,4), %rax
	leaq	(%r10,%r11), %rbx
	leaq	(%rdi,%rbx,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rax
	jae	LBB9_6
## %bb.5:
	leaq	(%r14,%r11), %rax
	leaq	(%r15,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r10,4), %rbx
	cmpq	%rax, %rbx
	jb	LBB9_19
LBB9_6:
	incq	%r11
	movq	%r11, %rax
	andq	$-32, %rax
	movq	%rax, -64(%rbp)                 ## 8-byte Spill
	addq	$-32, %rax
	movq	%rax, %r13
	shrq	$5, %r13
	incq	%r13
	movl	%r13d, %r12d
	andl	$3, %r12d
	cmpq	$96, %rax
	jae	LBB9_12
## %bb.7:
	xorl	%ebx, %ebx
	jmp	LBB9_14
LBB9_12:
	leaq	(%r15,%r14,4), %rax
	addq	$480, %rax                      ## imm = 0x1E0
	leaq	(%rdi,%r10,4), %r15
	addq	$480, %r15                      ## imm = 0x1E0
	andq	$-4, %r13
	negq	%r13
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB9_13:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%r15,%rbx,4), %ymm0
	vmovups	-448(%r15,%rbx,4), %ymm1
	vmovups	-416(%r15,%rbx,4), %ymm2
	vmovups	-384(%r15,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rax,%rbx,4)
	vmovups	%ymm1, -448(%rax,%rbx,4)
	vmovups	%ymm2, -416(%rax,%rbx,4)
	vmovups	%ymm3, -384(%rax,%rbx,4)
	vmovups	-352(%r15,%rbx,4), %ymm0
	vmovups	-320(%r15,%rbx,4), %ymm1
	vmovups	-288(%r15,%rbx,4), %ymm2
	vmovups	-256(%r15,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rax,%rbx,4)
	vmovups	%ymm1, -320(%rax,%rbx,4)
	vmovups	%ymm2, -288(%rax,%rbx,4)
	vmovups	%ymm3, -256(%rax,%rbx,4)
	vmovups	-224(%r15,%rbx,4), %ymm0
	vmovups	-192(%r15,%rbx,4), %ymm1
	vmovups	-160(%r15,%rbx,4), %ymm2
	vmovups	-128(%r15,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rax,%rbx,4)
	vmovups	%ymm1, -192(%rax,%rbx,4)
	vmovups	%ymm2, -160(%rax,%rbx,4)
	vmovups	%ymm3, -128(%rax,%rbx,4)
	vmovups	-96(%r15,%rbx,4), %ymm0
	vmovups	-64(%r15,%rbx,4), %ymm1
	vmovups	-32(%r15,%rbx,4), %ymm2
	vmovups	(%r15,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rax,%rbx,4)
	vmovups	%ymm1, -64(%rax,%rbx,4)
	vmovups	%ymm2, -32(%rax,%rbx,4)
	vmovups	%ymm3, (%rax,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %r13
	jne	LBB9_13
LBB9_14:
	testq	%r12, %r12
	je	LBB9_17
## %bb.15:
	leaq	(%rbx,%r10), %rax
	leaq	(%rdi,%rax,4), %r15
	addq	$96, %r15
	addq	%r14, %rbx
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%rbx,4), %rbx
	addq	$96, %rbx
	shlq	$7, %r12
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB9_16:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%r15,%rax), %ymm0
	vmovups	-64(%r15,%rax), %ymm1
	vmovups	-32(%r15,%rax), %ymm2
	vmovups	(%r15,%rax), %ymm3
	vmovups	%ymm0, -96(%rbx,%rax)
	vmovups	%ymm1, -64(%rbx,%rax)
	vmovups	%ymm2, -32(%rbx,%rax)
	vmovups	%ymm3, (%rbx,%rax)
	subq	$-128, %rax
	cmpq	%rax, %r12
	jne	LBB9_16
LBB9_17:
	movq	-64(%rbp), %rax                 ## 8-byte Reload
	addq	%rax, %r14
	cmpq	%rax, %r11
	je	LBB9_26
## %bb.18:
	addq	%rax, %r10
LBB9_19:
	movl	%edx, %r11d
	subl	%r10d, %r11d
	leal	1(%r11), %ebx
	andl	$7, %ebx
	je	LBB9_22
## %bb.20:
	movq	_b@GOTPCREL(%rip), %r15
	.p2align	4, 0x90
LBB9_21:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r10,4), %eax
	incq	%r10
	movl	%eax, (%r15,%r14,4)
	incq	%r14
	decl	%ebx
	jne	LBB9_21
LBB9_22:
	cmpl	$7, %r11d
	jb	LBB9_26
## %bb.23:
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r14,4), %r11
	addq	$28, %r11
	subl	%r10d, %edx
	incl	%edx
	leaq	(%rdi,%r10,4), %r10
	addq	$28, %r10
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB9_24:                                ## =>This Inner Loop Header: Depth=1
	movl	-28(%r10,%rbx,4), %eax
	movl	%eax, -28(%r11,%rbx,4)
	movl	-24(%r10,%rbx,4), %eax
	movl	%eax, -24(%r11,%rbx,4)
	movl	-20(%r10,%rbx,4), %eax
	movl	%eax, -20(%r11,%rbx,4)
	movl	-16(%r10,%rbx,4), %eax
	movl	%eax, -16(%r11,%rbx,4)
	movl	-12(%r10,%rbx,4), %eax
	movl	%eax, -12(%r11,%rbx,4)
	movl	-8(%r10,%rbx,4), %eax
	movl	%eax, -8(%r11,%rbx,4)
	movl	-4(%r10,%rbx,4), %eax
	movl	%eax, -4(%r11,%rbx,4)
	movl	(%r10,%rbx,4), %eax
	movl	%eax, (%r11,%rbx,4)
	addq	$8, %rbx
	cmpl	%ebx, %edx
	jne	LBB9_24
## %bb.25:
	addq	%rbx, %r14
LBB9_26:
	cmpl	%ecx, %r9d
	jg	LBB9_45
## %bb.27:
	movslq	%r14d, %r12
	movslq	%r9d, %r13
	movl	%ecx, %r10d
	subl	%r9d, %r10d
	cmpl	$31, %r10d
	jb	LBB9_39
## %bb.28:
	movq	_b@GOTPCREL(%rip), %r9
	leaq	(%r9,%r12,4), %rax
	leaq	(%r10,%r13), %rdx
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	cmpq	%rdx, %rax
	jae	LBB9_30
## %bb.29:
	leaq	(%r12,%r10), %rax
	leaq	(%r9,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r13,4), %rdx
	cmpq	%rax, %rdx
	jb	LBB9_39
LBB9_30:
	incq	%r10
	movq	%r10, %r11
	andq	$-32, %r11
	leaq	-32(%r11), %rax
	movq	%rax, %r15
	shrq	$5, %r15
	incq	%r15
	movl	%r15d, %r14d
	andl	$3, %r14d
	cmpq	$96, %rax
	jae	LBB9_32
## %bb.31:
	xorl	%ebx, %ebx
	jmp	LBB9_34
LBB9_32:
	leaq	(%rdi,%r13,4), %rax
	addq	$480, %rax                      ## imm = 0x1E0
	leaq	(%r9,%r12,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	andq	$-4, %r15
	negq	%r15
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB9_33:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rax,%rbx,4), %ymm0
	vmovups	-448(%rax,%rbx,4), %ymm1
	vmovups	-416(%rax,%rbx,4), %ymm2
	vmovups	-384(%rax,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rbx,4)
	vmovups	%ymm1, -448(%rdx,%rbx,4)
	vmovups	%ymm2, -416(%rdx,%rbx,4)
	vmovups	%ymm3, -384(%rdx,%rbx,4)
	vmovups	-352(%rax,%rbx,4), %ymm0
	vmovups	-320(%rax,%rbx,4), %ymm1
	vmovups	-288(%rax,%rbx,4), %ymm2
	vmovups	-256(%rax,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rbx,4)
	vmovups	%ymm1, -320(%rdx,%rbx,4)
	vmovups	%ymm2, -288(%rdx,%rbx,4)
	vmovups	%ymm3, -256(%rdx,%rbx,4)
	vmovups	-224(%rax,%rbx,4), %ymm0
	vmovups	-192(%rax,%rbx,4), %ymm1
	vmovups	-160(%rax,%rbx,4), %ymm2
	vmovups	-128(%rax,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rbx,4)
	vmovups	%ymm1, -192(%rdx,%rbx,4)
	vmovups	%ymm2, -160(%rdx,%rbx,4)
	vmovups	%ymm3, -128(%rdx,%rbx,4)
	vmovups	-96(%rax,%rbx,4), %ymm0
	vmovups	-64(%rax,%rbx,4), %ymm1
	vmovups	-32(%rax,%rbx,4), %ymm2
	vmovups	(%rax,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx,4)
	vmovups	%ymm1, -64(%rdx,%rbx,4)
	vmovups	%ymm2, -32(%rdx,%rbx,4)
	vmovups	%ymm3, (%rdx,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %r15
	jne	LBB9_33
LBB9_34:
	testq	%r14, %r14
	je	LBB9_37
## %bb.35:
	leaq	(%rbx,%r12), %rax
	leaq	(%r9,%rax,4), %rax
	addq	$96, %rax
	addq	%r13, %rbx
	leaq	(%rdi,%rbx,4), %rdx
	addq	$96, %rdx
	shlq	$7, %r14
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB9_36:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rdx,%rbx), %ymm0
	vmovups	-64(%rdx,%rbx), %ymm1
	vmovups	-32(%rdx,%rbx), %ymm2
	vmovups	(%rdx,%rbx), %ymm3
	vmovups	%ymm0, -96(%rax,%rbx)
	vmovups	%ymm1, -64(%rax,%rbx)
	vmovups	%ymm2, -32(%rax,%rbx)
	vmovups	%ymm3, (%rax,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r14
	jne	LBB9_36
LBB9_37:
	cmpq	%r11, %r10
	je	LBB9_45
## %bb.38:
	addq	%r11, %r13
	addq	%r11, %r12
LBB9_39:
	movl	%ecx, %r9d
	subl	%r13d, %r9d
	leal	1(%r9), %edx
	andl	$7, %edx
	je	LBB9_42
## %bb.40:
	movq	_b@GOTPCREL(%rip), %rbx
	.p2align	4, 0x90
LBB9_41:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r13,4), %eax
	incq	%r13
	movl	%eax, (%rbx,%r12,4)
	incq	%r12
	decl	%edx
	jne	LBB9_41
LBB9_42:
	cmpl	$7, %r9d
	jb	LBB9_45
## %bb.43:
	movl	%ecx, %r9d
	subl	%r13d, %r9d
	incl	%r9d
	leaq	(%rdi,%r13,4), %r10
	addq	$28, %r10
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r12,4), %rbx
	addq	$28, %rbx
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB9_44:                                ## =>This Inner Loop Header: Depth=1
	movl	-28(%r10,%rax,4), %edx
	movl	%edx, -28(%rbx,%rax,4)
	movl	-24(%r10,%rax,4), %edx
	movl	%edx, -24(%rbx,%rax,4)
	movl	-20(%r10,%rax,4), %edx
	movl	%edx, -20(%rbx,%rax,4)
	movl	-16(%r10,%rax,4), %edx
	movl	%edx, -16(%rbx,%rax,4)
	movl	-12(%r10,%rax,4), %edx
	movl	%edx, -12(%rbx,%rax,4)
	movl	-8(%r10,%rax,4), %edx
	movl	%edx, -8(%rbx,%rax,4)
	movl	-4(%r10,%rax,4), %edx
	movl	%edx, -4(%rbx,%rax,4)
	movl	(%r10,%rax,4), %edx
	movl	%edx, (%rbx,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %r9d
	jne	LBB9_44
LBB9_45:
	movl	%ecx, %r11d
	subl	%esi, %r11d
	jl	LBB9_64
## %bb.46:
	cmpl	$31, %r11d
	jb	LBB9_58
## %bb.47:
	leaq	(%rdi,%r8,4), %rsi
	leaq	(%r11,%r8), %rax
	movq	_b@GOTPCREL(%rip), %rdx
	leaq	(%rdx,%rax,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rsi
	jae	LBB9_49
## %bb.48:
	leaq	(%rdi,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdx,%r8,4), %rdx
	cmpq	%rax, %rdx
	jb	LBB9_58
LBB9_49:
	incq	%r11
	movq	%r11, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rax
	movq	%rax, %rsi
	shrq	$5, %rsi
	incq	%rsi
	movl	%esi, %r10d
	andl	$3, %r10d
	cmpq	$96, %rax
	jae	LBB9_51
## %bb.50:
	xorl	%edx, %edx
	jmp	LBB9_53
LBB9_51:
	leaq	(%rdi,%r8,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	480(,%r8,4), %rax
	addq	_b@GOTPCREL(%rip), %rax
	andq	$-4, %rsi
	negq	%rsi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB9_52:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rax,%rdx,4), %ymm0
	vmovups	-448(%rax,%rdx,4), %ymm1
	vmovups	-416(%rax,%rdx,4), %ymm2
	vmovups	-384(%rax,%rdx,4), %ymm3
	vmovups	%ymm0, -480(%rbx,%rdx,4)
	vmovups	%ymm1, -448(%rbx,%rdx,4)
	vmovups	%ymm2, -416(%rbx,%rdx,4)
	vmovups	%ymm3, -384(%rbx,%rdx,4)
	vmovups	-352(%rax,%rdx,4), %ymm0
	vmovups	-320(%rax,%rdx,4), %ymm1
	vmovups	-288(%rax,%rdx,4), %ymm2
	vmovups	-256(%rax,%rdx,4), %ymm3
	vmovups	%ymm0, -352(%rbx,%rdx,4)
	vmovups	%ymm1, -320(%rbx,%rdx,4)
	vmovups	%ymm2, -288(%rbx,%rdx,4)
	vmovups	%ymm3, -256(%rbx,%rdx,4)
	vmovups	-224(%rax,%rdx,4), %ymm0
	vmovups	-192(%rax,%rdx,4), %ymm1
	vmovups	-160(%rax,%rdx,4), %ymm2
	vmovups	-128(%rax,%rdx,4), %ymm3
	vmovups	%ymm0, -224(%rbx,%rdx,4)
	vmovups	%ymm1, -192(%rbx,%rdx,4)
	vmovups	%ymm2, -160(%rbx,%rdx,4)
	vmovups	%ymm3, -128(%rbx,%rdx,4)
	vmovups	-96(%rax,%rdx,4), %ymm0
	vmovups	-64(%rax,%rdx,4), %ymm1
	vmovups	-32(%rax,%rdx,4), %ymm2
	vmovups	(%rax,%rdx,4), %ymm3
	vmovups	%ymm0, -96(%rbx,%rdx,4)
	vmovups	%ymm1, -64(%rbx,%rdx,4)
	vmovups	%ymm2, -32(%rbx,%rdx,4)
	vmovups	%ymm3, (%rbx,%rdx,4)
	subq	$-128, %rdx
	addq	$4, %rsi
	jne	LBB9_52
LBB9_53:
	testq	%r10, %r10
	je	LBB9_56
## %bb.54:
	addq	%r8, %rdx
	leaq	(%rdi,%rdx,4), %rax
	addq	$96, %rax
	leaq	96(,%rdx,4), %rdx
	addq	_b@GOTPCREL(%rip), %rdx
	shlq	$7, %r10
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB9_55:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rdx,%rsi), %ymm0
	vmovups	-64(%rdx,%rsi), %ymm1
	vmovups	-32(%rdx,%rsi), %ymm2
	vmovups	(%rdx,%rsi), %ymm3
	vmovups	%ymm0, -96(%rax,%rsi)
	vmovups	%ymm1, -64(%rax,%rsi)
	vmovups	%ymm2, -32(%rax,%rsi)
	vmovups	%ymm3, (%rax,%rsi)
	subq	$-128, %rsi
	cmpq	%rsi, %r10
	jne	LBB9_55
LBB9_56:
	cmpq	%r9, %r11
	je	LBB9_64
## %bb.57:
	addq	%r9, %r8
LBB9_58:
	leal	1(%rcx), %eax
	movl	%eax, %edx
	subl	%r8d, %edx
	subl	%r8d, %ecx
	andl	$7, %edx
	je	LBB9_61
## %bb.59:
	movq	_b@GOTPCREL(%rip), %rsi
	.p2align	4, 0x90
LBB9_60:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rsi,%r8,4), %ebx
	movl	%ebx, (%rdi,%r8,4)
	incq	%r8
	decl	%edx
	jne	LBB9_60
LBB9_61:
	cmpl	$7, %ecx
	jb	LBB9_64
## %bb.62:
	movl	%eax, %eax
	movq	_b@GOTPCREL(%rip), %rcx
	.p2align	4, 0x90
LBB9_63:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rcx,%r8,4), %edx
	movl	%edx, (%rdi,%r8,4)
	movl	4(%rcx,%r8,4), %edx
	movl	%edx, 4(%rdi,%r8,4)
	movl	8(%rcx,%r8,4), %edx
	movl	%edx, 8(%rdi,%r8,4)
	movl	12(%rcx,%r8,4), %edx
	movl	%edx, 12(%rdi,%r8,4)
	movl	16(%rcx,%r8,4), %edx
	movl	%edx, 16(%rdi,%r8,4)
	movl	20(%rcx,%r8,4), %edx
	movl	%edx, 20(%rdi,%r8,4)
	movl	24(%rcx,%r8,4), %edx
	movl	%edx, 24(%rdi,%r8,4)
	movl	28(%rcx,%r8,4), %edx
	movl	%edx, 28(%rdi,%r8,4)
	addq	$8, %r8
	cmpl	%r8d, %eax
	jne	LBB9_63
LBB9_64:
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB9_66
## %bb.65:
	addq	$24, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
LBB9_66:
	vzeroupper
	callq	___stack_chk_fail
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_merge_optimized           ## -- Begin function sort_merge_optimized
	.p2align	4, 0x90
_sort_merge_optimized:                  ## @sort_merge_optimized
	.cfi_startproc
## %bb.0:
	cmpl	%edx, %esi
	jge	LBB10_1
## %bb.2:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movl	%edx, %r14d
	movl	%esi, %r12d
	movq	%rdi, %r15
	leal	(%r14,%r12), %eax
	movl	%eax, %ebx
	shrl	$31, %ebx
	addl	%eax, %ebx
	sarl	%ebx
	movl	%ebx, %edx
	callq	_sort_merge_optimized
	leal	1(%rbx), %esi
	movq	%r15, %rdi
	movl	%r14d, %edx
	callq	_sort_merge_optimized
	movq	%r15, %rdi
	movl	%r12d, %esi
	movl	%ebx, %edx
	movl	%r14d, %ecx
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	jmp	_merging_optimzed               ## TAILCALL
LBB10_1:
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_merging_standard               ## -- Begin function merging_standard
	.p2align	4, 0x90
_merging_standard:                      ## @merging_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $ecx killed $ecx def $rcx
                                        ## kill: def $edx killed $edx def $rdx
	leal	1(%rdx), %r14d
	cmpl	%edx, %esi
	jg	LBB11_1
## %bb.8:
	cmpl	%ecx, %edx
	jge	LBB11_1
## %bb.9:
	movslq	%esi, %r9
	shlq	$2, %r9
	addq	_b@GOTPCREL(%rip), %r9
	movl	%esi, %r8d
	movl	%esi, %ebx
	.p2align	4, 0x90
LBB11_10:                               ## =>This Inner Loop Header: Depth=1
	movslq	%ebx, %rbx
	movl	(%rdi,%rbx,4), %r15d
	movslq	%r14d, %r14
	movl	(%rdi,%r14,4), %r10d
	xorl	%r11d, %r11d
	xorl	%eax, %eax
	cmpl	%r10d, %r15d
	setg	%r11b
	setle	%al
	cmovgl	%r10d, %r15d
	addl	%eax, %ebx
	addl	%r11d, %r14d
	movl	%r15d, (%r9)
	incl	%r8d
	cmpl	%edx, %ebx
	jg	LBB11_2
## %bb.11:                              ##   in Loop: Header=BB11_10 Depth=1
	addq	$4, %r9
	cmpl	%ecx, %r14d
	jle	LBB11_10
	jmp	LBB11_2
LBB11_1:
	movl	%esi, %ebx
	movl	%esi, %r8d
LBB11_2:
	cmpl	%edx, %ebx
	jg	LBB11_26
## %bb.3:
	movslq	%r8d, %r8
	movslq	%ebx, %r9
	movl	%edx, %r10d
	subl	%ebx, %r10d
	cmpl	$31, %r10d
	jb	LBB11_19
## %bb.4:
	movq	_b@GOTPCREL(%rip), %r11
	leaq	(%r11,%r8,4), %rax
	leaq	(%r9,%r10), %rbx
	leaq	(%rdi,%rbx,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rax
	jae	LBB11_6
## %bb.5:
	leaq	(%r8,%r10), %rax
	leaq	(%r11,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r9,4), %rbx
	cmpq	%rax, %rbx
	jb	LBB11_19
LBB11_6:
	incq	%r10
	movq	%r10, %rax
	andq	$-32, %rax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	addq	$-32, %rax
	movq	%rax, %r12
	shrq	$5, %r12
	incq	%r12
	movl	%r12d, %r15d
	andl	$3, %r15d
	cmpq	$96, %rax
	jae	LBB11_12
## %bb.7:
	xorl	%r11d, %r11d
	jmp	LBB11_14
LBB11_12:
	leaq	(%rdi,%r9,4), %r13
	addq	$480, %r13                      ## imm = 0x1E0
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r8,4), %rax
	addq	$480, %rax                      ## imm = 0x1E0
	andq	$-4, %r12
	negq	%r12
	xorl	%r11d, %r11d
	.p2align	4, 0x90
LBB11_13:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%r13,%r11,4), %ymm0
	vmovups	-448(%r13,%r11,4), %ymm1
	vmovups	-416(%r13,%r11,4), %ymm2
	vmovups	-384(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -480(%rax,%r11,4)
	vmovups	%ymm1, -448(%rax,%r11,4)
	vmovups	%ymm2, -416(%rax,%r11,4)
	vmovups	%ymm3, -384(%rax,%r11,4)
	vmovups	-352(%r13,%r11,4), %ymm0
	vmovups	-320(%r13,%r11,4), %ymm1
	vmovups	-288(%r13,%r11,4), %ymm2
	vmovups	-256(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -352(%rax,%r11,4)
	vmovups	%ymm1, -320(%rax,%r11,4)
	vmovups	%ymm2, -288(%rax,%r11,4)
	vmovups	%ymm3, -256(%rax,%r11,4)
	vmovups	-224(%r13,%r11,4), %ymm0
	vmovups	-192(%r13,%r11,4), %ymm1
	vmovups	-160(%r13,%r11,4), %ymm2
	vmovups	-128(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -224(%rax,%r11,4)
	vmovups	%ymm1, -192(%rax,%r11,4)
	vmovups	%ymm2, -160(%rax,%r11,4)
	vmovups	%ymm3, -128(%rax,%r11,4)
	vmovups	-96(%r13,%r11,4), %ymm0
	vmovups	-64(%r13,%r11,4), %ymm1
	vmovups	-32(%r13,%r11,4), %ymm2
	vmovups	(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -96(%rax,%r11,4)
	vmovups	%ymm1, -64(%rax,%r11,4)
	vmovups	%ymm2, -32(%rax,%r11,4)
	vmovups	%ymm3, (%rax,%r11,4)
	subq	$-128, %r11
	addq	$4, %r12
	jne	LBB11_13
LBB11_14:
	testq	%r15, %r15
	je	LBB11_17
## %bb.15:
	leaq	(%r11,%r8), %rax
	movq	_b@GOTPCREL(%rip), %rbx
	leaq	(%rbx,%rax,4), %r12
	addq	$96, %r12
	addq	%r9, %r11
	leaq	(%rdi,%r11,4), %rbx
	addq	$96, %rbx
	shlq	$7, %r15
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB11_16:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rbx,%rax), %ymm0
	vmovups	-64(%rbx,%rax), %ymm1
	vmovups	-32(%rbx,%rax), %ymm2
	vmovups	(%rbx,%rax), %ymm3
	vmovups	%ymm0, -96(%r12,%rax)
	vmovups	%ymm1, -64(%r12,%rax)
	vmovups	%ymm2, -32(%r12,%rax)
	vmovups	%ymm3, (%r12,%rax)
	subq	$-128, %rax
	cmpq	%rax, %r15
	jne	LBB11_16
LBB11_17:
	movq	-48(%rbp), %rax                 ## 8-byte Reload
	addq	%rax, %r8
	cmpq	%rax, %r10
	je	LBB11_26
## %bb.18:
	addq	%rax, %r9
LBB11_19:
	movl	%edx, %r10d
	subl	%r9d, %r10d
	leal	1(%r10), %ebx
	andl	$7, %ebx
	je	LBB11_22
## %bb.20:
	movq	_b@GOTPCREL(%rip), %r11
	.p2align	4, 0x90
LBB11_21:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r9,4), %eax
	incq	%r9
	movl	%eax, (%r11,%r8,4)
	incq	%r8
	decl	%ebx
	jne	LBB11_21
LBB11_22:
	cmpl	$7, %r10d
	jb	LBB11_26
## %bb.23:
	subl	%r9d, %edx
	incl	%edx
	leaq	(%rdi,%r9,4), %r9
	addq	$28, %r9
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r8,4), %r10
	addq	$28, %r10
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB11_24:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%r9,%rbx,4), %eax
	movl	%eax, -28(%r10,%rbx,4)
	movl	-24(%r9,%rbx,4), %eax
	movl	%eax, -24(%r10,%rbx,4)
	movl	-20(%r9,%rbx,4), %eax
	movl	%eax, -20(%r10,%rbx,4)
	movl	-16(%r9,%rbx,4), %eax
	movl	%eax, -16(%r10,%rbx,4)
	movl	-12(%r9,%rbx,4), %eax
	movl	%eax, -12(%r10,%rbx,4)
	movl	-8(%r9,%rbx,4), %eax
	movl	%eax, -8(%r10,%rbx,4)
	movl	-4(%r9,%rbx,4), %eax
	movl	%eax, -4(%r10,%rbx,4)
	movl	(%r9,%rbx,4), %eax
	movl	%eax, (%r10,%rbx,4)
	addq	$8, %rbx
	cmpl	%ebx, %edx
	jne	LBB11_24
## %bb.25:
	addq	%rbx, %r8
LBB11_26:
	cmpl	%ecx, %r14d
	jg	LBB11_45
## %bb.27:
	movslq	%r8d, %r8
	movslq	%r14d, %r12
	movl	%ecx, %r9d
	subl	%r14d, %r9d
	cmpl	$31, %r9d
	jb	LBB11_39
## %bb.28:
	movq	_b@GOTPCREL(%rip), %r10
	leaq	(%r10,%r8,4), %rax
	leaq	(%r12,%r9), %rdx
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	cmpq	%rdx, %rax
	jae	LBB11_30
## %bb.29:
	leaq	(%r8,%r9), %rax
	leaq	(%r10,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r12,4), %rdx
	cmpq	%rax, %rdx
	jb	LBB11_39
LBB11_30:
	incq	%r9
	movq	%r9, %r11
	andq	$-32, %r11
	leaq	-32(%r11), %rax
	movq	%rax, %r15
	shrq	$5, %r15
	incq	%r15
	movl	%r15d, %r14d
	andl	$3, %r14d
	cmpq	$96, %rax
	jae	LBB11_32
## %bb.31:
	xorl	%eax, %eax
	jmp	LBB11_34
LBB11_32:
	leaq	(%rdi,%r12,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r10,%r8,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	andq	$-4, %r15
	negq	%r15
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB11_33:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rax,4), %ymm0
	vmovups	-448(%rbx,%rax,4), %ymm1
	vmovups	-416(%rbx,%rax,4), %ymm2
	vmovups	-384(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rax,4)
	vmovups	%ymm1, -448(%rdx,%rax,4)
	vmovups	%ymm2, -416(%rdx,%rax,4)
	vmovups	%ymm3, -384(%rdx,%rax,4)
	vmovups	-352(%rbx,%rax,4), %ymm0
	vmovups	-320(%rbx,%rax,4), %ymm1
	vmovups	-288(%rbx,%rax,4), %ymm2
	vmovups	-256(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rax,4)
	vmovups	%ymm1, -320(%rdx,%rax,4)
	vmovups	%ymm2, -288(%rdx,%rax,4)
	vmovups	%ymm3, -256(%rdx,%rax,4)
	vmovups	-224(%rbx,%rax,4), %ymm0
	vmovups	-192(%rbx,%rax,4), %ymm1
	vmovups	-160(%rbx,%rax,4), %ymm2
	vmovups	-128(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rax,4)
	vmovups	%ymm1, -192(%rdx,%rax,4)
	vmovups	%ymm2, -160(%rdx,%rax,4)
	vmovups	%ymm3, -128(%rdx,%rax,4)
	vmovups	-96(%rbx,%rax,4), %ymm0
	vmovups	-64(%rbx,%rax,4), %ymm1
	vmovups	-32(%rbx,%rax,4), %ymm2
	vmovups	(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rax,4)
	vmovups	%ymm1, -64(%rdx,%rax,4)
	vmovups	%ymm2, -32(%rdx,%rax,4)
	vmovups	%ymm3, (%rdx,%rax,4)
	subq	$-128, %rax
	addq	$4, %r15
	jne	LBB11_33
LBB11_34:
	testq	%r14, %r14
	je	LBB11_37
## %bb.35:
	leaq	(%rax,%r8), %rdx
	leaq	(%r10,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%r12, %rax
	leaq	(%rdi,%rax,4), %rax
	addq	$96, %rax
	shlq	$7, %r14
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB11_36:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rax,%rbx), %ymm0
	vmovups	-64(%rax,%rbx), %ymm1
	vmovups	-32(%rax,%rbx), %ymm2
	vmovups	(%rax,%rbx), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx)
	vmovups	%ymm1, -64(%rdx,%rbx)
	vmovups	%ymm2, -32(%rdx,%rbx)
	vmovups	%ymm3, (%rdx,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r14
	jne	LBB11_36
LBB11_37:
	cmpq	%r11, %r9
	je	LBB11_45
## %bb.38:
	addq	%r11, %r12
	addq	%r11, %r8
LBB11_39:
	movl	%ecx, %r9d
	subl	%r12d, %r9d
	leal	1(%r9), %edx
	andl	$7, %edx
	je	LBB11_42
## %bb.40:
	movq	_b@GOTPCREL(%rip), %rbx
	.p2align	4, 0x90
LBB11_41:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r12,4), %eax
	incq	%r12
	movl	%eax, (%rbx,%r8,4)
	incq	%r8
	decl	%edx
	jne	LBB11_41
LBB11_42:
	cmpl	$7, %r9d
	jb	LBB11_45
## %bb.43:
	movl	%ecx, %r9d
	subl	%r12d, %r9d
	incl	%r9d
	leaq	(%rdi,%r12,4), %r10
	addq	$28, %r10
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r8,4), %rbx
	addq	$28, %rbx
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB11_44:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%r10,%rax,4), %edx
	movl	%edx, -28(%rbx,%rax,4)
	movl	-24(%r10,%rax,4), %edx
	movl	%edx, -24(%rbx,%rax,4)
	movl	-20(%r10,%rax,4), %edx
	movl	%edx, -20(%rbx,%rax,4)
	movl	-16(%r10,%rax,4), %edx
	movl	%edx, -16(%rbx,%rax,4)
	movl	-12(%r10,%rax,4), %edx
	movl	%edx, -12(%rbx,%rax,4)
	movl	-8(%r10,%rax,4), %edx
	movl	%edx, -8(%rbx,%rax,4)
	movl	-4(%r10,%rax,4), %edx
	movl	%edx, -4(%rbx,%rax,4)
	movl	(%r10,%rax,4), %edx
	movl	%edx, (%rbx,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %r9d
	jne	LBB11_44
LBB11_45:
	movl	%ecx, %r10d
	subl	%esi, %r10d
	jl	LBB11_64
## %bb.46:
	movslq	%esi, %rax
	cmpl	$31, %r10d
	jb	LBB11_58
## %bb.47:
	leaq	(%rdi,%rax,4), %rbx
	leaq	(%r10,%rax), %rdx
	movq	_b@GOTPCREL(%rip), %r8
	leaq	(%r8,%rdx,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rbx
	jae	LBB11_49
## %bb.48:
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r8,%rax,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB11_58
LBB11_49:
	incq	%r10
	movq	%r10, %r8
	andq	$-32, %r8
	leaq	-32(%r8), %rdx
	movq	%rdx, %r11
	shrq	$5, %r11
	incq	%r11
	movl	%r11d, %r9d
	andl	$3, %r9d
	cmpq	$96, %rdx
	jae	LBB11_51
## %bb.50:
	xorl	%ebx, %ebx
	jmp	LBB11_53
LBB11_51:
	leaq	(%rdi,%rax,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	480(,%rax,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	andq	$-4, %r11
	negq	%r11
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB11_52:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rsi,%rbx,4), %ymm0
	vmovups	-448(%rsi,%rbx,4), %ymm1
	vmovups	-416(%rsi,%rbx,4), %ymm2
	vmovups	-384(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rbx,4)
	vmovups	%ymm1, -448(%rdx,%rbx,4)
	vmovups	%ymm2, -416(%rdx,%rbx,4)
	vmovups	%ymm3, -384(%rdx,%rbx,4)
	vmovups	-352(%rsi,%rbx,4), %ymm0
	vmovups	-320(%rsi,%rbx,4), %ymm1
	vmovups	-288(%rsi,%rbx,4), %ymm2
	vmovups	-256(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rbx,4)
	vmovups	%ymm1, -320(%rdx,%rbx,4)
	vmovups	%ymm2, -288(%rdx,%rbx,4)
	vmovups	%ymm3, -256(%rdx,%rbx,4)
	vmovups	-224(%rsi,%rbx,4), %ymm0
	vmovups	-192(%rsi,%rbx,4), %ymm1
	vmovups	-160(%rsi,%rbx,4), %ymm2
	vmovups	-128(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rbx,4)
	vmovups	%ymm1, -192(%rdx,%rbx,4)
	vmovups	%ymm2, -160(%rdx,%rbx,4)
	vmovups	%ymm3, -128(%rdx,%rbx,4)
	vmovups	-96(%rsi,%rbx,4), %ymm0
	vmovups	-64(%rsi,%rbx,4), %ymm1
	vmovups	-32(%rsi,%rbx,4), %ymm2
	vmovups	(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx,4)
	vmovups	%ymm1, -64(%rdx,%rbx,4)
	vmovups	%ymm2, -32(%rdx,%rbx,4)
	vmovups	%ymm3, (%rdx,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %r11
	jne	LBB11_52
LBB11_53:
	testq	%r9, %r9
	je	LBB11_56
## %bb.54:
	addq	%rax, %rbx
	leaq	(%rdi,%rbx,4), %rdx
	addq	$96, %rdx
	leaq	96(,%rbx,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	shlq	$7, %r9
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB11_55:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rbx), %ymm0
	vmovups	-64(%rsi,%rbx), %ymm1
	vmovups	-32(%rsi,%rbx), %ymm2
	vmovups	(%rsi,%rbx), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx)
	vmovups	%ymm1, -64(%rdx,%rbx)
	vmovups	%ymm2, -32(%rdx,%rbx)
	vmovups	%ymm3, (%rdx,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r9
	jne	LBB11_55
LBB11_56:
	cmpq	%r8, %r10
	je	LBB11_64
## %bb.57:
	addq	%r8, %rax
LBB11_58:
	leal	1(%rcx), %r8d
	movl	%r8d, %esi
	subl	%eax, %esi
	subl	%eax, %ecx
	andl	$7, %esi
	je	LBB11_61
## %bb.59:
	movq	_b@GOTPCREL(%rip), %rbx
	.p2align	4, 0x90
LBB11_60:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rbx,%rax,4), %edx
	movl	%edx, (%rdi,%rax,4)
	incq	%rax
	decl	%esi
	jne	LBB11_60
LBB11_61:
	cmpl	$7, %ecx
	jb	LBB11_64
## %bb.62:
	movl	%r8d, %ecx
	movq	_b@GOTPCREL(%rip), %rdx
	.p2align	4, 0x90
LBB11_63:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdx,%rax,4), %esi
	movl	%esi, (%rdi,%rax,4)
	movl	4(%rdx,%rax,4), %esi
	movl	%esi, 4(%rdi,%rax,4)
	movl	8(%rdx,%rax,4), %esi
	movl	%esi, 8(%rdi,%rax,4)
	movl	12(%rdx,%rax,4), %esi
	movl	%esi, 12(%rdi,%rax,4)
	movl	16(%rdx,%rax,4), %esi
	movl	%esi, 16(%rdi,%rax,4)
	movl	20(%rdx,%rax,4), %esi
	movl	%esi, 20(%rdi,%rax,4)
	movl	24(%rdx,%rax,4), %esi
	movl	%esi, 24(%rdi,%rax,4)
	movl	28(%rdx,%rax,4), %esi
	movl	%esi, 28(%rdi,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %ecx
	jne	LBB11_63
LBB11_64:
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_merge_standard            ## -- Begin function sort_merge_standard
	.p2align	4, 0x90
_sort_merge_standard:                   ## @sort_merge_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	%esi, %edx
	jle	LBB12_70
## %bb.1:
	movl	%edx, %r15d
	movl	%esi, %ebx
	movq	%rdi, %r12
	leal	(%r15,%rbx), %eax
	movl	%eax, %r13d
	shrl	$31, %r13d
	addl	%eax, %r13d
	sarl	%r13d
	movl	%r13d, %edx
	callq	_sort_merge_standard
	leal	1(%r13), %r14d
	movq	%r12, %rdi
	movl	%r14d, %esi
	movl	%r15d, %edx
	callq	_sort_merge_standard
	cmpl	%ebx, %r13d
	movq	%rbx, -48(%rbp)                 ## 8-byte Spill
	jl	LBB12_7
## %bb.2:
	cmpl	%r15d, %r13d
	movq	%r15, %r10
	jge	LBB12_6
## %bb.3:
	movslq	%ebx, %rdx
	shlq	$2, %rdx
	addq	_b@GOTPCREL(%rip), %rdx
	movl	%ebx, %r15d
	movl	%ebx, %ecx
	.p2align	4, 0x90
LBB12_4:                                ## =>This Inner Loop Header: Depth=1
	movslq	%ecx, %rcx
	movl	(%r12,%rcx,4), %esi
	movslq	%r14d, %r14
	movl	(%r12,%r14,4), %edi
	xorl	%eax, %eax
	xorl	%ebx, %ebx
	cmpl	%edi, %esi
	setg	%al
	setle	%bl
	cmovgl	%edi, %esi
	addl	%ebx, %ecx
	addl	%eax, %r14d
	movl	%esi, (%rdx)
	incl	%r15d
	cmpl	%r13d, %ecx
	jg	LBB12_9
## %bb.5:                               ##   in Loop: Header=BB12_4 Depth=1
	addq	$4, %rdx
	cmpl	%r10d, %r14d
	jle	LBB12_4
	jmp	LBB12_9
LBB12_6:
	movl	%ebx, %ecx
	jmp	LBB12_8
LBB12_7:
	movl	%ebx, %ecx
	movq	%r15, %r10
LBB12_8:
	movl	%ebx, %r15d
LBB12_9:
	movl	%r13d, %r11d
	subl	%ecx, %r11d
	jl	LBB12_30
## %bb.10:
	movslq	%r15d, %r15
	movslq	%ecx, %rcx
	cmpl	$31, %r11d
	jb	LBB12_23
## %bb.11:
	movq	_b@GOTPCREL(%rip), %rbx
	leaq	(%rbx,%r15,4), %rdx
	leaq	(%rcx,%r11), %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rdx
	jae	LBB12_13
## %bb.12:
	leaq	(%r15,%r11), %rdx
	leaq	(%rbx,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r12,%rcx,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB12_23
LBB12_13:
	movq	%r10, %rax
	incq	%r11
	movq	%r11, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rdi
	shrq	$5, %rdi
	incq	%rdi
	movl	%edi, %r10d
	andl	$3, %r10d
	cmpq	$96, %rdx
	jae	LBB12_15
## %bb.14:
	xorl	%esi, %esi
	jmp	LBB12_17
LBB12_15:
	leaq	(%r12,%rcx,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	(%rbx,%r15,4), %r8
	addq	$480, %r8                       ## imm = 0x1E0
	andq	$-4, %rdi
	negq	%rdi
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB12_16:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdx,%rsi,4), %ymm0
	vmovups	-448(%rdx,%rsi,4), %ymm1
	vmovups	-416(%rdx,%rsi,4), %ymm2
	vmovups	-384(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%r8,%rsi,4)
	vmovups	%ymm1, -448(%r8,%rsi,4)
	vmovups	%ymm2, -416(%r8,%rsi,4)
	vmovups	%ymm3, -384(%r8,%rsi,4)
	vmovups	-352(%rdx,%rsi,4), %ymm0
	vmovups	-320(%rdx,%rsi,4), %ymm1
	vmovups	-288(%rdx,%rsi,4), %ymm2
	vmovups	-256(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%r8,%rsi,4)
	vmovups	%ymm1, -320(%r8,%rsi,4)
	vmovups	%ymm2, -288(%r8,%rsi,4)
	vmovups	%ymm3, -256(%r8,%rsi,4)
	vmovups	-224(%rdx,%rsi,4), %ymm0
	vmovups	-192(%rdx,%rsi,4), %ymm1
	vmovups	-160(%rdx,%rsi,4), %ymm2
	vmovups	-128(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%r8,%rsi,4)
	vmovups	%ymm1, -192(%r8,%rsi,4)
	vmovups	%ymm2, -160(%r8,%rsi,4)
	vmovups	%ymm3, -128(%r8,%rsi,4)
	vmovups	-96(%rdx,%rsi,4), %ymm0
	vmovups	-64(%rdx,%rsi,4), %ymm1
	vmovups	-32(%rdx,%rsi,4), %ymm2
	vmovups	(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%r8,%rsi,4)
	vmovups	%ymm1, -64(%r8,%rsi,4)
	vmovups	%ymm2, -32(%r8,%rsi,4)
	vmovups	%ymm3, (%r8,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %rdi
	jne	LBB12_16
LBB12_17:
	testq	%r10, %r10
	je	LBB12_20
## %bb.18:
	leaq	(%rsi,%r15), %rdx
	leaq	(%rbx,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%rcx, %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r10
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB12_19:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r10
	jne	LBB12_19
LBB12_20:
	addq	%r9, %r15
	cmpq	%r9, %r11
	jne	LBB12_22
## %bb.21:
	movq	%rax, %r10
	jmp	LBB12_30
LBB12_22:
	addq	%r9, %rcx
	movq	%rax, %r10
LBB12_23:
	movl	%r13d, %r8d
	subl	%ecx, %r8d
	leal	1(%r8), %esi
	andl	$7, %esi
	je	LBB12_26
## %bb.24:
	movq	_b@GOTPCREL(%rip), %rdi
	.p2align	4, 0x90
LBB12_25:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r12,%rcx,4), %edx
	incq	%rcx
	movl	%edx, (%rdi,%r15,4)
	incq	%r15
	decl	%esi
	jne	LBB12_25
LBB12_26:
	cmpl	$7, %r8d
	jb	LBB12_30
## %bb.27:
	subl	%ecx, %r13d
	incl	%r13d
	leaq	(%r12,%rcx,4), %rcx
	addq	$28, %rcx
	movq	_b@GOTPCREL(%rip), %rdx
	leaq	(%rdx,%r15,4), %rsi
	addq	$28, %rsi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB12_28:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rcx,%rdx,4), %eax
	movl	%eax, -28(%rsi,%rdx,4)
	movl	-24(%rcx,%rdx,4), %eax
	movl	%eax, -24(%rsi,%rdx,4)
	movl	-20(%rcx,%rdx,4), %eax
	movl	%eax, -20(%rsi,%rdx,4)
	movl	-16(%rcx,%rdx,4), %eax
	movl	%eax, -16(%rsi,%rdx,4)
	movl	-12(%rcx,%rdx,4), %eax
	movl	%eax, -12(%rsi,%rdx,4)
	movl	-8(%rcx,%rdx,4), %eax
	movl	%eax, -8(%rsi,%rdx,4)
	movl	-4(%rcx,%rdx,4), %eax
	movl	%eax, -4(%rsi,%rdx,4)
	movl	(%rcx,%rdx,4), %eax
	movl	%eax, (%rsi,%rdx,4)
	addq	$8, %rdx
	cmpl	%edx, %r13d
	jne	LBB12_28
## %bb.29:
	addq	%rdx, %r15
LBB12_30:
	cmpl	%r10d, %r14d
	jg	LBB12_51
## %bb.31:
	movslq	%r15d, %rax
	movslq	%r14d, %rcx
	movq	%r10, %r15
                                        ## kill: def $r10d killed $r10d killed $r10 def $r10
	subl	%r14d, %r10d
	cmpl	$31, %r10d
	jb	LBB12_32
## %bb.33:
	movq	_b@GOTPCREL(%rip), %r8
	leaq	(%r8,%rax,4), %rdx
	leaq	(%rcx,%r10), %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rdx
	jae	LBB12_36
## %bb.34:
	leaq	(%rax,%r10), %rdx
	leaq	(%r8,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r12,%rcx,4), %rsi
	cmpq	%rdx, %rsi
	jae	LBB12_36
LBB12_32:
	movq	%r15, %r10
LBB12_45:
	movl	%r10d, %edx
	subl	%ecx, %edx
	leal	1(%rdx), %esi
	andl	$7, %esi
	je	LBB12_48
## %bb.46:
	movq	_b@GOTPCREL(%rip), %rdi
	.p2align	4, 0x90
LBB12_47:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r12,%rcx,4), %ebx
	incq	%rcx
	movl	%ebx, (%rdi,%rax,4)
	incq	%rax
	decl	%esi
	jne	LBB12_47
LBB12_48:
	cmpl	$7, %edx
	jb	LBB12_51
## %bb.49:
	movl	%r10d, %edx
	subl	%ecx, %edx
	incl	%edx
	leaq	(%r12,%rcx,4), %rcx
	addq	$28, %rcx
	movq	_b@GOTPCREL(%rip), %rsi
	leaq	(%rsi,%rax,4), %rax
	addq	$28, %rax
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB12_50:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rcx,%rsi,4), %edi
	movl	%edi, -28(%rax,%rsi,4)
	movl	-24(%rcx,%rsi,4), %edi
	movl	%edi, -24(%rax,%rsi,4)
	movl	-20(%rcx,%rsi,4), %edi
	movl	%edi, -20(%rax,%rsi,4)
	movl	-16(%rcx,%rsi,4), %edi
	movl	%edi, -16(%rax,%rsi,4)
	movl	-12(%rcx,%rsi,4), %edi
	movl	%edi, -12(%rax,%rsi,4)
	movl	-8(%rcx,%rsi,4), %edi
	movl	%edi, -8(%rax,%rsi,4)
	movl	-4(%rcx,%rsi,4), %edi
	movl	%edi, -4(%rax,%rsi,4)
	movl	(%rcx,%rsi,4), %edi
	movl	%edi, (%rax,%rsi,4)
	addq	$8, %rsi
	cmpl	%esi, %edx
	jne	LBB12_50
	jmp	LBB12_51
LBB12_36:
	incq	%r10
	movq	%r10, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rbx
	shrq	$5, %rbx
	incq	%rbx
	movl	%ebx, %r11d
	andl	$3, %r11d
	cmpq	$96, %rdx
	jae	LBB12_38
## %bb.37:
	xorl	%esi, %esi
	jmp	LBB12_40
LBB12_38:
	leaq	(%r12,%rcx,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	(%r8,%rax,4), %rdi
	addq	$480, %rdi                      ## imm = 0x1E0
	andq	$-4, %rbx
	negq	%rbx
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB12_39:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdx,%rsi,4), %ymm0
	vmovups	-448(%rdx,%rsi,4), %ymm1
	vmovups	-416(%rdx,%rsi,4), %ymm2
	vmovups	-384(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%rdi,%rsi,4)
	vmovups	%ymm1, -448(%rdi,%rsi,4)
	vmovups	%ymm2, -416(%rdi,%rsi,4)
	vmovups	%ymm3, -384(%rdi,%rsi,4)
	vmovups	-352(%rdx,%rsi,4), %ymm0
	vmovups	-320(%rdx,%rsi,4), %ymm1
	vmovups	-288(%rdx,%rsi,4), %ymm2
	vmovups	-256(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%rdi,%rsi,4)
	vmovups	%ymm1, -320(%rdi,%rsi,4)
	vmovups	%ymm2, -288(%rdi,%rsi,4)
	vmovups	%ymm3, -256(%rdi,%rsi,4)
	vmovups	-224(%rdx,%rsi,4), %ymm0
	vmovups	-192(%rdx,%rsi,4), %ymm1
	vmovups	-160(%rdx,%rsi,4), %ymm2
	vmovups	-128(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%rdi,%rsi,4)
	vmovups	%ymm1, -192(%rdi,%rsi,4)
	vmovups	%ymm2, -160(%rdi,%rsi,4)
	vmovups	%ymm3, -128(%rdi,%rsi,4)
	vmovups	-96(%rdx,%rsi,4), %ymm0
	vmovups	-64(%rdx,%rsi,4), %ymm1
	vmovups	-32(%rdx,%rsi,4), %ymm2
	vmovups	(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%rdi,%rsi,4)
	vmovups	%ymm1, -64(%rdi,%rsi,4)
	vmovups	%ymm2, -32(%rdi,%rsi,4)
	vmovups	%ymm3, (%rdi,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %rbx
	jne	LBB12_39
LBB12_40:
	testq	%r11, %r11
	je	LBB12_43
## %bb.41:
	leaq	(%rsi,%rax), %rdx
	leaq	(%r8,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%rcx, %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r11
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB12_42:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r11
	jne	LBB12_42
LBB12_43:
	cmpq	%r9, %r10
	movq	%r15, %r10
	jne	LBB12_44
LBB12_51:
	movl	%r10d, %ecx
	movq	-48(%rbp), %rax                 ## 8-byte Reload
	subl	%eax, %ecx
	jl	LBB12_70
## %bb.52:
	cltq
	cmpl	$31, %ecx
	jb	LBB12_64
## %bb.53:
	leaq	(%r12,%rax,4), %rdi
	leaq	(%rcx,%rax), %rdx
	movq	_b@GOTPCREL(%rip), %rsi
	leaq	(%rsi,%rdx,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rdi
	jae	LBB12_55
## %bb.54:
	leaq	(%r12,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%rsi,%rax,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB12_64
LBB12_55:
	incq	%rcx
	movq	%rcx, %r8
	andq	$-32, %r8
	leaq	-32(%r8), %rdx
	movq	%rdx, %rdi
	shrq	$5, %rdi
	incq	%rdi
	movl	%edi, %r9d
	andl	$3, %r9d
	cmpq	$96, %rdx
	jae	LBB12_57
## %bb.56:
	xorl	%ebx, %ebx
	jmp	LBB12_59
LBB12_44:
	addq	%r9, %rcx
	addq	%r9, %rax
	jmp	LBB12_45
LBB12_57:
	leaq	(%r12,%rax,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	480(,%rax,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	andq	$-4, %rdi
	negq	%rdi
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB12_58:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rsi,%rbx,4), %ymm0
	vmovups	-448(%rsi,%rbx,4), %ymm1
	vmovups	-416(%rsi,%rbx,4), %ymm2
	vmovups	-384(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rbx,4)
	vmovups	%ymm1, -448(%rdx,%rbx,4)
	vmovups	%ymm2, -416(%rdx,%rbx,4)
	vmovups	%ymm3, -384(%rdx,%rbx,4)
	vmovups	-352(%rsi,%rbx,4), %ymm0
	vmovups	-320(%rsi,%rbx,4), %ymm1
	vmovups	-288(%rsi,%rbx,4), %ymm2
	vmovups	-256(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rbx,4)
	vmovups	%ymm1, -320(%rdx,%rbx,4)
	vmovups	%ymm2, -288(%rdx,%rbx,4)
	vmovups	%ymm3, -256(%rdx,%rbx,4)
	vmovups	-224(%rsi,%rbx,4), %ymm0
	vmovups	-192(%rsi,%rbx,4), %ymm1
	vmovups	-160(%rsi,%rbx,4), %ymm2
	vmovups	-128(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rbx,4)
	vmovups	%ymm1, -192(%rdx,%rbx,4)
	vmovups	%ymm2, -160(%rdx,%rbx,4)
	vmovups	%ymm3, -128(%rdx,%rbx,4)
	vmovups	-96(%rsi,%rbx,4), %ymm0
	vmovups	-64(%rsi,%rbx,4), %ymm1
	vmovups	-32(%rsi,%rbx,4), %ymm2
	vmovups	(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx,4)
	vmovups	%ymm1, -64(%rdx,%rbx,4)
	vmovups	%ymm2, -32(%rdx,%rbx,4)
	vmovups	%ymm3, (%rdx,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %rdi
	jne	LBB12_58
LBB12_59:
	testq	%r9, %r9
	je	LBB12_62
## %bb.60:
	addq	%rax, %rbx
	leaq	(%r12,%rbx,4), %rdx
	addq	$96, %rdx
	leaq	96(,%rbx,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	shlq	$7, %r9
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB12_61:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r9
	jne	LBB12_61
LBB12_62:
	cmpq	%r8, %rcx
	je	LBB12_70
## %bb.63:
	addq	%r8, %rax
LBB12_64:
	leal	1(%r10), %ecx
	movl	%ecx, %edx
	subl	%eax, %edx
	subl	%eax, %r10d
	andl	$7, %edx
	je	LBB12_67
## %bb.65:
	movq	_b@GOTPCREL(%rip), %rsi
	.p2align	4, 0x90
LBB12_66:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rsi,%rax,4), %edi
	movl	%edi, (%r12,%rax,4)
	incq	%rax
	decl	%edx
	jne	LBB12_66
LBB12_67:
	cmpl	$7, %r10d
	jb	LBB12_70
## %bb.68:
	movl	%ecx, %ecx
	movq	_b@GOTPCREL(%rip), %rdx
	.p2align	4, 0x90
LBB12_69:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdx,%rax,4), %esi
	movl	%esi, (%r12,%rax,4)
	movl	4(%rdx,%rax,4), %esi
	movl	%esi, 4(%r12,%rax,4)
	movl	8(%rdx,%rax,4), %esi
	movl	%esi, 8(%r12,%rax,4)
	movl	12(%rdx,%rax,4), %esi
	movl	%esi, 12(%r12,%rax,4)
	movl	16(%rdx,%rax,4), %esi
	movl	%esi, 16(%r12,%rax,4)
	movl	20(%rdx,%rax,4), %esi
	movl	%esi, 20(%r12,%rax,4)
	movl	24(%rdx,%rax,4), %esi
	movl	%esi, 24(%r12,%rax,4)
	movl	28(%rdx,%rax,4), %esi
	movl	%esi, 28(%r12,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %ecx
	jne	LBB12_69
LBB12_70:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_max                            ## -- Begin function max
	.p2align	4, 0x90
_max:                                   ## @max
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	%esi, %eax
	cmpl	%esi, %edi
	cmovgl	%edi, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_optimized      ## -- Begin function partition_quick_optimized
	.p2align	4, 0x90
_partition_quick_optimized:             ## @partition_quick_optimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB14_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%rdi,%r8,4), %r9d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r15d
	movslq	%edx, %r11
	movl	(%rdi,%r11,4), %r14d
	cmpl	%r15d, %r9d
	movl	%r15d, %ebx
	cmovll	%r9d, %ebx
	movl	%r15d, %ecx
	cmovgl	%r9d, %ecx
	cmpl	%r14d, %ebx
	cmovgel	%r14d, %ebx
	cmpl	%r14d, %ecx
	cmovlel	%r14d, %ecx
	addl	%r9d, %r15d
	addl	%r14d, %r15d
	subl	%ebx, %r15d
	subl	%ecx, %r15d
	movl	%ebx, (%rdi,%r8,4)
	movl	%r15d, (%rdi,%r11,4)
	movl	%ecx, (%rdi,%r10,4)
	movl	%edx, %r9d
	subl	%esi, %r9d
	jg	LBB14_5
LBB14_4:
	movslq	%edx, %r14
	jmp	LBB14_10
LBB14_2:
	movslq	%edx, %rax
	movl	(%rdi,%rax,4), %r15d
	movl	%edx, %r9d
	subl	%esi, %r9d
	jle	LBB14_4
LBB14_5:
	movslq	%esi, %rcx
	movslq	%edx, %r14
	movq	%rcx, %r8
	notq	%r8
	testb	$1, %r9b
	jne	LBB14_7
## %bb.6:
                                        ## implicit-def: $r9d
	addq	%r14, %r8
	jne	LBB14_11
	jmp	LBB14_9
LBB14_7:
	movl	(%rdi,%rcx,4), %r11d
	xorl	%r9d, %r9d
	cmpl	%r11d, %r15d
	setg	%r9b
	movl	(%rdi,%rcx,4), %r10d
	movl	%r10d, %ebx
	cmovgl	%r11d, %ebx
	movl	%ebx, (%rdi,%rcx,4)
	cmovgl	%r10d, %r11d
	movl	%r11d, (%rdi,%rcx,4)
	addl	%esi, %r9d
	incq	%rcx
	movl	%r9d, %esi
	addq	%r14, %r8
	jne	LBB14_11
LBB14_9:
	movl	%r9d, %esi
	jmp	LBB14_10
	.p2align	4, 0x90
LBB14_11:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rcx,4), %ebx
	xorl	%r8d, %r8d
	cmpl	%ebx, %r15d
	setg	%r8b
	movslq	%esi, %rsi
	movl	(%rdi,%rsi,4), %edx
	movl	%edx, %eax
	cmovgl	%ebx, %eax
	movl	%eax, (%rdi,%rsi,4)
	cmovgl	%edx, %ebx
	movl	%ebx, (%rdi,%rcx,4)
	addl	%r8d, %esi
	movl	4(%rdi,%rcx,4), %eax
	xorl	%r8d, %r8d
	cmpl	%eax, %r15d
	setg	%r8b
	movslq	%esi, %rsi
	movl	(%rdi,%rsi,4), %edx
	movl	%edx, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%edx, %eax
	movl	%eax, 4(%rdi,%rcx,4)
	addl	%r8d, %esi
	addq	$2, %rcx
	cmpq	%rcx, %r14
	jne	LBB14_11
LBB14_10:
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r14,4), %esi
	movl	%esi, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r14,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_optimized           ## -- Begin function sort_quick_optimized
	.p2align	4, 0x90
_sort_quick_optimized:                  ## @sort_quick_optimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB15_11
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %r12
	movslq	%edx, %r15
	movq	%r15, %rax
	negq	%rax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	jmp	LBB15_2
	.p2align	4, 0x90
LBB15_10:                               ##   in Loop: Header=BB15_2 Depth=1
	movslq	%edi, %rbx
	movl	(%r12,%rbx,4), %eax
	movl	(%r12,%r15,4), %ecx
	movl	%ecx, (%r12,%rbx,4)
	movl	%eax, (%r12,%r15,4)
	leal	-1(%rbx), %edx
	movq	%r12, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	callq	_sort_quick_optimized
	incl	%ebx
	movl	%ebx, %esi
	cmpl	%r14d, %ebx
	jge	LBB15_11
LBB15_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB15_9 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB15_11
## %bb.3:                               ##   in Loop: Header=BB15_2 Depth=1
	cmpl	$1, %eax
	jne	LBB15_4
## %bb.5:                               ##   in Loop: Header=BB15_2 Depth=1
	movl	(%r12,%r15,4), %r13d
	movslq	%esi, %r11
	jmp	LBB15_6
	.p2align	4, 0x90
LBB15_4:                                ##   in Loop: Header=BB15_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %edx
	shrl	$31, %edx
	addl	%eax, %edx
	sarl	%edx
	movslq	%esi, %r11
	movl	(%r12,%r11,4), %r9d
	movslq	%edx, %r8
	movl	(%r12,%r8,4), %r13d
	movl	(%r12,%r15,4), %r10d
	cmpl	%r13d, %r9d
	movl	%r13d, %edi
	cmovll	%r9d, %edi
	movl	%r13d, %edx
	cmovgl	%r9d, %edx
	cmpl	%r10d, %edi
	cmovgel	%r10d, %edi
	cmpl	%r10d, %edx
	cmovlel	%r10d, %edx
	addl	%r9d, %r13d
	addl	%r10d, %r13d
	subl	%edi, %r13d
	subl	%edx, %r13d
	movl	%edi, (%r12,%r11,4)
	movl	%r13d, (%r12,%r15,4)
	movl	%edx, (%r12,%r8,4)
LBB15_6:                                ##   in Loop: Header=BB15_2 Depth=1
	movl	%r14d, %ecx
	subl	%r11d, %ecx
	movq	%r11, %rdx
	movl	%esi, %edi
	testb	$1, %cl
	je	LBB15_8
## %bb.7:                               ##   in Loop: Header=BB15_2 Depth=1
	movl	(%r12,%r11,4), %ecx
	xorl	%edi, %edi
	cmpl	%ecx, %r13d
	setg	%dil
	movslq	%esi, %r9
	movl	(%r12,%r9,4), %r8d
	movl	%r8d, %edx
	cmovgl	%ecx, %edx
	movl	%edx, (%r12,%r9,4)
	cmovgl	%r8d, %ecx
	movl	%ecx, (%r12,%r11,4)
	addl	%esi, %edi
	leaq	1(%r11), %rdx
LBB15_8:                                ##   in Loop: Header=BB15_2 Depth=1
	notq	%r11
	cmpq	-48(%rbp), %r11                 ## 8-byte Folded Reload
	je	LBB15_10
	.p2align	4, 0x90
LBB15_9:                                ##   Parent Loop BB15_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r12,%rdx,4), %ecx
	xorl	%r8d, %r8d
	cmpl	%ecx, %r13d
	setg	%r8b
	movslq	%edi, %rdi
	movl	(%r12,%rdi,4), %eax
	movl	%eax, %ebx
	cmovgl	%ecx, %ebx
	movl	%ebx, (%r12,%rdi,4)
	cmovgl	%eax, %ecx
	movl	%ecx, (%r12,%rdx,4)
	addl	%r8d, %edi
	movl	4(%r12,%rdx,4), %eax
	xorl	%r8d, %r8d
	cmpl	%eax, %r13d
	setg	%r8b
	movslq	%edi, %rdi
	movl	(%r12,%rdi,4), %ecx
	movl	%ecx, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%r12,%rdi,4)
	cmovgl	%ecx, %eax
	movl	%eax, 4(%r12,%rdx,4)
	addl	%r8d, %edi
	addq	$2, %rdx
	cmpq	%rdx, %r15
	jne	LBB15_9
	jmp	LBB15_10
LBB15_11:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_hsum_epi32_avx                 ## -- Begin function hsum_epi32_avx
	.p2align	4, 0x90
_hsum_epi32_avx:                        ## @hsum_epi32_avx
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	vpshufd	$238, %xmm0, %xmm1              ## xmm1 = xmm0[2,3,2,3]
	vpaddd	%xmm0, %xmm1, %xmm0
	vpshufd	$85, %xmm0, %xmm1               ## xmm1 = xmm0[1,1,1,1]
	vpaddd	%xmm0, %xmm1, %xmm0
	vmovd	%xmm0, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_hsum_8x32                      ## -- Begin function hsum_8x32
	.p2align	4, 0x90
_hsum_8x32:                             ## @hsum_8x32
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	vextracti128	$1, %ymm0, %xmm1
	vpaddd	%xmm0, %xmm1, %xmm0
	vpshufd	$238, %xmm0, %xmm1              ## xmm1 = xmm0[2,3,2,3]
	vpaddd	%xmm1, %xmm0, %xmm0
	vpshufd	$85, %xmm0, %xmm1               ## xmm1 = xmm0[1,1,1,1]
	vpaddd	%xmm0, %xmm1, %xmm0
	vmovd	%xmm0, %eax
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_multi          ## -- Begin function partition_quick_multi
	.p2align	4, 0x90
_partition_quick_multi:                 ## @partition_quick_multi
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%rbx
	.cfi_offset %rbx, -24
	movl	%edx, %r8d
	movslq	%esi, %rax
	subl	%esi, %r8d
	jle	LBB18_1
## %bb.7:
	vmovdqu	(%rdi,%rax,4), %ymm0
	movslq	%edx, %r10
	vmovd	%xmm0, %r11d
	leaq	1(%rax), %rsi
	movq	_tmp@GOTPCREL(%rip), %r9
	.p2align	4, 0x90
LBB18_8:                                ## =>This Inner Loop Header: Depth=1
	vmovd	%r11d, %xmm1
	vpbroadcastd	%xmm1, %ymm1
	vpcmpgtd	%ymm1, %ymm0, %ymm1
	vextracti128	$1, %ymm1, %xmm2
	vpaddd	%xmm1, %xmm2, %xmm1
	vpshufd	$238, %xmm1, %xmm2              ## xmm2 = xmm1[2,3,2,3]
	vpaddd	%xmm2, %xmm1, %xmm1
	vpshufd	$85, %xmm1, %xmm2               ## xmm2 = xmm1[1,1,1,1]
	vpaddd	%xmm1, %xmm2, %xmm1
	vmovd	%xmm1, %edx
	addl	$8, %edx
	movslq	(%rcx,%rdx,4), %rbx
	movl	%r11d, (%r9,%rbx,4)
	incl	(%rcx,%rdx,4)
	cmpq	%rsi, %r10
	je	LBB18_1
## %bb.9:                               ##   in Loop: Header=BB18_8 Depth=1
	movl	(%rdi,%rsi,4), %r11d
	incq	%rsi
	jmp	LBB18_8
LBB18_1:
	movslq	%r8d, %r8
	xorl	%r11d, %r11d
	movq	_tmp@GOTPCREL(%rip), %r10
	jmp	LBB18_2
	.p2align	4, 0x90
LBB18_5:                                ##   in Loop: Header=BB18_2 Depth=1
	subl	%r9d, %esi
	movl	%esi, (%rcx,%r11,4)
	incq	%r11
	cmpq	$9, %r11
	je	LBB18_6
LBB18_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB18_10 Depth 2
                                        ##     Child Loop BB18_4 Depth 2
	movq	%r11, %r9
	imulq	%r8, %r9
	movslq	(%rcx,%r11,4), %rsi
	movq	%rsi, %rbx
	addq	$-8, %rbx
	movq	%r9, %rdx
	cmpq	%rbx, %r9
	jge	LBB18_3
	.p2align	4, 0x90
LBB18_10:                               ##   Parent Loop BB18_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	vmovdqu	(%r10,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%rdi,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	movslq	(%rcx,%r11,4), %rsi
	leaq	-8(%rsi), %rbx
	cmpq	%rbx, %rdx
	jl	LBB18_10
LBB18_3:                                ##   in Loop: Header=BB18_2 Depth=1
	movslq	%esi, %rbx
	cmpq	%rbx, %rdx
	jge	LBB18_5
	.p2align	4, 0x90
LBB18_4:                                ##   Parent Loop BB18_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r10,%rdx,4), %esi
	movl	%esi, (%rdi,%rax,4)
	incq	%rax
	incq	%rdx
	movslq	(%rcx,%r11,4), %rsi
	cmpq	%rsi, %rdx
	jl	LBB18_4
	jmp	LBB18_5
LBB18_6:
	popq	%rbx
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.section	__TEXT,__literal16,16byte_literals
	.p2align	4                               ## -- Begin function sort_quick_multi
LCPI19_0:
	.long	2                               ## 0x2
	.long	3                               ## 0x3
	.long	4                               ## 0x4
	.long	5                               ## 0x5
	.section	__TEXT,__text,regular,pure_instructions
	.globl	_sort_quick_multi
	.p2align	4, 0x90
_sort_quick_multi:                      ## @sort_quick_multi
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$120, %rsp
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	movq	%rax, -48(%rbp)
	movl	%edx, %eax
	subl	%esi, %eax
	jle	LBB19_39
## %bb.1:
	movq	%rdi, %r14
	cmpl	$201, %eax
	jl	LBB19_37
## %bb.2:
	leal	1(%rax), %ecx
	movl	$0, -96(%rbp)
	movl	%ecx, -92(%rbp)
	vmovd	%ecx, %xmm0
	vpbroadcastd	%xmm0, %xmm0
	vpmulld	LCPI19_0(%rip), %xmm0, %xmm0
	vmovdqu	%xmm0, -88(%rbp)
	leal	2(%rax,%rax), %edi
	leal	(%rdi,%rdi,2), %edi
	movl	%edi, -72(%rbp)
	leal	8(,%rax,8), %eax
	movl	%eax, %edi
	subl	%ecx, %edi
	movl	%edi, -68(%rbp)
	movl	%eax, -64(%rbp)
	incl	%edx
	movslq	%edx, %r10
	subl	%esi, %edx
	movslq	%edx, %r9
	movq	%rsi, -160(%rbp)                ## 8-byte Spill
	movslq	%esi, %rax
	vmovdqu	(%r14,%rax,4), %ymm0
	vmovdqu	(%r14,%rax,4), %xmm1
	vmovd	%xmm1, %edi
	leaq	1(%rax), %rsi
	movq	_tmp@GOTPCREL(%rip), %r8
	.p2align	4, 0x90
LBB19_3:                                ## =>This Inner Loop Header: Depth=1
	vmovd	%edi, %xmm1
	vpbroadcastd	%xmm1, %ymm1
	vpcmpgtd	%ymm1, %ymm0, %ymm1
	vextracti128	$1, %ymm1, %xmm2
	vpaddd	%xmm1, %xmm2, %xmm1
	vpshufd	$238, %xmm1, %xmm2              ## xmm2 = xmm1[2,3,2,3]
	vpaddd	%xmm2, %xmm1, %xmm1
	vpshufd	$85, %xmm1, %xmm2               ## xmm2 = xmm1[1,1,1,1]
	vpaddd	%xmm1, %xmm2, %xmm1
	vmovd	%xmm1, %ebx
	addl	$8, %ebx
	movslq	-96(%rbp,%rbx,4), %rcx
	movl	%edi, (%r8,%rcx,4)
	incl	%ecx
	movl	%ecx, -96(%rbp,%rbx,4)
	cmpq	%rsi, %r10
	je	LBB19_4
## %bb.6:                               ##   in Loop: Header=BB19_3 Depth=1
	movl	(%r14,%rsi,4), %edi
	incq	%rsi
	jmp	LBB19_3
LBB19_37:
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB19_206
## %bb.38:
	movq	%r14, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	addq	$120, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	jmp	_sort_quick_optimized           ## TAILCALL
LBB19_4:
	movslq	-96(%rbp), %r15
	cmpq	$9, %r15
	jl	LBB19_5
## %bb.35:
	leaq	-8(%r15), %rsi
	leaq	(%r14,%rax,4), %rdi
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB19_36:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rcx,4), %ymm0
	vmovdqu	%ymm0, (%rdi,%rcx,4)
	addq	$8, %rcx
	cmpq	%rsi, %rcx
	jl	LBB19_36
## %bb.7:
	addq	%rcx, %rax
	cmpq	%r15, %rcx
	movq	%r15, -152(%rbp)                ## 8-byte Spill
	jl	LBB19_9
	jmp	LBB19_27
LBB19_5:
	xorl	%ecx, %ecx
	cmpq	%r15, %rcx
	movq	%r15, -152(%rbp)                ## 8-byte Spill
	jge	LBB19_27
LBB19_9:
	movq	%r15, %r11
	subq	%rcx, %r11
	cmpq	$32, %r11
	jb	LBB19_21
## %bb.10:
	leaq	(%r14,%rax,4), %rsi
	leaq	(%r8,%r15,4), %rdi
	cmpq	%rdi, %rsi
	jae	LBB19_12
## %bb.11:
	leaq	(%rax,%r15), %rsi
	subq	%rcx, %rsi
	leaq	(%r14,%rsi,4), %rsi
	leaq	(%r8,%rcx,4), %rdi
	cmpq	%rsi, %rdi
	jb	LBB19_21
LBB19_12:
	movq	%r11, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %r12
	shrq	$5, %r12
	incq	%r12
	movl	%r12d, %r15d
	andl	$3, %r15d
	cmpq	$96, %rsi
	jae	LBB19_14
## %bb.13:
	xorl	%edi, %edi
	jmp	LBB19_16
LBB19_14:
	leaq	(%r8,%rcx,4), %r13
	addq	$480, %r13                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	andq	$-4, %r12
	negq	%r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_15:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%r13,%rdi,4), %ymm0
	vmovups	-448(%r13,%rdi,4), %ymm1
	vmovups	-416(%r13,%rdi,4), %ymm2
	vmovups	-384(%r13,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rbx,%rdi,4)
	vmovups	%ymm1, -448(%rbx,%rdi,4)
	vmovups	%ymm2, -416(%rbx,%rdi,4)
	vmovups	%ymm3, -384(%rbx,%rdi,4)
	vmovups	-352(%r13,%rdi,4), %ymm0
	vmovups	-320(%r13,%rdi,4), %ymm1
	vmovups	-288(%r13,%rdi,4), %ymm2
	vmovups	-256(%r13,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rbx,%rdi,4)
	vmovups	%ymm1, -320(%rbx,%rdi,4)
	vmovups	%ymm2, -288(%rbx,%rdi,4)
	vmovups	%ymm3, -256(%rbx,%rdi,4)
	vmovups	-224(%r13,%rdi,4), %ymm0
	vmovups	-192(%r13,%rdi,4), %ymm1
	vmovups	-160(%r13,%rdi,4), %ymm2
	vmovups	-128(%r13,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rbx,%rdi,4)
	vmovups	%ymm1, -192(%rbx,%rdi,4)
	vmovups	%ymm2, -160(%rbx,%rdi,4)
	vmovups	%ymm3, -128(%rbx,%rdi,4)
	vmovdqu	-96(%r13,%rdi,4), %ymm0
	vmovdqu	-64(%r13,%rdi,4), %ymm1
	vmovdqu	-32(%r13,%rdi,4), %ymm2
	vmovups	(%r13,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rbx,%rdi,4)
	vmovdqu	%ymm1, -64(%rbx,%rdi,4)
	vmovdqu	%ymm2, -32(%rbx,%rdi,4)
	vmovups	%ymm3, (%rbx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r12
	jne	LBB19_15
LBB19_16:
	testq	%r15, %r15
	je	LBB19_19
## %bb.17:
	leaq	(%rax,%rdi), %rsi
	leaq	(%r14,%rsi,4), %rsi
	addq	$96, %rsi
	addq	%rcx, %rdi
	leaq	(%r8,%rdi,4), %rdi
	addq	$96, %rdi
	shlq	$7, %r15
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB19_18:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rdi,%rbx), %ymm0
	vmovdqu	-64(%rdi,%rbx), %ymm1
	vmovdqu	-32(%rdi,%rbx), %ymm2
	vmovups	(%rdi,%rbx), %ymm3
	vmovdqu	%ymm0, -96(%rsi,%rbx)
	vmovdqu	%ymm1, -64(%rsi,%rbx)
	vmovdqu	%ymm2, -32(%rsi,%rbx)
	vmovups	%ymm3, (%rsi,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r15
	jne	LBB19_18
LBB19_19:
	addq	%r10, %rax
	cmpq	%r10, %r11
	movq	-152(%rbp), %r15                ## 8-byte Reload
	je	LBB19_27
## %bb.20:
	addq	%r10, %rcx
LBB19_21:
	movl	%r15d, %edi
	subl	%ecx, %edi
	movq	%rcx, %rsi
	notq	%rsi
	addq	%r15, %rsi
	andq	$7, %rdi
	je	LBB19_23
	.p2align	4, 0x90
LBB19_22:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rcx,4), %ebx
	movl	%ebx, (%r14,%rax,4)
	incq	%rax
	incq	%rcx
	decq	%rdi
	jne	LBB19_22
LBB19_23:
	cmpq	$7, %rsi
	jb	LBB19_27
## %bb.24:
	movq	%r15, %r10
	subq	%rcx, %r10
	leaq	(%r8,%rcx,4), %rdi
	addq	$28, %rdi
	leaq	(%r14,%rax,4), %rbx
	addq	$28, %rbx
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB19_25:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rdi,%rcx,4), %esi
	movl	%esi, -28(%rbx,%rcx,4)
	movl	-24(%rdi,%rcx,4), %esi
	movl	%esi, -24(%rbx,%rcx,4)
	movl	-20(%rdi,%rcx,4), %esi
	movl	%esi, -20(%rbx,%rcx,4)
	movl	-16(%rdi,%rcx,4), %esi
	movl	%esi, -16(%rbx,%rcx,4)
	movl	-12(%rdi,%rcx,4), %esi
	movl	%esi, -12(%rbx,%rcx,4)
	movl	-8(%rdi,%rcx,4), %esi
	movl	%esi, -8(%rbx,%rcx,4)
	movl	-4(%rdi,%rcx,4), %esi
	movl	%esi, -4(%rbx,%rcx,4)
	movl	(%rdi,%rcx,4), %esi
	movl	%esi, (%rbx,%rcx,4)
	addq	$8, %rcx
	cmpq	%rcx, %r10
	jne	LBB19_25
## %bb.26:
	addq	%rcx, %rax
LBB19_27:
	movslq	-92(%rbp), %r15
	leaq	-8(%r15), %rsi
	movq	%r9, %rcx
	cmpl	%esi, %edx
	jge	LBB19_29
	.p2align	4, 0x90
LBB19_28:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rcx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rcx
	cmpq	%rsi, %rcx
	jl	LBB19_28
LBB19_29:
	cmpq	%r15, %rcx
	jge	LBB19_54
## %bb.30:
	movq	%r15, %r11
	subq	%rcx, %r11
	cmpq	$32, %r11
	jb	LBB19_48
## %bb.31:
	leaq	(%r14,%rax,4), %rsi
	leaq	(%r8,%r15,4), %rdi
	cmpq	%rdi, %rsi
	jae	LBB19_33
## %bb.32:
	leaq	(%rax,%r15), %rsi
	subq	%rcx, %rsi
	leaq	(%r14,%rsi,4), %rsi
	leaq	(%r8,%rcx,4), %rdi
	cmpq	%rsi, %rdi
	jb	LBB19_48
LBB19_33:
	movq	%r15, -144(%rbp)                ## 8-byte Spill
	movq	%r11, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rsi
	movq	%rsi, %r12
	shrq	$5, %r12
	incq	%r12
	movl	%r12d, %r15d
	andl	$3, %r15d
	cmpq	$96, %rsi
	jae	LBB19_41
## %bb.34:
	xorl	%edi, %edi
	jmp	LBB19_43
LBB19_41:
	leaq	(%r8,%rcx,4), %r13
	addq	$480, %r13                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	andq	$-4, %r12
	negq	%r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_42:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%r13,%rdi,4), %ymm0
	vmovups	-448(%r13,%rdi,4), %ymm1
	vmovups	-416(%r13,%rdi,4), %ymm2
	vmovups	-384(%r13,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rbx,%rdi,4)
	vmovups	%ymm1, -448(%rbx,%rdi,4)
	vmovups	%ymm2, -416(%rbx,%rdi,4)
	vmovups	%ymm3, -384(%rbx,%rdi,4)
	vmovups	-352(%r13,%rdi,4), %ymm0
	vmovups	-320(%r13,%rdi,4), %ymm1
	vmovups	-288(%r13,%rdi,4), %ymm2
	vmovups	-256(%r13,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rbx,%rdi,4)
	vmovups	%ymm1, -320(%rbx,%rdi,4)
	vmovups	%ymm2, -288(%rbx,%rdi,4)
	vmovups	%ymm3, -256(%rbx,%rdi,4)
	vmovups	-224(%r13,%rdi,4), %ymm0
	vmovups	-192(%r13,%rdi,4), %ymm1
	vmovups	-160(%r13,%rdi,4), %ymm2
	vmovups	-128(%r13,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rbx,%rdi,4)
	vmovups	%ymm1, -192(%rbx,%rdi,4)
	vmovups	%ymm2, -160(%rbx,%rdi,4)
	vmovups	%ymm3, -128(%rbx,%rdi,4)
	vmovdqu	-96(%r13,%rdi,4), %ymm0
	vmovdqu	-64(%r13,%rdi,4), %ymm1
	vmovdqu	-32(%r13,%rdi,4), %ymm2
	vmovups	(%r13,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rbx,%rdi,4)
	vmovdqu	%ymm1, -64(%rbx,%rdi,4)
	vmovdqu	%ymm2, -32(%rbx,%rdi,4)
	vmovups	%ymm3, (%rbx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r12
	jne	LBB19_42
LBB19_43:
	testq	%r15, %r15
	je	LBB19_46
## %bb.44:
	leaq	(%rax,%rdi), %rsi
	leaq	(%r14,%rsi,4), %rsi
	addq	$96, %rsi
	addq	%rcx, %rdi
	leaq	(%r8,%rdi,4), %rdi
	addq	$96, %rdi
	shlq	$7, %r15
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB19_45:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rdi,%rbx), %ymm0
	vmovdqu	-64(%rdi,%rbx), %ymm1
	vmovdqu	-32(%rdi,%rbx), %ymm2
	vmovups	(%rdi,%rbx), %ymm3
	vmovdqu	%ymm0, -96(%rsi,%rbx)
	vmovdqu	%ymm1, -64(%rsi,%rbx)
	vmovdqu	%ymm2, -32(%rsi,%rbx)
	vmovups	%ymm3, (%rsi,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r15
	jne	LBB19_45
LBB19_46:
	addq	%r10, %rax
	cmpq	%r10, %r11
	movq	-144(%rbp), %r15                ## 8-byte Reload
	je	LBB19_54
## %bb.47:
	addq	%r10, %rcx
LBB19_48:
	movl	%r15d, %edi
	subl	%ecx, %edi
	movq	%rcx, %rsi
	notq	%rsi
	addq	%r15, %rsi
	andq	$7, %rdi
	je	LBB19_50
	.p2align	4, 0x90
LBB19_49:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rcx,4), %ebx
	movl	%ebx, (%r14,%rax,4)
	incq	%rax
	incq	%rcx
	decq	%rdi
	jne	LBB19_49
LBB19_50:
	cmpq	$7, %rsi
	jb	LBB19_54
## %bb.51:
	movq	%r15, %r10
	subq	%rcx, %r10
	leaq	(%r8,%rcx,4), %rdi
	addq	$28, %rdi
	leaq	(%r14,%rax,4), %rbx
	addq	$28, %rbx
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB19_52:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rdi,%rcx,4), %esi
	movl	%esi, -28(%rbx,%rcx,4)
	movl	-24(%rdi,%rcx,4), %esi
	movl	%esi, -24(%rbx,%rcx,4)
	movl	-20(%rdi,%rcx,4), %esi
	movl	%esi, -20(%rbx,%rcx,4)
	movl	-16(%rdi,%rcx,4), %esi
	movl	%esi, -16(%rbx,%rcx,4)
	movl	-12(%rdi,%rcx,4), %esi
	movl	%esi, -12(%rbx,%rcx,4)
	movl	-8(%rdi,%rcx,4), %esi
	movl	%esi, -8(%rbx,%rcx,4)
	movl	-4(%rdi,%rcx,4), %esi
	movl	%esi, -4(%rbx,%rcx,4)
	movl	(%rdi,%rcx,4), %esi
	movl	%esi, (%rbx,%rcx,4)
	addq	$8, %rcx
	cmpq	%rcx, %r10
	jne	LBB19_52
## %bb.53:
	addq	%rcx, %rax
LBB19_54:
	subl	%edx, %r15d
	movl	%r15d, -92(%rbp)
	leaq	(%r9,%r9), %r11
	movslq	-88(%rbp), %r10
	leaq	-8(%r10), %rcx
	movq	%r11, %rdx
	cmpq	%rcx, %r11
	jge	LBB19_56
	.p2align	4, 0x90
LBB19_55:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	cmpq	%rcx, %rdx
	jl	LBB19_55
LBB19_56:
	cmpq	%r10, %rdx
	movq	%r15, -144(%rbp)                ## 8-byte Spill
	jge	LBB19_76
## %bb.57:
	movq	%r10, %r15
	subq	%rdx, %r15
	cmpq	$32, %r15
	jb	LBB19_70
## %bb.58:
	leaq	(%r14,%rax,4), %rcx
	leaq	(%r8,%r10,4), %rsi
	cmpq	%rsi, %rcx
	jae	LBB19_60
## %bb.59:
	leaq	(%rax,%r10), %rcx
	subq	%rdx, %rcx
	leaq	(%r14,%rcx,4), %rcx
	leaq	(%r8,%rdx,4), %rsi
	cmpq	%rcx, %rsi
	jb	LBB19_70
LBB19_60:
	movq	%r10, -136(%rbp)                ## 8-byte Spill
	movq	%r15, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rcx
	movq	%rcx, %r13
	shrq	$5, %r13
	incq	%r13
	movl	%r13d, %r12d
	andl	$3, %r12d
	cmpq	$96, %rcx
	jae	LBB19_62
## %bb.61:
	xorl	%edi, %edi
	jmp	LBB19_64
LBB19_62:
	leaq	(%r8,%rdx,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rcx
	addq	$480, %rcx                      ## imm = 0x1E0
	andq	$-4, %r13
	negq	%r13
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_63:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rdi,4), %ymm0
	vmovups	-448(%rbx,%rdi,4), %ymm1
	vmovups	-416(%rbx,%rdi,4), %ymm2
	vmovups	-384(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rcx,%rdi,4)
	vmovups	%ymm1, -448(%rcx,%rdi,4)
	vmovups	%ymm2, -416(%rcx,%rdi,4)
	vmovups	%ymm3, -384(%rcx,%rdi,4)
	vmovups	-352(%rbx,%rdi,4), %ymm0
	vmovups	-320(%rbx,%rdi,4), %ymm1
	vmovups	-288(%rbx,%rdi,4), %ymm2
	vmovups	-256(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rcx,%rdi,4)
	vmovups	%ymm1, -320(%rcx,%rdi,4)
	vmovups	%ymm2, -288(%rcx,%rdi,4)
	vmovups	%ymm3, -256(%rcx,%rdi,4)
	vmovups	-224(%rbx,%rdi,4), %ymm0
	vmovups	-192(%rbx,%rdi,4), %ymm1
	vmovups	-160(%rbx,%rdi,4), %ymm2
	vmovups	-128(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rcx,%rdi,4)
	vmovups	%ymm1, -192(%rcx,%rdi,4)
	vmovups	%ymm2, -160(%rcx,%rdi,4)
	vmovups	%ymm3, -128(%rcx,%rdi,4)
	vmovdqu	-96(%rbx,%rdi,4), %ymm0
	vmovdqu	-64(%rbx,%rdi,4), %ymm1
	vmovdqu	-32(%rbx,%rdi,4), %ymm2
	vmovups	(%rbx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi,4)
	vmovdqu	%ymm1, -64(%rcx,%rdi,4)
	vmovdqu	%ymm2, -32(%rcx,%rdi,4)
	vmovups	%ymm3, (%rcx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r13
	jne	LBB19_63
LBB19_64:
	testq	%r12, %r12
	je	LBB19_67
## %bb.65:
	leaq	(%rax,%rdi), %rcx
	leaq	(%r14,%rcx,4), %rcx
	addq	$96, %rcx
	addq	%rdx, %rdi
	leaq	(%r8,%rdi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_66:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rsi,%rdi), %ymm0
	vmovdqu	-64(%rsi,%rdi), %ymm1
	vmovdqu	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi)
	vmovdqu	%ymm1, -64(%rcx,%rdi)
	vmovdqu	%ymm2, -32(%rcx,%rdi)
	vmovups	%ymm3, (%rcx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r12
	jne	LBB19_66
LBB19_67:
	addq	%r10, %rax
	cmpq	%r10, %r15
	jne	LBB19_69
## %bb.68:
	movq	-136(%rbp), %r10                ## 8-byte Reload
	jmp	LBB19_76
LBB19_69:
	addq	%r10, %rdx
	movq	-136(%rbp), %r10                ## 8-byte Reload
LBB19_70:
	movl	%r10d, %esi
	subl	%edx, %esi
	movq	%rdx, %rcx
	notq	%rcx
	addq	%r10, %rcx
	andq	$7, %rsi
	je	LBB19_72
	.p2align	4, 0x90
LBB19_71:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rdx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rdx
	decq	%rsi
	jne	LBB19_71
LBB19_72:
	cmpq	$7, %rcx
	jb	LBB19_76
## %bb.73:
	movq	%r10, %rcx
	subq	%rdx, %rcx
	leaq	(%r8,%rdx,4), %rsi
	addq	$28, %rsi
	leaq	(%r14,%rax,4), %rdi
	addq	$28, %rdi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB19_74:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rdx,4), %ebx
	movl	%ebx, -28(%rdi,%rdx,4)
	movl	-24(%rsi,%rdx,4), %ebx
	movl	%ebx, -24(%rdi,%rdx,4)
	movl	-20(%rsi,%rdx,4), %ebx
	movl	%ebx, -20(%rdi,%rdx,4)
	movl	-16(%rsi,%rdx,4), %ebx
	movl	%ebx, -16(%rdi,%rdx,4)
	movl	-12(%rsi,%rdx,4), %ebx
	movl	%ebx, -12(%rdi,%rdx,4)
	movl	-8(%rsi,%rdx,4), %ebx
	movl	%ebx, -8(%rdi,%rdx,4)
	movl	-4(%rsi,%rdx,4), %ebx
	movl	%ebx, -4(%rdi,%rdx,4)
	movl	(%rsi,%rdx,4), %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB19_74
## %bb.75:
	addq	%rdx, %rax
LBB19_76:
	subl	%r11d, %r10d
	movl	%r10d, -88(%rbp)
	leaq	(%r9,%r9,2), %r11
	movslq	-84(%rbp), %r12
	leaq	-8(%r12), %rcx
	movq	%r11, %rdx
	cmpq	%rcx, %r11
	jge	LBB19_78
	.p2align	4, 0x90
LBB19_77:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	cmpq	%rcx, %rdx
	jl	LBB19_77
LBB19_78:
	cmpq	%r12, %rdx
	movq	%r10, -136(%rbp)                ## 8-byte Spill
	jge	LBB19_98
## %bb.79:
	movq	%r12, %r15
	subq	%rdx, %r15
	cmpq	$32, %r15
	jb	LBB19_92
## %bb.80:
	leaq	(%r14,%rax,4), %rcx
	leaq	(%r8,%r12,4), %rsi
	cmpq	%rsi, %rcx
	jae	LBB19_82
## %bb.81:
	leaq	(%rax,%r12), %rcx
	subq	%rdx, %rcx
	leaq	(%r14,%rcx,4), %rcx
	leaq	(%r8,%rdx,4), %rsi
	cmpq	%rcx, %rsi
	jb	LBB19_92
LBB19_82:
	movq	%r12, -128(%rbp)                ## 8-byte Spill
	movq	%r15, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rcx
	movq	%rcx, %r13
	shrq	$5, %r13
	incq	%r13
	movl	%r13d, %r12d
	andl	$3, %r12d
	cmpq	$96, %rcx
	jae	LBB19_84
## %bb.83:
	xorl	%edi, %edi
	jmp	LBB19_86
LBB19_84:
	leaq	(%r8,%rdx,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rcx
	addq	$480, %rcx                      ## imm = 0x1E0
	andq	$-4, %r13
	negq	%r13
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_85:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rdi,4), %ymm0
	vmovups	-448(%rbx,%rdi,4), %ymm1
	vmovups	-416(%rbx,%rdi,4), %ymm2
	vmovups	-384(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rcx,%rdi,4)
	vmovups	%ymm1, -448(%rcx,%rdi,4)
	vmovups	%ymm2, -416(%rcx,%rdi,4)
	vmovups	%ymm3, -384(%rcx,%rdi,4)
	vmovups	-352(%rbx,%rdi,4), %ymm0
	vmovups	-320(%rbx,%rdi,4), %ymm1
	vmovups	-288(%rbx,%rdi,4), %ymm2
	vmovups	-256(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rcx,%rdi,4)
	vmovups	%ymm1, -320(%rcx,%rdi,4)
	vmovups	%ymm2, -288(%rcx,%rdi,4)
	vmovups	%ymm3, -256(%rcx,%rdi,4)
	vmovups	-224(%rbx,%rdi,4), %ymm0
	vmovups	-192(%rbx,%rdi,4), %ymm1
	vmovups	-160(%rbx,%rdi,4), %ymm2
	vmovups	-128(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rcx,%rdi,4)
	vmovups	%ymm1, -192(%rcx,%rdi,4)
	vmovups	%ymm2, -160(%rcx,%rdi,4)
	vmovups	%ymm3, -128(%rcx,%rdi,4)
	vmovdqu	-96(%rbx,%rdi,4), %ymm0
	vmovdqu	-64(%rbx,%rdi,4), %ymm1
	vmovdqu	-32(%rbx,%rdi,4), %ymm2
	vmovups	(%rbx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi,4)
	vmovdqu	%ymm1, -64(%rcx,%rdi,4)
	vmovdqu	%ymm2, -32(%rcx,%rdi,4)
	vmovups	%ymm3, (%rcx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r13
	jne	LBB19_85
LBB19_86:
	testq	%r12, %r12
	je	LBB19_89
## %bb.87:
	leaq	(%rax,%rdi), %rcx
	leaq	(%r14,%rcx,4), %rcx
	addq	$96, %rcx
	addq	%rdx, %rdi
	leaq	(%r8,%rdi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_88:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rsi,%rdi), %ymm0
	vmovdqu	-64(%rsi,%rdi), %ymm1
	vmovdqu	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi)
	vmovdqu	%ymm1, -64(%rcx,%rdi)
	vmovdqu	%ymm2, -32(%rcx,%rdi)
	vmovups	%ymm3, (%rcx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r12
	jne	LBB19_88
LBB19_89:
	addq	%r10, %rax
	cmpq	%r10, %r15
	jne	LBB19_91
## %bb.90:
	movq	-128(%rbp), %r12                ## 8-byte Reload
	jmp	LBB19_98
LBB19_91:
	addq	%r10, %rdx
	movq	-128(%rbp), %r12                ## 8-byte Reload
LBB19_92:
	movl	%r12d, %esi
	subl	%edx, %esi
	movq	%rdx, %rcx
	notq	%rcx
	addq	%r12, %rcx
	andq	$7, %rsi
	je	LBB19_94
	.p2align	4, 0x90
LBB19_93:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rdx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rdx
	decq	%rsi
	jne	LBB19_93
LBB19_94:
	cmpq	$7, %rcx
	jb	LBB19_98
## %bb.95:
	movq	%r12, %rcx
	subq	%rdx, %rcx
	leaq	(%r8,%rdx,4), %rsi
	addq	$28, %rsi
	leaq	(%r14,%rax,4), %rdi
	addq	$28, %rdi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB19_96:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rdx,4), %ebx
	movl	%ebx, -28(%rdi,%rdx,4)
	movl	-24(%rsi,%rdx,4), %ebx
	movl	%ebx, -24(%rdi,%rdx,4)
	movl	-20(%rsi,%rdx,4), %ebx
	movl	%ebx, -20(%rdi,%rdx,4)
	movl	-16(%rsi,%rdx,4), %ebx
	movl	%ebx, -16(%rdi,%rdx,4)
	movl	-12(%rsi,%rdx,4), %ebx
	movl	%ebx, -12(%rdi,%rdx,4)
	movl	-8(%rsi,%rdx,4), %ebx
	movl	%ebx, -8(%rdi,%rdx,4)
	movl	-4(%rsi,%rdx,4), %ebx
	movl	%ebx, -4(%rdi,%rdx,4)
	movl	(%rsi,%rdx,4), %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB19_96
## %bb.97:
	addq	%rdx, %rax
LBB19_98:
	subl	%r11d, %r12d
	movl	%r12d, -84(%rbp)
	leaq	(,%r9,4), %r11
	movslq	-80(%rbp), %r10
	leaq	-8(%r10), %rcx
	movq	%r11, %rdx
	cmpq	%rcx, %r11
	jge	LBB19_100
	.p2align	4, 0x90
LBB19_99:                               ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	cmpq	%rcx, %rdx
	jl	LBB19_99
LBB19_100:
	cmpq	%r10, %rdx
	movq	%r12, -128(%rbp)                ## 8-byte Spill
	jge	LBB19_120
## %bb.101:
	movq	%r10, %r15
	subq	%rdx, %r15
	cmpq	$32, %r15
	jb	LBB19_114
## %bb.102:
	leaq	(%r14,%rax,4), %rcx
	leaq	(%r8,%r10,4), %rsi
	cmpq	%rsi, %rcx
	jae	LBB19_104
## %bb.103:
	leaq	(%rax,%r10), %rcx
	subq	%rdx, %rcx
	leaq	(%r14,%rcx,4), %rcx
	leaq	(%r8,%rdx,4), %rsi
	cmpq	%rcx, %rsi
	jb	LBB19_114
LBB19_104:
	movq	%r10, -120(%rbp)                ## 8-byte Spill
	movq	%r15, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rcx
	movq	%rcx, %r13
	shrq	$5, %r13
	incq	%r13
	movl	%r13d, %r12d
	andl	$3, %r12d
	cmpq	$96, %rcx
	jae	LBB19_106
## %bb.105:
	xorl	%edi, %edi
	jmp	LBB19_108
LBB19_106:
	leaq	(%r8,%rdx,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rcx
	addq	$480, %rcx                      ## imm = 0x1E0
	andq	$-4, %r13
	negq	%r13
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_107:                              ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rdi,4), %ymm0
	vmovups	-448(%rbx,%rdi,4), %ymm1
	vmovups	-416(%rbx,%rdi,4), %ymm2
	vmovups	-384(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rcx,%rdi,4)
	vmovups	%ymm1, -448(%rcx,%rdi,4)
	vmovups	%ymm2, -416(%rcx,%rdi,4)
	vmovups	%ymm3, -384(%rcx,%rdi,4)
	vmovups	-352(%rbx,%rdi,4), %ymm0
	vmovups	-320(%rbx,%rdi,4), %ymm1
	vmovups	-288(%rbx,%rdi,4), %ymm2
	vmovups	-256(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rcx,%rdi,4)
	vmovups	%ymm1, -320(%rcx,%rdi,4)
	vmovups	%ymm2, -288(%rcx,%rdi,4)
	vmovups	%ymm3, -256(%rcx,%rdi,4)
	vmovups	-224(%rbx,%rdi,4), %ymm0
	vmovups	-192(%rbx,%rdi,4), %ymm1
	vmovups	-160(%rbx,%rdi,4), %ymm2
	vmovups	-128(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rcx,%rdi,4)
	vmovups	%ymm1, -192(%rcx,%rdi,4)
	vmovups	%ymm2, -160(%rcx,%rdi,4)
	vmovups	%ymm3, -128(%rcx,%rdi,4)
	vmovdqu	-96(%rbx,%rdi,4), %ymm0
	vmovdqu	-64(%rbx,%rdi,4), %ymm1
	vmovdqu	-32(%rbx,%rdi,4), %ymm2
	vmovups	(%rbx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi,4)
	vmovdqu	%ymm1, -64(%rcx,%rdi,4)
	vmovdqu	%ymm2, -32(%rcx,%rdi,4)
	vmovups	%ymm3, (%rcx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r13
	jne	LBB19_107
LBB19_108:
	testq	%r12, %r12
	je	LBB19_111
## %bb.109:
	leaq	(%rax,%rdi), %rcx
	leaq	(%r14,%rcx,4), %rcx
	addq	$96, %rcx
	addq	%rdx, %rdi
	leaq	(%r8,%rdi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_110:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rsi,%rdi), %ymm0
	vmovdqu	-64(%rsi,%rdi), %ymm1
	vmovdqu	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi)
	vmovdqu	%ymm1, -64(%rcx,%rdi)
	vmovdqu	%ymm2, -32(%rcx,%rdi)
	vmovups	%ymm3, (%rcx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r12
	jne	LBB19_110
LBB19_111:
	addq	%r10, %rax
	cmpq	%r10, %r15
	jne	LBB19_113
## %bb.112:
	movq	-120(%rbp), %r10                ## 8-byte Reload
	jmp	LBB19_120
LBB19_113:
	addq	%r10, %rdx
	movq	-120(%rbp), %r10                ## 8-byte Reload
LBB19_114:
	movl	%r10d, %esi
	subl	%edx, %esi
	movq	%rdx, %rcx
	notq	%rcx
	addq	%r10, %rcx
	andq	$7, %rsi
	je	LBB19_116
	.p2align	4, 0x90
LBB19_115:                              ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rdx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rdx
	decq	%rsi
	jne	LBB19_115
LBB19_116:
	cmpq	$7, %rcx
	jb	LBB19_120
## %bb.117:
	movq	%r10, %rcx
	subq	%rdx, %rcx
	leaq	(%r8,%rdx,4), %rsi
	addq	$28, %rsi
	leaq	(%r14,%rax,4), %rdi
	addq	$28, %rdi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB19_118:                              ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rdx,4), %ebx
	movl	%ebx, -28(%rdi,%rdx,4)
	movl	-24(%rsi,%rdx,4), %ebx
	movl	%ebx, -24(%rdi,%rdx,4)
	movl	-20(%rsi,%rdx,4), %ebx
	movl	%ebx, -20(%rdi,%rdx,4)
	movl	-16(%rsi,%rdx,4), %ebx
	movl	%ebx, -16(%rdi,%rdx,4)
	movl	-12(%rsi,%rdx,4), %ebx
	movl	%ebx, -12(%rdi,%rdx,4)
	movl	-8(%rsi,%rdx,4), %ebx
	movl	%ebx, -8(%rdi,%rdx,4)
	movl	-4(%rsi,%rdx,4), %ebx
	movl	%ebx, -4(%rdi,%rdx,4)
	movl	(%rsi,%rdx,4), %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB19_118
## %bb.119:
	addq	%rdx, %rax
LBB19_120:
	subl	%r11d, %r10d
	movl	%r10d, -80(%rbp)
	leaq	(%r9,%r9,4), %r11
	movslq	-76(%rbp), %r12
	leaq	-8(%r12), %rcx
	movq	%r11, %rdx
	cmpq	%rcx, %r11
	jge	LBB19_122
	.p2align	4, 0x90
LBB19_121:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	cmpq	%rcx, %rdx
	jl	LBB19_121
LBB19_122:
	cmpq	%r12, %rdx
	movq	%r10, -120(%rbp)                ## 8-byte Spill
	jge	LBB19_142
## %bb.123:
	movq	%r12, %r15
	subq	%rdx, %r15
	cmpq	$32, %r15
	jb	LBB19_136
## %bb.124:
	leaq	(%r14,%rax,4), %rcx
	leaq	(%r8,%r12,4), %rsi
	cmpq	%rsi, %rcx
	jae	LBB19_126
## %bb.125:
	leaq	(%rax,%r12), %rcx
	subq	%rdx, %rcx
	leaq	(%r14,%rcx,4), %rcx
	leaq	(%r8,%rdx,4), %rsi
	cmpq	%rcx, %rsi
	jb	LBB19_136
LBB19_126:
	movq	%r12, -112(%rbp)                ## 8-byte Spill
	movq	%r15, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rcx
	movq	%rcx, %r13
	shrq	$5, %r13
	incq	%r13
	movl	%r13d, %r12d
	andl	$3, %r12d
	cmpq	$96, %rcx
	jae	LBB19_128
## %bb.127:
	xorl	%edi, %edi
	jmp	LBB19_130
LBB19_128:
	leaq	(%r8,%rdx,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rcx
	addq	$480, %rcx                      ## imm = 0x1E0
	andq	$-4, %r13
	negq	%r13
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_129:                              ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rdi,4), %ymm0
	vmovups	-448(%rbx,%rdi,4), %ymm1
	vmovups	-416(%rbx,%rdi,4), %ymm2
	vmovups	-384(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rcx,%rdi,4)
	vmovups	%ymm1, -448(%rcx,%rdi,4)
	vmovups	%ymm2, -416(%rcx,%rdi,4)
	vmovups	%ymm3, -384(%rcx,%rdi,4)
	vmovups	-352(%rbx,%rdi,4), %ymm0
	vmovups	-320(%rbx,%rdi,4), %ymm1
	vmovups	-288(%rbx,%rdi,4), %ymm2
	vmovups	-256(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rcx,%rdi,4)
	vmovups	%ymm1, -320(%rcx,%rdi,4)
	vmovups	%ymm2, -288(%rcx,%rdi,4)
	vmovups	%ymm3, -256(%rcx,%rdi,4)
	vmovups	-224(%rbx,%rdi,4), %ymm0
	vmovups	-192(%rbx,%rdi,4), %ymm1
	vmovups	-160(%rbx,%rdi,4), %ymm2
	vmovups	-128(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rcx,%rdi,4)
	vmovups	%ymm1, -192(%rcx,%rdi,4)
	vmovups	%ymm2, -160(%rcx,%rdi,4)
	vmovups	%ymm3, -128(%rcx,%rdi,4)
	vmovdqu	-96(%rbx,%rdi,4), %ymm0
	vmovdqu	-64(%rbx,%rdi,4), %ymm1
	vmovdqu	-32(%rbx,%rdi,4), %ymm2
	vmovups	(%rbx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi,4)
	vmovdqu	%ymm1, -64(%rcx,%rdi,4)
	vmovdqu	%ymm2, -32(%rcx,%rdi,4)
	vmovups	%ymm3, (%rcx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r13
	jne	LBB19_129
LBB19_130:
	testq	%r12, %r12
	je	LBB19_133
## %bb.131:
	leaq	(%rax,%rdi), %rcx
	leaq	(%r14,%rcx,4), %rcx
	addq	$96, %rcx
	addq	%rdx, %rdi
	leaq	(%r8,%rdi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_132:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rsi,%rdi), %ymm0
	vmovdqu	-64(%rsi,%rdi), %ymm1
	vmovdqu	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi)
	vmovdqu	%ymm1, -64(%rcx,%rdi)
	vmovdqu	%ymm2, -32(%rcx,%rdi)
	vmovups	%ymm3, (%rcx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r12
	jne	LBB19_132
LBB19_133:
	addq	%r10, %rax
	cmpq	%r10, %r15
	jne	LBB19_135
## %bb.134:
	movq	-112(%rbp), %r12                ## 8-byte Reload
	jmp	LBB19_142
LBB19_135:
	addq	%r10, %rdx
	movq	-112(%rbp), %r12                ## 8-byte Reload
LBB19_136:
	movl	%r12d, %esi
	subl	%edx, %esi
	movq	%rdx, %rcx
	notq	%rcx
	addq	%r12, %rcx
	andq	$7, %rsi
	je	LBB19_138
	.p2align	4, 0x90
LBB19_137:                              ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rdx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rdx
	decq	%rsi
	jne	LBB19_137
LBB19_138:
	cmpq	$7, %rcx
	jb	LBB19_142
## %bb.139:
	movq	%r12, %rcx
	subq	%rdx, %rcx
	leaq	(%r8,%rdx,4), %rsi
	addq	$28, %rsi
	leaq	(%r14,%rax,4), %rdi
	addq	$28, %rdi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB19_140:                              ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rdx,4), %ebx
	movl	%ebx, -28(%rdi,%rdx,4)
	movl	-24(%rsi,%rdx,4), %ebx
	movl	%ebx, -24(%rdi,%rdx,4)
	movl	-20(%rsi,%rdx,4), %ebx
	movl	%ebx, -20(%rdi,%rdx,4)
	movl	-16(%rsi,%rdx,4), %ebx
	movl	%ebx, -16(%rdi,%rdx,4)
	movl	-12(%rsi,%rdx,4), %ebx
	movl	%ebx, -12(%rdi,%rdx,4)
	movl	-8(%rsi,%rdx,4), %ebx
	movl	%ebx, -8(%rdi,%rdx,4)
	movl	-4(%rsi,%rdx,4), %ebx
	movl	%ebx, -4(%rdi,%rdx,4)
	movl	(%rsi,%rdx,4), %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB19_140
## %bb.141:
	addq	%rdx, %rax
LBB19_142:
	subl	%r11d, %r12d
	movl	%r12d, -76(%rbp)
	leaq	(%r9,%r9), %rcx
	leaq	(%rcx,%rcx,2), %r11
	movslq	-72(%rbp), %r10
	leaq	-8(%r10), %rcx
	movq	%r11, %rdx
	cmpq	%rcx, %r11
	jge	LBB19_144
	.p2align	4, 0x90
LBB19_143:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	cmpq	%rcx, %rdx
	jl	LBB19_143
LBB19_144:
	cmpq	%r10, %rdx
	movq	%r12, -112(%rbp)                ## 8-byte Spill
	jge	LBB19_164
## %bb.145:
	movq	%r10, %r15
	subq	%rdx, %r15
	cmpq	$32, %r15
	jb	LBB19_158
## %bb.146:
	leaq	(%r14,%rax,4), %rcx
	leaq	(%r8,%r10,4), %rsi
	cmpq	%rsi, %rcx
	jae	LBB19_148
## %bb.147:
	leaq	(%rax,%r10), %rcx
	subq	%rdx, %rcx
	leaq	(%r14,%rcx,4), %rcx
	leaq	(%r8,%rdx,4), %rsi
	cmpq	%rcx, %rsi
	jb	LBB19_158
LBB19_148:
	movq	%r10, -104(%rbp)                ## 8-byte Spill
	movq	%r15, %r10
	andq	$-32, %r10
	leaq	-32(%r10), %rcx
	movq	%rcx, %r13
	shrq	$5, %r13
	incq	%r13
	movl	%r13d, %r12d
	andl	$3, %r12d
	cmpq	$96, %rcx
	jae	LBB19_150
## %bb.149:
	xorl	%edi, %edi
	jmp	LBB19_152
LBB19_150:
	leaq	(%r8,%rdx,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rcx
	addq	$480, %rcx                      ## imm = 0x1E0
	andq	$-4, %r13
	negq	%r13
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_151:                              ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rdi,4), %ymm0
	vmovups	-448(%rbx,%rdi,4), %ymm1
	vmovups	-416(%rbx,%rdi,4), %ymm2
	vmovups	-384(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rcx,%rdi,4)
	vmovups	%ymm1, -448(%rcx,%rdi,4)
	vmovups	%ymm2, -416(%rcx,%rdi,4)
	vmovups	%ymm3, -384(%rcx,%rdi,4)
	vmovups	-352(%rbx,%rdi,4), %ymm0
	vmovups	-320(%rbx,%rdi,4), %ymm1
	vmovups	-288(%rbx,%rdi,4), %ymm2
	vmovups	-256(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rcx,%rdi,4)
	vmovups	%ymm1, -320(%rcx,%rdi,4)
	vmovups	%ymm2, -288(%rcx,%rdi,4)
	vmovups	%ymm3, -256(%rcx,%rdi,4)
	vmovups	-224(%rbx,%rdi,4), %ymm0
	vmovups	-192(%rbx,%rdi,4), %ymm1
	vmovups	-160(%rbx,%rdi,4), %ymm2
	vmovups	-128(%rbx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rcx,%rdi,4)
	vmovups	%ymm1, -192(%rcx,%rdi,4)
	vmovups	%ymm2, -160(%rcx,%rdi,4)
	vmovups	%ymm3, -128(%rcx,%rdi,4)
	vmovdqu	-96(%rbx,%rdi,4), %ymm0
	vmovdqu	-64(%rbx,%rdi,4), %ymm1
	vmovdqu	-32(%rbx,%rdi,4), %ymm2
	vmovups	(%rbx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi,4)
	vmovdqu	%ymm1, -64(%rcx,%rdi,4)
	vmovdqu	%ymm2, -32(%rcx,%rdi,4)
	vmovups	%ymm3, (%rcx,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %r13
	jne	LBB19_151
LBB19_152:
	testq	%r12, %r12
	je	LBB19_155
## %bb.153:
	leaq	(%rax,%rdi), %rcx
	leaq	(%r14,%rcx,4), %rcx
	addq	$96, %rcx
	addq	%rdx, %rdi
	leaq	(%r8,%rdi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r12
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_154:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rsi,%rdi), %ymm0
	vmovdqu	-64(%rsi,%rdi), %ymm1
	vmovdqu	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rdi)
	vmovdqu	%ymm1, -64(%rcx,%rdi)
	vmovdqu	%ymm2, -32(%rcx,%rdi)
	vmovups	%ymm3, (%rcx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r12
	jne	LBB19_154
LBB19_155:
	addq	%r10, %rax
	cmpq	%r10, %r15
	jne	LBB19_157
## %bb.156:
	movq	-104(%rbp), %r10                ## 8-byte Reload
	jmp	LBB19_164
LBB19_157:
	addq	%r10, %rdx
	movq	-104(%rbp), %r10                ## 8-byte Reload
LBB19_158:
	movl	%r10d, %esi
	subl	%edx, %esi
	movq	%rdx, %rcx
	notq	%rcx
	addq	%r10, %rcx
	andq	$7, %rsi
	je	LBB19_160
	.p2align	4, 0x90
LBB19_159:                              ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rdx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rdx
	decq	%rsi
	jne	LBB19_159
LBB19_160:
	cmpq	$7, %rcx
	jb	LBB19_164
## %bb.161:
	movq	%r10, %rcx
	subq	%rdx, %rcx
	leaq	(%r8,%rdx,4), %rsi
	addq	$28, %rsi
	leaq	(%r14,%rax,4), %rdi
	addq	$28, %rdi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB19_162:                              ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rdx,4), %ebx
	movl	%ebx, -28(%rdi,%rdx,4)
	movl	-24(%rsi,%rdx,4), %ebx
	movl	%ebx, -24(%rdi,%rdx,4)
	movl	-20(%rsi,%rdx,4), %ebx
	movl	%ebx, -20(%rdi,%rdx,4)
	movl	-16(%rsi,%rdx,4), %ebx
	movl	%ebx, -16(%rdi,%rdx,4)
	movl	-12(%rsi,%rdx,4), %ebx
	movl	%ebx, -12(%rdi,%rdx,4)
	movl	-8(%rsi,%rdx,4), %ebx
	movl	%ebx, -8(%rdi,%rdx,4)
	movl	-4(%rsi,%rdx,4), %ebx
	movl	%ebx, -4(%rdi,%rdx,4)
	movl	(%rsi,%rdx,4), %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB19_162
## %bb.163:
	addq	%rdx, %rax
LBB19_164:
	subl	%r11d, %r10d
	movq	%r10, -104(%rbp)                ## 8-byte Spill
	movl	%r10d, -72(%rbp)
	leaq	(,%r9,8), %r10
	movq	%r10, %r15
	subq	%r9, %r15
	movslq	-68(%rbp), %r12
	leaq	-8(%r12), %rcx
	movq	%r15, %rdx
	cmpq	%rcx, %r15
	jge	LBB19_166
	.p2align	4, 0x90
LBB19_165:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rdx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rdx
	cmpq	%rcx, %rdx
	jl	LBB19_165
LBB19_166:
	cmpq	%r12, %rdx
	jge	LBB19_185
## %bb.167:
	movq	%r12, %r11
	subq	%rdx, %r11
	cmpq	$32, %r11
	jb	LBB19_179
## %bb.168:
	leaq	(%r14,%rax,4), %rcx
	leaq	(%r8,%r12,4), %rsi
	cmpq	%rsi, %rcx
	jae	LBB19_170
## %bb.169:
	leaq	(%rax,%r12), %rcx
	subq	%rdx, %rcx
	leaq	(%r14,%rcx,4), %rcx
	leaq	(%r8,%rdx,4), %rsi
	cmpq	%rcx, %rsi
	jb	LBB19_179
LBB19_170:
	movq	%r11, %rsi
	andq	$-32, %rsi
	leaq	-32(%rsi), %rcx
	movq	%rcx, %rbx
	shrq	$5, %rbx
	incq	%rbx
	movl	%ebx, %r13d
	andl	$3, %r13d
	cmpq	$96, %rcx
	jae	LBB19_172
## %bb.171:
	xorl	%edi, %edi
	jmp	LBB19_174
LBB19_172:
	leaq	(%r8,%rdx,4), %rcx
	addq	$480, %rcx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %r9
	addq	$480, %r9                       ## imm = 0x1E0
	andq	$-4, %rbx
	negq	%rbx
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_173:                              ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rcx,%rdi,4), %ymm0
	vmovups	-448(%rcx,%rdi,4), %ymm1
	vmovups	-416(%rcx,%rdi,4), %ymm2
	vmovups	-384(%rcx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%r9,%rdi,4)
	vmovups	%ymm1, -448(%r9,%rdi,4)
	vmovups	%ymm2, -416(%r9,%rdi,4)
	vmovups	%ymm3, -384(%r9,%rdi,4)
	vmovups	-352(%rcx,%rdi,4), %ymm0
	vmovups	-320(%rcx,%rdi,4), %ymm1
	vmovups	-288(%rcx,%rdi,4), %ymm2
	vmovups	-256(%rcx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%r9,%rdi,4)
	vmovups	%ymm1, -320(%r9,%rdi,4)
	vmovups	%ymm2, -288(%r9,%rdi,4)
	vmovups	%ymm3, -256(%r9,%rdi,4)
	vmovups	-224(%rcx,%rdi,4), %ymm0
	vmovups	-192(%rcx,%rdi,4), %ymm1
	vmovups	-160(%rcx,%rdi,4), %ymm2
	vmovups	-128(%rcx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%r9,%rdi,4)
	vmovups	%ymm1, -192(%r9,%rdi,4)
	vmovups	%ymm2, -160(%r9,%rdi,4)
	vmovups	%ymm3, -128(%r9,%rdi,4)
	vmovdqu	-96(%rcx,%rdi,4), %ymm0
	vmovdqu	-64(%rcx,%rdi,4), %ymm1
	vmovdqu	-32(%rcx,%rdi,4), %ymm2
	vmovups	(%rcx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%r9,%rdi,4)
	vmovdqu	%ymm1, -64(%r9,%rdi,4)
	vmovdqu	%ymm2, -32(%r9,%rdi,4)
	vmovups	%ymm3, (%r9,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %rbx
	jne	LBB19_173
LBB19_174:
	testq	%r13, %r13
	je	LBB19_177
## %bb.175:
	leaq	(%rax,%rdi), %rcx
	leaq	(%r14,%rcx,4), %rcx
	addq	$96, %rcx
	addq	%rdx, %rdi
	leaq	(%r8,%rdi,4), %rdi
	addq	$96, %rdi
	shlq	$7, %r13
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB19_176:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rdi,%rbx), %ymm0
	vmovdqu	-64(%rdi,%rbx), %ymm1
	vmovdqu	-32(%rdi,%rbx), %ymm2
	vmovups	(%rdi,%rbx), %ymm3
	vmovdqu	%ymm0, -96(%rcx,%rbx)
	vmovdqu	%ymm1, -64(%rcx,%rbx)
	vmovdqu	%ymm2, -32(%rcx,%rbx)
	vmovups	%ymm3, (%rcx,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r13
	jne	LBB19_176
LBB19_177:
	addq	%rsi, %rax
	cmpq	%rsi, %r11
	je	LBB19_185
## %bb.178:
	addq	%rsi, %rdx
LBB19_179:
	movl	%r12d, %esi
	subl	%edx, %esi
	movq	%rdx, %rcx
	notq	%rcx
	addq	%r12, %rcx
	andq	$7, %rsi
	je	LBB19_181
	.p2align	4, 0x90
LBB19_180:                              ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rdx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rdx
	decq	%rsi
	jne	LBB19_180
LBB19_181:
	cmpq	$7, %rcx
	jb	LBB19_185
## %bb.182:
	movq	%r12, %rcx
	subq	%rdx, %rcx
	leaq	(%r8,%rdx,4), %rsi
	addq	$28, %rsi
	leaq	(%r14,%rax,4), %rdi
	addq	$28, %rdi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB19_183:                              ## =>This Inner Loop Header: Depth=1
	movl	-28(%rsi,%rdx,4), %ebx
	movl	%ebx, -28(%rdi,%rdx,4)
	movl	-24(%rsi,%rdx,4), %ebx
	movl	%ebx, -24(%rdi,%rdx,4)
	movl	-20(%rsi,%rdx,4), %ebx
	movl	%ebx, -20(%rdi,%rdx,4)
	movl	-16(%rsi,%rdx,4), %ebx
	movl	%ebx, -16(%rdi,%rdx,4)
	movl	-12(%rsi,%rdx,4), %ebx
	movl	%ebx, -12(%rdi,%rdx,4)
	movl	-8(%rsi,%rdx,4), %ebx
	movl	%ebx, -8(%rdi,%rdx,4)
	movl	-4(%rsi,%rdx,4), %ebx
	movl	%ebx, -4(%rdi,%rdx,4)
	movl	(%rsi,%rdx,4), %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	$8, %rdx
	cmpq	%rdx, %rcx
	jne	LBB19_183
## %bb.184:
	addq	%rdx, %rax
LBB19_185:
	subl	%r15d, %r12d
	movl	%r12d, -68(%rbp)
	movslq	-64(%rbp), %r13
	leaq	-8(%r13), %rdx
	movq	%r10, %rcx
	cmpq	%rdx, %r10
	jge	LBB19_187
	.p2align	4, 0x90
LBB19_186:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	(%r8,%rcx,4), %ymm0
	vmovdqu	%ymm0, (%r14,%rax,4)
	addq	$8, %rax
	addq	$8, %rcx
	cmpq	%rdx, %rcx
	jl	LBB19_186
LBB19_187:
	cmpq	%r13, %rcx
	jge	LBB19_205
## %bb.188:
	movq	%r13, %r11
	subq	%rcx, %r11
	cmpq	$32, %r11
	jb	LBB19_200
## %bb.189:
	leaq	(%r14,%rax,4), %rdx
	leaq	(%r8,%r13,4), %rsi
	cmpq	%rsi, %rdx
	jae	LBB19_191
## %bb.190:
	leaq	(%rax,%r13), %rdx
	subq	%rcx, %rdx
	leaq	(%r14,%rdx,4), %rdx
	leaq	(%r8,%rcx,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB19_200
LBB19_191:
	movq	%r11, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rbx
	shrq	$5, %rbx
	incq	%rbx
	movl	%ebx, %r15d
	andl	$3, %r15d
	cmpq	$96, %rdx
	jae	LBB19_193
## %bb.192:
	xorl	%edi, %edi
	jmp	LBB19_195
LBB19_193:
	leaq	(%r8,%rcx,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	(%r14,%rax,4), %rsi
	addq	$480, %rsi                      ## imm = 0x1E0
	andq	$-4, %rbx
	negq	%rbx
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_194:                              ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdx,%rdi,4), %ymm0
	vmovups	-448(%rdx,%rdi,4), %ymm1
	vmovups	-416(%rdx,%rdi,4), %ymm2
	vmovups	-384(%rdx,%rdi,4), %ymm3
	vmovups	%ymm0, -480(%rsi,%rdi,4)
	vmovups	%ymm1, -448(%rsi,%rdi,4)
	vmovups	%ymm2, -416(%rsi,%rdi,4)
	vmovups	%ymm3, -384(%rsi,%rdi,4)
	vmovups	-352(%rdx,%rdi,4), %ymm0
	vmovups	-320(%rdx,%rdi,4), %ymm1
	vmovups	-288(%rdx,%rdi,4), %ymm2
	vmovups	-256(%rdx,%rdi,4), %ymm3
	vmovups	%ymm0, -352(%rsi,%rdi,4)
	vmovups	%ymm1, -320(%rsi,%rdi,4)
	vmovups	%ymm2, -288(%rsi,%rdi,4)
	vmovups	%ymm3, -256(%rsi,%rdi,4)
	vmovups	-224(%rdx,%rdi,4), %ymm0
	vmovups	-192(%rdx,%rdi,4), %ymm1
	vmovups	-160(%rdx,%rdi,4), %ymm2
	vmovups	-128(%rdx,%rdi,4), %ymm3
	vmovups	%ymm0, -224(%rsi,%rdi,4)
	vmovups	%ymm1, -192(%rsi,%rdi,4)
	vmovups	%ymm2, -160(%rsi,%rdi,4)
	vmovups	%ymm3, -128(%rsi,%rdi,4)
	vmovdqu	-96(%rdx,%rdi,4), %ymm0
	vmovdqu	-64(%rdx,%rdi,4), %ymm1
	vmovdqu	-32(%rdx,%rdi,4), %ymm2
	vmovups	(%rdx,%rdi,4), %ymm3
	vmovdqu	%ymm0, -96(%rsi,%rdi,4)
	vmovdqu	%ymm1, -64(%rsi,%rdi,4)
	vmovdqu	%ymm2, -32(%rsi,%rdi,4)
	vmovups	%ymm3, (%rsi,%rdi,4)
	subq	$-128, %rdi
	addq	$4, %rbx
	jne	LBB19_194
LBB19_195:
	testq	%r15, %r15
	je	LBB19_198
## %bb.196:
	leaq	(%rax,%rdi), %rdx
	leaq	(%r14,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%rcx, %rdi
	leaq	(%r8,%rdi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r15
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB19_197:                              ## =>This Inner Loop Header: Depth=1
	vmovdqu	-96(%rsi,%rdi), %ymm0
	vmovdqu	-64(%rsi,%rdi), %ymm1
	vmovdqu	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovdqu	%ymm0, -96(%rdx,%rdi)
	vmovdqu	%ymm1, -64(%rdx,%rdi)
	vmovdqu	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r15
	jne	LBB19_197
LBB19_198:
	cmpq	%r9, %r11
	je	LBB19_205
## %bb.199:
	addq	%r9, %rcx
	addq	%r9, %rax
LBB19_200:
	movl	%r13d, %esi
	subl	%ecx, %esi
	movq	%rcx, %rdx
	notq	%rdx
	addq	%r13, %rdx
	andq	$7, %rsi
	je	LBB19_202
	.p2align	4, 0x90
LBB19_201:                              ## =>This Inner Loop Header: Depth=1
	movl	(%r8,%rcx,4), %edi
	movl	%edi, (%r14,%rax,4)
	incq	%rax
	incq	%rcx
	decq	%rsi
	jne	LBB19_201
LBB19_202:
	cmpq	$7, %rdx
	jb	LBB19_205
## %bb.203:
	movq	%r13, %rdx
	subq	%rcx, %rdx
	leaq	(%r8,%rcx,4), %rcx
	addq	$28, %rcx
	leaq	(%r14,%rax,4), %rax
	addq	$28, %rax
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB19_204:                              ## =>This Inner Loop Header: Depth=1
	movl	-28(%rcx,%rsi,4), %edi
	movl	%edi, -28(%rax,%rsi,4)
	movl	-24(%rcx,%rsi,4), %edi
	movl	%edi, -24(%rax,%rsi,4)
	movl	-20(%rcx,%rsi,4), %edi
	movl	%edi, -20(%rax,%rsi,4)
	movl	-16(%rcx,%rsi,4), %edi
	movl	%edi, -16(%rax,%rsi,4)
	movl	-12(%rcx,%rsi,4), %edi
	movl	%edi, -12(%rax,%rsi,4)
	movl	-8(%rcx,%rsi,4), %edi
	movl	%edi, -8(%rax,%rsi,4)
	movl	-4(%rcx,%rsi,4), %edi
	movl	%edi, -4(%rax,%rsi,4)
	movl	(%rcx,%rsi,4), %edi
	movl	%edi, (%rax,%rsi,4)
	addq	$8, %rsi
	cmpq	%rsi, %rdx
	jne	LBB19_204
LBB19_205:
	subl	%r10d, %r13d
	movq	-152(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %ebx
	movq	-160(%rbp), %rsi                ## 8-byte Reload
	addl	%esi, %ebx
	leal	(%rax,%rsi), %edx
	decl	%edx
	movq	%r14, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	vzeroupper
	callq	_sort_quick_multi
	movq	-144(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %r15d
	addl	%ebx, %r15d
	leal	(%rax,%rbx), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%ebx, %esi
	callq	_sort_quick_multi
	movq	-136(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %ebx
	addl	%r15d, %ebx
	leal	(%rax,%r15), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%r15d, %esi
	callq	_sort_quick_multi
	movq	-128(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %r15d
	addl	%ebx, %r15d
	leal	(%rax,%rbx), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%ebx, %esi
	callq	_sort_quick_multi
	movq	-120(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %ebx
	addl	%r15d, %ebx
	leal	(%rax,%r15), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%r15d, %esi
	callq	_sort_quick_multi
	movq	-112(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %r15d
	addl	%ebx, %r15d
	leal	(%rax,%rbx), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%ebx, %esi
	callq	_sort_quick_multi
	movq	-104(%rbp), %rax                ## 8-byte Reload
	movl	%eax, %ebx
	addl	%r15d, %ebx
	leal	(%rax,%r15), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%r15d, %esi
	callq	_sort_quick_multi
	movl	%r12d, %r15d
	addl	%ebx, %r15d
	leal	(%r12,%rbx), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%ebx, %esi
	callq	_sort_quick_multi
	leal	(%r15,%r13), %edx
	decl	%edx
	movq	%r14, %rdi
	movl	%r15d, %esi
	callq	_sort_quick_multi
LBB19_39:
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB19_206
## %bb.40:
	addq	$120, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB19_206:
	callq	___stack_chk_fail
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_simd           ## -- Begin function partition_quick_simd
	.p2align	4, 0x90
_partition_quick_simd:                  ## @partition_quick_simd
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %ecx
	subl	%esi, %ecx
	cmpl	$2, %ecx
	jl	LBB20_2
## %bb.1:
	leal	(%rdx,%rsi), %r8d
	movl	%r8d, %eax
	shrl	$31, %eax
	addl	%r8d, %eax
	sarl	%eax
	movslq	%esi, %r9
	movl	(%rdi,%r9,4), %r10d
	movslq	%eax, %r11
	movl	(%rdi,%r11,4), %r8d
	movslq	%edx, %r14
	movl	(%rdi,%r14,4), %r15d
	cmpl	%r8d, %r10d
	movl	%r8d, %eax
	cmovll	%r10d, %eax
	movl	%r8d, %ebx
	cmovgl	%r10d, %ebx
	cmpl	%r15d, %eax
	cmovgel	%r15d, %eax
	cmpl	%r15d, %ebx
	cmovlel	%r15d, %ebx
	addl	%r10d, %r8d
	addl	%r15d, %r8d
	subl	%eax, %r8d
	subl	%ebx, %r8d
	movl	%eax, (%rdi,%r9,4)
	movl	%r8d, (%rdi,%r14,4)
	movl	%ebx, (%rdi,%r11,4)
	jmp	LBB20_3
LBB20_2:
	movslq	%edx, %rax
	movl	(%rdi,%rax,4), %r8d
LBB20_3:
	leal	7(%rcx), %eax
	testl	%ecx, %ecx
	cmovnsl	%ecx, %eax
	andl	$-8, %eax
	cmpl	%esi, %eax
	jle	LBB20_4
## %bb.12:
	vmovd	%r8d, %xmm0
	vpbroadcastd	%xmm0, %ymm0
	movslq	%esi, %r11
	movslq	%eax, %r9
	.p2align	4, 0x90
LBB20_13:                               ## =>This Inner Loop Header: Depth=1
	vpcmpgtd	(%rdi,%r11,4), %ymm0, %ymm1
	vpsrld	$31, %ymm1, %ymm1
	vmovdqu	(%rdi,%r11,4), %xmm2
	vmovdqu	%ymm1, -64(%rbp)
	vmovd	%xmm1, %r14d
	movslq	%esi, %rsi
	movl	(%rdi,%rsi,4), %r10d
	vmovd	%xmm2, %eax
	movl	%r14d, %ebx
	xorl	$1, %ebx
	movl	%eax, %ecx
	imull	%ebx, %ecx
	imull	%r10d, %ebx
	imull	%r14d, %r10d
	addl	%r10d, %ecx
	imull	%r14d, %eax
	addl	%ebx, %eax
	movl	%ecx, (%rdi,%r11,4)
	movl	%eax, (%rdi,%rsi,4)
	addl	%r14d, %esi
	vpextrd	$1, %xmm1, %r10d
	movslq	%esi, %rcx
	movl	(%rdi,%rcx,4), %r14d
	movl	4(%rdi,%r11,4), %ebx
	movl	%r10d, %eax
	xorl	$1, %eax
	movl	%ebx, %esi
	imull	%eax, %esi
	imull	%r14d, %eax
	imull	%r10d, %r14d
	addl	%r14d, %esi
	imull	%r10d, %ebx
	addl	%eax, %ebx
	movl	%esi, 4(%rdi,%r11,4)
	movl	%ebx, (%rdi,%rcx,4)
	addl	%r10d, %ecx
	vpextrd	$2, %xmm1, %r14d
	movslq	%ecx, %rcx
	movl	(%rdi,%rcx,4), %r10d
	movl	8(%rdi,%r11,4), %ebx
	movl	%r14d, %eax
	xorl	$1, %eax
	movl	%ebx, %esi
	imull	%eax, %esi
	imull	%r10d, %eax
	imull	%r14d, %r10d
	addl	%r10d, %esi
	imull	%r14d, %ebx
	addl	%eax, %ebx
	movl	%esi, 8(%rdi,%r11,4)
	movl	%ebx, (%rdi,%rcx,4)
	addl	%r14d, %ecx
	vpextrd	$3, %xmm1, %r14d
	movslq	%ecx, %rcx
	movl	(%rdi,%rcx,4), %r10d
	movl	12(%rdi,%r11,4), %ebx
	movl	%r14d, %eax
	xorl	$1, %eax
	movl	%ebx, %esi
	imull	%eax, %esi
	imull	%r10d, %eax
	imull	%r14d, %r10d
	addl	%r10d, %esi
	imull	%r14d, %ebx
	addl	%eax, %ebx
	movl	%esi, 12(%rdi,%r11,4)
	movl	%ebx, (%rdi,%rcx,4)
	addl	%r14d, %ecx
	vextracti128	$1, %ymm1, %xmm1
	vmovd	%xmm1, %r14d
	movslq	%ecx, %rcx
	movl	(%rdi,%rcx,4), %r10d
	movl	16(%rdi,%r11,4), %ebx
	movl	%r14d, %eax
	xorl	$1, %eax
	movl	%ebx, %esi
	imull	%eax, %esi
	imull	%r10d, %eax
	imull	%r14d, %r10d
	addl	%r10d, %esi
	imull	%r14d, %ebx
	addl	%eax, %ebx
	movl	%esi, 16(%rdi,%r11,4)
	movl	%ebx, (%rdi,%rcx,4)
	addl	%r14d, %ecx
	vpextrd	$1, %xmm1, %r14d
	movslq	%ecx, %rcx
	movl	(%rdi,%rcx,4), %r10d
	movl	20(%rdi,%r11,4), %ebx
	movl	%r14d, %eax
	xorl	$1, %eax
	movl	%ebx, %esi
	imull	%eax, %esi
	imull	%r10d, %eax
	imull	%r14d, %r10d
	addl	%r10d, %esi
	imull	%r14d, %ebx
	addl	%eax, %ebx
	movl	%esi, 20(%rdi,%r11,4)
	movl	%ebx, (%rdi,%rcx,4)
	addl	%r14d, %ecx
	movl	-40(%rbp), %r14d
	movslq	%ecx, %rcx
	movl	(%rdi,%rcx,4), %r10d
	movl	24(%rdi,%r11,4), %ebx
	movl	$1, %esi
	subl	%r14d, %esi
	movl	%ebx, %eax
	imull	%esi, %eax
	imull	%r10d, %esi
	imull	%r14d, %r10d
	addl	%r10d, %eax
	imull	%r14d, %ebx
	addl	%esi, %ebx
	movl	%eax, 24(%rdi,%r11,4)
	movl	%ebx, (%rdi,%rcx,4)
	addl	%r14d, %ecx
	movl	-36(%rbp), %r14d
	movslq	%ecx, %rsi
	movl	(%rdi,%rsi,4), %r10d
	movl	28(%rdi,%r11,4), %ebx
	movl	$1, %ecx
	subl	%r14d, %ecx
	movl	%ebx, %eax
	imull	%ecx, %eax
	imull	%r10d, %ecx
	imull	%r14d, %r10d
	addl	%r10d, %eax
	imull	%r14d, %ebx
	addl	%ecx, %ebx
	movl	%eax, 28(%rdi,%r11,4)
	movl	%ebx, (%rdi,%rsi,4)
	addl	%r14d, %esi
	addq	$8, %r11
	cmpq	%r9, %r11
	jl	LBB20_13
## %bb.5:
	cmpl	%edx, %r11d
	jge	LBB20_6
LBB20_8:
	movslq	%r11d, %r14
	movslq	%edx, %r9
	subl	%r11d, %edx
	movq	%r14, %rcx
	notq	%rcx
	testb	$1, %dl
	je	LBB20_10
## %bb.9:
	movl	(%rdi,%r14,4), %edx
	xorl	%r10d, %r10d
	cmpl	%edx, %r8d
	setg	%r10b
	movslq	%esi, %rsi
	movl	(%rdi,%rsi,4), %r11d
	movl	%r11d, %ebx
	cmovgl	%edx, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%r11d, %edx
	movl	%edx, (%rdi,%r14,4)
	addl	%r10d, %esi
	incq	%r14
LBB20_10:
	addq	%r9, %rcx
	je	LBB20_7
	.p2align	4, 0x90
LBB20_11:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r14,4), %ecx
	xorl	%edx, %edx
	cmpl	%ecx, %r8d
	setg	%dl
	movslq	%esi, %rsi
	movl	(%rdi,%rsi,4), %eax
	movl	%eax, %ebx
	cmovgl	%ecx, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%eax, %ecx
	movl	%ecx, (%rdi,%r14,4)
	addl	%edx, %esi
	movl	4(%rdi,%r14,4), %eax
	xorl	%ecx, %ecx
	cmpl	%eax, %r8d
	setg	%cl
	movslq	%esi, %rsi
	movl	(%rdi,%rsi,4), %ebx
	movl	%ebx, %edx
	cmovgl	%eax, %edx
	movl	%edx, (%rdi,%rsi,4)
	cmovgl	%ebx, %eax
	movl	%eax, 4(%rdi,%r14,4)
	addl	%ecx, %esi
	addq	$2, %r14
	cmpq	%r14, %r9
	jne	LBB20_11
	jmp	LBB20_7
LBB20_4:
	movl	%esi, %r11d
	cmpl	%edx, %r11d
	jl	LBB20_8
LBB20_6:
	movslq	%edx, %r9
LBB20_7:
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r9,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r9,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_simd                ## -- Begin function sort_quick_simd
	.p2align	4, 0x90
_sort_quick_simd:                       ## @sort_quick_simd
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	%edx, %esi
	jge	LBB21_3
## %bb.1:
	movl	%edx, %r14d
	movl	%esi, %r12d
	movq	%rdi, %r15
	.p2align	4, 0x90
LBB21_2:                                ## =>This Inner Loop Header: Depth=1
	movq	%r15, %rdi
	movl	%r12d, %esi
	movl	%r14d, %edx
	callq	_partition_quick_simd
	movl	%eax, %ebx
	leal	-1(%rbx), %edx
	movq	%r15, %rdi
	movl	%r12d, %esi
	callq	_sort_quick_simd
	incl	%ebx
	movl	%ebx, %r12d
	cmpl	%r14d, %ebx
	jl	LBB21_2
LBB21_3:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_optimized_swap ## -- Begin function partition_quick_optimized_swap
	.p2align	4, 0x90
_partition_quick_optimized_swap:        ## @partition_quick_optimized_swap
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB22_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %r9d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r15d
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r11d
	cmpl	%r15d, %r9d
	movl	%r15d, %ebx
	cmovll	%r9d, %ebx
	movl	%r15d, %r14d
	cmovgl	%r9d, %r14d
	cmpl	%r11d, %ebx
	cmovgel	%r11d, %ebx
	cmpl	%r11d, %r14d
	cmovlel	%r11d, %r14d
	addl	%r9d, %r15d
	addl	%r11d, %r15d
	subl	%ebx, %r15d
	subl	%r14d, %r15d
	movl	%ebx, (%rdi,%rax,4)
	movl	%r15d, (%rdi,%r8,4)
	movl	%r14d, (%rdi,%r10,4)
	cmpl	%esi, %edx
	jg	LBB22_4
	jmp	LBB22_8
LBB22_2:
	movslq	%edx, %r8
	movl	(%rdi,%r8,4), %r15d
	movslq	%esi, %rax
	cmpl	%esi, %edx
	jle	LBB22_8
LBB22_4:
	movl	%r8d, %r10d
	subl	%eax, %r10d
	movq	%rax, %r9
	notq	%r9
	addq	%r8, %r9
	movq	%rax, %rdx
	andq	$3, %r10
	je	LBB22_6
	.p2align	4, 0x90
LBB22_5:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %ebx
	xorl	%ecx, %ecx
	cmpl	%ebx, %r15d
	setg	%cl
	movl	(%rdi,%rax,4), %r11d
	movl	%r11d, %esi
	cmovgl	%ebx, %esi
	movl	%esi, (%rdi,%rax,4)
	cmovgl	%r11d, %ebx
	movl	%ebx, (%rdi,%rdx,4)
	addq	%rcx, %rax
	incq	%rdx
	decq	%r10
	jne	LBB22_5
LBB22_6:
	cmpq	$3, %r9
	jb	LBB22_8
	.p2align	4, 0x90
LBB22_7:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rdx,4), %ecx
	xorl	%esi, %esi
	cmpl	%ecx, %r15d
	setg	%sil
	movl	(%rdi,%rax,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%ecx, %ebx
	movl	%ebx, (%rdi,%rax,4)
	cmovgl	%r9d, %ecx
	movl	%ecx, (%rdi,%rdx,4)
	addq	%rax, %rsi
	movl	4(%rdi,%rdx,4), %eax
	xorl	%ecx, %ecx
	cmpl	%eax, %r15d
	setg	%cl
	movl	(%rdi,%rsi,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%r9d, %eax
	movl	%eax, 4(%rdi,%rdx,4)
	addq	%rsi, %rcx
	movl	8(%rdi,%rdx,4), %eax
	xorl	%esi, %esi
	cmpl	%eax, %r15d
	setg	%sil
	movl	(%rdi,%rcx,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%rdi,%rcx,4)
	cmovgl	%r9d, %eax
	movl	%eax, 8(%rdi,%rdx,4)
	addq	%rcx, %rsi
	movl	12(%rdi,%rdx,4), %ecx
	xorl	%eax, %eax
	cmpl	%ecx, %r15d
	setg	%al
	movl	(%rdi,%rsi,4), %r9d
	movl	%r9d, %ebx
	cmovgl	%ecx, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%r9d, %ecx
	movl	%ecx, 12(%rdi,%rdx,4)
	addq	%rsi, %rax
	addq	$4, %rdx
	cmpq	%rdx, %r8
	jne	LBB22_7
LBB22_8:
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r8,4), %edx
	movl	%edx, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r8,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_optimized_swap      ## -- Begin function sort_quick_optimized_swap
	.p2align	4, 0x90
_sort_quick_optimized_swap:             ## @sort_quick_optimized_swap
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB23_11
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %r12
	movslq	%edx, %r15
	jmp	LBB23_2
	.p2align	4, 0x90
LBB23_10:                               ##   in Loop: Header=BB23_2 Depth=1
	movl	(%r12,%rbx,4), %eax
	movl	(%r12,%r15,4), %ecx
	movl	%ecx, (%r12,%rbx,4)
	movl	%eax, (%r12,%r15,4)
	leal	-1(%rbx), %edx
	movq	%r12, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	callq	_sort_quick_optimized_swap
	incl	%ebx
	movl	%ebx, %esi
	cmpl	%r14d, %ebx
	jge	LBB23_11
LBB23_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB23_7 Depth 2
                                        ##     Child Loop BB23_9 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB23_11
## %bb.3:                               ##   in Loop: Header=BB23_2 Depth=1
	cmpl	$1, %eax
	jne	LBB23_4
## %bb.5:                               ##   in Loop: Header=BB23_2 Depth=1
	movl	(%r12,%r15,4), %r10d
	movslq	%esi, %rbx
	jmp	LBB23_6
	.p2align	4, 0x90
LBB23_4:                                ##   in Loop: Header=BB23_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rbx
	movl	(%r12,%rbx,4), %r9d
	movslq	%ecx, %r8
	movl	(%r12,%r8,4), %r10d
	movl	(%r12,%r15,4), %edi
	cmpl	%r10d, %r9d
	movl	%r10d, %ecx
	cmovll	%r9d, %ecx
	movl	%r10d, %edx
	cmovgl	%r9d, %edx
	cmpl	%edi, %ecx
	cmovgel	%edi, %ecx
	cmpl	%edi, %edx
	cmovlel	%edi, %edx
	addl	%r9d, %r10d
	addl	%edi, %r10d
	subl	%ecx, %r10d
	subl	%edx, %r10d
	movl	%ecx, (%r12,%rbx,4)
	movl	%r10d, (%r12,%r15,4)
	movl	%edx, (%r12,%r8,4)
LBB23_6:                                ##   in Loop: Header=BB23_2 Depth=1
	movl	%r14d, %r9d
	subl	%ebx, %r9d
	movq	%rbx, %r8
	notq	%r8
	addq	%r15, %r8
	movq	%rbx, %rcx
	andq	$3, %r9
	je	LBB23_8
	.p2align	4, 0x90
LBB23_7:                                ##   Parent Loop BB23_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r12,%rcx,4), %edx
	xorl	%eax, %eax
	cmpl	%edx, %r10d
	setg	%al
	movl	(%r12,%rbx,4), %r11d
	movl	%r11d, %edi
	cmovgl	%edx, %edi
	movl	%edi, (%r12,%rbx,4)
	cmovgl	%r11d, %edx
	movl	%edx, (%r12,%rcx,4)
	addq	%rax, %rbx
	incq	%rcx
	decq	%r9
	jne	LBB23_7
LBB23_8:                                ##   in Loop: Header=BB23_2 Depth=1
	cmpq	$3, %r8
	jb	LBB23_10
	.p2align	4, 0x90
LBB23_9:                                ##   Parent Loop BB23_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r12,%rcx,4), %eax
	xorl	%edx, %edx
	cmpl	%eax, %r10d
	setg	%dl
	movl	(%r12,%rbx,4), %r8d
	movl	%r8d, %edi
	cmovgl	%eax, %edi
	movl	%edi, (%r12,%rbx,4)
	cmovgl	%r8d, %eax
	movl	%eax, (%r12,%rcx,4)
	addq	%rbx, %rdx
	movl	4(%r12,%rcx,4), %eax
	xorl	%edi, %edi
	cmpl	%eax, %r10d
	setg	%dil
	movl	(%r12,%rdx,4), %r8d
	movl	%r8d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%r12,%rdx,4)
	cmovgl	%r8d, %eax
	movl	%eax, 4(%r12,%rcx,4)
	addq	%rdx, %rdi
	movl	8(%r12,%rcx,4), %eax
	xorl	%edx, %edx
	cmpl	%eax, %r10d
	setg	%dl
	movl	(%r12,%rdi,4), %r8d
	movl	%r8d, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%r12,%rdi,4)
	cmovgl	%r8d, %eax
	movl	%eax, 8(%r12,%rcx,4)
	addq	%rdi, %rdx
	movl	12(%r12,%rcx,4), %eax
	xorl	%ebx, %ebx
	cmpl	%eax, %r10d
	setg	%bl
	movl	(%r12,%rdx,4), %r8d
	movl	%r8d, %edi
	cmovgl	%eax, %edi
	movl	%edi, (%r12,%rdx,4)
	cmovgl	%r8d, %eax
	movl	%eax, 12(%r12,%rcx,4)
	addq	%rdx, %rbx
	addq	$4, %rcx
	cmpq	%rcx, %r15
	jne	LBB23_9
	jmp	LBB23_10
LBB23_11:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_standard       ## -- Begin function partition_quick_standard
	.p2align	4, 0x90
_partition_quick_standard:              ## @partition_quick_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -32
	.cfi_offset %r14, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB24_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%rdi,%r8,4), %r14d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r9d
	movslq	%edx, %r11
	movl	(%rdi,%r11,4), %ecx
	cmpl	%r9d, %r14d
	movl	%r9d, %ebx
	cmovll	%r14d, %ebx
	movl	%r9d, %eax
	cmovgl	%r14d, %eax
	cmpl	%ecx, %ebx
	cmovgel	%ecx, %ebx
	cmpl	%ecx, %eax
	cmovlel	%ecx, %eax
	addl	%r14d, %r9d
	addl	%ecx, %r9d
	subl	%ebx, %r9d
	subl	%eax, %r9d
	movl	%ebx, (%rdi,%r8,4)
	movl	%r9d, (%rdi,%r11,4)
	movl	%eax, (%rdi,%r10,4)
	leal	-1(%rsi), %eax
	movl	%edx, %ecx
	subl	%esi, %ecx
	jg	LBB24_5
LBB24_4:
	movslq	%edx, %r10
	jmp	LBB24_19
LBB24_2:
	movslq	%edx, %rax
	movl	(%rdi,%rax,4), %r9d
	leal	-1(%rsi), %eax
	movl	%edx, %ecx
	subl	%esi, %ecx
	jle	LBB24_4
LBB24_5:
	movslq	%esi, %rsi
	movslq	%edx, %r10
	movq	%rsi, %r8
	notq	%r8
	addq	%r10, %r8
	andq	$3, %rcx
	jne	LBB24_6
LBB24_9:
	cmpq	$3, %r8
	jae	LBB24_10
LBB24_19:
	movslq	%eax, %rcx
	incl	%eax
	movl	4(%rdi,%rcx,4), %edx
	movl	(%rdi,%r10,4), %esi
	movl	%esi, 4(%rdi,%rcx,4)
	movl	%edx, (%rdi,%r10,4)
	popq	%rbx
	popq	%r14
	popq	%rbp
	retq
	.p2align	4, 0x90
LBB24_8:                                ##   in Loop: Header=BB24_6 Depth=1
	incq	%rsi
	decq	%rcx
	je	LBB24_9
LBB24_6:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rsi,4), %edx
	cmpl	%r9d, %edx
	jg	LBB24_8
## %bb.7:                               ##   in Loop: Header=BB24_6 Depth=1
	movslq	%eax, %rbx
	incl	%eax
	movl	4(%rdi,%rbx,4), %r11d
	movl	%edx, 4(%rdi,%rbx,4)
	movl	%r11d, (%rdi,%rsi,4)
	jmp	LBB24_8
	.p2align	4, 0x90
LBB24_18:                               ##   in Loop: Header=BB24_10 Depth=1
	addq	$4, %rsi
	cmpq	%rsi, %r10
	je	LBB24_19
LBB24_10:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB24_11
## %bb.12:                              ##   in Loop: Header=BB24_10 Depth=1
	movl	4(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB24_13
LBB24_14:                               ##   in Loop: Header=BB24_10 Depth=1
	movl	8(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB24_15
LBB24_16:                               ##   in Loop: Header=BB24_10 Depth=1
	movl	12(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB24_18
	jmp	LBB24_17
	.p2align	4, 0x90
LBB24_11:                               ##   in Loop: Header=BB24_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, (%rdi,%rsi,4)
	movl	4(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB24_14
LBB24_13:                               ##   in Loop: Header=BB24_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, 4(%rdi,%rsi,4)
	movl	8(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB24_16
LBB24_15:                               ##   in Loop: Header=BB24_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, 8(%rdi,%rsi,4)
	movl	12(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB24_18
LBB24_17:                               ##   in Loop: Header=BB24_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, 12(%rdi,%rsi,4)
	jmp	LBB24_18
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_standard            ## -- Begin function sort_quick_standard
	.p2align	4, 0x90
_sort_quick_standard:                   ## @sort_quick_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB25_21
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %rbx
	movslq	%edx, %r12
	jmp	LBB25_2
	.p2align	4, 0x90
LBB25_20:                               ##   in Loop: Header=BB25_2 Depth=1
	movslq	%r10d, %r15
	movl	4(%rbx,%r15,4), %eax
	movl	(%rbx,%r12,4), %ecx
	movl	%ecx, 4(%rbx,%r15,4)
	movl	%eax, (%rbx,%r12,4)
	movq	%rbx, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	movl	%r15d, %edx
	callq	_sort_quick_standard
	addl	$2, %r15d
	movl	%r15d, %esi
	cmpl	%r14d, %r15d
	jge	LBB25_21
LBB25_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB25_7 Depth 2
                                        ##     Child Loop BB25_11 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB25_21
## %bb.3:                               ##   in Loop: Header=BB25_2 Depth=1
	cmpl	$1, %eax
	jne	LBB25_4
## %bb.5:                               ##   in Loop: Header=BB25_2 Depth=1
	movl	(%rbx,%r12,4), %r9d
	movslq	%esi, %rax
	jmp	LBB25_6
	.p2align	4, 0x90
LBB25_4:                                ##   in Loop: Header=BB25_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rbx,%rax,4), %r10d
	movslq	%ecx, %r8
	movl	(%rbx,%r8,4), %r9d
	movl	(%rbx,%r12,4), %edi
	cmpl	%r9d, %r10d
	movl	%r9d, %ecx
	cmovll	%r10d, %ecx
	movl	%r9d, %edx
	cmovgl	%r10d, %edx
	cmpl	%edi, %ecx
	cmovgel	%edi, %ecx
	cmpl	%edi, %edx
	cmovlel	%edi, %edx
	addl	%r10d, %r9d
	addl	%edi, %r9d
	subl	%ecx, %r9d
	subl	%edx, %r9d
	movl	%ecx, (%rbx,%rax,4)
	movl	%r9d, (%rbx,%r12,4)
	movl	%edx, (%rbx,%r8,4)
LBB25_6:                                ##   in Loop: Header=BB25_2 Depth=1
	leal	-1(%rsi), %r10d
	movl	%r14d, %edi
	subl	%eax, %edi
	movq	%rax, %r8
	notq	%r8
	addq	%r12, %r8
	andq	$3, %rdi
	jne	LBB25_7
LBB25_10:                               ##   in Loop: Header=BB25_2 Depth=1
	cmpq	$3, %r8
	jae	LBB25_11
	jmp	LBB25_20
	.p2align	4, 0x90
LBB25_9:                                ##   in Loop: Header=BB25_7 Depth=2
	incq	%rax
	decq	%rdi
	je	LBB25_10
LBB25_7:                                ##   Parent Loop BB25_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB25_9
## %bb.8:                               ##   in Loop: Header=BB25_7 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %r11d
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%r11d, (%rbx,%rax,4)
	jmp	LBB25_9
	.p2align	4, 0x90
LBB25_19:                               ##   in Loop: Header=BB25_11 Depth=2
	addq	$4, %rax
	cmpq	%rax, %r12
	je	LBB25_20
LBB25_11:                               ##   Parent Loop BB25_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB25_12
## %bb.13:                              ##   in Loop: Header=BB25_11 Depth=2
	movl	4(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB25_14
LBB25_15:                               ##   in Loop: Header=BB25_11 Depth=2
	movl	8(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB25_16
LBB25_17:                               ##   in Loop: Header=BB25_11 Depth=2
	movl	12(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB25_19
	jmp	LBB25_18
	.p2align	4, 0x90
LBB25_12:                               ##   in Loop: Header=BB25_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, (%rbx,%rax,4)
	movl	4(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB25_15
LBB25_14:                               ##   in Loop: Header=BB25_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, 4(%rbx,%rax,4)
	movl	8(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB25_17
LBB25_16:                               ##   in Loop: Header=BB25_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, 8(%rbx,%rax,4)
	movl	12(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB25_19
LBB25_18:                               ##   in Loop: Header=BB25_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, 12(%rbx,%rax,4)
	jmp	LBB25_19
LBB25_21:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_shuffle_data                   ## -- Begin function shuffle_data
	.p2align	4, 0x90
_shuffle_data:                          ## @shuffle_data
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movl	%esi, %eax
	decl	%eax
	je	LBB26_6
## %bb.1:
	movl	%esi, %r14d
	movq	%rdi, %r13
	movslq	%eax, %r15
	movslq	%esi, %r12
	xorl	%ebx, %ebx
	jmp	LBB26_2
	.p2align	4, 0x90
LBB26_4:                                ##   in Loop: Header=BB26_2 Depth=1
	xorl	%edx, %edx
	divq	%r12
LBB26_5:                                ##   in Loop: Header=BB26_2 Depth=1
	movl	(%r13,%rdx,4), %eax
	movl	(%r13,%rbx,4), %ecx
	movl	%ecx, (%r13,%rdx,4)
	movl	%eax, (%r13,%rbx,4)
	incq	%rbx
	cmpq	%r15, %rbx
	jae	LBB26_6
LBB26_2:                                ## =>This Inner Loop Header: Depth=1
	callq	_rand
	cltq
	addq	%rbx, %rax
	movq	%rax, %rcx
	orq	%r12, %rcx
	shrq	$32, %rcx
	jne	LBB26_4
## %bb.3:                               ##   in Loop: Header=BB26_2 Depth=1
                                        ## kill: def $eax killed $eax killed $rax
	xorl	%edx, %edx
	divl	%r14d
                                        ## kill: def $edx killed $edx def $rdx
	jmp	LBB26_5
LBB26_6:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.section	__TEXT,__literal4,4byte_literals
	.p2align	2                               ## -- Begin function bench
LCPI27_0:
	.long	0x447a0000                      ## float 1000
LCPI27_1:
	.long	0x49742400                      ## float 1.0E+6
	.section	__TEXT,__text,regular,pure_instructions
	.globl	_bench
	.p2align	4, 0x90
_bench:                                 ## @bench
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$72, %rsp
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movq	%rcx, %rbx
	movl	%edx, %r14d
	movq	%rsi, -64(%rbp)                 ## 8-byte Spill
	movl	%edx, %ecx
	decl	%ecx
	je	LBB27_5
## %bb.1:
	movq	%rdi, -80(%rbp)                 ## 8-byte Spill
	movslq	%ecx, %r15
	movslq	%r14d, %r13
	movl	%ecx, %eax
	sarl	$31, %eax
	movl	%ecx, -52(%rbp)                 ## 4-byte Spill
	andnl	%ecx, %eax, %edi
	xorl	%r9d, %r9d
	xorl	%ecx, %ecx
	movq	%rdi, -96(%rbp)                 ## 8-byte Spill
	.p2align	4, 0x90
LBB27_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB27_3 Depth 2
                                        ##     Child Loop BB27_18 Depth 2
	movq	%rcx, -72(%rbp)                 ## 8-byte Spill
	movq	%r9, -48(%rbp)                  ## 8-byte Spill
	movl	%r14d, %r12d
	xorl	%r14d, %r14d
	jmp	LBB27_3
	.p2align	4, 0x90
LBB27_4:                                ##   in Loop: Header=BB27_3 Depth=2
                                        ## kill: def $eax killed $eax killed $rax
	xorl	%edx, %edx
	divl	%r12d
                                        ## kill: def $edx killed $edx def $rdx
LBB27_12:                               ##   in Loop: Header=BB27_3 Depth=2
	movl	(%rbx,%rdx,4), %eax
	movl	(%rbx,%r14,4), %ecx
	movl	%ecx, (%rbx,%rdx,4)
	movl	%eax, (%rbx,%r14,4)
	incq	%r14
	cmpq	%r15, %r14
	jae	LBB27_13
LBB27_3:                                ##   Parent Loop BB27_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	callq	_rand
	cltq
	addq	%r14, %rax
	movq	%rax, %rcx
	orq	%r13, %rcx
	shrq	$32, %rcx
	je	LBB27_4
## %bb.11:                              ##   in Loop: Header=BB27_3 Depth=2
	xorl	%edx, %edx
	divq	%r13
	jmp	LBB27_12
	.p2align	4, 0x90
LBB27_13:                               ##   in Loop: Header=BB27_2 Depth=1
	movl	$12, %edi
	callq	_clock_gettime_nsec_np
	movq	%rax, -104(%rbp)                ## 8-byte Spill
	movq	%rbx, %rdi
	xorl	%esi, %esi
	movl	-52(%rbp), %edx                 ## 4-byte Reload
	callq	*-64(%rbp)                      ## 8-byte Folded Reload
	movl	$12, %edi
	callq	_clock_gettime_nsec_np
	movl	%r12d, %r14d
	cmpl	$10, %r12d
	movq	-72(%rbp), %r8                  ## 8-byte Reload
	jne	LBB27_16
## %bb.14:                              ##   in Loop: Header=BB27_2 Depth=1
	testl	%r8d, %r8d
	jne	LBB27_16
## %bb.15:                              ##   in Loop: Header=BB27_2 Depth=1
	movl	$10, %edi
	movq	%rax, -88(%rbp)                 ## 8-byte Spill
	callq	_putchar
	movl	(%rbx), %esi
	leaq	L_.str.1(%rip), %r12
	movq	%r12, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	4(%rbx), %esi
	movq	%r12, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	8(%rbx), %esi
	movq	%r12, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	12(%rbx), %esi
	movq	%r12, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	16(%rbx), %esi
	movq	%r12, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	20(%rbx), %esi
	movq	%r12, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	24(%rbx), %esi
	movq	%r12, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	28(%rbx), %esi
	movq	%r12, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	32(%rbx), %esi
	movq	%r12, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	36(%rbx), %esi
	movq	%r12, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	$10, %edi
	callq	_putchar
	movq	-88(%rbp), %rax                 ## 8-byte Reload
	movq	-72(%rbp), %r8                  ## 8-byte Reload
LBB27_16:                               ##   in Loop: Header=BB27_2 Depth=1
	testl	%r8d, %r8d
	movq	-48(%rbp), %r9                  ## 8-byte Reload
	movq	-96(%rbp), %rdi                 ## 8-byte Reload
	je	LBB27_17
LBB27_21:                               ##   in Loop: Header=BB27_2 Depth=1
	subq	-104(%rbp), %r9                 ## 8-byte Folded Reload
	leal	1(%r8), %edx
	addq	%rax, %r9
	cmpl	$9, %r8d
	movl	%edx, %ecx
	jb	LBB27_2
## %bb.22:                              ##   in Loop: Header=BB27_2 Depth=1
	movl	%edx, %ecx
	cmpq	$100000000, %r9                 ## imm = 0x5F5E100
	jb	LBB27_2
	jmp	LBB27_23
	.p2align	4, 0x90
LBB27_17:                               ##   in Loop: Header=BB27_2 Depth=1
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB27_18:                               ##   Parent Loop BB27_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	cmpq	%rdx, %rdi
	je	LBB27_21
## %bb.19:                              ##   in Loop: Header=BB27_18 Depth=2
	movl	(%rbx,%rdx,4), %ecx
	leaq	1(%rdx), %rsi
	cmpl	4(%rbx,%rdx,4), %ecx
	movq	%rsi, %rdx
	jle	LBB27_18
## %bb.20:
	leaq	L_.str.2(%rip), %rdi
	movq	-80(%rbp), %rsi                 ## 8-byte Reload
	xorl	%eax, %eax
	callq	_printf
	movl	$1, %edi
	callq	_exit
LBB27_5:
	xorl	%r9d, %r9d
	xorl	%r12d, %r12d
	.p2align	4, 0x90
LBB27_6:                                ## =>This Inner Loop Header: Depth=1
	movl	$12, %edi
	movq	%r9, %r15
	callq	_clock_gettime_nsec_np
	movq	%rax, %r13
	movq	%rbx, %rdi
	xorl	%esi, %esi
	xorl	%edx, %edx
	callq	*-64(%rbp)                      ## 8-byte Folded Reload
	movl	$12, %edi
	callq	_clock_gettime_nsec_np
	movq	%r15, %r9
	movq	%rax, %r15
	subq	%r13, %r9
	cmpl	$10, %r14d
	jne	LBB27_9
## %bb.7:                               ##   in Loop: Header=BB27_6 Depth=1
	testl	%r12d, %r12d
	jne	LBB27_9
## %bb.8:                               ##   in Loop: Header=BB27_6 Depth=1
	movl	$10, %edi
	movq	%r9, -48(%rbp)                  ## 8-byte Spill
	callq	_putchar
	movl	(%rbx), %esi
	leaq	L_.str.1(%rip), %r13
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	4(%rbx), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	8(%rbx), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	12(%rbx), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	16(%rbx), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	20(%rbx), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	24(%rbx), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	28(%rbx), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	32(%rbx), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	36(%rbx), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	$10, %edi
	callq	_putchar
	movq	-48(%rbp), %r9                  ## 8-byte Reload
LBB27_9:                                ##   in Loop: Header=BB27_6 Depth=1
	leal	1(%r12), %edx
	addq	%r15, %r9
	cmpl	$9, %r12d
	movl	%edx, %r12d
	jb	LBB27_6
## %bb.10:                              ##   in Loop: Header=BB27_6 Depth=1
	movl	%edx, %r12d
	cmpq	$100000000, %r9                 ## imm = 0x5F5E100
	jb	LBB27_6
LBB27_23:
	testq	%r9, %r9
	js	LBB27_24
## %bb.25:
	vcvtsi2ss	%r9, %xmm0, %xmm0
	jmp	LBB27_26
LBB27_24:
	movq	%r9, %rcx
	shrq	%rcx
	andl	$1, %r9d
	orq	%rcx, %r9
	vcvtsi2ss	%r9, %xmm0, %xmm0
	vaddss	%xmm0, %xmm0, %xmm0
LBB27_26:
	vmulss	LCPI27_0(%rip), %xmm0, %xmm0
	vdivss	LCPI27_1(%rip), %xmm0, %xmm0
	vcvtsi2ss	%edx, %xmm1, %xmm1
	vdivss	%xmm1, %xmm0, %xmm0
	vcvtss2sd	%xmm0, %xmm0, %xmm0
	leaq	L_.str.3(%rip), %rdi
	movb	$1, %al
	addq	$72, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	jmp	_printf                         ## TAILCALL
	.cfi_endproc
                                        ## -- End function
	.globl	_main                           ## -- Begin function main
	.p2align	4, 0x90
_main:                                  ## @main
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	movl	$8000008, %eax                  ## imm = 0x7A1208
	callq	____chkstk_darwin
	subq	%rax, %rsp
	popq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	movq	%rax, -48(%rbp)
	leaq	L_str(%rip), %rdi
	callq	_puts
	leaq	L_str.14(%rip), %rdi
	callq	_puts
	callq	_clock
	movl	%eax, %edi
	callq	_srand
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB28_1:                                ## =>This Inner Loop Header: Depth=1
	callq	_rand
	movl	%eax, -8000048(%rbp,%rbx,4)
	incq	%rbx
	cmpq	$2000000, %rbx                  ## imm = 0x1E8480
	jne	LBB28_1
## %bb.2:
	leaq	L_.str.6(%rip), %r13
	leaq	_sort_quick_standard(%rip), %rsi
	leaq	-8000048(%rbp), %rbx
	movq	%r13, %rdi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.7(%rip), %rdi
	leaq	_sort_quick_optimized(%rip), %rsi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.8(%rip), %rdi
	leaq	_sort_quick_simd(%rip), %rsi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.9(%rip), %rdi
	leaq	_sort_quick_optimized_swap(%rip), %rsi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.10(%rip), %rdi
	leaq	_sort_quick_multi(%rip), %rsi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.11(%rip), %rdi
	leaq	_sort_quick_block(%rip), %rsi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.12(%rip), %rdi
	leaq	_sort_merge_standard(%rip), %rsi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.13(%rip), %r12
	leaq	_sort_merge_optimized(%rip), %r14
	movq	%r12, %rdi
	movq	%r14, %rsi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	movq	%r13, %rdi
	leaq	_sort_quick_standard(%rip), %rsi
	movq	%rsi, %r15
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.7(%rip), %rdi
	leaq	_sort_quick_optimized(%rip), %rsi
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.8(%rip), %rdi
	leaq	_sort_quick_simd(%rip), %rsi
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.9(%rip), %rdi
	leaq	_sort_quick_optimized_swap(%rip), %rsi
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.10(%rip), %rdi
	leaq	_sort_quick_multi(%rip), %rsi
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.11(%rip), %rdi
	leaq	_sort_quick_block(%rip), %rsi
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.12(%rip), %rdi
	leaq	_sort_merge_standard(%rip), %rsi
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	movq	%r12, %rdi
	movq	%r14, %rsi
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	movq	%r13, %rdi
	movq	%r15, %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.7(%rip), %rdi
	movq	%rdi, %r13
	leaq	_sort_quick_optimized(%rip), %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.8(%rip), %rdi
	leaq	_sort_quick_simd(%rip), %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.9(%rip), %rdi
	leaq	_sort_quick_optimized_swap(%rip), %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.10(%rip), %rdi
	leaq	_sort_quick_multi(%rip), %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.11(%rip), %rdi
	leaq	_sort_quick_block(%rip), %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.12(%rip), %rdi
	leaq	_sort_merge_standard(%rip), %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	movq	%r12, %rdi
	movq	%r14, %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	leaq	L_.str.6(%rip), %rdi
	movq	%r15, %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	movq	%r13, %rdi
	leaq	_sort_quick_optimized(%rip), %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.8(%rip), %rdi
	leaq	_sort_quick_simd(%rip), %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.9(%rip), %rdi
	leaq	_sort_quick_optimized_swap(%rip), %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.10(%rip), %rdi
	leaq	_sort_quick_multi(%rip), %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.11(%rip), %rdi
	leaq	_sort_quick_block(%rip), %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.12(%rip), %rdi
	leaq	_sort_merge_standard(%rip), %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	movq	%r12, %rdi
	movq	%r14, %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	leaq	L_.str.6(%rip), %rdi
	movq	%r15, %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	movq	%r13, %rdi
	leaq	_sort_quick_optimized(%rip), %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.8(%rip), %rdi
	leaq	_sort_quick_simd(%rip), %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.9(%rip), %rdi
	leaq	_sort_quick_optimized_swap(%rip), %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.10(%rip), %rdi
	leaq	_sort_quick_multi(%rip), %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.11(%rip), %rdi
	leaq	_sort_quick_block(%rip), %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.12(%rip), %rdi
	leaq	_sort_merge_standard(%rip), %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	movq	%r12, %rdi
	movq	%r14, %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	leaq	L_.str.6(%rip), %rdi
	movq	%r15, %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	movq	%r13, %rdi
	leaq	_sort_quick_optimized(%rip), %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.8(%rip), %rdi
	leaq	_sort_quick_simd(%rip), %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.9(%rip), %rdi
	leaq	_sort_quick_optimized_swap(%rip), %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.10(%rip), %rdi
	leaq	_sort_quick_multi(%rip), %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.11(%rip), %rdi
	leaq	_sort_quick_block(%rip), %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	leaq	L_.str.12(%rip), %rdi
	leaq	_sort_merge_standard(%rip), %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	movq	%r12, %rdi
	movq	%r14, %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB28_4
## %bb.3:
	xorl	%eax, %eax
	addq	$8000008, %rsp                  ## imm = 0x7A1208
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB28_4:
	callq	___stack_chk_fail
	.cfi_endproc
                                        ## -- End function
	.section	__TEXT,__const
	.globl	_INSERTION_SORT_THRESH_BLOCK    ## @INSERTION_SORT_THRESH_BLOCK
	.p2align	2
_INSERTION_SORT_THRESH_BLOCK:
	.long	20                              ## 0x14

	.globl	_blocksize                      ## @blocksize
	.p2align	2
_blocksize:
	.long	128                             ## 0x80

	.comm	_b,4000000,4                    ## @b
	.globl	_INSERTION_SORT_THRESH_O        ## @INSERTION_SORT_THRESH_O
	.p2align	2
_INSERTION_SORT_THRESH_O:
	.long	0                               ## 0x0

	.globl	_INSERTION_SORT_THRESH_MULTI    ## @INSERTION_SORT_THRESH_MULTI
	.p2align	2
_INSERTION_SORT_THRESH_MULTI:
	.long	200                             ## 0xc8

	.comm	_tmp,36000000,4                 ## @tmp
	.globl	_INSERTION_SORT_THRESH_SWAP     ## @INSERTION_SORT_THRESH_SWAP
	.p2align	2
_INSERTION_SORT_THRESH_SWAP:
	.long	0                               ## 0x0

	.globl	_INSERTION_SORT_THRESH_U        ## @INSERTION_SORT_THRESH_U
	.p2align	2
_INSERTION_SORT_THRESH_U:
	.long	0                               ## 0x0

	.globl	_DATA_AMOUNT                    ## @DATA_AMOUNT
	.p2align	2
_DATA_AMOUNT:
	.long	2000000                         ## 0x1e8480

	.globl	_RUNS_PER_BENCH                 ## @RUNS_PER_BENCH
	.p2align	2
_RUNS_PER_BENCH:
	.long	1                               ## 0x1

	.section	__TEXT,__cstring,cstring_literals
L_.str.1:                               ## @.str.1
	.asciz	"%d "

L_.str.2:                               ## @.str.2
	.asciz	"Integrity check failed for %s\n"

L_.str.3:                               ## @.str.3
	.asciz	"%f\t"

L_.str.6:                               ## @.str.6
	.asciz	"  Quicksort Standard    "

L_.str.7:                               ## @.str.7
	.asciz	"  Quicksort Optimized   "

L_.str.8:                               ## @.str.8
	.asciz	"  Quicksort SIMD        "

L_.str.9:                               ## @.str.9
	.asciz	"  Quicksort      Swap   "

L_.str.10:                              ## @.str.10
	.asciz	"  Quicksort     Multi   "

L_.str.11:                              ## @.str.11
	.asciz	"  Block Quicksort       "

L_.str.12:                              ## @.str.12
	.asciz	"  Mergesort Standard    "

L_.str.13:                              ## @.str.13
	.asciz	"  Mergesort Optimized   "

	.comm	_x,8,2                          ## @x
L_str:                                  ## @str
	.asciz	"Starting"

L_str.14:                               ## @str.14
	.asciz	"Generating random data"

.subsections_via_symbols
