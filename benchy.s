	.section	__TEXT,__text,regular,pure_instructions
	.build_version macos, 11, 3	sdk_version 11, 3
	.globl	_partition_quick_block          ## -- Begin function partition_quick_block
	.p2align	4, 0x90
_partition_quick_block:                 ## @partition_quick_block
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$1128, %rsp                     ## imm = 0x468
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movq	%rdi, %r13
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	movq	%rax, -48(%rbp)
	movl	%edx, %eax
	subl	%esi, %eax
	movslq	%edx, %r11
	cmpl	$3, %eax
	jl	LBB0_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%r13,%r8,4), %edi
	movslq	%ecx, %r9
	movl	(%r13,%r9,4), %r10d
	movl	(%r13,%r11,4), %ecx
	cmpl	%r10d, %edi
	movl	%r10d, %ebx
	cmovll	%edi, %ebx
	movl	%r10d, %eax
	cmovgl	%edi, %eax
	cmpl	%ecx, %ebx
	cmovgel	%ecx, %ebx
	cmpl	%ecx, %eax
	cmovlel	%ecx, %eax
	addl	%edi, %r10d
	addl	%ecx, %r10d
	subl	%ebx, %r10d
	subl	%eax, %r10d
	movl	%ebx, (%r13,%r8,4)
	movl	%r10d, (%r13,%r11,4)
	movl	%eax, (%r13,%r9,4)
	jmp	LBB0_3
LBB0_2:
	movl	(%r13,%r11,4), %r10d
LBB0_3:
	movq	%r11, -1112(%rbp)               ## 8-byte Spill
	decl	%edx
	movq	%rdx, %r9
	movl	%edx, %ebx
	subl	%esi, %ebx
	cmpl	$256, %ebx                      ## imm = 0x100
	movq	%r13, -1080(%rbp)               ## 8-byte Spill
	movq	%rsi, %rdi
	jl	LBB0_4
## %bb.12:
	leaq	12(%r13), %rax
	movq	%rax, -1136(%rbp)               ## 8-byte Spill
	xorl	%ecx, %ecx
	xorl	%r11d, %r11d
	xorl	%r12d, %r12d
	xorl	%r8d, %r8d
	movq	%r9, %rsi
	jmp	LBB0_13
	.p2align	4, 0x90
LBB0_25:                                ##   in Loop: Header=BB0_13 Depth=1
	addl	%ebx, %r8d
	addl	%ebx, %r12d
	leal	128(%rdi), %eax
	subl	%ebx, %r11d
	cmovel	%eax, %edi
	leal	-128(%rsi), %eax
	subl	%ebx, %ecx
	cmovel	%eax, %esi
	movl	%esi, %ebx
	subl	%edi, %ebx
	cmpl	$255, %ebx
	jle	LBB0_26
LBB0_13:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB0_15 Depth 2
                                        ##     Child Loop BB0_19 Depth 2
                                        ##     Child Loop BB0_36 Depth 2
	testl	%r11d, %r11d
	je	LBB0_14
## %bb.17:                              ##   in Loop: Header=BB0_13 Depth=1
	testl	%ecx, %ecx
	jne	LBB0_20
	jmp	LBB0_18
	.p2align	4, 0x90
LBB0_14:                                ##   in Loop: Header=BB0_13 Depth=1
	movq	%rsi, %r14
	movslq	%edi, %rax
	movq	-1136(%rbp), %rdx               ## 8-byte Reload
	leaq	(%rdx,%rax,4), %rax
	xorl	%r8d, %r8d
	xorl	%ebx, %ebx
	xorl	%r11d, %r11d
	.p2align	4, 0x90
LBB0_15:                                ##   Parent Loop BB0_13 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	%r11d, %edx
	movl	%ebx, -560(%rbp,%rdx,4)
	xorl	%edx, %edx
	cmpl	-12(%rax,%rbx,4), %r10d
	setle	%dl
	addl	%r11d, %edx
	leal	1(%rbx), %esi
	movl	%esi, -560(%rbp,%rdx,4)
	xorl	%esi, %esi
	cmpl	-8(%rax,%rbx,4), %r10d
	setle	%sil
	addl	%edx, %esi
	leal	2(%rbx), %edx
	movl	%edx, -560(%rbp,%rsi,4)
	xorl	%edx, %edx
	cmpl	-4(%rax,%rbx,4), %r10d
	setle	%dl
	addl	%esi, %edx
	leal	3(%rbx), %esi
	movl	%esi, -560(%rbp,%rdx,4)
	xorl	%r11d, %r11d
	cmpl	(%rax,%rbx,4), %r10d
	setle	%r11b
	addl	%edx, %r11d
	addq	$4, %rbx
	cmpq	$128, %rbx
	jne	LBB0_15
## %bb.16:                              ##   in Loop: Header=BB0_13 Depth=1
	movq	%r14, %rsi
	testl	%ecx, %ecx
	jne	LBB0_20
LBB0_18:                                ##   in Loop: Header=BB0_13 Depth=1
	movslq	%esi, %rax
	leaq	(,%rax,4), %rax
	addq	%r13, %rax
	xorl	%r12d, %r12d
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_19:                                ##   Parent Loop BB0_13 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	%ecx, %edx
	movl	%ebx, -1072(%rbp,%rdx,4)
	xorl	%edx, %edx
	cmpl	(%rax), %r10d
	setge	%dl
	addl	%ecx, %edx
	movl	%ebx, %ecx
	orl	$1, %ecx
	movl	%ecx, -1072(%rbp,%rdx,4)
	xorl	%ecx, %ecx
	cmpl	-4(%rax), %r10d
	setge	%cl
	addl	%edx, %ecx
	movl	%ebx, %edx
	orl	$2, %edx
	movl	%edx, -1072(%rbp,%rcx,4)
	xorl	%edx, %edx
	cmpl	-8(%rax), %r10d
	setge	%dl
	addl	%ecx, %edx
	movl	%ebx, %ecx
	orl	$3, %ecx
	movl	%ecx, -1072(%rbp,%rdx,4)
	xorl	%ecx, %ecx
	cmpl	-12(%rax), %r10d
	setge	%cl
	addl	%edx, %ecx
	addq	$4, %rbx
	addq	$-16, %rax
	cmpq	$128, %rbx
	jne	LBB0_19
LBB0_20:                                ##   in Loop: Header=BB0_13 Depth=1
	cmpl	%ecx, %r11d
	movl	%ecx, %ebx
	cmovll	%r11d, %ebx
	testl	%ebx, %ebx
	jle	LBB0_25
## %bb.21:                              ##   in Loop: Header=BB0_13 Depth=1
	movq	%r8, -1128(%rbp)                ## 8-byte Spill
	movq	%rsi, %rax
	movslq	%r8d, %rsi
	movq	%r12, -1104(%rbp)               ## 8-byte Spill
	movslq	%r12d, %rdx
	movl	%ebx, %r8d
	movq	%rdi, -1160(%rbp)               ## 8-byte Spill
	movslq	%edi, %r15
	movq	%rax, -1120(%rbp)               ## 8-byte Spill
	movslq	%eax, %r14
	movl	%ebx, -1084(%rbp)               ## 4-byte Spill
	cmpl	$1, %ebx
	movq	%rdx, -1152(%rbp)               ## 8-byte Spill
	movq	%rsi, -1144(%rbp)               ## 8-byte Spill
	movq	%r8, -1096(%rbp)                ## 8-byte Spill
	jne	LBB0_35
## %bb.22:                              ##   in Loop: Header=BB0_13 Depth=1
	xorl	%r9d, %r9d
	jmp	LBB0_23
	.p2align	4, 0x90
LBB0_35:                                ##   in Loop: Header=BB0_13 Depth=1
                                        ## kill: def $r8d killed $r8d killed $r8 def $r8
	andl	$-2, %r8d
	leaq	-556(%rbp), %rax
	leaq	(%rax,%rsi,4), %rsi
	leaq	-1068(%rbp), %rax
	leaq	(%rax,%rdx,4), %r12
	xorl	%r9d, %r9d
	.p2align	4, 0x90
LBB0_36:                                ##   Parent Loop BB0_13 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movslq	-4(%rsi,%r9,4), %rdx
	addq	%r15, %rdx
	movslq	-4(%r12,%r9,4), %r13
	movq	%r14, %rax
	subq	%r13, %rax
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	movl	(%r13,%rdx,4), %ebx
	movl	(%r13,%rax,4), %edi
	movl	%edi, (%r13,%rdx,4)
	movl	%ebx, (%r13,%rax,4)
	movslq	(%rsi,%r9,4), %rax
	addq	%r15, %rax
	movslq	(%r12,%r9,4), %rdx
	movq	%r14, %rdi
	subq	%rdx, %rdi
	movl	(%r13,%rax,4), %edx
	movl	(%r13,%rdi,4), %ebx
	movl	%ebx, (%r13,%rax,4)
	movl	%edx, (%r13,%rdi,4)
	addq	$2, %r9
	cmpq	%r9, %r8
	jne	LBB0_36
LBB0_23:                                ##   in Loop: Header=BB0_13 Depth=1
	testb	$1, -1096(%rbp)                 ## 1-byte Folded Reload
	movq	-1120(%rbp), %rsi               ## 8-byte Reload
	movq	-1160(%rbp), %rdi               ## 8-byte Reload
	movq	-1128(%rbp), %r8                ## 8-byte Reload
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	-1084(%rbp), %ebx               ## 4-byte Reload
	je	LBB0_25
## %bb.24:                              ##   in Loop: Header=BB0_13 Depth=1
	movq	-1144(%rbp), %rax               ## 8-byte Reload
	addq	%r9, %rax
	movslq	-560(%rbp,%rax,4), %rdx
	addq	%r15, %rdx
	movq	-1152(%rbp), %rax               ## 8-byte Reload
	addq	%r9, %rax
	movq	%rsi, %r9
	movslq	-1072(%rbp,%rax,4), %rsi
	subq	%rsi, %r14
	movl	(%r13,%rdx,4), %r8d
	movl	(%r13,%r14,4), %esi
	movl	%esi, (%r13,%rdx,4)
	movq	%r9, %rsi
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	%r8d, (%r13,%r14,4)
	movq	-1128(%rbp), %r8                ## 8-byte Reload
	jmp	LBB0_25
LBB0_4:
	movq	%r9, %rsi
	jmp	LBB0_5
LBB0_26:
	movl	%ecx, %eax
	orl	%r11d, %eax
	je	LBB0_5
## %bb.27:
	leal	-127(%rbx), %r9d
	testl	%ecx, %ecx
	movq	%rsi, -1120(%rbp)               ## 8-byte Spill
	je	LBB0_43
## %bb.28:
	xorl	%r8d, %r8d
	cmpl	$128, %ebx
	jl	LBB0_34
## %bb.29:
	movslq	%edi, %r14
	movl	%r9d, %r13d
	leaq	-1(%r13), %rax
	movl	%r13d, %r15d
	andl	$3, %r15d
	xorl	%r8d, %r8d
	cmpq	$3, %rax
	jae	LBB0_40
## %bb.30:
	xorl	%ebx, %ebx
	jmp	LBB0_31
LBB0_5:
	leal	1(%rbx), %r14d
	movl	%r14d, %eax
	shrl	$31, %eax
	leal	(%rbx,%rax), %edx
	incl	%edx
	sarl	%edx
	subl	%edx, %r14d
	xorl	%r8d, %r8d
	movl	$0, %r11d
	movl	$0, %ecx
	testl	%ebx, %ebx
	movq	%rsi, -1120(%rbp)               ## 8-byte Spill
	jle	LBB0_10
## %bb.6:
	movq	%rsi, %r9
	movq	%rdi, %rsi
	movslq	%edi, %r15
	movslq	%r9d, %rcx
	testl	%edx, %edx
	movl	$1, %r8d
	movl	%edx, -1084(%rbp)               ## 4-byte Spill
	cmovgl	%edx, %r8d
	cmpl	$3, %ebx
	movq	%rcx, -1104(%rbp)               ## 8-byte Spill
	jge	LBB0_37
## %bb.7:
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	xorl	%r11d, %r11d
	jmp	LBB0_8
LBB0_37:
	movq	%r13, %rax
	movl	%r8d, %r13d
	andl	$2147483646, %r13d              ## imm = 0x7FFFFFFE
	movq	%r15, %rdi
	leaq	(%rax,%r15,4), %r15
	addq	$4, %r15
	leaq	(%rax,%rcx,4), %r12
	xorl	%ebx, %ebx
	xorl	%ecx, %ecx
	xorl	%r11d, %r11d
	.p2align	4, 0x90
LBB0_38:                                ## =>This Inner Loop Header: Depth=1
	movl	%r11d, %eax
	movl	%ebx, -560(%rbp,%rax,4)
	xorl	%eax, %eax
	cmpl	-4(%r15,%rbx,4), %r10d
	setle	%al
	addl	%r11d, %eax
	movl	%ecx, %edx
	movl	%ebx, -1072(%rbp,%rdx,4)
	xorl	%edx, %edx
	cmpl	(%r12), %r10d
	setge	%dl
	addl	%ecx, %edx
	leal	1(%rbx), %ecx
	movl	%ecx, -560(%rbp,%rax,4)
	xorl	%r11d, %r11d
	cmpl	(%r15,%rbx,4), %r10d
	setle	%r11b
	addl	%eax, %r11d
	movl	%ecx, -1072(%rbp,%rdx,4)
	xorl	%ecx, %ecx
	cmpl	-4(%r12), %r10d
	setge	%cl
	addl	%edx, %ecx
	addq	$2, %rbx
	addq	$-8, %r12
	cmpq	%rbx, %r13
	jne	LBB0_38
## %bb.39:
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	movq	-1120(%rbp), %r9                ## 8-byte Reload
	movq	%rdi, %r15
LBB0_8:
	testb	$1, %r8b
	movl	$0, %r8d
	movq	%rsi, %rdi
	movq	%r9, %rsi
	movl	-1084(%rbp), %edx               ## 4-byte Reload
	je	LBB0_10
## %bb.9:
	movl	%r11d, %eax
	movl	%ebx, -560(%rbp,%rax,4)
	addq	%rbx, %r15
	movl	%ecx, %eax
	movq	-1104(%rbp), %rsi               ## 8-byte Reload
	subq	%rbx, %rsi
	xorl	%r12d, %r12d
	cmpl	(%r13,%r15,4), %r10d
	movl	%ebx, -1072(%rbp,%rax,4)
	setle	%r12b
	xorl	%eax, %eax
	cmpl	(%r13,%rsi,4), %r10d
	movq	%r9, %rsi
	setge	%al
	addl	%ecx, %eax
	addl	%r11d, %r12d
	movl	%r12d, %r11d
	movl	%eax, %ecx
LBB0_10:
	cmpl	%r14d, %edx
	movl	%edx, %ebx
	movq	%r14, -1096(%rbp)               ## 8-byte Spill
	jge	LBB0_55
## %bb.11:
	leal	-1(%r14), %eax
	movl	%ecx, %edx
	movl	%eax, -1072(%rbp,%rdx,4)
	movl	%esi, %eax
	subl	%r14d, %eax
	incl	%eax
	cltq
	xorl	%edx, %edx
	cmpl	(%r13,%rax,4), %r10d
	setge	%dl
	addl	%ecx, %edx
	xorl	%r12d, %r12d
	movl	%edx, %ecx
	jmp	LBB0_56
LBB0_43:
	xorl	%r12d, %r12d
	cmpl	$128, %ebx
	jl	LBB0_44
## %bb.45:
	movq	%rdi, %rdx
	movq	%r8, %rdi
	movslq	%esi, %r13
	movl	%r9d, %r8d
	leaq	-1(%r8), %rax
	movl	%r8d, %r14d
	andl	$3, %r14d
	xorl	%r12d, %r12d
	cmpq	$3, %rax
	jae	LBB0_47
## %bb.46:
	movl	%r9d, %ebx
	xorl	%r15d, %r15d
	xorl	%ecx, %ecx
	testq	%r14, %r14
	movq	%rdi, %r8
	movq	%rdx, %rdi
	je	LBB0_51
LBB0_52:
	leaq	(,%r15,4), %rax
	movq	-1080(%rbp), %rdx               ## 8-byte Reload
	subq	%rax, %rdx
	leaq	(%rdx,%r13,4), %rax
	negq	%r14
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB0_53:                                ## =>This Inner Loop Header: Depth=1
	movl	%ecx, %esi
	movl	%ecx, %ecx
	movl	%r15d, -1072(%rbp,%rcx,4)
	xorl	%ecx, %ecx
	cmpl	(%rax,%rdx,4), %r10d
	setge	%cl
	addl	%esi, %ecx
	decq	%rdx
	incl	%r15d
	cmpq	%rdx, %r14
	jne	LBB0_53
## %bb.54:
	movl	%ebx, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	$128, %ebx
	movq	-1080(%rbp), %r13               ## 8-byte Reload
LBB0_55:
	xorl	%r12d, %r12d
	jmp	LBB0_56
LBB0_44:
	xorl	%ecx, %ecx
	movl	%r9d, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	$128, %ebx
	jmp	LBB0_56
LBB0_40:
	andl	$-4, %r13d
	movq	-1080(%rbp), %rax               ## 8-byte Reload
	leaq	(%rax,%r14,4), %r8
	addq	$12, %r8
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB0_41:                                ## =>This Inner Loop Header: Depth=1
	movslq	%r11d, %rax
	movl	%ebx, -560(%rbp,%rax,4)
	xorl	%edx, %edx
	cmpl	-12(%r8,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %eax
	cltq
	leal	1(%rbx), %edx
	movl	%edx, -560(%rbp,%rax,4)
	xorl	%edx, %edx
	cmpl	-8(%r8,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %eax
	cltq
	leal	2(%rbx), %edx
	movl	%edx, -560(%rbp,%rax,4)
	xorl	%edx, %edx
	cmpl	-4(%r8,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %eax
	movslq	%eax, %r11
	leal	3(%rbx), %eax
	movl	%eax, -560(%rbp,%r11,4)
	xorl	%eax, %eax
	cmpl	(%r8,%rbx,4), %r10d
	setle	%al
	addl	%eax, %r11d
	addq	$4, %rbx
	cmpq	%rbx, %r13
	jne	LBB0_41
## %bb.42:
	xorl	%r8d, %r8d
LBB0_31:
	testq	%r15, %r15
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	je	LBB0_34
## %bb.32:
	leaq	(,%r14,4), %rax
	addq	%r13, %rax
	.p2align	4, 0x90
LBB0_33:                                ## =>This Inner Loop Header: Depth=1
	movslq	%r11d, %r11
	movl	%ebx, -560(%rbp,%r11,4)
	xorl	%edx, %edx
	cmpl	(%rax,%rbx,4), %r10d
	setle	%dl
	addl	%edx, %r11d
	incq	%rbx
	decq	%r15
	jne	LBB0_33
LBB0_34:
	movl	$128, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	%r9d, %ebx
LBB0_56:
	cmpl	%ecx, %r11d
	movl	%ecx, %r10d
	cmovll	%r11d, %r10d
	testl	%r10d, %r10d
	jle	LBB0_61
## %bb.57:
	movl	%ebx, -1084(%rbp)               ## 4-byte Spill
	movq	%r8, -1128(%rbp)                ## 8-byte Spill
	movslq	%r8d, %rdx
	movq	%r12, -1104(%rbp)               ## 8-byte Spill
	movslq	%r12d, %rax
	movl	%r10d, %r12d
	movq	%rdi, -1160(%rbp)               ## 8-byte Spill
	movslq	%edi, %r9
	movslq	-1120(%rbp), %r14               ## 4-byte Folded Reload
	movq	%r10, -1152(%rbp)               ## 8-byte Spill
	cmpl	$1, %r10d
	movq	%rax, -1136(%rbp)               ## 8-byte Spill
	movq	%rdx, -1168(%rbp)               ## 8-byte Spill
	movq	%r12, -1144(%rbp)               ## 8-byte Spill
	jne	LBB0_64
## %bb.58:
	xorl	%eax, %eax
	jmp	LBB0_59
LBB0_64:
                                        ## kill: def $r12d killed $r12d killed $r12 def $r12
	andl	$-2, %r12d
	leaq	-556(,%rdx,4), %r15
	addq	%rbp, %r15
	leaq	-1068(,%rax,4), %r10
	addq	%rbp, %r10
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB0_65:                                ## =>This Inner Loop Header: Depth=1
	movslq	-4(%r15,%rax,4), %rdx
	addq	%r9, %rdx
	movslq	-4(%r10,%rax,4), %rdi
	movq	%r14, %r13
	subq	%rdi, %r13
	movq	-1080(%rbp), %rsi               ## 8-byte Reload
	movl	(%rsi,%rdx,4), %edi
	movq	-1080(%rbp), %rsi               ## 8-byte Reload
	movl	(%rsi,%r13,4), %r8d
	movq	-1080(%rbp), %rsi               ## 8-byte Reload
	movl	%r8d, (%rsi,%rdx,4)
	movq	-1080(%rbp), %rdx               ## 8-byte Reload
	movl	%edi, (%rdx,%r13,4)
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	movslq	(%r15,%rax,4), %rdx
	addq	%r9, %rdx
	movslq	(%r10,%rax,4), %rdi
	movq	%r14, %rsi
	subq	%rdi, %rsi
	movl	(%r13,%rdx,4), %edi
	movl	(%r13,%rsi,4), %ebx
	movl	%ebx, (%r13,%rdx,4)
	movl	%edi, (%r13,%rsi,4)
	addq	$2, %rax
	cmpq	%rax, %r12
	jne	LBB0_65
LBB0_59:
	testb	$1, -1144(%rbp)                 ## 1-byte Folded Reload
	movq	-1160(%rbp), %rdi               ## 8-byte Reload
	movq	-1128(%rbp), %r8                ## 8-byte Reload
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	-1084(%rbp), %ebx               ## 4-byte Reload
	movq	-1152(%rbp), %r10               ## 8-byte Reload
	je	LBB0_61
## %bb.60:
	movq	-1168(%rbp), %rdx               ## 8-byte Reload
	addq	%rax, %rdx
	movslq	-560(%rbp,%rdx,4), %rdx
	addq	%r9, %rdx
	movq	-1136(%rbp), %rsi               ## 8-byte Reload
	addq	%rax, %rsi
	movslq	-1072(%rbp,%rsi,4), %rax
	subq	%rax, %r14
	movl	(%r13,%rdx,4), %eax
	movl	(%r13,%r14,4), %esi
	movl	%esi, (%r13,%rdx,4)
	movq	-1104(%rbp), %r12               ## 8-byte Reload
	movl	%eax, (%r13,%r14,4)
LBB0_61:
	leal	(%r10,%r12), %r9d
	addl	%edi, %ebx
	xorl	%eax, %eax
	cmpl	%ecx, %r11d
	movq	-1096(%rbp), %rdx               ## 8-byte Reload
	cmovll	%eax, %edx
	movq	-1120(%rbp), %r15               ## 8-byte Reload
	subl	%edx, %r15d
	cmpl	%ecx, %r11d
	cmovlel	%ebx, %edi
	jle	LBB0_79
## %bb.62:
	addl	%r8d, %r10d
	leal	(%r11,%r8), %eax
	subl	%edi, %r15d
	movslq	%r10d, %r14
	cmpl	%r10d, %eax
	jle	LBB0_63
## %bb.66:
	movslq	%eax, %rcx
	leal	-1(%r10), %eax
	leal	(%r11,%r8), %ebx
	decl	%ebx
	movq	-1112(%rbp), %rdx               ## 8-byte Reload
	.p2align	4, 0x90
LBB0_67:                                ## =>This Inner Loop Header: Depth=1
	cmpl	-564(%rbp,%rcx,4), %r15d
	jne	LBB0_70
## %bb.68:                              ##   in Loop: Header=BB0_67 Depth=1
	decq	%rcx
	decl	%r15d
	decl	%ebx
	cmpq	%r14, %rcx
	jg	LBB0_67
## %bb.69:
	movl	%eax, %ebx
	jmp	LBB0_70
LBB0_79:
	jge	LBB0_95
## %bb.80:
	leal	(%rcx,%r12), %edx
	movl	%r15d, %eax
	subl	%edi, %eax
	movslq	%r9d, %r10
	cmpl	%r9d, %edx
	movq	-1112(%rbp), %r11               ## 8-byte Reload
	jle	LBB0_81
## %bb.82:
	movslq	%edx, %rsi
	leal	-1(%r9), %edx
	addl	%r12d, %ecx
	decl	%ecx
	.p2align	4, 0x90
LBB0_83:                                ## =>This Inner Loop Header: Depth=1
	cmpl	-1076(%rbp,%rsi,4), %eax
	jne	LBB0_86
## %bb.84:                              ##   in Loop: Header=BB0_83 Depth=1
	decq	%rsi
	decl	%eax
	decl	%ecx
	cmpq	%r10, %rsi
	jg	LBB0_83
## %bb.85:
	movl	%edx, %ecx
	jmp	LBB0_86
LBB0_63:
	leal	(%r11,%r8), %ebx
	decl	%ebx
	movq	-1112(%rbp), %rdx               ## 8-byte Reload
LBB0_70:
	movl	%ebx, %ecx
	subl	%r10d, %ecx
	jl	LBB0_78
## %bb.71:
	movslq	%r15d, %rax
	movq	%rdi, %r12
	movslq	%edi, %r9
	movslq	%ebx, %rbx
	incl	%ecx
	movq	%rbx, %r8
	subq	%r14, %r8
	andq	$3, %rcx
	je	LBB0_74
## %bb.72:
	leaq	(,%r9,4), %r10
	addq	%r13, %r10
	negq	%rcx
	movq	%rax, %rsi
	.p2align	4, 0x90
LBB0_73:                                ## =>This Inner Loop Header: Depth=1
	leaq	-1(%rsi), %rax
	movslq	-560(%rbp,%rbx,4), %rdi
	decq	%rbx
	addq	%r9, %rdi
	movl	(%r10,%rsi,4), %r11d
	movl	(%r13,%rdi,4), %edx
	movl	%edx, (%r10,%rsi,4)
	movl	%r11d, (%r13,%rdi,4)
	movq	%rax, %rsi
	incq	%rcx
	jne	LBB0_73
LBB0_74:
	movq	%rax, %r15
	cmpq	$3, %r8
	jb	LBB0_77
## %bb.75:
	incq	%rbx
	leaq	(,%r9,4), %rcx
	addq	%r13, %rcx
	.p2align	4, 0x90
LBB0_76:                                ## =>This Inner Loop Header: Depth=1
	movslq	-564(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, (%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	movslq	-568(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	-4(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, -4(%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	movslq	-572(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	-8(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, -8(%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	leaq	-4(%rax), %r15
	movslq	-576(%rbp,%rbx,4), %rdx
	addq	%r9, %rdx
	movl	-12(%rcx,%rax,4), %esi
	movl	(%r13,%rdx,4), %edi
	movl	%edi, -12(%rcx,%rax,4)
	movl	%esi, (%r13,%rdx,4)
	addq	$-4, %rbx
	movq	%r15, %rax
	cmpq	%r14, %rbx
	jg	LBB0_76
LBB0_77:
	movq	-1112(%rbp), %rdx               ## 8-byte Reload
	movq	%r12, %rdi
LBB0_78:
	leaq	(,%rdx,4), %rcx
	addq	%r13, %rcx
	addl	%r15d, %edi
	incl	%edi
	movl	%edi, %ebx
	jmp	LBB0_96
LBB0_95:
	movq	-1112(%rbp), %rax               ## 8-byte Reload
	leaq	(,%rax,4), %rcx
	addq	%r13, %rcx
	jmp	LBB0_96
LBB0_81:
	addl	%r12d, %ecx
	decl	%ecx
LBB0_86:
	movl	%ecx, %edx
	subl	%r9d, %edx
	jl	LBB0_94
## %bb.87:
	movq	%r9, %rsi
	movl	%eax, %r9d
	movslq	%ecx, %rbx
	incl	%edx
	movslq	%r15d, %r14
	testb	$1, %dl
	je	LBB0_89
## %bb.88:
	decq	%r9
	movl	%r15d, %edx
	subl	%eax, %edx
	decl	%eax
	movslq	%edx, %r11
	movslq	-1072(%rbp,%rbx,4), %r8
	decq	%rbx
	movq	%r14, %rdi
	subq	%r8, %rdi
	movl	(%r13,%r11,4), %r8d
	movl	(%r13,%rdi,4), %edx
	movl	%edx, (%r13,%r11,4)
	movq	-1112(%rbp), %r11               ## 8-byte Reload
	movl	%r8d, (%r13,%rdi,4)
LBB0_89:
	cmpl	%esi, %ecx
	je	LBB0_93
## %bb.90:
	incq	%rbx
	cltq
	movq	%r14, %rcx
	subq	%rax, %rcx
	leaq	4(,%rcx,4), %rcx
	addq	%r13, %rcx
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB0_91:                                ## =>This Inner Loop Header: Depth=1
	movslq	-1076(%rbp,%rbx,4), %rdx
	movq	%r14, %rdi
	subq	%rdx, %rdi
	movl	-4(%rcx,%rax,4), %edx
	movl	(%r13,%rdi,4), %esi
	movl	%esi, -4(%rcx,%rax,4)
	movl	%edx, (%r13,%rdi,4)
	movslq	-1080(%rbp,%rbx,4), %rdx
	movq	%r14, %rsi
	subq	%rdx, %rsi
	movl	(%rcx,%rax,4), %edx
	movl	(%r13,%rsi,4), %edi
	movl	%edi, (%rcx,%rax,4)
	movl	%edx, (%r13,%rsi,4)
	addq	$-2, %rbx
	addq	$2, %rax
	cmpq	%r10, %rbx
	jg	LBB0_91
## %bb.92:
	subq	%rax, %r9
LBB0_93:
	movl	%r9d, %eax
LBB0_94:
	leaq	(,%r11,4), %rcx
	addq	%r13, %rcx
	subl	%eax, %r15d
	movl	%r15d, %edi
	movl	%r15d, %ebx
LBB0_96:
	movslq	%edi, %rax
	movl	(%rcx), %edx
	movl	(%r13,%rax,4), %esi
	movl	%esi, (%rcx)
	movl	%edx, (%r13,%rax,4)
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB0_98
## %bb.97:
	movl	%ebx, %eax
	addq	$1128, %rsp                     ## imm = 0x468
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB0_47:
	andl	$-4, %r8d
	movq	-1080(%rbp), %rax               ## 8-byte Reload
	leaq	(%rax,%r13,4), %rbx
	xorl	%r15d, %r15d
	xorl	%ecx, %ecx
	.p2align	4, 0x90
LBB0_48:                                ## =>This Inner Loop Header: Depth=1
	movl	%ecx, %eax
	movl	%r15d, -1072(%rbp,%rax,4)
	xorl	%eax, %eax
	cmpl	(%rbx), %r10d
	setge	%al
	addl	%ecx, %eax
	leal	1(%r15), %ecx
	movl	%ecx, -1072(%rbp,%rax,4)
	xorl	%ecx, %ecx
	cmpl	-4(%rbx), %r10d
	setge	%cl
	addl	%eax, %ecx
	leal	2(%r15), %eax
	movl	%eax, -1072(%rbp,%rcx,4)
	xorl	%eax, %eax
	cmpl	-8(%rbx), %r10d
	setge	%al
	addl	%ecx, %eax
	leal	3(%r15), %ecx
	movl	%ecx, -1072(%rbp,%rax,4)
	xorl	%ecx, %ecx
	cmpl	-12(%rbx), %r10d
	setge	%cl
	addl	%eax, %ecx
	addq	$4, %r15
	addq	$-16, %rbx
	cmpq	%r15, %r8
	jne	LBB0_48
## %bb.49:
	movl	%r9d, %ebx
	testq	%r14, %r14
	movq	%rdi, %r8
	movq	%rdx, %rdi
	jne	LBB0_52
LBB0_51:
	movl	%ebx, %eax
	movq	%rax, -1096(%rbp)               ## 8-byte Spill
	movl	$128, %ebx
	movq	-1080(%rbp), %r13               ## 8-byte Reload
	jmp	LBB0_56
LBB0_98:
	callq	___stack_chk_fail
	.cfi_endproc
                                        ## -- End function
	.globl	_median_of_three                ## -- Begin function median_of_three
	.p2align	4, 0x90
_median_of_three:                       ## @median_of_three
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%rdi,%r8,4), %r11d
	movslq	%ecx, %r9
	movl	(%rdi,%r9,4), %eax
	movslq	%edx, %r10
	movl	(%rdi,%r10,4), %ecx
	cmpl	%eax, %r11d
	movl	%eax, %edx
	cmovll	%r11d, %edx
	movl	%eax, %esi
	cmovgl	%r11d, %esi
	cmpl	%ecx, %edx
	cmovgel	%ecx, %edx
	cmpl	%ecx, %esi
	cmovlel	%ecx, %esi
	addl	%r11d, %eax
	addl	%ecx, %eax
	subl	%edx, %eax
	subl	%esi, %eax
	movl	%edx, (%rdi,%r8,4)
	movl	%eax, (%rdi,%r10,4)
	movl	%esi, (%rdi,%r9,4)
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_min                            ## -- Begin function min
	.p2align	4, 0x90
_min:                                   ## @min
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	%esi, %eax
	cmpl	%esi, %edi
	cmovll	%edi, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_swap                           ## -- Begin function swap
	.p2align	4, 0x90
_swap:                                  ## @swap
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	(%rdi), %eax
	movl	(%rsi), %ecx
	movl	%ecx, (%rdi)
	movl	%eax, (%rsi)
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_block               ## -- Begin function sort_quick_block
	.p2align	4, 0x90
_sort_quick_block:                      ## @sort_quick_block
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	%esi, %edx
	jle	LBB4_22
## %bb.1:
	movl	%edx, %r15d
	movl	%esi, %r12d
	movq	%rdi, %r14
	.p2align	4, 0x90
LBB4_2:                                 ## =>This Inner Loop Header: Depth=1
	movl	%r15d, %esi
	subl	%r12d, %esi
	cmpl	$21, %esi
	jl	LBB4_4
## %bb.3:                               ##   in Loop: Header=BB4_2 Depth=1
	movq	%r14, %rdi
	movl	%r12d, %esi
	movl	%r15d, %edx
	callq	_partition_quick_block
	movl	%eax, %ebx
	leal	-1(%rbx), %edx
	movq	%r14, %rdi
	movl	%r12d, %esi
	callq	_sort_quick_block
	incl	%ebx
	movl	%ebx, %r12d
	cmpl	%r15d, %ebx
	jl	LBB4_2
	jmp	LBB4_22
LBB4_4:
	testl	%esi, %esi
	jle	LBB4_22
## %bb.5:
	movslq	%r12d, %rax
	leaq	(%r14,%rax,4), %rax
	movabsq	$-4294967296, %rcx              ## imm = 0xFFFFFFFF00000000
	movl	%esi, %r8d
	movl	$1, %r15d
	cmpl	$1, %esi
	jne	LBB4_6
LBB4_16:
	testb	$1, %r8b
	je	LBB4_22
## %bb.17:
	movl	(%rax,%r15,4), %esi
	movq	%r15, %rdi
	shlq	$32, %rdi
	addq	%rcx, %rdi
	.p2align	4, 0x90
LBB4_18:                                ## =>This Inner Loop Header: Depth=1
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB4_21
## %bb.19:                              ##   in Loop: Header=BB4_18 Depth=1
	movl	%edx, (%rax,%r15,4)
	leaq	-1(%r15), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %r15
	movq	%rdx, %r15
	jg	LBB4_18
## %bb.20:
	xorl	%r15d, %r15d
LBB4_21:
	movslq	%r15d, %rcx
	movl	%esi, (%rax,%rcx,4)
LBB4_22:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB4_6:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movl	%r8d, %r10d
	andl	$-2, %r10d
	movl	$1, %r15d
	movabsq	$4294967296, %r11               ## imm = 0x100000000
	xorl	%r14d, %r14d
	jmp	LBB4_7
	.p2align	4, 0x90
LBB4_15:                                ##   in Loop: Header=BB4_7 Depth=1
	movslq	%ebx, %rdx
	movl	%esi, (%rax,%rdx,4)
	addq	$2, %r15
	addq	%r9, %r14
	addq	%r9, %r11
	addq	$-2, %r10
	je	LBB4_16
LBB4_7:                                 ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB4_8 Depth 2
                                        ##     Child Loop BB4_12 Depth 2
	movl	(%rax,%r15,4), %esi
	movq	%r14, %rdi
	movq	%r15, %rbx
	.p2align	4, 0x90
LBB4_8:                                 ##   Parent Loop BB4_7 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB4_11
## %bb.9:                               ##   in Loop: Header=BB4_8 Depth=2
	movl	%edx, (%rax,%rbx,4)
	leaq	-1(%rbx), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %rbx
	movq	%rdx, %rbx
	jg	LBB4_8
## %bb.10:                              ##   in Loop: Header=BB4_7 Depth=1
	xorl	%ebx, %ebx
LBB4_11:                                ##   in Loop: Header=BB4_7 Depth=1
	movslq	%ebx, %rdx
	movl	%esi, (%rax,%rdx,4)
	leaq	1(%r15), %rbx
	movl	4(%rax,%r15,4), %esi
	movq	%r11, %rdi
	.p2align	4, 0x90
LBB4_12:                                ##   Parent Loop BB4_7 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB4_15
## %bb.13:                              ##   in Loop: Header=BB4_12 Depth=2
	movl	%edx, (%rax,%rbx,4)
	leaq	-1(%rbx), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %rbx
	movq	%rdx, %rbx
	jg	LBB4_12
## %bb.14:                              ##   in Loop: Header=BB4_7 Depth=1
	xorl	%ebx, %ebx
	jmp	LBB4_15
	.cfi_endproc
                                        ## -- End function
	.globl	_insertionSort                  ## -- Begin function insertionSort
	.p2align	4, 0x90
_insertionSort:                         ## @insertionSort
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	$2, %esi
	jl	LBB5_18
## %bb.1:
	movabsq	$-4294967296, %rax              ## imm = 0xFFFFFFFF00000000
	movl	%esi, %r8d
	decq	%r8
	movl	$1, %r15d
	cmpl	$2, %esi
	jne	LBB5_2
LBB5_12:
	testb	$1, %r8b
	je	LBB5_18
## %bb.13:
	movl	(%rdi,%r15,4), %edx
	movq	%r15, %rsi
	shlq	$32, %rsi
	addq	%rax, %rsi
	.p2align	4, 0x90
LBB5_14:                                ## =>This Inner Loop Header: Depth=1
	movq	%rsi, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%edx, %ecx
	jle	LBB5_17
## %bb.15:                              ##   in Loop: Header=BB5_14 Depth=1
	movl	%ecx, (%rdi,%r15,4)
	leaq	-1(%r15), %rcx
	addq	%rax, %rsi
	cmpq	$1, %r15
	movq	%rcx, %r15
	jg	LBB5_14
## %bb.16:
	xorl	%r15d, %r15d
LBB5_17:
	movslq	%r15d, %rax
	movl	%edx, (%rdi,%rax,4)
LBB5_18:
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB5_2:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movq	%r8, %r10
	andq	$-2, %r10
	movl	$1, %r15d
	movabsq	$4294967296, %r11               ## imm = 0x100000000
	xorl	%r14d, %r14d
	jmp	LBB5_3
	.p2align	4, 0x90
LBB5_11:                                ##   in Loop: Header=BB5_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	addq	$2, %r15
	addq	%r9, %r14
	addq	%r9, %r11
	addq	$-2, %r10
	je	LBB5_12
LBB5_3:                                 ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB5_4 Depth 2
                                        ##     Child Loop BB5_8 Depth 2
	movl	(%rdi,%r15,4), %esi
	movq	%r14, %rdx
	movq	%r15, %rbx
	.p2align	4, 0x90
LBB5_4:                                 ##   Parent Loop BB5_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB5_7
## %bb.5:                               ##   in Loop: Header=BB5_4 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB5_4
## %bb.6:                               ##   in Loop: Header=BB5_3 Depth=1
	xorl	%ebx, %ebx
LBB5_7:                                 ##   in Loop: Header=BB5_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	leaq	1(%r15), %rbx
	movl	4(%rdi,%r15,4), %esi
	movq	%r11, %rdx
	.p2align	4, 0x90
LBB5_8:                                 ##   Parent Loop BB5_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB5_11
## %bb.9:                               ##   in Loop: Header=BB5_8 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB5_8
## %bb.10:                              ##   in Loop: Header=BB5_3 Depth=1
	xorl	%ebx, %ebx
	jmp	LBB5_11
	.cfi_endproc
                                        ## -- End function
	.globl	_random_data                    ## -- Begin function random_data
	.p2align	4, 0x90
_random_data:                           ## @random_data
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movl	%esi, %r14d
	movq	%rdi, %r15
	callq	_clock
	movl	%eax, %edi
	callq	_srand
	testl	%r14d, %r14d
	jle	LBB6_3
## %bb.1:
	movl	%r14d, %r14d
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB6_2:                                 ## =>This Inner Loop Header: Depth=1
	callq	_rand
	movl	%eax, (%r15,%rbx,4)
	incq	%rbx
	cmpq	%rbx, %r14
	jne	LBB6_2
LBB6_3:
	addq	$8, %rsp
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_insertionSortOptimized         ## -- Begin function insertionSortOptimized
	.p2align	4, 0x90
_insertionSortOptimized:                ## @insertionSortOptimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	$2, %esi
	jl	LBB7_18
## %bb.1:
	movabsq	$-4294967296, %rax              ## imm = 0xFFFFFFFF00000000
	movl	%esi, %r8d
	decq	%r8
	movl	$1, %r15d
	cmpl	$2, %esi
	jne	LBB7_2
LBB7_12:
	testb	$1, %r8b
	je	LBB7_18
## %bb.13:
	movl	(%rdi,%r15,4), %edx
	movq	%r15, %rsi
	shlq	$32, %rsi
	addq	%rax, %rsi
	.p2align	4, 0x90
LBB7_14:                                ## =>This Inner Loop Header: Depth=1
	movq	%rsi, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%edx, %ecx
	jle	LBB7_17
## %bb.15:                              ##   in Loop: Header=BB7_14 Depth=1
	movl	%ecx, (%rdi,%r15,4)
	leaq	-1(%r15), %rcx
	addq	%rax, %rsi
	cmpq	$1, %r15
	movq	%rcx, %r15
	jg	LBB7_14
## %bb.16:
	xorl	%r15d, %r15d
LBB7_17:
	movslq	%r15d, %rax
	movl	%edx, (%rdi,%rax,4)
LBB7_18:
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB7_2:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movq	%r8, %r10
	andq	$-2, %r10
	movl	$1, %r15d
	movabsq	$4294967296, %r11               ## imm = 0x100000000
	xorl	%r14d, %r14d
	jmp	LBB7_3
	.p2align	4, 0x90
LBB7_11:                                ##   in Loop: Header=BB7_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	addq	$2, %r15
	addq	%r9, %r14
	addq	%r9, %r11
	addq	$-2, %r10
	je	LBB7_12
LBB7_3:                                 ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB7_4 Depth 2
                                        ##     Child Loop BB7_8 Depth 2
	movl	(%rdi,%r15,4), %esi
	movq	%r14, %rdx
	movq	%r15, %rbx
	.p2align	4, 0x90
LBB7_4:                                 ##   Parent Loop BB7_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB7_7
## %bb.5:                               ##   in Loop: Header=BB7_4 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB7_4
## %bb.6:                               ##   in Loop: Header=BB7_3 Depth=1
	xorl	%ebx, %ebx
LBB7_7:                                 ##   in Loop: Header=BB7_3 Depth=1
	movslq	%ebx, %rcx
	movl	%esi, (%rdi,%rcx,4)
	leaq	1(%r15), %rbx
	movl	4(%rdi,%r15,4), %esi
	movq	%r11, %rdx
	.p2align	4, 0x90
LBB7_8:                                 ##   Parent Loop BB7_3 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdx, %rcx
	sarq	$30, %rcx
	movl	(%rdi,%rcx), %ecx
	cmpl	%esi, %ecx
	jle	LBB7_11
## %bb.9:                               ##   in Loop: Header=BB7_8 Depth=2
	movl	%ecx, (%rdi,%rbx,4)
	leaq	-1(%rbx), %rcx
	addq	%rax, %rdx
	cmpq	$1, %rbx
	movq	%rcx, %rbx
	jg	LBB7_8
## %bb.10:                              ##   in Loop: Header=BB7_3 Depth=1
	xorl	%ebx, %ebx
	jmp	LBB7_11
	.cfi_endproc
                                        ## -- End function
	.globl	_sign                           ## -- Begin function sign
	.p2align	4, 0x90
_sign:                                  ## @sign
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	%edi, %ecx
	sarl	$31, %ecx
	xorl	%eax, %eax
	testl	%edi, %edi
	setne	%al
	orl	%ecx, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_merging_optimzed               ## -- Begin function merging_optimzed
	.p2align	4, 0x90
_merging_optimzed:                      ## @merging_optimzed
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$24, %rsp
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $ecx killed $ecx def $rcx
                                        ## kill: def $edx killed $edx def $rdx
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	movq	%rax, -48(%rbp)
	leal	1(%rdx), %r9d
	movslq	%esi, %r8
	movl	(%rdi,%r8,4), %r10d
	movl	%r10d, -56(%rbp)
	movslq	%r9d, %rax
	movl	(%rdi,%rax,4), %r11d
	movl	%r11d, -52(%rbp)
	cmpl	%ecx, %edx
	jge	LBB9_1
## %bb.8:
	cmpl	%edx, %esi
	jg	LBB9_1
## %bb.9:
	leaq	(,%r8,4), %r12
	addq	_b@GOTPCREL(%rip), %r12
	movl	%esi, %r14d
	movl	%esi, %ebx
	.p2align	4, 0x90
LBB9_10:                                ## =>This Inner Loop Header: Depth=1
	movl	%ebx, %r15d
	xorl	%ebx, %ebx
	xorl	%eax, %eax
	cmpl	%r11d, %r10d
	setle	%bl
	setg	%al
	addl	%r15d, %ebx
	addl	%eax, %r9d
	movl	-56(%rbp,%rax,4), %eax
	movl	%eax, (%r12)
	movslq	%ebx, %rax
	movl	(%rdi,%rax,4), %r10d
	movl	%r10d, -56(%rbp)
	movslq	%r9d, %rax
	movl	(%rdi,%rax,4), %r11d
	movl	%r11d, -52(%rbp)
	incl	%r14d
	cmpl	%ecx, %eax
	jg	LBB9_2
## %bb.11:                              ##   in Loop: Header=BB9_10 Depth=1
	addq	$4, %r12
	cmpl	%edx, %ebx
	jle	LBB9_10
	jmp	LBB9_2
LBB9_1:
	movl	%esi, %r14d
	movl	%esi, %ebx
LBB9_2:
	cmpl	%edx, %ebx
	jg	LBB9_26
## %bb.3:
	movslq	%ebx, %r10
	movslq	%r14d, %r14
	movl	%edx, %r11d
	subl	%ebx, %r11d
	cmpl	$31, %r11d
	jb	LBB9_19
## %bb.4:
	movq	_b@GOTPCREL(%rip), %r15
	leaq	(%r15,%r14,4), %rax
	leaq	(%r10,%r11), %rbx
	leaq	(%rdi,%rbx,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rax
	jae	LBB9_6
## %bb.5:
	leaq	(%r14,%r11), %rax
	leaq	(%r15,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r10,4), %rbx
	cmpq	%rax, %rbx
	jb	LBB9_19
LBB9_6:
	incq	%r11
	movq	%r11, %rax
	andq	$-32, %rax
	movq	%rax, -64(%rbp)                 ## 8-byte Spill
	addq	$-32, %rax
	movq	%rax, %r13
	shrq	$5, %r13
	incq	%r13
	movl	%r13d, %r12d
	andl	$3, %r12d
	cmpq	$96, %rax
	jae	LBB9_12
## %bb.7:
	xorl	%ebx, %ebx
	jmp	LBB9_14
LBB9_12:
	leaq	(%r15,%r14,4), %rax
	addq	$480, %rax                      ## imm = 0x1E0
	leaq	(%rdi,%r10,4), %r15
	addq	$480, %r15                      ## imm = 0x1E0
	andq	$-4, %r13
	negq	%r13
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB9_13:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%r15,%rbx,4), %ymm0
	vmovups	-448(%r15,%rbx,4), %ymm1
	vmovups	-416(%r15,%rbx,4), %ymm2
	vmovups	-384(%r15,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rax,%rbx,4)
	vmovups	%ymm1, -448(%rax,%rbx,4)
	vmovups	%ymm2, -416(%rax,%rbx,4)
	vmovups	%ymm3, -384(%rax,%rbx,4)
	vmovups	-352(%r15,%rbx,4), %ymm0
	vmovups	-320(%r15,%rbx,4), %ymm1
	vmovups	-288(%r15,%rbx,4), %ymm2
	vmovups	-256(%r15,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rax,%rbx,4)
	vmovups	%ymm1, -320(%rax,%rbx,4)
	vmovups	%ymm2, -288(%rax,%rbx,4)
	vmovups	%ymm3, -256(%rax,%rbx,4)
	vmovups	-224(%r15,%rbx,4), %ymm0
	vmovups	-192(%r15,%rbx,4), %ymm1
	vmovups	-160(%r15,%rbx,4), %ymm2
	vmovups	-128(%r15,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rax,%rbx,4)
	vmovups	%ymm1, -192(%rax,%rbx,4)
	vmovups	%ymm2, -160(%rax,%rbx,4)
	vmovups	%ymm3, -128(%rax,%rbx,4)
	vmovups	-96(%r15,%rbx,4), %ymm0
	vmovups	-64(%r15,%rbx,4), %ymm1
	vmovups	-32(%r15,%rbx,4), %ymm2
	vmovups	(%r15,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rax,%rbx,4)
	vmovups	%ymm1, -64(%rax,%rbx,4)
	vmovups	%ymm2, -32(%rax,%rbx,4)
	vmovups	%ymm3, (%rax,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %r13
	jne	LBB9_13
LBB9_14:
	testq	%r12, %r12
	je	LBB9_17
## %bb.15:
	leaq	(%rbx,%r10), %rax
	leaq	(%rdi,%rax,4), %r15
	addq	$96, %r15
	addq	%r14, %rbx
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%rbx,4), %rbx
	addq	$96, %rbx
	shlq	$7, %r12
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB9_16:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%r15,%rax), %ymm0
	vmovups	-64(%r15,%rax), %ymm1
	vmovups	-32(%r15,%rax), %ymm2
	vmovups	(%r15,%rax), %ymm3
	vmovups	%ymm0, -96(%rbx,%rax)
	vmovups	%ymm1, -64(%rbx,%rax)
	vmovups	%ymm2, -32(%rbx,%rax)
	vmovups	%ymm3, (%rbx,%rax)
	subq	$-128, %rax
	cmpq	%rax, %r12
	jne	LBB9_16
LBB9_17:
	movq	-64(%rbp), %rax                 ## 8-byte Reload
	addq	%rax, %r14
	cmpq	%rax, %r11
	je	LBB9_26
## %bb.18:
	addq	%rax, %r10
LBB9_19:
	movl	%edx, %r11d
	subl	%r10d, %r11d
	leal	1(%r11), %ebx
	andl	$7, %ebx
	je	LBB9_22
## %bb.20:
	movq	_b@GOTPCREL(%rip), %r15
	.p2align	4, 0x90
LBB9_21:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r10,4), %eax
	incq	%r10
	movl	%eax, (%r15,%r14,4)
	incq	%r14
	decl	%ebx
	jne	LBB9_21
LBB9_22:
	cmpl	$7, %r11d
	jb	LBB9_26
## %bb.23:
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r14,4), %r11
	addq	$28, %r11
	subl	%r10d, %edx
	incl	%edx
	leaq	(%rdi,%r10,4), %r10
	addq	$28, %r10
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB9_24:                                ## =>This Inner Loop Header: Depth=1
	movl	-28(%r10,%rbx,4), %eax
	movl	%eax, -28(%r11,%rbx,4)
	movl	-24(%r10,%rbx,4), %eax
	movl	%eax, -24(%r11,%rbx,4)
	movl	-20(%r10,%rbx,4), %eax
	movl	%eax, -20(%r11,%rbx,4)
	movl	-16(%r10,%rbx,4), %eax
	movl	%eax, -16(%r11,%rbx,4)
	movl	-12(%r10,%rbx,4), %eax
	movl	%eax, -12(%r11,%rbx,4)
	movl	-8(%r10,%rbx,4), %eax
	movl	%eax, -8(%r11,%rbx,4)
	movl	-4(%r10,%rbx,4), %eax
	movl	%eax, -4(%r11,%rbx,4)
	movl	(%r10,%rbx,4), %eax
	movl	%eax, (%r11,%rbx,4)
	addq	$8, %rbx
	cmpl	%ebx, %edx
	jne	LBB9_24
## %bb.25:
	addq	%rbx, %r14
LBB9_26:
	cmpl	%ecx, %r9d
	jg	LBB9_45
## %bb.27:
	movslq	%r14d, %r12
	movslq	%r9d, %r13
	movl	%ecx, %r10d
	subl	%r9d, %r10d
	cmpl	$31, %r10d
	jb	LBB9_39
## %bb.28:
	movq	_b@GOTPCREL(%rip), %r9
	leaq	(%r9,%r12,4), %rax
	leaq	(%r10,%r13), %rdx
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	cmpq	%rdx, %rax
	jae	LBB9_30
## %bb.29:
	leaq	(%r12,%r10), %rax
	leaq	(%r9,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r13,4), %rdx
	cmpq	%rax, %rdx
	jb	LBB9_39
LBB9_30:
	incq	%r10
	movq	%r10, %r11
	andq	$-32, %r11
	leaq	-32(%r11), %rax
	movq	%rax, %r15
	shrq	$5, %r15
	incq	%r15
	movl	%r15d, %r14d
	andl	$3, %r14d
	cmpq	$96, %rax
	jae	LBB9_32
## %bb.31:
	xorl	%ebx, %ebx
	jmp	LBB9_34
LBB9_32:
	leaq	(%rdi,%r13,4), %rax
	addq	$480, %rax                      ## imm = 0x1E0
	leaq	(%r9,%r12,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	andq	$-4, %r15
	negq	%r15
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB9_33:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rax,%rbx,4), %ymm0
	vmovups	-448(%rax,%rbx,4), %ymm1
	vmovups	-416(%rax,%rbx,4), %ymm2
	vmovups	-384(%rax,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rbx,4)
	vmovups	%ymm1, -448(%rdx,%rbx,4)
	vmovups	%ymm2, -416(%rdx,%rbx,4)
	vmovups	%ymm3, -384(%rdx,%rbx,4)
	vmovups	-352(%rax,%rbx,4), %ymm0
	vmovups	-320(%rax,%rbx,4), %ymm1
	vmovups	-288(%rax,%rbx,4), %ymm2
	vmovups	-256(%rax,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rbx,4)
	vmovups	%ymm1, -320(%rdx,%rbx,4)
	vmovups	%ymm2, -288(%rdx,%rbx,4)
	vmovups	%ymm3, -256(%rdx,%rbx,4)
	vmovups	-224(%rax,%rbx,4), %ymm0
	vmovups	-192(%rax,%rbx,4), %ymm1
	vmovups	-160(%rax,%rbx,4), %ymm2
	vmovups	-128(%rax,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rbx,4)
	vmovups	%ymm1, -192(%rdx,%rbx,4)
	vmovups	%ymm2, -160(%rdx,%rbx,4)
	vmovups	%ymm3, -128(%rdx,%rbx,4)
	vmovups	-96(%rax,%rbx,4), %ymm0
	vmovups	-64(%rax,%rbx,4), %ymm1
	vmovups	-32(%rax,%rbx,4), %ymm2
	vmovups	(%rax,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx,4)
	vmovups	%ymm1, -64(%rdx,%rbx,4)
	vmovups	%ymm2, -32(%rdx,%rbx,4)
	vmovups	%ymm3, (%rdx,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %r15
	jne	LBB9_33
LBB9_34:
	testq	%r14, %r14
	je	LBB9_37
## %bb.35:
	leaq	(%rbx,%r12), %rax
	leaq	(%r9,%rax,4), %rax
	addq	$96, %rax
	addq	%r13, %rbx
	leaq	(%rdi,%rbx,4), %rdx
	addq	$96, %rdx
	shlq	$7, %r14
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB9_36:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rdx,%rbx), %ymm0
	vmovups	-64(%rdx,%rbx), %ymm1
	vmovups	-32(%rdx,%rbx), %ymm2
	vmovups	(%rdx,%rbx), %ymm3
	vmovups	%ymm0, -96(%rax,%rbx)
	vmovups	%ymm1, -64(%rax,%rbx)
	vmovups	%ymm2, -32(%rax,%rbx)
	vmovups	%ymm3, (%rax,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r14
	jne	LBB9_36
LBB9_37:
	cmpq	%r11, %r10
	je	LBB9_45
## %bb.38:
	addq	%r11, %r13
	addq	%r11, %r12
LBB9_39:
	movl	%ecx, %r9d
	subl	%r13d, %r9d
	leal	1(%r9), %edx
	andl	$7, %edx
	je	LBB9_42
## %bb.40:
	movq	_b@GOTPCREL(%rip), %rbx
	.p2align	4, 0x90
LBB9_41:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r13,4), %eax
	incq	%r13
	movl	%eax, (%rbx,%r12,4)
	incq	%r12
	decl	%edx
	jne	LBB9_41
LBB9_42:
	cmpl	$7, %r9d
	jb	LBB9_45
## %bb.43:
	movl	%ecx, %r9d
	subl	%r13d, %r9d
	incl	%r9d
	leaq	(%rdi,%r13,4), %r10
	addq	$28, %r10
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r12,4), %rbx
	addq	$28, %rbx
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB9_44:                                ## =>This Inner Loop Header: Depth=1
	movl	-28(%r10,%rax,4), %edx
	movl	%edx, -28(%rbx,%rax,4)
	movl	-24(%r10,%rax,4), %edx
	movl	%edx, -24(%rbx,%rax,4)
	movl	-20(%r10,%rax,4), %edx
	movl	%edx, -20(%rbx,%rax,4)
	movl	-16(%r10,%rax,4), %edx
	movl	%edx, -16(%rbx,%rax,4)
	movl	-12(%r10,%rax,4), %edx
	movl	%edx, -12(%rbx,%rax,4)
	movl	-8(%r10,%rax,4), %edx
	movl	%edx, -8(%rbx,%rax,4)
	movl	-4(%r10,%rax,4), %edx
	movl	%edx, -4(%rbx,%rax,4)
	movl	(%r10,%rax,4), %edx
	movl	%edx, (%rbx,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %r9d
	jne	LBB9_44
LBB9_45:
	movl	%ecx, %r11d
	subl	%esi, %r11d
	jl	LBB9_64
## %bb.46:
	cmpl	$31, %r11d
	jb	LBB9_58
## %bb.47:
	leaq	(%rdi,%r8,4), %rsi
	leaq	(%r11,%r8), %rax
	movq	_b@GOTPCREL(%rip), %rdx
	leaq	(%rdx,%rax,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rsi
	jae	LBB9_49
## %bb.48:
	leaq	(%rdi,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdx,%r8,4), %rdx
	cmpq	%rax, %rdx
	jb	LBB9_58
LBB9_49:
	incq	%r11
	movq	%r11, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rax
	movq	%rax, %rsi
	shrq	$5, %rsi
	incq	%rsi
	movl	%esi, %r10d
	andl	$3, %r10d
	cmpq	$96, %rax
	jae	LBB9_51
## %bb.50:
	xorl	%edx, %edx
	jmp	LBB9_53
LBB9_51:
	leaq	(%rdi,%r8,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	480(,%r8,4), %rax
	addq	_b@GOTPCREL(%rip), %rax
	andq	$-4, %rsi
	negq	%rsi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB9_52:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rax,%rdx,4), %ymm0
	vmovups	-448(%rax,%rdx,4), %ymm1
	vmovups	-416(%rax,%rdx,4), %ymm2
	vmovups	-384(%rax,%rdx,4), %ymm3
	vmovups	%ymm0, -480(%rbx,%rdx,4)
	vmovups	%ymm1, -448(%rbx,%rdx,4)
	vmovups	%ymm2, -416(%rbx,%rdx,4)
	vmovups	%ymm3, -384(%rbx,%rdx,4)
	vmovups	-352(%rax,%rdx,4), %ymm0
	vmovups	-320(%rax,%rdx,4), %ymm1
	vmovups	-288(%rax,%rdx,4), %ymm2
	vmovups	-256(%rax,%rdx,4), %ymm3
	vmovups	%ymm0, -352(%rbx,%rdx,4)
	vmovups	%ymm1, -320(%rbx,%rdx,4)
	vmovups	%ymm2, -288(%rbx,%rdx,4)
	vmovups	%ymm3, -256(%rbx,%rdx,4)
	vmovups	-224(%rax,%rdx,4), %ymm0
	vmovups	-192(%rax,%rdx,4), %ymm1
	vmovups	-160(%rax,%rdx,4), %ymm2
	vmovups	-128(%rax,%rdx,4), %ymm3
	vmovups	%ymm0, -224(%rbx,%rdx,4)
	vmovups	%ymm1, -192(%rbx,%rdx,4)
	vmovups	%ymm2, -160(%rbx,%rdx,4)
	vmovups	%ymm3, -128(%rbx,%rdx,4)
	vmovups	-96(%rax,%rdx,4), %ymm0
	vmovups	-64(%rax,%rdx,4), %ymm1
	vmovups	-32(%rax,%rdx,4), %ymm2
	vmovups	(%rax,%rdx,4), %ymm3
	vmovups	%ymm0, -96(%rbx,%rdx,4)
	vmovups	%ymm1, -64(%rbx,%rdx,4)
	vmovups	%ymm2, -32(%rbx,%rdx,4)
	vmovups	%ymm3, (%rbx,%rdx,4)
	subq	$-128, %rdx
	addq	$4, %rsi
	jne	LBB9_52
LBB9_53:
	testq	%r10, %r10
	je	LBB9_56
## %bb.54:
	addq	%r8, %rdx
	leaq	(%rdi,%rdx,4), %rax
	addq	$96, %rax
	leaq	96(,%rdx,4), %rdx
	addq	_b@GOTPCREL(%rip), %rdx
	shlq	$7, %r10
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB9_55:                                ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rdx,%rsi), %ymm0
	vmovups	-64(%rdx,%rsi), %ymm1
	vmovups	-32(%rdx,%rsi), %ymm2
	vmovups	(%rdx,%rsi), %ymm3
	vmovups	%ymm0, -96(%rax,%rsi)
	vmovups	%ymm1, -64(%rax,%rsi)
	vmovups	%ymm2, -32(%rax,%rsi)
	vmovups	%ymm3, (%rax,%rsi)
	subq	$-128, %rsi
	cmpq	%rsi, %r10
	jne	LBB9_55
LBB9_56:
	cmpq	%r9, %r11
	je	LBB9_64
## %bb.57:
	addq	%r9, %r8
LBB9_58:
	leal	1(%rcx), %eax
	movl	%eax, %edx
	subl	%r8d, %edx
	subl	%r8d, %ecx
	andl	$7, %edx
	je	LBB9_61
## %bb.59:
	movq	_b@GOTPCREL(%rip), %rsi
	.p2align	4, 0x90
LBB9_60:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rsi,%r8,4), %ebx
	movl	%ebx, (%rdi,%r8,4)
	incq	%r8
	decl	%edx
	jne	LBB9_60
LBB9_61:
	cmpl	$7, %ecx
	jb	LBB9_64
## %bb.62:
	movl	%eax, %eax
	movq	_b@GOTPCREL(%rip), %rcx
	.p2align	4, 0x90
LBB9_63:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rcx,%r8,4), %edx
	movl	%edx, (%rdi,%r8,4)
	movl	4(%rcx,%r8,4), %edx
	movl	%edx, 4(%rdi,%r8,4)
	movl	8(%rcx,%r8,4), %edx
	movl	%edx, 8(%rdi,%r8,4)
	movl	12(%rcx,%r8,4), %edx
	movl	%edx, 12(%rdi,%r8,4)
	movl	16(%rcx,%r8,4), %edx
	movl	%edx, 16(%rdi,%r8,4)
	movl	20(%rcx,%r8,4), %edx
	movl	%edx, 20(%rdi,%r8,4)
	movl	24(%rcx,%r8,4), %edx
	movl	%edx, 24(%rdi,%r8,4)
	movl	28(%rcx,%r8,4), %edx
	movl	%edx, 28(%rdi,%r8,4)
	addq	$8, %r8
	cmpl	%r8d, %eax
	jne	LBB9_63
LBB9_64:
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB9_66
## %bb.65:
	addq	$24, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
LBB9_66:
	vzeroupper
	callq	___stack_chk_fail
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_merge_optimized           ## -- Begin function sort_merge_optimized
	.p2align	4, 0x90
_sort_merge_optimized:                  ## @sort_merge_optimized
	.cfi_startproc
## %bb.0:
	cmpl	%edx, %esi
	jge	LBB10_1
## %bb.2:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movl	%edx, %r14d
	movl	%esi, %r12d
	movq	%rdi, %r15
	leal	(%r14,%r12), %eax
	movl	%eax, %ebx
	shrl	$31, %ebx
	addl	%eax, %ebx
	sarl	%ebx
	movl	%ebx, %edx
	callq	_sort_merge_optimized
	leal	1(%rbx), %esi
	movq	%r15, %rdi
	movl	%r14d, %edx
	callq	_sort_merge_optimized
	movq	%r15, %rdi
	movl	%r12d, %esi
	movl	%ebx, %edx
	movl	%r14d, %ecx
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	jmp	_merging_optimzed               ## TAILCALL
LBB10_1:
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_merging_standard               ## -- Begin function merging_standard
	.p2align	4, 0x90
_merging_standard:                      ## @merging_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $ecx killed $ecx def $rcx
                                        ## kill: def $edx killed $edx def $rdx
	leal	1(%rdx), %r14d
	cmpl	%edx, %esi
	jg	LBB11_1
## %bb.8:
	cmpl	%ecx, %edx
	jge	LBB11_1
## %bb.9:
	movslq	%esi, %r9
	shlq	$2, %r9
	addq	_b@GOTPCREL(%rip), %r9
	movl	%esi, %r8d
	movl	%esi, %ebx
	.p2align	4, 0x90
LBB11_10:                               ## =>This Inner Loop Header: Depth=1
	movslq	%ebx, %rbx
	movl	(%rdi,%rbx,4), %r15d
	movslq	%r14d, %r14
	movl	(%rdi,%r14,4), %r10d
	xorl	%r11d, %r11d
	xorl	%eax, %eax
	cmpl	%r10d, %r15d
	setg	%r11b
	setle	%al
	cmovgl	%r10d, %r15d
	addl	%eax, %ebx
	addl	%r11d, %r14d
	movl	%r15d, (%r9)
	incl	%r8d
	cmpl	%edx, %ebx
	jg	LBB11_2
## %bb.11:                              ##   in Loop: Header=BB11_10 Depth=1
	addq	$4, %r9
	cmpl	%ecx, %r14d
	jle	LBB11_10
	jmp	LBB11_2
LBB11_1:
	movl	%esi, %ebx
	movl	%esi, %r8d
LBB11_2:
	cmpl	%edx, %ebx
	jg	LBB11_26
## %bb.3:
	movslq	%r8d, %r8
	movslq	%ebx, %r9
	movl	%edx, %r10d
	subl	%ebx, %r10d
	cmpl	$31, %r10d
	jb	LBB11_19
## %bb.4:
	movq	_b@GOTPCREL(%rip), %r11
	leaq	(%r11,%r8,4), %rax
	leaq	(%r9,%r10), %rbx
	leaq	(%rdi,%rbx,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rax
	jae	LBB11_6
## %bb.5:
	leaq	(%r8,%r10), %rax
	leaq	(%r11,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r9,4), %rbx
	cmpq	%rax, %rbx
	jb	LBB11_19
LBB11_6:
	incq	%r10
	movq	%r10, %rax
	andq	$-32, %rax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	addq	$-32, %rax
	movq	%rax, %r12
	shrq	$5, %r12
	incq	%r12
	movl	%r12d, %r15d
	andl	$3, %r15d
	cmpq	$96, %rax
	jae	LBB11_12
## %bb.7:
	xorl	%r11d, %r11d
	jmp	LBB11_14
LBB11_12:
	leaq	(%rdi,%r9,4), %r13
	addq	$480, %r13                      ## imm = 0x1E0
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r8,4), %rax
	addq	$480, %rax                      ## imm = 0x1E0
	andq	$-4, %r12
	negq	%r12
	xorl	%r11d, %r11d
	.p2align	4, 0x90
LBB11_13:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%r13,%r11,4), %ymm0
	vmovups	-448(%r13,%r11,4), %ymm1
	vmovups	-416(%r13,%r11,4), %ymm2
	vmovups	-384(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -480(%rax,%r11,4)
	vmovups	%ymm1, -448(%rax,%r11,4)
	vmovups	%ymm2, -416(%rax,%r11,4)
	vmovups	%ymm3, -384(%rax,%r11,4)
	vmovups	-352(%r13,%r11,4), %ymm0
	vmovups	-320(%r13,%r11,4), %ymm1
	vmovups	-288(%r13,%r11,4), %ymm2
	vmovups	-256(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -352(%rax,%r11,4)
	vmovups	%ymm1, -320(%rax,%r11,4)
	vmovups	%ymm2, -288(%rax,%r11,4)
	vmovups	%ymm3, -256(%rax,%r11,4)
	vmovups	-224(%r13,%r11,4), %ymm0
	vmovups	-192(%r13,%r11,4), %ymm1
	vmovups	-160(%r13,%r11,4), %ymm2
	vmovups	-128(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -224(%rax,%r11,4)
	vmovups	%ymm1, -192(%rax,%r11,4)
	vmovups	%ymm2, -160(%rax,%r11,4)
	vmovups	%ymm3, -128(%rax,%r11,4)
	vmovups	-96(%r13,%r11,4), %ymm0
	vmovups	-64(%r13,%r11,4), %ymm1
	vmovups	-32(%r13,%r11,4), %ymm2
	vmovups	(%r13,%r11,4), %ymm3
	vmovups	%ymm0, -96(%rax,%r11,4)
	vmovups	%ymm1, -64(%rax,%r11,4)
	vmovups	%ymm2, -32(%rax,%r11,4)
	vmovups	%ymm3, (%rax,%r11,4)
	subq	$-128, %r11
	addq	$4, %r12
	jne	LBB11_13
LBB11_14:
	testq	%r15, %r15
	je	LBB11_17
## %bb.15:
	leaq	(%r11,%r8), %rax
	movq	_b@GOTPCREL(%rip), %rbx
	leaq	(%rbx,%rax,4), %r12
	addq	$96, %r12
	addq	%r9, %r11
	leaq	(%rdi,%r11,4), %rbx
	addq	$96, %rbx
	shlq	$7, %r15
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB11_16:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rbx,%rax), %ymm0
	vmovups	-64(%rbx,%rax), %ymm1
	vmovups	-32(%rbx,%rax), %ymm2
	vmovups	(%rbx,%rax), %ymm3
	vmovups	%ymm0, -96(%r12,%rax)
	vmovups	%ymm1, -64(%r12,%rax)
	vmovups	%ymm2, -32(%r12,%rax)
	vmovups	%ymm3, (%r12,%rax)
	subq	$-128, %rax
	cmpq	%rax, %r15
	jne	LBB11_16
LBB11_17:
	movq	-48(%rbp), %rax                 ## 8-byte Reload
	addq	%rax, %r8
	cmpq	%rax, %r10
	je	LBB11_26
## %bb.18:
	addq	%rax, %r9
LBB11_19:
	movl	%edx, %r10d
	subl	%r9d, %r10d
	leal	1(%r10), %ebx
	andl	$7, %ebx
	je	LBB11_22
## %bb.20:
	movq	_b@GOTPCREL(%rip), %r11
	.p2align	4, 0x90
LBB11_21:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r9,4), %eax
	incq	%r9
	movl	%eax, (%r11,%r8,4)
	incq	%r8
	decl	%ebx
	jne	LBB11_21
LBB11_22:
	cmpl	$7, %r10d
	jb	LBB11_26
## %bb.23:
	subl	%r9d, %edx
	incl	%edx
	leaq	(%rdi,%r9,4), %r9
	addq	$28, %r9
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r8,4), %r10
	addq	$28, %r10
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB11_24:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%r9,%rbx,4), %eax
	movl	%eax, -28(%r10,%rbx,4)
	movl	-24(%r9,%rbx,4), %eax
	movl	%eax, -24(%r10,%rbx,4)
	movl	-20(%r9,%rbx,4), %eax
	movl	%eax, -20(%r10,%rbx,4)
	movl	-16(%r9,%rbx,4), %eax
	movl	%eax, -16(%r10,%rbx,4)
	movl	-12(%r9,%rbx,4), %eax
	movl	%eax, -12(%r10,%rbx,4)
	movl	-8(%r9,%rbx,4), %eax
	movl	%eax, -8(%r10,%rbx,4)
	movl	-4(%r9,%rbx,4), %eax
	movl	%eax, -4(%r10,%rbx,4)
	movl	(%r9,%rbx,4), %eax
	movl	%eax, (%r10,%rbx,4)
	addq	$8, %rbx
	cmpl	%ebx, %edx
	jne	LBB11_24
## %bb.25:
	addq	%rbx, %r8
LBB11_26:
	cmpl	%ecx, %r14d
	jg	LBB11_45
## %bb.27:
	movslq	%r8d, %r8
	movslq	%r14d, %r12
	movl	%ecx, %r9d
	subl	%r14d, %r9d
	cmpl	$31, %r9d
	jb	LBB11_39
## %bb.28:
	movq	_b@GOTPCREL(%rip), %r10
	leaq	(%r10,%r8,4), %rax
	leaq	(%r12,%r9), %rdx
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	cmpq	%rdx, %rax
	jae	LBB11_30
## %bb.29:
	leaq	(%r8,%r9), %rax
	leaq	(%r10,%rax,4), %rax
	addq	$4, %rax
	leaq	(%rdi,%r12,4), %rdx
	cmpq	%rax, %rdx
	jb	LBB11_39
LBB11_30:
	incq	%r9
	movq	%r9, %r11
	andq	$-32, %r11
	leaq	-32(%r11), %rax
	movq	%rax, %r15
	shrq	$5, %r15
	incq	%r15
	movl	%r15d, %r14d
	andl	$3, %r14d
	cmpq	$96, %rax
	jae	LBB11_32
## %bb.31:
	xorl	%eax, %eax
	jmp	LBB11_34
LBB11_32:
	leaq	(%rdi,%r12,4), %rbx
	addq	$480, %rbx                      ## imm = 0x1E0
	leaq	(%r10,%r8,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	andq	$-4, %r15
	negq	%r15
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB11_33:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rbx,%rax,4), %ymm0
	vmovups	-448(%rbx,%rax,4), %ymm1
	vmovups	-416(%rbx,%rax,4), %ymm2
	vmovups	-384(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rax,4)
	vmovups	%ymm1, -448(%rdx,%rax,4)
	vmovups	%ymm2, -416(%rdx,%rax,4)
	vmovups	%ymm3, -384(%rdx,%rax,4)
	vmovups	-352(%rbx,%rax,4), %ymm0
	vmovups	-320(%rbx,%rax,4), %ymm1
	vmovups	-288(%rbx,%rax,4), %ymm2
	vmovups	-256(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rax,4)
	vmovups	%ymm1, -320(%rdx,%rax,4)
	vmovups	%ymm2, -288(%rdx,%rax,4)
	vmovups	%ymm3, -256(%rdx,%rax,4)
	vmovups	-224(%rbx,%rax,4), %ymm0
	vmovups	-192(%rbx,%rax,4), %ymm1
	vmovups	-160(%rbx,%rax,4), %ymm2
	vmovups	-128(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rax,4)
	vmovups	%ymm1, -192(%rdx,%rax,4)
	vmovups	%ymm2, -160(%rdx,%rax,4)
	vmovups	%ymm3, -128(%rdx,%rax,4)
	vmovups	-96(%rbx,%rax,4), %ymm0
	vmovups	-64(%rbx,%rax,4), %ymm1
	vmovups	-32(%rbx,%rax,4), %ymm2
	vmovups	(%rbx,%rax,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rax,4)
	vmovups	%ymm1, -64(%rdx,%rax,4)
	vmovups	%ymm2, -32(%rdx,%rax,4)
	vmovups	%ymm3, (%rdx,%rax,4)
	subq	$-128, %rax
	addq	$4, %r15
	jne	LBB11_33
LBB11_34:
	testq	%r14, %r14
	je	LBB11_37
## %bb.35:
	leaq	(%rax,%r8), %rdx
	leaq	(%r10,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%r12, %rax
	leaq	(%rdi,%rax,4), %rax
	addq	$96, %rax
	shlq	$7, %r14
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB11_36:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rax,%rbx), %ymm0
	vmovups	-64(%rax,%rbx), %ymm1
	vmovups	-32(%rax,%rbx), %ymm2
	vmovups	(%rax,%rbx), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx)
	vmovups	%ymm1, -64(%rdx,%rbx)
	vmovups	%ymm2, -32(%rdx,%rbx)
	vmovups	%ymm3, (%rdx,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r14
	jne	LBB11_36
LBB11_37:
	cmpq	%r11, %r9
	je	LBB11_45
## %bb.38:
	addq	%r11, %r12
	addq	%r11, %r8
LBB11_39:
	movl	%ecx, %r9d
	subl	%r12d, %r9d
	leal	1(%r9), %edx
	andl	$7, %edx
	je	LBB11_42
## %bb.40:
	movq	_b@GOTPCREL(%rip), %rbx
	.p2align	4, 0x90
LBB11_41:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%r12,4), %eax
	incq	%r12
	movl	%eax, (%rbx,%r8,4)
	incq	%r8
	decl	%edx
	jne	LBB11_41
LBB11_42:
	cmpl	$7, %r9d
	jb	LBB11_45
## %bb.43:
	movl	%ecx, %r9d
	subl	%r12d, %r9d
	incl	%r9d
	leaq	(%rdi,%r12,4), %r10
	addq	$28, %r10
	movq	_b@GOTPCREL(%rip), %rax
	leaq	(%rax,%r8,4), %rbx
	addq	$28, %rbx
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB11_44:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%r10,%rax,4), %edx
	movl	%edx, -28(%rbx,%rax,4)
	movl	-24(%r10,%rax,4), %edx
	movl	%edx, -24(%rbx,%rax,4)
	movl	-20(%r10,%rax,4), %edx
	movl	%edx, -20(%rbx,%rax,4)
	movl	-16(%r10,%rax,4), %edx
	movl	%edx, -16(%rbx,%rax,4)
	movl	-12(%r10,%rax,4), %edx
	movl	%edx, -12(%rbx,%rax,4)
	movl	-8(%r10,%rax,4), %edx
	movl	%edx, -8(%rbx,%rax,4)
	movl	-4(%r10,%rax,4), %edx
	movl	%edx, -4(%rbx,%rax,4)
	movl	(%r10,%rax,4), %edx
	movl	%edx, (%rbx,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %r9d
	jne	LBB11_44
LBB11_45:
	movl	%ecx, %r10d
	subl	%esi, %r10d
	jl	LBB11_64
## %bb.46:
	movslq	%esi, %rax
	cmpl	$31, %r10d
	jb	LBB11_58
## %bb.47:
	leaq	(%rdi,%rax,4), %rbx
	leaq	(%r10,%rax), %rdx
	movq	_b@GOTPCREL(%rip), %r8
	leaq	(%r8,%rdx,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rbx
	jae	LBB11_49
## %bb.48:
	leaq	(%rdi,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r8,%rax,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB11_58
LBB11_49:
	incq	%r10
	movq	%r10, %r8
	andq	$-32, %r8
	leaq	-32(%r8), %rdx
	movq	%rdx, %r11
	shrq	$5, %r11
	incq	%r11
	movl	%r11d, %r9d
	andl	$3, %r9d
	cmpq	$96, %rdx
	jae	LBB11_51
## %bb.50:
	xorl	%ebx, %ebx
	jmp	LBB11_53
LBB11_51:
	leaq	(%rdi,%rax,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	480(,%rax,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	andq	$-4, %r11
	negq	%r11
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB11_52:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rsi,%rbx,4), %ymm0
	vmovups	-448(%rsi,%rbx,4), %ymm1
	vmovups	-416(%rsi,%rbx,4), %ymm2
	vmovups	-384(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rbx,4)
	vmovups	%ymm1, -448(%rdx,%rbx,4)
	vmovups	%ymm2, -416(%rdx,%rbx,4)
	vmovups	%ymm3, -384(%rdx,%rbx,4)
	vmovups	-352(%rsi,%rbx,4), %ymm0
	vmovups	-320(%rsi,%rbx,4), %ymm1
	vmovups	-288(%rsi,%rbx,4), %ymm2
	vmovups	-256(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rbx,4)
	vmovups	%ymm1, -320(%rdx,%rbx,4)
	vmovups	%ymm2, -288(%rdx,%rbx,4)
	vmovups	%ymm3, -256(%rdx,%rbx,4)
	vmovups	-224(%rsi,%rbx,4), %ymm0
	vmovups	-192(%rsi,%rbx,4), %ymm1
	vmovups	-160(%rsi,%rbx,4), %ymm2
	vmovups	-128(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rbx,4)
	vmovups	%ymm1, -192(%rdx,%rbx,4)
	vmovups	%ymm2, -160(%rdx,%rbx,4)
	vmovups	%ymm3, -128(%rdx,%rbx,4)
	vmovups	-96(%rsi,%rbx,4), %ymm0
	vmovups	-64(%rsi,%rbx,4), %ymm1
	vmovups	-32(%rsi,%rbx,4), %ymm2
	vmovups	(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx,4)
	vmovups	%ymm1, -64(%rdx,%rbx,4)
	vmovups	%ymm2, -32(%rdx,%rbx,4)
	vmovups	%ymm3, (%rdx,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %r11
	jne	LBB11_52
LBB11_53:
	testq	%r9, %r9
	je	LBB11_56
## %bb.54:
	addq	%rax, %rbx
	leaq	(%rdi,%rbx,4), %rdx
	addq	$96, %rdx
	leaq	96(,%rbx,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	shlq	$7, %r9
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB11_55:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rbx), %ymm0
	vmovups	-64(%rsi,%rbx), %ymm1
	vmovups	-32(%rsi,%rbx), %ymm2
	vmovups	(%rsi,%rbx), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx)
	vmovups	%ymm1, -64(%rdx,%rbx)
	vmovups	%ymm2, -32(%rdx,%rbx)
	vmovups	%ymm3, (%rdx,%rbx)
	subq	$-128, %rbx
	cmpq	%rbx, %r9
	jne	LBB11_55
LBB11_56:
	cmpq	%r8, %r10
	je	LBB11_64
## %bb.57:
	addq	%r8, %rax
LBB11_58:
	leal	1(%rcx), %r8d
	movl	%r8d, %esi
	subl	%eax, %esi
	subl	%eax, %ecx
	andl	$7, %esi
	je	LBB11_61
## %bb.59:
	movq	_b@GOTPCREL(%rip), %rbx
	.p2align	4, 0x90
LBB11_60:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rbx,%rax,4), %edx
	movl	%edx, (%rdi,%rax,4)
	incq	%rax
	decl	%esi
	jne	LBB11_60
LBB11_61:
	cmpl	$7, %ecx
	jb	LBB11_64
## %bb.62:
	movl	%r8d, %ecx
	movq	_b@GOTPCREL(%rip), %rdx
	.p2align	4, 0x90
LBB11_63:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdx,%rax,4), %esi
	movl	%esi, (%rdi,%rax,4)
	movl	4(%rdx,%rax,4), %esi
	movl	%esi, 4(%rdi,%rax,4)
	movl	8(%rdx,%rax,4), %esi
	movl	%esi, 8(%rdi,%rax,4)
	movl	12(%rdx,%rax,4), %esi
	movl	%esi, 12(%rdi,%rax,4)
	movl	16(%rdx,%rax,4), %esi
	movl	%esi, 16(%rdi,%rax,4)
	movl	20(%rdx,%rax,4), %esi
	movl	%esi, 20(%rdi,%rax,4)
	movl	24(%rdx,%rax,4), %esi
	movl	%esi, 24(%rdi,%rax,4)
	movl	28(%rdx,%rax,4), %esi
	movl	%esi, 28(%rdi,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %ecx
	jne	LBB11_63
LBB11_64:
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_merge_standard            ## -- Begin function sort_merge_standard
	.p2align	4, 0x90
_sort_merge_standard:                   ## @sort_merge_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	%esi, %edx
	jle	LBB12_70
## %bb.1:
	movl	%edx, %r15d
	movl	%esi, %ebx
	movq	%rdi, %r12
	leal	(%r15,%rbx), %eax
	movl	%eax, %r13d
	shrl	$31, %r13d
	addl	%eax, %r13d
	sarl	%r13d
	movl	%r13d, %edx
	callq	_sort_merge_standard
	leal	1(%r13), %r14d
	movq	%r12, %rdi
	movl	%r14d, %esi
	movl	%r15d, %edx
	callq	_sort_merge_standard
	cmpl	%ebx, %r13d
	movq	%rbx, -48(%rbp)                 ## 8-byte Spill
	jl	LBB12_7
## %bb.2:
	cmpl	%r15d, %r13d
	movq	%r15, %r10
	jge	LBB12_6
## %bb.3:
	movslq	%ebx, %rdx
	shlq	$2, %rdx
	addq	_b@GOTPCREL(%rip), %rdx
	movl	%ebx, %r15d
	movl	%ebx, %ecx
	.p2align	4, 0x90
LBB12_4:                                ## =>This Inner Loop Header: Depth=1
	movslq	%ecx, %rcx
	movl	(%r12,%rcx,4), %esi
	movslq	%r14d, %r14
	movl	(%r12,%r14,4), %edi
	xorl	%eax, %eax
	xorl	%ebx, %ebx
	cmpl	%edi, %esi
	setg	%al
	setle	%bl
	cmovgl	%edi, %esi
	addl	%ebx, %ecx
	addl	%eax, %r14d
	movl	%esi, (%rdx)
	incl	%r15d
	cmpl	%r13d, %ecx
	jg	LBB12_9
## %bb.5:                               ##   in Loop: Header=BB12_4 Depth=1
	addq	$4, %rdx
	cmpl	%r10d, %r14d
	jle	LBB12_4
	jmp	LBB12_9
LBB12_6:
	movl	%ebx, %ecx
	jmp	LBB12_8
LBB12_7:
	movl	%ebx, %ecx
	movq	%r15, %r10
LBB12_8:
	movl	%ebx, %r15d
LBB12_9:
	movl	%r13d, %r11d
	subl	%ecx, %r11d
	jl	LBB12_30
## %bb.10:
	movslq	%r15d, %r15
	movslq	%ecx, %rcx
	cmpl	$31, %r11d
	jb	LBB12_23
## %bb.11:
	movq	_b@GOTPCREL(%rip), %rbx
	leaq	(%rbx,%r15,4), %rdx
	leaq	(%rcx,%r11), %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rdx
	jae	LBB12_13
## %bb.12:
	leaq	(%r15,%r11), %rdx
	leaq	(%rbx,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r12,%rcx,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB12_23
LBB12_13:
	movq	%r10, %rax
	incq	%r11
	movq	%r11, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rdi
	shrq	$5, %rdi
	incq	%rdi
	movl	%edi, %r10d
	andl	$3, %r10d
	cmpq	$96, %rdx
	jae	LBB12_15
## %bb.14:
	xorl	%esi, %esi
	jmp	LBB12_17
LBB12_15:
	leaq	(%r12,%rcx,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	(%rbx,%r15,4), %r8
	addq	$480, %r8                       ## imm = 0x1E0
	andq	$-4, %rdi
	negq	%rdi
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB12_16:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdx,%rsi,4), %ymm0
	vmovups	-448(%rdx,%rsi,4), %ymm1
	vmovups	-416(%rdx,%rsi,4), %ymm2
	vmovups	-384(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%r8,%rsi,4)
	vmovups	%ymm1, -448(%r8,%rsi,4)
	vmovups	%ymm2, -416(%r8,%rsi,4)
	vmovups	%ymm3, -384(%r8,%rsi,4)
	vmovups	-352(%rdx,%rsi,4), %ymm0
	vmovups	-320(%rdx,%rsi,4), %ymm1
	vmovups	-288(%rdx,%rsi,4), %ymm2
	vmovups	-256(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%r8,%rsi,4)
	vmovups	%ymm1, -320(%r8,%rsi,4)
	vmovups	%ymm2, -288(%r8,%rsi,4)
	vmovups	%ymm3, -256(%r8,%rsi,4)
	vmovups	-224(%rdx,%rsi,4), %ymm0
	vmovups	-192(%rdx,%rsi,4), %ymm1
	vmovups	-160(%rdx,%rsi,4), %ymm2
	vmovups	-128(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%r8,%rsi,4)
	vmovups	%ymm1, -192(%r8,%rsi,4)
	vmovups	%ymm2, -160(%r8,%rsi,4)
	vmovups	%ymm3, -128(%r8,%rsi,4)
	vmovups	-96(%rdx,%rsi,4), %ymm0
	vmovups	-64(%rdx,%rsi,4), %ymm1
	vmovups	-32(%rdx,%rsi,4), %ymm2
	vmovups	(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%r8,%rsi,4)
	vmovups	%ymm1, -64(%r8,%rsi,4)
	vmovups	%ymm2, -32(%r8,%rsi,4)
	vmovups	%ymm3, (%r8,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %rdi
	jne	LBB12_16
LBB12_17:
	testq	%r10, %r10
	je	LBB12_20
## %bb.18:
	leaq	(%rsi,%r15), %rdx
	leaq	(%rbx,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%rcx, %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r10
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB12_19:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r10
	jne	LBB12_19
LBB12_20:
	addq	%r9, %r15
	cmpq	%r9, %r11
	jne	LBB12_22
## %bb.21:
	movq	%rax, %r10
	jmp	LBB12_30
LBB12_22:
	addq	%r9, %rcx
	movq	%rax, %r10
LBB12_23:
	movl	%r13d, %r8d
	subl	%ecx, %r8d
	leal	1(%r8), %esi
	andl	$7, %esi
	je	LBB12_26
## %bb.24:
	movq	_b@GOTPCREL(%rip), %rdi
	.p2align	4, 0x90
LBB12_25:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r12,%rcx,4), %edx
	incq	%rcx
	movl	%edx, (%rdi,%r15,4)
	incq	%r15
	decl	%esi
	jne	LBB12_25
LBB12_26:
	cmpl	$7, %r8d
	jb	LBB12_30
## %bb.27:
	subl	%ecx, %r13d
	incl	%r13d
	leaq	(%r12,%rcx,4), %rcx
	addq	$28, %rcx
	movq	_b@GOTPCREL(%rip), %rdx
	leaq	(%rdx,%r15,4), %rsi
	addq	$28, %rsi
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB12_28:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rcx,%rdx,4), %eax
	movl	%eax, -28(%rsi,%rdx,4)
	movl	-24(%rcx,%rdx,4), %eax
	movl	%eax, -24(%rsi,%rdx,4)
	movl	-20(%rcx,%rdx,4), %eax
	movl	%eax, -20(%rsi,%rdx,4)
	movl	-16(%rcx,%rdx,4), %eax
	movl	%eax, -16(%rsi,%rdx,4)
	movl	-12(%rcx,%rdx,4), %eax
	movl	%eax, -12(%rsi,%rdx,4)
	movl	-8(%rcx,%rdx,4), %eax
	movl	%eax, -8(%rsi,%rdx,4)
	movl	-4(%rcx,%rdx,4), %eax
	movl	%eax, -4(%rsi,%rdx,4)
	movl	(%rcx,%rdx,4), %eax
	movl	%eax, (%rsi,%rdx,4)
	addq	$8, %rdx
	cmpl	%edx, %r13d
	jne	LBB12_28
## %bb.29:
	addq	%rdx, %r15
LBB12_30:
	cmpl	%r10d, %r14d
	jg	LBB12_51
## %bb.31:
	movslq	%r15d, %rax
	movslq	%r14d, %rcx
	movq	%r10, %r15
                                        ## kill: def $r10d killed $r10d killed $r10 def $r10
	subl	%r14d, %r10d
	cmpl	$31, %r10d
	jb	LBB12_32
## %bb.33:
	movq	_b@GOTPCREL(%rip), %r8
	leaq	(%r8,%rax,4), %rdx
	leaq	(%rcx,%r10), %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$4, %rsi
	cmpq	%rsi, %rdx
	jae	LBB12_36
## %bb.34:
	leaq	(%rax,%r10), %rdx
	leaq	(%r8,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%r12,%rcx,4), %rsi
	cmpq	%rdx, %rsi
	jae	LBB12_36
LBB12_32:
	movq	%r15, %r10
LBB12_45:
	movl	%r10d, %edx
	subl	%ecx, %edx
	leal	1(%rdx), %esi
	andl	$7, %esi
	je	LBB12_48
## %bb.46:
	movq	_b@GOTPCREL(%rip), %rdi
	.p2align	4, 0x90
LBB12_47:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r12,%rcx,4), %ebx
	incq	%rcx
	movl	%ebx, (%rdi,%rax,4)
	incq	%rax
	decl	%esi
	jne	LBB12_47
LBB12_48:
	cmpl	$7, %edx
	jb	LBB12_51
## %bb.49:
	movl	%r10d, %edx
	subl	%ecx, %edx
	incl	%edx
	leaq	(%r12,%rcx,4), %rcx
	addq	$28, %rcx
	movq	_b@GOTPCREL(%rip), %rsi
	leaq	(%rsi,%rax,4), %rax
	addq	$28, %rax
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB12_50:                               ## =>This Inner Loop Header: Depth=1
	movl	-28(%rcx,%rsi,4), %edi
	movl	%edi, -28(%rax,%rsi,4)
	movl	-24(%rcx,%rsi,4), %edi
	movl	%edi, -24(%rax,%rsi,4)
	movl	-20(%rcx,%rsi,4), %edi
	movl	%edi, -20(%rax,%rsi,4)
	movl	-16(%rcx,%rsi,4), %edi
	movl	%edi, -16(%rax,%rsi,4)
	movl	-12(%rcx,%rsi,4), %edi
	movl	%edi, -12(%rax,%rsi,4)
	movl	-8(%rcx,%rsi,4), %edi
	movl	%edi, -8(%rax,%rsi,4)
	movl	-4(%rcx,%rsi,4), %edi
	movl	%edi, -4(%rax,%rsi,4)
	movl	(%rcx,%rsi,4), %edi
	movl	%edi, (%rax,%rsi,4)
	addq	$8, %rsi
	cmpl	%esi, %edx
	jne	LBB12_50
	jmp	LBB12_51
LBB12_36:
	incq	%r10
	movq	%r10, %r9
	andq	$-32, %r9
	leaq	-32(%r9), %rdx
	movq	%rdx, %rbx
	shrq	$5, %rbx
	incq	%rbx
	movl	%ebx, %r11d
	andl	$3, %r11d
	cmpq	$96, %rdx
	jae	LBB12_38
## %bb.37:
	xorl	%esi, %esi
	jmp	LBB12_40
LBB12_38:
	leaq	(%r12,%rcx,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	(%r8,%rax,4), %rdi
	addq	$480, %rdi                      ## imm = 0x1E0
	andq	$-4, %rbx
	negq	%rbx
	xorl	%esi, %esi
	.p2align	4, 0x90
LBB12_39:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rdx,%rsi,4), %ymm0
	vmovups	-448(%rdx,%rsi,4), %ymm1
	vmovups	-416(%rdx,%rsi,4), %ymm2
	vmovups	-384(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -480(%rdi,%rsi,4)
	vmovups	%ymm1, -448(%rdi,%rsi,4)
	vmovups	%ymm2, -416(%rdi,%rsi,4)
	vmovups	%ymm3, -384(%rdi,%rsi,4)
	vmovups	-352(%rdx,%rsi,4), %ymm0
	vmovups	-320(%rdx,%rsi,4), %ymm1
	vmovups	-288(%rdx,%rsi,4), %ymm2
	vmovups	-256(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -352(%rdi,%rsi,4)
	vmovups	%ymm1, -320(%rdi,%rsi,4)
	vmovups	%ymm2, -288(%rdi,%rsi,4)
	vmovups	%ymm3, -256(%rdi,%rsi,4)
	vmovups	-224(%rdx,%rsi,4), %ymm0
	vmovups	-192(%rdx,%rsi,4), %ymm1
	vmovups	-160(%rdx,%rsi,4), %ymm2
	vmovups	-128(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -224(%rdi,%rsi,4)
	vmovups	%ymm1, -192(%rdi,%rsi,4)
	vmovups	%ymm2, -160(%rdi,%rsi,4)
	vmovups	%ymm3, -128(%rdi,%rsi,4)
	vmovups	-96(%rdx,%rsi,4), %ymm0
	vmovups	-64(%rdx,%rsi,4), %ymm1
	vmovups	-32(%rdx,%rsi,4), %ymm2
	vmovups	(%rdx,%rsi,4), %ymm3
	vmovups	%ymm0, -96(%rdi,%rsi,4)
	vmovups	%ymm1, -64(%rdi,%rsi,4)
	vmovups	%ymm2, -32(%rdi,%rsi,4)
	vmovups	%ymm3, (%rdi,%rsi,4)
	subq	$-128, %rsi
	addq	$4, %rbx
	jne	LBB12_39
LBB12_40:
	testq	%r11, %r11
	je	LBB12_43
## %bb.41:
	leaq	(%rsi,%rax), %rdx
	leaq	(%r8,%rdx,4), %rdx
	addq	$96, %rdx
	addq	%rcx, %rsi
	leaq	(%r12,%rsi,4), %rsi
	addq	$96, %rsi
	shlq	$7, %r11
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB12_42:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r11
	jne	LBB12_42
LBB12_43:
	cmpq	%r9, %r10
	movq	%r15, %r10
	jne	LBB12_44
LBB12_51:
	movl	%r10d, %ecx
	movq	-48(%rbp), %rax                 ## 8-byte Reload
	subl	%eax, %ecx
	jl	LBB12_70
## %bb.52:
	cltq
	cmpl	$31, %ecx
	jb	LBB12_64
## %bb.53:
	leaq	(%r12,%rax,4), %rdi
	leaq	(%rcx,%rax), %rdx
	movq	_b@GOTPCREL(%rip), %rsi
	leaq	(%rsi,%rdx,4), %rbx
	addq	$4, %rbx
	cmpq	%rbx, %rdi
	jae	LBB12_55
## %bb.54:
	leaq	(%r12,%rdx,4), %rdx
	addq	$4, %rdx
	leaq	(%rsi,%rax,4), %rsi
	cmpq	%rdx, %rsi
	jb	LBB12_64
LBB12_55:
	incq	%rcx
	movq	%rcx, %r8
	andq	$-32, %r8
	leaq	-32(%r8), %rdx
	movq	%rdx, %rdi
	shrq	$5, %rdi
	incq	%rdi
	movl	%edi, %r9d
	andl	$3, %r9d
	cmpq	$96, %rdx
	jae	LBB12_57
## %bb.56:
	xorl	%ebx, %ebx
	jmp	LBB12_59
LBB12_44:
	addq	%r9, %rcx
	addq	%r9, %rax
	jmp	LBB12_45
LBB12_57:
	leaq	(%r12,%rax,4), %rdx
	addq	$480, %rdx                      ## imm = 0x1E0
	leaq	480(,%rax,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	andq	$-4, %rdi
	negq	%rdi
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB12_58:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-480(%rsi,%rbx,4), %ymm0
	vmovups	-448(%rsi,%rbx,4), %ymm1
	vmovups	-416(%rsi,%rbx,4), %ymm2
	vmovups	-384(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -480(%rdx,%rbx,4)
	vmovups	%ymm1, -448(%rdx,%rbx,4)
	vmovups	%ymm2, -416(%rdx,%rbx,4)
	vmovups	%ymm3, -384(%rdx,%rbx,4)
	vmovups	-352(%rsi,%rbx,4), %ymm0
	vmovups	-320(%rsi,%rbx,4), %ymm1
	vmovups	-288(%rsi,%rbx,4), %ymm2
	vmovups	-256(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -352(%rdx,%rbx,4)
	vmovups	%ymm1, -320(%rdx,%rbx,4)
	vmovups	%ymm2, -288(%rdx,%rbx,4)
	vmovups	%ymm3, -256(%rdx,%rbx,4)
	vmovups	-224(%rsi,%rbx,4), %ymm0
	vmovups	-192(%rsi,%rbx,4), %ymm1
	vmovups	-160(%rsi,%rbx,4), %ymm2
	vmovups	-128(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -224(%rdx,%rbx,4)
	vmovups	%ymm1, -192(%rdx,%rbx,4)
	vmovups	%ymm2, -160(%rdx,%rbx,4)
	vmovups	%ymm3, -128(%rdx,%rbx,4)
	vmovups	-96(%rsi,%rbx,4), %ymm0
	vmovups	-64(%rsi,%rbx,4), %ymm1
	vmovups	-32(%rsi,%rbx,4), %ymm2
	vmovups	(%rsi,%rbx,4), %ymm3
	vmovups	%ymm0, -96(%rdx,%rbx,4)
	vmovups	%ymm1, -64(%rdx,%rbx,4)
	vmovups	%ymm2, -32(%rdx,%rbx,4)
	vmovups	%ymm3, (%rdx,%rbx,4)
	subq	$-128, %rbx
	addq	$4, %rdi
	jne	LBB12_58
LBB12_59:
	testq	%r9, %r9
	je	LBB12_62
## %bb.60:
	addq	%rax, %rbx
	leaq	(%r12,%rbx,4), %rdx
	addq	$96, %rdx
	leaq	96(,%rbx,4), %rsi
	addq	_b@GOTPCREL(%rip), %rsi
	shlq	$7, %r9
	xorl	%edi, %edi
	.p2align	4, 0x90
LBB12_61:                               ## =>This Inner Loop Header: Depth=1
	vmovups	-96(%rsi,%rdi), %ymm0
	vmovups	-64(%rsi,%rdi), %ymm1
	vmovups	-32(%rsi,%rdi), %ymm2
	vmovups	(%rsi,%rdi), %ymm3
	vmovups	%ymm0, -96(%rdx,%rdi)
	vmovups	%ymm1, -64(%rdx,%rdi)
	vmovups	%ymm2, -32(%rdx,%rdi)
	vmovups	%ymm3, (%rdx,%rdi)
	subq	$-128, %rdi
	cmpq	%rdi, %r9
	jne	LBB12_61
LBB12_62:
	cmpq	%r8, %rcx
	je	LBB12_70
## %bb.63:
	addq	%r8, %rax
LBB12_64:
	leal	1(%r10), %ecx
	movl	%ecx, %edx
	subl	%eax, %edx
	subl	%eax, %r10d
	andl	$7, %edx
	je	LBB12_67
## %bb.65:
	movq	_b@GOTPCREL(%rip), %rsi
	.p2align	4, 0x90
LBB12_66:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rsi,%rax,4), %edi
	movl	%edi, (%r12,%rax,4)
	incq	%rax
	decl	%edx
	jne	LBB12_66
LBB12_67:
	cmpl	$7, %r10d
	jb	LBB12_70
## %bb.68:
	movl	%ecx, %ecx
	movq	_b@GOTPCREL(%rip), %rdx
	.p2align	4, 0x90
LBB12_69:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdx,%rax,4), %esi
	movl	%esi, (%r12,%rax,4)
	movl	4(%rdx,%rax,4), %esi
	movl	%esi, 4(%r12,%rax,4)
	movl	8(%rdx,%rax,4), %esi
	movl	%esi, 8(%r12,%rax,4)
	movl	12(%rdx,%rax,4), %esi
	movl	%esi, 12(%r12,%rax,4)
	movl	16(%rdx,%rax,4), %esi
	movl	%esi, 16(%r12,%rax,4)
	movl	20(%rdx,%rax,4), %esi
	movl	%esi, 20(%r12,%rax,4)
	movl	24(%rdx,%rax,4), %esi
	movl	%esi, 24(%r12,%rax,4)
	movl	28(%rdx,%rax,4), %esi
	movl	%esi, 28(%r12,%rax,4)
	addq	$8, %rax
	cmpl	%eax, %ecx
	jne	LBB12_69
LBB12_70:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	vzeroupper
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_max                            ## -- Begin function max
	.p2align	4, 0x90
_max:                                   ## @max
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movl	%esi, %eax
	cmpl	%esi, %edi
	cmovgl	%edi, %eax
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_optimized      ## -- Begin function partition_quick_optimized
	.p2align	4, 0x90
_partition_quick_optimized:             ## @partition_quick_optimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB14_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%rdi,%r8,4), %r9d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r15d
	movslq	%edx, %r11
	movl	(%rdi,%r11,4), %r14d
	cmpl	%r15d, %r9d
	movl	%r15d, %ebx
	cmovll	%r9d, %ebx
	movl	%r15d, %ecx
	cmovgl	%r9d, %ecx
	cmpl	%r14d, %ebx
	cmovgel	%r14d, %ebx
	cmpl	%r14d, %ecx
	cmovlel	%r14d, %ecx
	addl	%r9d, %r15d
	addl	%r14d, %r15d
	subl	%ebx, %r15d
	subl	%ecx, %r15d
	movl	%ebx, (%rdi,%r8,4)
	movl	%r15d, (%rdi,%r11,4)
	movl	%ecx, (%rdi,%r10,4)
	movl	%edx, %r9d
	subl	%esi, %r9d
	jg	LBB14_5
LBB14_4:
	movslq	%edx, %r14
	jmp	LBB14_10
LBB14_2:
	movslq	%edx, %rax
	movl	(%rdi,%rax,4), %r15d
	movl	%edx, %r9d
	subl	%esi, %r9d
	jle	LBB14_4
LBB14_5:
	movslq	%esi, %rcx
	movslq	%edx, %r14
	movq	%rcx, %r8
	notq	%r8
	testb	$1, %r9b
	jne	LBB14_7
## %bb.6:
                                        ## implicit-def: $r9d
	addq	%r14, %r8
	jne	LBB14_11
	jmp	LBB14_9
LBB14_7:
	movl	(%rdi,%rcx,4), %r11d
	xorl	%r9d, %r9d
	cmpl	%r11d, %r15d
	setg	%r9b
	movl	(%rdi,%rcx,4), %r10d
	movl	%r10d, %ebx
	cmovgl	%r11d, %ebx
	movl	%ebx, (%rdi,%rcx,4)
	cmovgl	%r10d, %r11d
	movl	%r11d, (%rdi,%rcx,4)
	addl	%esi, %r9d
	incq	%rcx
	movl	%r9d, %esi
	addq	%r14, %r8
	jne	LBB14_11
LBB14_9:
	movl	%r9d, %esi
	jmp	LBB14_10
	.p2align	4, 0x90
LBB14_11:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rcx,4), %ebx
	xorl	%r8d, %r8d
	cmpl	%ebx, %r15d
	setg	%r8b
	movslq	%esi, %rsi
	movl	(%rdi,%rsi,4), %edx
	movl	%edx, %eax
	cmovgl	%ebx, %eax
	movl	%eax, (%rdi,%rsi,4)
	cmovgl	%edx, %ebx
	movl	%ebx, (%rdi,%rcx,4)
	addl	%r8d, %esi
	movl	4(%rdi,%rcx,4), %eax
	xorl	%r8d, %r8d
	cmpl	%eax, %r15d
	setg	%r8b
	movslq	%esi, %rsi
	movl	(%rdi,%rsi,4), %edx
	movl	%edx, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%rdi,%rsi,4)
	cmovgl	%edx, %eax
	movl	%eax, 4(%rdi,%rcx,4)
	addl	%r8d, %esi
	addq	$2, %rcx
	cmpq	%rcx, %r14
	jne	LBB14_11
LBB14_10:
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r14,4), %esi
	movl	%esi, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r14,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_optimized           ## -- Begin function sort_quick_optimized
	.p2align	4, 0x90
_sort_quick_optimized:                  ## @sort_quick_optimized
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB15_26
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %r12
	movslq	%edx, %r15
	movq	%r15, %rax
	negq	%rax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	jmp	LBB15_2
	.p2align	4, 0x90
LBB15_7:                                ##   in Loop: Header=BB15_2 Depth=1
	movslq	%edx, %rbx
	movl	(%r12,%rbx,4), %eax
	movl	(%r12,%r15,4), %ecx
	movl	%ecx, (%r12,%rbx,4)
	movl	%eax, (%r12,%r15,4)
	leal	-1(%rbx), %edx
	movq	%r12, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	callq	_sort_quick_optimized
	incl	%ebx
	movl	%ebx, %esi
	cmpl	%r14d, %ebx
	jge	LBB15_26
LBB15_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB15_6 Depth 2
	movl	%r14d, %r11d
	subl	%esi, %r11d
	cmpl	$6, %r11d
	jl	LBB15_8
## %bb.3:                               ##   in Loop: Header=BB15_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%r12,%r8,4), %r10d
	movslq	%ecx, %r9
	movl	(%r12,%r9,4), %r13d
	movl	(%r12,%r15,4), %ecx
	cmpl	%r13d, %r10d
	movl	%r13d, %edx
	cmovll	%r10d, %edx
	movl	%r13d, %edi
	cmovgl	%r10d, %edi
	cmpl	%ecx, %edx
	cmovgel	%ecx, %edx
	cmpl	%ecx, %edi
	cmovlel	%ecx, %edi
	addl	%r10d, %r13d
	addl	%ecx, %r13d
	subl	%edx, %r13d
	subl	%edi, %r13d
	movl	%edx, (%r12,%r8,4)
	movl	%r13d, (%r12,%r15,4)
	movl	%edi, (%r12,%r9,4)
	movq	%r8, %rcx
	movl	%esi, %edx
	testb	$1, %r11b
	je	LBB15_5
## %bb.4:                               ##   in Loop: Header=BB15_2 Depth=1
	movl	(%r12,%r8,4), %ecx
	xorl	%edx, %edx
	cmpl	%ecx, %r13d
	setg	%dl
	movl	(%r12,%r8,4), %r9d
	movl	%r9d, %edi
	cmovgl	%ecx, %edi
	movl	%edi, (%r12,%r8,4)
	cmovgl	%r9d, %ecx
	movl	%ecx, (%r12,%r8,4)
	addl	%esi, %edx
	leaq	1(%r8), %rcx
LBB15_5:                                ##   in Loop: Header=BB15_2 Depth=1
	notq	%r8
	cmpq	-48(%rbp), %r8                  ## 8-byte Folded Reload
	je	LBB15_7
	.p2align	4, 0x90
LBB15_6:                                ##   Parent Loop BB15_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r12,%rcx,4), %edi
	xorl	%r8d, %r8d
	cmpl	%edi, %r13d
	setg	%r8b
	movslq	%edx, %rdx
	movl	(%r12,%rdx,4), %eax
	movl	%eax, %ebx
	cmovgl	%edi, %ebx
	movl	%ebx, (%r12,%rdx,4)
	cmovgl	%eax, %edi
	movl	%edi, (%r12,%rcx,4)
	addl	%r8d, %edx
	movl	4(%r12,%rcx,4), %eax
	xorl	%r8d, %r8d
	cmpl	%eax, %r13d
	setg	%r8b
	movslq	%edx, %rdx
	movl	(%r12,%rdx,4), %edi
	movl	%edi, %ebx
	cmovgl	%eax, %ebx
	movl	%ebx, (%r12,%rdx,4)
	cmovgl	%edi, %eax
	movl	%eax, 4(%r12,%rcx,4)
	addl	%r8d, %edx
	addq	$2, %rcx
	cmpq	%rcx, %r15
	jne	LBB15_6
	jmp	LBB15_7
LBB15_8:
	testl	%r11d, %r11d
	jle	LBB15_26
## %bb.9:
	movslq	%esi, %rax
	leaq	(%r12,%rax,4), %rax
	movabsq	$-4294967296, %rcx              ## imm = 0xFFFFFFFF00000000
	movl	%r11d, %r8d
	movl	$1, %r15d
	cmpl	$1, %r11d
	jne	LBB15_10
LBB15_20:
	testb	$1, %r8b
	je	LBB15_26
## %bb.21:
	movl	(%rax,%r15,4), %esi
	movq	%r15, %rdi
	shlq	$32, %rdi
	addq	%rcx, %rdi
	.p2align	4, 0x90
LBB15_22:                               ## =>This Inner Loop Header: Depth=1
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB15_25
## %bb.23:                              ##   in Loop: Header=BB15_22 Depth=1
	movl	%edx, (%rax,%r15,4)
	leaq	-1(%r15), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %r15
	movq	%rdx, %r15
	jg	LBB15_22
## %bb.24:
	xorl	%r15d, %r15d
LBB15_25:
	movslq	%r15d, %rcx
	movl	%esi, (%rax,%rcx,4)
LBB15_26:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB15_10:
	movabsq	$8589934592, %r9                ## imm = 0x200000000
	movl	%r8d, %r10d
	andl	$-2, %r10d
	movl	$1, %r15d
	movabsq	$4294967296, %r11               ## imm = 0x100000000
	xorl	%r14d, %r14d
	jmp	LBB15_11
	.p2align	4, 0x90
LBB15_19:                               ##   in Loop: Header=BB15_11 Depth=1
	movslq	%ebx, %rdx
	movl	%esi, (%rax,%rdx,4)
	addq	$2, %r15
	addq	%r9, %r14
	addq	%r9, %r11
	addq	$-2, %r10
	je	LBB15_20
LBB15_11:                               ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB15_12 Depth 2
                                        ##     Child Loop BB15_16 Depth 2
	movl	(%rax,%r15,4), %esi
	movq	%r14, %rdi
	movq	%r15, %rbx
	.p2align	4, 0x90
LBB15_12:                               ##   Parent Loop BB15_11 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB15_15
## %bb.13:                              ##   in Loop: Header=BB15_12 Depth=2
	movl	%edx, (%rax,%rbx,4)
	leaq	-1(%rbx), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %rbx
	movq	%rdx, %rbx
	jg	LBB15_12
## %bb.14:                              ##   in Loop: Header=BB15_11 Depth=1
	xorl	%ebx, %ebx
LBB15_15:                               ##   in Loop: Header=BB15_11 Depth=1
	movslq	%ebx, %rdx
	movl	%esi, (%rax,%rdx,4)
	leaq	1(%r15), %rbx
	movl	4(%rax,%r15,4), %esi
	movq	%r11, %rdi
	.p2align	4, 0x90
LBB15_16:                               ##   Parent Loop BB15_11 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movq	%rdi, %rdx
	sarq	$30, %rdx
	movl	(%rax,%rdx), %edx
	cmpl	%esi, %edx
	jle	LBB15_19
## %bb.17:                              ##   in Loop: Header=BB15_16 Depth=2
	movl	%edx, (%rax,%rbx,4)
	leaq	-1(%rbx), %rdx
	addq	%rcx, %rdi
	cmpq	$1, %rbx
	movq	%rdx, %rbx
	jg	LBB15_16
## %bb.18:                              ##   in Loop: Header=BB15_11 Depth=1
	xorl	%ebx, %ebx
	jmp	LBB15_19
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_simd           ## -- Begin function partition_quick_simd
	.p2align	4, 0x90
_partition_quick_simd:                  ## @partition_quick_simd
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$104, %rsp
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
	movl	%esi, %ebx
	movq	%rdi, %r14
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB16_2
## %bb.1:
	leal	(%rdx,%rbx), %ecx
	movl	%ecx, %edi
	shrl	$31, %edi
	addl	%ecx, %edi
	sarl	%edi
	movslq	%ebx, %r8
	movl	(%r14,%r8,4), %r15d
	movslq	%edi, %r9
	movl	(%r14,%r9,4), %r10d
	movslq	%edx, %r11
	movl	(%r14,%r11,4), %esi
	cmpl	%r10d, %r15d
	movl	%r10d, %ecx
	cmovll	%r15d, %ecx
	movl	%r10d, %edi
	cmovgl	%r15d, %edi
	cmpl	%esi, %ecx
	cmovgel	%esi, %ecx
	cmpl	%esi, %edi
	cmovlel	%esi, %edi
	addl	%r15d, %r10d
	addl	%esi, %r10d
	subl	%ecx, %r10d
	subl	%edi, %r10d
	movl	%ecx, (%r14,%r8,4)
	movl	%r10d, (%r14,%r11,4)
	movl	%edi, (%r14,%r9,4)
	jmp	LBB16_3
LBB16_2:
	movslq	%edx, %rcx
	movl	(%r14,%rcx,4), %r10d
LBB16_3:
	leal	3(%rax), %ecx
	testl	%eax, %eax
	cmovnsl	%eax, %ecx
	andl	$-4, %ecx
	cmpl	%ebx, %ecx
	jle	LBB16_4
## %bb.13:
	movq	%rdx, -104(%rbp)                ## 8-byte Spill
	movl	%r10d, -44(%rbp)                ## 4-byte Spill
	vmovd	%r10d, %xmm0
	vpbroadcastd	%xmm0, %xmm0
	vmovdqa	%xmm0, -128(%rbp)               ## 16-byte Spill
	movslq	%ebx, %r12
	movl	%ecx, -48(%rbp)                 ## 4-byte Spill
	.p2align	4, 0x90
LBB16_14:                               ## =>This Inner Loop Header: Depth=1
	vmovdqa	-128(%rbp), %xmm0               ## 16-byte Reload
	vpcmpgtd	(%r14,%r12,4), %xmm0, %xmm0
	vpsrld	$31, %xmm0, %xmm1
	vmovdqa	%xmm1, -80(%rbp)                ## 16-byte Spill
	vmovdqa	%xmm1, -144(%rbp)
	vpslldq	$4, %xmm1, %xmm1                ## xmm1 = zero,zero,zero,zero,xmm1[0,1,2,3,4,5,6,7,8,9,10,11]
	vpsubd	%xmm0, %xmm1, %xmm0
	vpslldq	$8, %xmm0, %xmm1                ## xmm1 = zero,zero,zero,zero,zero,zero,zero,zero,xmm0[0,1,2,3,4,5,6,7]
	vpaddd	%xmm1, %xmm0, %xmm0
	vmovdqa	%xmm0, -96(%rbp)                ## 16-byte Spill
	leaq	L_.str(%rip), %rdi
	xorl	%eax, %eax
	callq	_printf
	vmovdqa	-80(%rbp), %xmm0                ## 16-byte Reload
	vmovd	%xmm0, %r13d
	leaq	L_.str.1(%rip), %r15
	movq	%r15, %rdi
	movl	%r13d, %esi
	xorl	%eax, %eax
	callq	_printf
	vmovaps	-80(%rbp), %xmm0                ## 16-byte Reload
	vextractps	$1, %xmm0, %esi
	movl	%esi, -52(%rbp)                 ## 4-byte Spill
	movq	%r15, %rdi
	xorl	%eax, %eax
	callq	_printf
	vmovaps	-80(%rbp), %xmm0                ## 16-byte Reload
	vextractps	$2, %xmm0, %esi
	movl	%esi, -56(%rbp)                 ## 4-byte Spill
	movq	%r15, %rdi
	xorl	%eax, %eax
	callq	_printf
	vmovaps	-80(%rbp), %xmm0                ## 16-byte Reload
	vextractps	$3, %xmm0, %esi
	movq	%r15, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	$10, %edi
	callq	_putchar
	leaq	L_.str.3(%rip), %rdi
	xorl	%eax, %eax
	callq	_printf
	vmovdqa	-96(%rbp), %xmm0                ## 16-byte Reload
	vmovd	%xmm0, %esi
	movq	%r15, %rdi
	xorl	%eax, %eax
	callq	_printf
	vmovaps	-96(%rbp), %xmm0                ## 16-byte Reload
	vextractps	$1, %xmm0, %esi
	movq	%r15, %rdi
	xorl	%eax, %eax
	callq	_printf
	vmovaps	-96(%rbp), %xmm0                ## 16-byte Reload
	vextractps	$2, %xmm0, %esi
	movq	%r15, %rdi
	xorl	%eax, %eax
	callq	_printf
	vmovdqa	-96(%rbp), %xmm0                ## 16-byte Reload
	vpextrd	$3, %xmm0, %esi
	movq	%r15, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	$10, %edi
	callq	_putchar
	movslq	%ebx, %rax
	movl	(%r14,%rax,4), %ecx
	movl	(%r14,%r12,4), %edx
	movl	%r13d, %esi
	xorl	$1, %esi
	movl	%edx, %edi
	imull	%esi, %edi
	imull	%ecx, %esi
	imull	%r13d, %ecx
	addl	%ecx, %edi
	imull	%r13d, %edx
	addl	%esi, %edx
	movl	%edx, (%r14,%rax,4)
	movl	%edi, (%r14,%r12,4)
	addl	%r13d, %eax
	cltq
	movl	(%r14,%rax,4), %ecx
	movl	4(%r14,%r12,4), %edx
	movl	-52(%rbp), %ebx                 ## 4-byte Reload
	movl	%ebx, %esi
	xorl	$1, %esi
	movl	%edx, %edi
	imull	%esi, %edi
	imull	%ecx, %esi
	imull	%ebx, %ecx
	addl	%ecx, %edi
	imull	%ebx, %edx
	addl	%esi, %edx
	movl	%edx, (%r14,%rax,4)
	movl	%edi, 4(%r14,%r12,4)
	addl	%ebx, %eax
	cltq
	movl	(%r14,%rax,4), %ecx
	movl	8(%r14,%r12,4), %edx
	movl	-56(%rbp), %ebx                 ## 4-byte Reload
	movl	%ebx, %esi
	xorl	$1, %esi
	movl	%edx, %edi
	imull	%esi, %edi
	imull	%ecx, %esi
	imull	%ebx, %ecx
	addl	%ecx, %edi
	imull	%ebx, %edx
	addl	%esi, %edx
	movl	%edx, (%r14,%rax,4)
	movl	%edi, 8(%r14,%r12,4)
	addl	%ebx, %eax
	movl	-132(%rbp), %ecx
	movslq	%eax, %rbx
	movl	(%r14,%rbx,4), %eax
	movl	12(%r14,%r12,4), %edx
	movl	$1, %esi
	subl	%ecx, %esi
	movl	%edx, %edi
	imull	%esi, %edi
	imull	%eax, %esi
	imull	%ecx, %eax
	addl	%eax, %edi
	imull	%ecx, %edx
	addl	%esi, %edx
	movl	%edx, (%r14,%rbx,4)
	movl	%edi, 12(%r14,%r12,4)
	addl	%ecx, %ebx
	movl	-48(%rbp), %ecx                 ## 4-byte Reload
	addq	$4, %r12
	cmpl	%ecx, %r12d
	jl	LBB16_14
## %bb.5:
	movl	-44(%rbp), %r10d                ## 4-byte Reload
	movq	-104(%rbp), %rdx                ## 8-byte Reload
	cmpl	%edx, %r12d
	jl	LBB16_9
LBB16_7:
	movslq	%edx, %r9
	jmp	LBB16_8
LBB16_4:
	movl	%ebx, %r12d
	cmpl	%edx, %r12d
	jge	LBB16_7
LBB16_9:
	movslq	%r12d, %rax
	movslq	%edx, %r9
	subl	%r12d, %edx
	movq	%rax, %rcx
	notq	%rcx
	testb	$1, %dl
	je	LBB16_11
## %bb.10:
	movl	(%r14,%rax,4), %edi
	xorl	%r8d, %r8d
	cmpl	%edi, %r10d
	setg	%r8b
	movslq	%ebx, %rbx
	movl	(%r14,%rbx,4), %edx
	movl	%edi, %esi
	cmovgl	%edx, %esi
	cmovgl	%edi, %edx
	movl	%edx, (%r14,%rbx,4)
	movl	%esi, (%r14,%rax,4)
	addl	%r8d, %ebx
	incq	%rax
LBB16_11:
	addq	%r9, %rcx
	je	LBB16_8
	.p2align	4, 0x90
LBB16_12:                               ## =>This Inner Loop Header: Depth=1
	movl	(%r14,%rax,4), %ecx
	xorl	%esi, %esi
	cmpl	%ecx, %r10d
	setg	%sil
	movslq	%ebx, %rdi
	movl	(%r14,%rdi,4), %ebx
	movl	%ecx, %edx
	cmovgl	%ebx, %edx
	cmovgl	%ecx, %ebx
	movl	%ebx, (%r14,%rdi,4)
	movl	%edx, (%r14,%rax,4)
	addl	%esi, %edi
	movl	4(%r14,%rax,4), %ecx
	xorl	%edx, %edx
	cmpl	%ecx, %r10d
	setg	%dl
	movslq	%edi, %rbx
	movl	(%r14,%rbx,4), %esi
	movl	%ecx, %edi
	cmovgl	%esi, %edi
	cmovgl	%ecx, %esi
	movl	%esi, (%r14,%rbx,4)
	movl	%edi, 4(%r14,%rax,4)
	addl	%edx, %ebx
	addq	$2, %rax
	cmpq	%rax, %r9
	jne	LBB16_12
LBB16_8:
	movslq	%ebx, %rax
	movl	(%r14,%rax,4), %ecx
	movl	(%r14,%r9,4), %edx
	movl	%edx, (%r14,%rax,4)
	movl	%ecx, (%r14,%r9,4)
                                        ## kill: def $eax killed $eax killed $rax
	addq	$104, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_simd                ## -- Begin function sort_quick_simd
	.p2align	4, 0x90
_sort_quick_simd:                       ## @sort_quick_simd
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	cmpl	%edx, %esi
	jge	LBB17_3
## %bb.1:
	movl	%edx, %r14d
	movl	%esi, %r12d
	movq	%rdi, %r15
	.p2align	4, 0x90
LBB17_2:                                ## =>This Inner Loop Header: Depth=1
	movq	%r15, %rdi
	movl	%r12d, %esi
	movl	%r14d, %edx
	callq	_partition_quick_simd
	movl	%eax, %ebx
	leal	-1(%rbx), %edx
	movq	%r15, %rdi
	movl	%r12d, %esi
	callq	_sort_quick_simd
	incl	%ebx
	movl	%ebx, %r12d
	cmpl	%r14d, %ebx
	jl	LBB17_2
LBB17_3:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_optimized_swap ## -- Begin function partition_quick_optimized_swap
	.p2align	4, 0x90
_partition_quick_optimized_swap:        ## @partition_quick_optimized_swap
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB18_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%rdi,%r8,4), %r9d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r15d
	movslq	%edx, %r11
	movl	(%rdi,%r11,4), %r14d
	cmpl	%r15d, %r9d
	movl	%r15d, %ebx
	cmovll	%r9d, %ebx
	movl	%r15d, %ecx
	cmovgl	%r9d, %ecx
	cmpl	%r14d, %ebx
	cmovgel	%r14d, %ebx
	cmpl	%r14d, %ecx
	cmovlel	%r14d, %ecx
	addl	%r9d, %r15d
	addl	%r14d, %r15d
	subl	%ebx, %r15d
	subl	%ecx, %r15d
	movl	%ebx, (%rdi,%r8,4)
	movl	%r15d, (%rdi,%r11,4)
	movl	%ecx, (%rdi,%r10,4)
	movl	%edx, %r9d
	subl	%esi, %r9d
	jg	LBB18_5
LBB18_4:
	movslq	%edx, %r14
	jmp	LBB18_10
LBB18_2:
	movslq	%edx, %rax
	movl	(%rdi,%rax,4), %r15d
	movl	%edx, %r9d
	subl	%esi, %r9d
	jle	LBB18_4
LBB18_5:
	movslq	%esi, %rcx
	movslq	%edx, %r14
	movq	%rcx, %r8
	notq	%r8
	testb	$1, %r9b
	jne	LBB18_7
## %bb.6:
                                        ## implicit-def: $r9d
	addq	%r14, %r8
	jne	LBB18_11
	jmp	LBB18_9
LBB18_7:
	movl	(%rdi,%rcx,4), %r10d
	xorl	%r9d, %r9d
	cmpl	%r10d, %r15d
	setg	%r9b
	movl	(%rdi,%rcx,4), %ebx
	movl	%r10d, %r11d
	cmovgl	%ebx, %r11d
	cmovgl	%r10d, %ebx
	movl	%r11d, (%rdi,%rcx,4)
	movl	%ebx, (%rdi,%rcx,4)
	addl	%esi, %r9d
	incq	%rcx
	movl	%r9d, %esi
	addq	%r14, %r8
	jne	LBB18_11
LBB18_9:
	movl	%r9d, %esi
	jmp	LBB18_10
	.p2align	4, 0x90
LBB18_11:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rcx,4), %edx
	xorl	%r8d, %r8d
	cmpl	%edx, %r15d
	setg	%r8b
	movslq	%esi, %rsi
	movl	(%rdi,%rsi,4), %eax
	movl	%edx, %ebx
	cmovgl	%eax, %ebx
	cmovgl	%edx, %eax
	movl	%ebx, (%rdi,%rcx,4)
	movl	%eax, (%rdi,%rsi,4)
	addl	%r8d, %esi
	movl	4(%rdi,%rcx,4), %edx
	xorl	%r8d, %r8d
	cmpl	%edx, %r15d
	setg	%r8b
	movslq	%esi, %rsi
	movl	(%rdi,%rsi,4), %ebx
	movl	%edx, %eax
	cmovgl	%ebx, %eax
	cmovgl	%edx, %ebx
	movl	%eax, 4(%rdi,%rcx,4)
	movl	%ebx, (%rdi,%rsi,4)
	addl	%r8d, %esi
	addq	$2, %rcx
	cmpq	%rcx, %r14
	jne	LBB18_11
LBB18_10:
	movslq	%esi, %rax
	movl	(%rdi,%rax,4), %ecx
	movl	(%rdi,%r14,4), %esi
	movl	%esi, (%rdi,%rax,4)
	movl	%ecx, (%rdi,%r14,4)
                                        ## kill: def $eax killed $eax killed $rax
	popq	%rbx
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_optimized_swap      ## -- Begin function sort_quick_optimized_swap
	.p2align	4, 0x90
_sort_quick_optimized_swap:             ## @sort_quick_optimized_swap
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB19_11
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %r12
	movslq	%edx, %r15
	movq	%r15, %rax
	negq	%rax
	movq	%rax, -48(%rbp)                 ## 8-byte Spill
	jmp	LBB19_2
	.p2align	4, 0x90
LBB19_10:                               ##   in Loop: Header=BB19_2 Depth=1
	movslq	%edi, %rbx
	movl	(%r12,%rbx,4), %eax
	movl	(%r12,%r15,4), %ecx
	movl	%ecx, (%r12,%rbx,4)
	movl	%eax, (%r12,%r15,4)
	leal	-1(%rbx), %edx
	movq	%r12, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	callq	_sort_quick_optimized_swap
	incl	%ebx
	movl	%ebx, %esi
	cmpl	%r14d, %ebx
	jge	LBB19_11
LBB19_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB19_9 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB19_11
## %bb.3:                               ##   in Loop: Header=BB19_2 Depth=1
	cmpl	$1, %eax
	jne	LBB19_4
## %bb.5:                               ##   in Loop: Header=BB19_2 Depth=1
	movl	(%r12,%r15,4), %r13d
	movslq	%esi, %r11
	jmp	LBB19_6
	.p2align	4, 0x90
LBB19_4:                                ##   in Loop: Header=BB19_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %edx
	shrl	$31, %edx
	addl	%eax, %edx
	sarl	%edx
	movslq	%esi, %r11
	movl	(%r12,%r11,4), %r9d
	movslq	%edx, %r8
	movl	(%r12,%r8,4), %r13d
	movl	(%r12,%r15,4), %r10d
	cmpl	%r13d, %r9d
	movl	%r13d, %edi
	cmovll	%r9d, %edi
	movl	%r13d, %edx
	cmovgl	%r9d, %edx
	cmpl	%r10d, %edi
	cmovgel	%r10d, %edi
	cmpl	%r10d, %edx
	cmovlel	%r10d, %edx
	addl	%r9d, %r13d
	addl	%r10d, %r13d
	subl	%edi, %r13d
	subl	%edx, %r13d
	movl	%edi, (%r12,%r11,4)
	movl	%r13d, (%r12,%r15,4)
	movl	%edx, (%r12,%r8,4)
LBB19_6:                                ##   in Loop: Header=BB19_2 Depth=1
	movl	%r14d, %ecx
	subl	%r11d, %ecx
	movq	%r11, %rdx
	movl	%esi, %edi
	testb	$1, %cl
	je	LBB19_8
## %bb.7:                               ##   in Loop: Header=BB19_2 Depth=1
	movl	(%r12,%r11,4), %r9d
	xorl	%edi, %edi
	cmpl	%r9d, %r13d
	setg	%dil
	movslq	%esi, %r8
	movl	(%r12,%r8,4), %edx
	movl	%r9d, %ecx
	cmovgl	%edx, %ecx
	cmovgl	%r9d, %edx
	movl	%ecx, (%r12,%r11,4)
	movl	%edx, (%r12,%r8,4)
	addl	%esi, %edi
	leaq	1(%r11), %rdx
LBB19_8:                                ##   in Loop: Header=BB19_2 Depth=1
	notq	%r11
	cmpq	-48(%rbp), %r11                 ## 8-byte Folded Reload
	je	LBB19_10
	.p2align	4, 0x90
LBB19_9:                                ##   Parent Loop BB19_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%r12,%rdx,4), %eax
	xorl	%r8d, %r8d
	cmpl	%eax, %r13d
	setg	%r8b
	movslq	%edi, %rdi
	movl	(%r12,%rdi,4), %ebx
	movl	%eax, %ecx
	cmovgl	%ebx, %ecx
	cmovgl	%eax, %ebx
	movl	%ecx, (%r12,%rdx,4)
	movl	%ebx, (%r12,%rdi,4)
	addl	%r8d, %edi
	movl	4(%r12,%rdx,4), %ecx
	xorl	%r8d, %r8d
	cmpl	%ecx, %r13d
	setg	%r8b
	movslq	%edi, %rdi
	movl	(%r12,%rdi,4), %ebx
	movl	%ecx, %eax
	cmovgl	%ebx, %eax
	cmovgl	%ecx, %ebx
	movl	%eax, 4(%r12,%rdx,4)
	movl	%ebx, (%r12,%rdi,4)
	addl	%r8d, %edi
	addq	$2, %rdx
	cmpq	%rdx, %r15
	jne	LBB19_9
	jmp	LBB19_10
LBB19_11:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_partition_quick_standard       ## -- Begin function partition_quick_standard
	.p2align	4, 0x90
_partition_quick_standard:              ## @partition_quick_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r14
	pushq	%rbx
	.cfi_offset %rbx, -32
	.cfi_offset %r14, -24
                                        ## kill: def $edx killed $edx def $rdx
                                        ## kill: def $esi killed $esi def $rsi
	movl	%edx, %eax
	subl	%esi, %eax
	cmpl	$2, %eax
	jl	LBB20_2
## %bb.1:
	leal	(%rdx,%rsi), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %r8
	movl	(%rdi,%r8,4), %r14d
	movslq	%ecx, %r10
	movl	(%rdi,%r10,4), %r9d
	movslq	%edx, %r11
	movl	(%rdi,%r11,4), %ecx
	cmpl	%r9d, %r14d
	movl	%r9d, %ebx
	cmovll	%r14d, %ebx
	movl	%r9d, %eax
	cmovgl	%r14d, %eax
	cmpl	%ecx, %ebx
	cmovgel	%ecx, %ebx
	cmpl	%ecx, %eax
	cmovlel	%ecx, %eax
	addl	%r14d, %r9d
	addl	%ecx, %r9d
	subl	%ebx, %r9d
	subl	%eax, %r9d
	movl	%ebx, (%rdi,%r8,4)
	movl	%r9d, (%rdi,%r11,4)
	movl	%eax, (%rdi,%r10,4)
	leal	-1(%rsi), %eax
	movl	%edx, %ecx
	subl	%esi, %ecx
	jg	LBB20_5
LBB20_4:
	movslq	%edx, %r10
	jmp	LBB20_19
LBB20_2:
	movslq	%edx, %rax
	movl	(%rdi,%rax,4), %r9d
	leal	-1(%rsi), %eax
	movl	%edx, %ecx
	subl	%esi, %ecx
	jle	LBB20_4
LBB20_5:
	movslq	%esi, %rsi
	movslq	%edx, %r10
	movq	%rsi, %r8
	notq	%r8
	addq	%r10, %r8
	andq	$3, %rcx
	jne	LBB20_6
LBB20_9:
	cmpq	$3, %r8
	jae	LBB20_10
LBB20_19:
	movslq	%eax, %rcx
	incl	%eax
	movl	4(%rdi,%rcx,4), %edx
	movl	(%rdi,%r10,4), %esi
	movl	%esi, 4(%rdi,%rcx,4)
	movl	%edx, (%rdi,%r10,4)
	popq	%rbx
	popq	%r14
	popq	%rbp
	retq
	.p2align	4, 0x90
LBB20_8:                                ##   in Loop: Header=BB20_6 Depth=1
	incq	%rsi
	decq	%rcx
	je	LBB20_9
LBB20_6:                                ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rsi,4), %edx
	cmpl	%r9d, %edx
	jg	LBB20_8
## %bb.7:                               ##   in Loop: Header=BB20_6 Depth=1
	movslq	%eax, %rbx
	incl	%eax
	movl	4(%rdi,%rbx,4), %r11d
	movl	%edx, 4(%rdi,%rbx,4)
	movl	%r11d, (%rdi,%rsi,4)
	jmp	LBB20_8
	.p2align	4, 0x90
LBB20_18:                               ##   in Loop: Header=BB20_10 Depth=1
	addq	$4, %rsi
	cmpq	%rsi, %r10
	je	LBB20_19
LBB20_10:                               ## =>This Inner Loop Header: Depth=1
	movl	(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB20_11
## %bb.12:                              ##   in Loop: Header=BB20_10 Depth=1
	movl	4(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB20_13
LBB20_14:                               ##   in Loop: Header=BB20_10 Depth=1
	movl	8(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB20_15
LBB20_16:                               ##   in Loop: Header=BB20_10 Depth=1
	movl	12(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB20_18
	jmp	LBB20_17
	.p2align	4, 0x90
LBB20_11:                               ##   in Loop: Header=BB20_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, (%rdi,%rsi,4)
	movl	4(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB20_14
LBB20_13:                               ##   in Loop: Header=BB20_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, 4(%rdi,%rsi,4)
	movl	8(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB20_16
LBB20_15:                               ##   in Loop: Header=BB20_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, 8(%rdi,%rsi,4)
	movl	12(%rdi,%rsi,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB20_18
LBB20_17:                               ##   in Loop: Header=BB20_10 Depth=1
	movslq	%eax, %rdx
	incl	%eax
	movl	4(%rdi,%rdx,4), %ebx
	movl	%ecx, 4(%rdi,%rdx,4)
	movl	%ebx, 12(%rdi,%rsi,4)
	jmp	LBB20_18
	.cfi_endproc
                                        ## -- End function
	.globl	_sort_quick_standard            ## -- Begin function sort_quick_standard
	.p2align	4, 0x90
_sort_quick_standard:                   ## @sort_quick_standard
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r12
	pushq	%rbx
	.cfi_offset %rbx, -48
	.cfi_offset %r12, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
                                        ## kill: def $esi killed $esi def $rsi
	cmpl	%esi, %edx
	jle	LBB21_21
## %bb.1:
	movl	%edx, %r14d
	movq	%rdi, %rbx
	movslq	%edx, %r12
	jmp	LBB21_2
	.p2align	4, 0x90
LBB21_20:                               ##   in Loop: Header=BB21_2 Depth=1
	movslq	%r10d, %r15
	movl	4(%rbx,%r15,4), %eax
	movl	(%rbx,%r12,4), %ecx
	movl	%ecx, 4(%rbx,%r15,4)
	movl	%eax, (%rbx,%r12,4)
	movq	%rbx, %rdi
                                        ## kill: def $esi killed $esi killed $rsi
	movl	%r15d, %edx
	callq	_sort_quick_standard
	addl	$2, %r15d
	movl	%r15d, %esi
	cmpl	%r14d, %r15d
	jge	LBB21_21
LBB21_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB21_7 Depth 2
                                        ##     Child Loop BB21_11 Depth 2
	movl	%r14d, %eax
	subl	%esi, %eax
	jle	LBB21_21
## %bb.3:                               ##   in Loop: Header=BB21_2 Depth=1
	cmpl	$1, %eax
	jne	LBB21_4
## %bb.5:                               ##   in Loop: Header=BB21_2 Depth=1
	movl	(%rbx,%r12,4), %r9d
	movslq	%esi, %rax
	jmp	LBB21_6
	.p2align	4, 0x90
LBB21_4:                                ##   in Loop: Header=BB21_2 Depth=1
	leal	(%rsi,%r14), %eax
	movl	%eax, %ecx
	shrl	$31, %ecx
	addl	%eax, %ecx
	sarl	%ecx
	movslq	%esi, %rax
	movl	(%rbx,%rax,4), %r10d
	movslq	%ecx, %r8
	movl	(%rbx,%r8,4), %r9d
	movl	(%rbx,%r12,4), %edi
	cmpl	%r9d, %r10d
	movl	%r9d, %ecx
	cmovll	%r10d, %ecx
	movl	%r9d, %edx
	cmovgl	%r10d, %edx
	cmpl	%edi, %ecx
	cmovgel	%edi, %ecx
	cmpl	%edi, %edx
	cmovlel	%edi, %edx
	addl	%r10d, %r9d
	addl	%edi, %r9d
	subl	%ecx, %r9d
	subl	%edx, %r9d
	movl	%ecx, (%rbx,%rax,4)
	movl	%r9d, (%rbx,%r12,4)
	movl	%edx, (%rbx,%r8,4)
LBB21_6:                                ##   in Loop: Header=BB21_2 Depth=1
	leal	-1(%rsi), %r10d
	movl	%r14d, %edi
	subl	%eax, %edi
	movq	%rax, %r8
	notq	%r8
	addq	%r12, %r8
	andq	$3, %rdi
	jne	LBB21_7
LBB21_10:                               ##   in Loop: Header=BB21_2 Depth=1
	cmpq	$3, %r8
	jae	LBB21_11
	jmp	LBB21_20
	.p2align	4, 0x90
LBB21_9:                                ##   in Loop: Header=BB21_7 Depth=2
	incq	%rax
	decq	%rdi
	je	LBB21_10
LBB21_7:                                ##   Parent Loop BB21_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB21_9
## %bb.8:                               ##   in Loop: Header=BB21_7 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %r11d
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%r11d, (%rbx,%rax,4)
	jmp	LBB21_9
	.p2align	4, 0x90
LBB21_19:                               ##   in Loop: Header=BB21_11 Depth=2
	addq	$4, %rax
	cmpq	%rax, %r12
	je	LBB21_20
LBB21_11:                               ##   Parent Loop BB21_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	movl	(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB21_12
## %bb.13:                              ##   in Loop: Header=BB21_11 Depth=2
	movl	4(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB21_14
LBB21_15:                               ##   in Loop: Header=BB21_11 Depth=2
	movl	8(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jle	LBB21_16
LBB21_17:                               ##   in Loop: Header=BB21_11 Depth=2
	movl	12(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB21_19
	jmp	LBB21_18
	.p2align	4, 0x90
LBB21_12:                               ##   in Loop: Header=BB21_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, (%rbx,%rax,4)
	movl	4(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB21_15
LBB21_14:                               ##   in Loop: Header=BB21_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, 4(%rbx,%rax,4)
	movl	8(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB21_17
LBB21_16:                               ##   in Loop: Header=BB21_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, 8(%rbx,%rax,4)
	movl	12(%rbx,%rax,4), %ecx
	cmpl	%r9d, %ecx
	jg	LBB21_19
LBB21_18:                               ##   in Loop: Header=BB21_11 Depth=2
	movslq	%r10d, %rdx
	incl	%r10d
	movl	4(%rbx,%rdx,4), %edi
	movl	%ecx, 4(%rbx,%rdx,4)
	movl	%edi, 12(%rbx,%rax,4)
	jmp	LBB21_19
LBB21_21:
	popq	%rbx
	popq	%r12
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_shuffle_data                   ## -- Begin function shuffle_data
	.p2align	4, 0x90
_shuffle_data:                          ## @shuffle_data
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movl	%esi, %eax
	decl	%eax
	je	LBB22_6
## %bb.1:
	movl	%esi, %r14d
	movq	%rdi, %r13
	movslq	%eax, %r15
	movslq	%esi, %r12
	xorl	%ebx, %ebx
	jmp	LBB22_2
	.p2align	4, 0x90
LBB22_4:                                ##   in Loop: Header=BB22_2 Depth=1
	xorl	%edx, %edx
	divq	%r12
LBB22_5:                                ##   in Loop: Header=BB22_2 Depth=1
	movl	(%r13,%rdx,4), %eax
	movl	(%r13,%rbx,4), %ecx
	movl	%ecx, (%r13,%rdx,4)
	movl	%eax, (%r13,%rbx,4)
	incq	%rbx
	cmpq	%r15, %rbx
	jae	LBB22_6
LBB22_2:                                ## =>This Inner Loop Header: Depth=1
	callq	_rand
	cltq
	addq	%rbx, %rax
	movq	%rax, %rcx
	orq	%r12, %rcx
	shrq	$32, %rcx
	jne	LBB22_4
## %bb.3:                               ##   in Loop: Header=BB22_2 Depth=1
                                        ## kill: def $eax killed $eax killed $rax
	xorl	%edx, %edx
	divl	%r14d
                                        ## kill: def $edx killed $edx def $rdx
	jmp	LBB22_5
LBB22_6:
	addq	$8, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
	.section	__TEXT,__literal4,4byte_literals
	.p2align	2                               ## -- Begin function bench
LCPI23_0:
	.long	0x49742400                      ## float 1.0E+6
	.section	__TEXT,__text,regular,pure_instructions
	.globl	_bench
	.p2align	4, 0x90
_bench:                                 ## @bench
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	subq	$40, %rsp
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movq	%rcx, %r14
	movl	%edx, %r12d
	movq	%rsi, -72(%rbp)                 ## 8-byte Spill
	movl	%edx, %eax
	decl	%eax
	movl	%edx, -44(%rbp)                 ## 4-byte Spill
	je	LBB23_5
## %bb.1:
	movl	%eax, -60(%rbp)                 ## 4-byte Spill
	movslq	%eax, %r13
	movslq	%r12d, %r15
	xorl	%ebx, %ebx
	xorl	%edx, %edx
	.p2align	4, 0x90
LBB23_2:                                ## =>This Loop Header: Depth=1
                                        ##     Child Loop BB23_3 Depth 2
	movq	%rbx, -56(%rbp)                 ## 8-byte Spill
	movl	%edx, %eax
	movq	%rax, -80(%rbp)                 ## 8-byte Spill
	xorl	%ebx, %ebx
	jmp	LBB23_3
	.p2align	4, 0x90
LBB23_4:                                ##   in Loop: Header=BB23_3 Depth=2
                                        ## kill: def $eax killed $eax killed $rax
	xorl	%edx, %edx
	divl	%r12d
                                        ## kill: def $edx killed $edx def $rdx
LBB23_12:                               ##   in Loop: Header=BB23_3 Depth=2
	movl	(%r14,%rdx,4), %eax
	movl	(%r14,%rbx,4), %ecx
	movl	%ecx, (%r14,%rdx,4)
	movl	%eax, (%r14,%rbx,4)
	incq	%rbx
	cmpq	%r13, %rbx
	jae	LBB23_13
LBB23_3:                                ##   Parent Loop BB23_2 Depth=1
                                        ## =>  This Inner Loop Header: Depth=2
	callq	_rand
	cltq
	addq	%rbx, %rax
	movq	%rax, %rcx
	orq	%r15, %rcx
	shrq	$32, %rcx
	je	LBB23_4
## %bb.11:                              ##   in Loop: Header=BB23_3 Depth=2
	xorl	%edx, %edx
	divq	%r15
	jmp	LBB23_12
	.p2align	4, 0x90
LBB23_13:                               ##   in Loop: Header=BB23_2 Depth=1
	callq	_clock
	movq	%rax, %r12
	movq	%r14, %rdi
	xorl	%esi, %esi
	movl	-60(%rbp), %edx                 ## 4-byte Reload
	callq	*-72(%rbp)                      ## 8-byte Folded Reload
	callq	_clock
	movq	-56(%rbp), %rbx                 ## 8-byte Reload
	subq	%r12, %rbx
	movl	-44(%rbp), %r12d                ## 4-byte Reload
	cmpl	$10, %r12d
	jne	LBB23_16
## %bb.14:                              ##   in Loop: Header=BB23_2 Depth=1
	cmpl	$0, -80(%rbp)                   ## 4-byte Folded Reload
	jne	LBB23_16
## %bb.15:                              ##   in Loop: Header=BB23_2 Depth=1
	movl	$10, %edi
	movq	%rax, -56(%rbp)                 ## 8-byte Spill
	callq	_putchar
	movl	(%r14), %esi
	leaq	L_.str.1(%rip), %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	4(%r14), %esi
	leaq	L_.str.1(%rip), %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	8(%r14), %esi
	leaq	L_.str.1(%rip), %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	12(%r14), %esi
	leaq	L_.str.1(%rip), %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	16(%r14), %esi
	leaq	L_.str.1(%rip), %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	20(%r14), %esi
	leaq	L_.str.1(%rip), %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	24(%r14), %esi
	leaq	L_.str.1(%rip), %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	28(%r14), %esi
	leaq	L_.str.1(%rip), %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	32(%r14), %esi
	leaq	L_.str.1(%rip), %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	36(%r14), %esi
	leaq	L_.str.1(%rip), %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	$10, %edi
	callq	_putchar
	movq	-56(%rbp), %rax                 ## 8-byte Reload
LBB23_16:                               ##   in Loop: Header=BB23_2 Depth=1
	movq	-80(%rbp), %rcx                 ## 8-byte Reload
	leal	1(%rcx), %edx
	addq	%rax, %rbx
	cmpl	$9, %ecx
	jb	LBB23_2
## %bb.17:                              ##   in Loop: Header=BB23_2 Depth=1
	cmpq	$10000, %rbx                    ## imm = 0x2710
	jb	LBB23_2
	jmp	LBB23_18
LBB23_5:
	xorl	%ebx, %ebx
	xorl	%r15d, %r15d
	.p2align	4, 0x90
LBB23_6:                                ## =>This Inner Loop Header: Depth=1
	callq	_clock
	movq	%rax, %r13
	movq	%r14, %rdi
	xorl	%esi, %esi
	xorl	%edx, %edx
	callq	*-72(%rbp)                      ## 8-byte Folded Reload
	callq	_clock
	movl	%r12d, %ecx
	movq	%rax, %r12
	subq	%r13, %rbx
	cmpl	$10, %ecx
	jne	LBB23_9
## %bb.7:                               ##   in Loop: Header=BB23_6 Depth=1
	testl	%r15d, %r15d
	jne	LBB23_9
## %bb.8:                               ##   in Loop: Header=BB23_6 Depth=1
	movl	$10, %edi
	callq	_putchar
	movl	(%r14), %esi
	leaq	L_.str.1(%rip), %r13
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	4(%r14), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	8(%r14), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	12(%r14), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	16(%r14), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	20(%r14), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	24(%r14), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	28(%r14), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	32(%r14), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	36(%r14), %esi
	movq	%r13, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	$10, %edi
	callq	_putchar
LBB23_9:                                ##   in Loop: Header=BB23_6 Depth=1
	leal	1(%r15), %edx
	addq	%r12, %rbx
	cmpl	$9, %r15d
	movl	%edx, %r15d
	movl	-44(%rbp), %r12d                ## 4-byte Reload
	jb	LBB23_6
## %bb.10:                              ##   in Loop: Header=BB23_6 Depth=1
	movl	%edx, %r15d
	cmpq	$10000, %rbx                    ## imm = 0x2710
	jb	LBB23_6
LBB23_18:
	testq	%rbx, %rbx
	js	LBB23_19
## %bb.20:
	vcvtsi2ss	%rbx, %xmm0, %xmm0
	jmp	LBB23_21
LBB23_19:
	movq	%rbx, %rcx
	shrq	%rcx
	andl	$1, %ebx
	orq	%rcx, %rbx
	vcvtsi2ss	%rbx, %xmm0, %xmm0
	vaddss	%xmm0, %xmm0, %xmm0
LBB23_21:
	vmovss	LCPI23_0(%rip), %xmm1           ## xmm1 = mem[0],zero,zero,zero
	vmulss	%xmm1, %xmm0, %xmm0
	vcvtsi2ss	%edx, %xmm2, %xmm2
	vdivss	%xmm1, %xmm0, %xmm0
	vdivss	%xmm2, %xmm0, %xmm0
	vcvtss2sd	%xmm0, %xmm0, %xmm0
	leaq	L_.str.4(%rip), %rdi
	movb	$1, %al
	addq	$40, %rsp
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	jmp	_printf                         ## TAILCALL
	.cfi_endproc
                                        ## -- End function
	.globl	_main                           ## -- Begin function main
	.p2align	4, 0x90
_main:                                  ## @main
	.cfi_startproc
## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	pushq	%r15
	pushq	%r14
	pushq	%r13
	pushq	%r12
	pushq	%rbx
	pushq	%rax
	movl	$8000008, %eax                  ## imm = 0x7A1208
	callq	____chkstk_darwin
	subq	%rax, %rsp
	popq	%rax
	.cfi_offset %rbx, -56
	.cfi_offset %r12, -48
	.cfi_offset %r13, -40
	.cfi_offset %r14, -32
	.cfi_offset %r15, -24
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	movq	%rax, -48(%rbp)
	leaq	L_str(%rip), %rdi
	callq	_puts
	leaq	L_str.13(%rip), %rdi
	callq	_puts
	callq	_clock
	movl	%eax, %edi
	callq	_srand
	xorl	%ebx, %ebx
	.p2align	4, 0x90
LBB24_1:                                ## =>This Inner Loop Header: Depth=1
	callq	_rand
	movl	%eax, -8000048(%rbp,%rbx,4)
	incq	%rbx
	cmpq	$2000000, %rbx                  ## imm = 0x1E8480
	jne	LBB24_1
## %bb.2:
	leaq	_sort_quick_standard(%rip), %r13
	leaq	-8000048(%rbp), %rbx
	movq	%r13, %rsi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_quick_optimized(%rip), %r14
	movq	%r14, %rsi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_quick_optimized_swap(%rip), %rsi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_quick_block(%rip), %rsi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_merge_standard(%rip), %rsi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_merge_optimized(%rip), %r12
	movq	%r12, %rsi
	movl	$10, %edx
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	movq	%r13, %rsi
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	movq	%r14, %rsi
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_quick_optimized_swap(%rip), %rsi
	movq	%rsi, %r15
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_quick_block(%rip), %rsi
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_merge_standard(%rip), %rsi
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	movq	%r12, %rsi
	movl	$100, %edx
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	movq	%r13, %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	movq	%r14, %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	movq	%r15, %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_quick_block(%rip), %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_merge_standard(%rip), %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	movq	%r12, %rsi
	movl	$1000, %edx                     ## imm = 0x3E8
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	movq	%r13, %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	movq	%r14, %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	movq	%r15, %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_quick_block(%rip), %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_merge_standard(%rip), %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	movq	%r12, %rsi
	movl	$10000, %edx                    ## imm = 0x2710
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	movq	%r13, %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	movq	%r14, %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	movq	%r15, %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_quick_block(%rip), %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_merge_standard(%rip), %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	movq	%r12, %rsi
	movl	$100000, %edx                   ## imm = 0x186A0
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	movq	%r13, %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	movq	%r14, %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	movq	%r15, %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_quick_block(%rip), %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_merge_standard(%rip), %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	movq	%r12, %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	movq	%r13, %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	movq	%r14, %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	movq	%r15, %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_quick_block(%rip), %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	leaq	_sort_merge_standard(%rip), %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	movq	%r12, %rsi
	movl	$1000000, %edx                  ## imm = 0xF4240
	movq	%rbx, %rcx
	callq	_bench
	movl	$10, %edi
	callq	_putchar
	movq	___stack_chk_guard@GOTPCREL(%rip), %rax
	movq	(%rax), %rax
	cmpq	-48(%rbp), %rax
	jne	LBB24_4
## %bb.3:
	xorl	%eax, %eax
	addq	$8000008, %rsp                  ## imm = 0x7A1208
	popq	%rbx
	popq	%r12
	popq	%r13
	popq	%r14
	popq	%r15
	popq	%rbp
	retq
LBB24_4:
	callq	___stack_chk_fail
	.cfi_endproc
                                        ## -- End function
	.section	__TEXT,__const
	.globl	_INSERTION_SORT_THRESH_BLOCK    ## @INSERTION_SORT_THRESH_BLOCK
	.p2align	2
_INSERTION_SORT_THRESH_BLOCK:
	.long	20                              ## 0x14

	.globl	_blocksize                      ## @blocksize
	.p2align	2
_blocksize:
	.long	128                             ## 0x80

	.comm	_b,4000000,4                    ## @b
	.globl	_INSERTION_SORT_THRESH_O        ## @INSERTION_SORT_THRESH_O
	.p2align	2
_INSERTION_SORT_THRESH_O:
	.long	5                               ## 0x5

	.section	__TEXT,__cstring,cstring_literals
L_.str:                                 ## @.str
	.asciz	"Cs:      "

L_.str.1:                               ## @.str.1
	.asciz	"%d "

L_.str.3:                               ## @.str.3
	.asciz	"Offsets: "

	.section	__TEXT,__const
	.globl	_INSERTION_SORT_THRESH_SWAP     ## @INSERTION_SORT_THRESH_SWAP
	.p2align	2
_INSERTION_SORT_THRESH_SWAP:
	.long	0                               ## 0x0

	.globl	_INSERTION_SORT_THRESH_U        ## @INSERTION_SORT_THRESH_U
	.p2align	2
_INSERTION_SORT_THRESH_U:
	.long	0                               ## 0x0

	.globl	_DATA_AMOUNT                    ## @DATA_AMOUNT
	.p2align	2
_DATA_AMOUNT:
	.long	2000000                         ## 0x1e8480

	.globl	_RUNS_PER_BENCH                 ## @RUNS_PER_BENCH
	.p2align	2
_RUNS_PER_BENCH:
	.long	1                               ## 0x1

	.section	__TEXT,__cstring,cstring_literals
L_.str.4:                               ## @.str.4
	.asciz	"%f\t"

	.comm	_x,8,2                          ## @x
L_str:                                  ## @str
	.asciz	"Starting"

L_str.13:                               ## @str.13
	.asciz	"Generating random data"

.subsections_via_symbols
